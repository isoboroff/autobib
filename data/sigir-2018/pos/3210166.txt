Demonstration Papers I

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

A2A: Benchmark Your Clinical Decision Support Search
Sarvnaz Karimi

Vincent Nguyen

Falk Scholer

CSIRO Data61
Marsfield, NSW, Australia
sarvnaz.karimi@csiro.au

CSIRO Data61
Marsfield, NSW, Australia
vngu4919@uni.sydney.edu.au

RMIT University
Melbourne, VIC, Australia
falk.scholer@rmit.edu.au

Brian Jin

Sara Falamaki

CSIRO Data61
Marsfield, NSW, Australia
brian.jin@csiro.au

CSIRO Data61
Marsfield, NSW, Australia
sara.falamaki@csiro.au

ABSTRACT

in a clinical setting is much less advanced [10]. Specific to the clinical setting is the need for finding evidence that answers questions
on testing, diagnosis, and treatment given a patient’s conditions.
For three years, from 2014 to 2016, TREC challenged the Information Retrieval (IR) community with the Clinical Decision Support
(CDS) track [9, 11, 13]. Similar to many other tasks, the experimental setup included indexing a large set of documents, in this
case PubMed Central (PMC) articles; processing the topics to create queries that potentially retrieve relevant articles; running the
search; and evaluating the results when relevance judgements were
released. Teams often start with typical query and document processing techniques from within the biomedical search community,
including concept extraction using Metamap, negation detection
and removal, or query expansion using in-domain and generic resources such as Wikipedia. All the setup could easily take weeks,
before even a simple experiment can be executed. Our system,
Apples to Apples (A2A), provides a user-friendly platform for IR
researchers to run many of the most common experiments in a
very short amount of time, with flexibility to alter different search
parameters. This in turn will translate to (1) reduce the need to
re-implement the most common query and document processing
methods; and (2) allow fair comparison of these methods on a unified platform. These hopefully lead to advances in the field of search
for clinical decision support and ultimately evidence-based medicine, by reducing the need for every researcher to set up similar
experiments in their own lab.

Clinical Decision Support (CDS) systems aim to assist clinicians in
their daily decision-making related to diagnosis, tests, and treatments of patients by providing relevant evidence from the scientific
literature. This promise however is yet to be fulfilled, with search
for relevant literature for a given patient condition still being an
active research topic. The TREC CDS track was designed to address
this research gap. We developed a platform to facilitate experimentation and hypothesis testing for information retrieval researchers
working on this topic. It provides a large range of query and document processing techniques that are explored in the biomedical
search domain.

CCS CONCEPTS
• Information systems → Computing platforms; Decision support systems; Evaluation of retrieval results; • Applied computing
→ Health informatics;

KEYWORDS
Clinical Decision Support; Experimentation; Search; Reproducibility
ACM Reference Format:
Sarvnaz Karimi, Vincent Nguyen, Falk Scholer, Brian Jin, and Sara Falamaki.
2018. A2A: Benchmark Your Clinical Decision Support Search. In SIGIR ’18:
The 41st International ACM SIGIR Conference on Research and Development
in Information Retrieval, July 8–12, 2018, Ann Arbor, MI, USA. ACM, New
York, NY, USA, 4 pages. https://doi.org/10.1145/3209978.3210166

1

2

INTRODUCTION

While there are a number of search engines for biomedical literature—
such as PubMed, askMEDLINE, PICO1 [12], or OVID2 —such search
1 https://pubmedhh.nlm.nih.gov/nlmd/pico/piconew.php
2 http://www.ovid.com

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGIR ’18, July 8–12, 2018, Ann Arbor, MI, USA
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5657-2/18/07.
https://doi.org/10.1145/3209978.3210166

DEMONSTRATION SYSTEM

Our platform enables researchers to perform experiments within
the TREC CDS framework, providing an index of PubMed Central
(PMC) full-text articles. It allows experiments that include one or
more of following methods or parameters to be defined (Figure 2):
Topics: Users may choose to use the TREC Clinical Decision
Support topics from 2014-16 (already in the system), or upload their own topics in the format of the TREC Clinical
Decision Support topics. Similar to the TREC CDS settings,
they can construct queries using the description, summary
or note3 section of each topic. A sample topic from 2016 is
shown in Figure 1.
Query Expansion: Users can expand the queries using (1)
UMLS concepts; (2) word embeddings created using MEDLINE, Wikipedia or PMC; and (3) Pseudo Relevance Feedback
3 Notes

1277

were only introduced in 2016.

Demonstration Papers I

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

<topic number="27" type="treatment">
<note>
96F found unresponsive on ground at nursing home. Pt was in dining room and found
by staff. Unresponsive for 1 min after found. Pt cannot recollect events preceding fall
but with some c/o HA and some neck/shoulder discomfort. Taken to [**Hospital1 1218**]
where NCHCT preformed at 18:32 showed 9mm L parietal SDH. C-spine negative. Family / Social history: dementia, HTN, afib, CAD SURGICAL Hx: unknown. SOCIAL Hx:
Daughter serves as HCP; Pt currently DNR/DNI except for elective procedure (****SEE
CLARIFICATIOIN BELOW****).. ALLERGIES: NKDA Physical Examination General Appearance: No acute distress, Thin Eyes / Conjunctiva: PERRL, Conjunctiva pale Head, Ears,
Nose, Throat: Normocephalic, Poor dentition Lymphatic: Cervical WNL, Supraclavicular
WNL Cardiovascular: (S1: Normal), (S2: Normal) Peripheral Vascular: (Right radial pulse:
Present), (Left radial pulse: Present), (Right DP pulse: Diminished), (Left DP pulse: Diminished) Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: Clear : bialterally)
Abdominal: Soft, Non-tender, Bowel sounds present
Extremities: Right: Absent, Left: Absent
Skin: Warm
Neurologic: Attentive, Follows simple commands, Responds to: Verbal stimuli, Oriented
(to): A+O x 2, Movement: Not assessed, Tone: Not assessed Imaging: CT head w/o contrast Acute left subdural hematoma measuring 1.5 cm maximal dimensions with leftward
subfalcine herniation of 8 mm, downward transtentorial herniation with obliteration of
the left suprasellar cistern, and uncal herniation. No fx, destructive infiltrative lesion involving the skull base
</note>
<description>
A 96 y/o female found unresponsive on ground at nursing home. Pt was in dining room
and found by staff. Unresponsive for 1 min after found. Pt cannot recollect events preceding fall but with some c/o HA and some neck/shoulder discomfort. NCHCT showed
9mm L parietal SDH. C-spine negative. Imaging: CT head w/o contrast Acute left subdural
hematoma measuring 1.5 cm maximal dimensions with leftward subfalcine herniation of
8 mm, downward transtentorial herniation with obliteration of the left suprasellar cistern,
and uncal herniation. No fx, destructive infiltrative lesion involving the skull base.
</description>
<summary>
A 96 y/o female found unresponsive on ground at nursing home pressents with headache,
herniation, and some neck/shoulder discomfort. CT head shows acute left subdural hematoma.
</summary>
</topic>

Figure 2: Register a search request page.

Figure 1: A sample topic (clinical note, description, and summary) from TREC CDS 2016. Clinical note is long and it contains abbreviations and incomplete sentences.

(PRF). They can decide on the weight of the expanded terms
(default is 1.0). For PRF, the number of documents to be considered for expansion, and number of top terms to be added,
can be specified.
Negation Detection in Topics: We provide two negation handling options: (1) removal of negated words from topics only,
and (2) hyphenating negations through the Solr hyphenation filter. Hyphenation ensures that documents that contain
the negated terms are completely irrelevant and cannot be
in the final retrieved list. There are two approaches implemented for negation detection: NegEx [2] or CLPsych [3].
NegEx is the most popular negation detection method and is
integrated with Metamap. Originally, it was proposed to detect negated findings or diseases mentioned within narrative
medical reports. More recently, CLPsych was introduced for
identifying mentions of suicidality in mental health records
and it was shown to perform more effectively than NegEx.
Demographic Normalisation in Topics: Using some heuristics, the system can normalise the mentions of demographic
attributes of patients. For example, 86 y/o m is replaced with
elderly male (similar to Karimi et al. [5, 6]). This aims to increase the chances of matching queries with what is typically
written in scientific articles.

1278

Ranking Methods: The system uses the Okapi BM25 ranking
function as provided by Solr 6.6.0. Users can adjust the parameters of the BM25 ranking function. The default values are
set to b = 0.75 and k1 = 1.2.
Facet Search: Users can run queries on particular facets of
the scientific articles (title, abstract, their UMLS concepts,
MeSH headings or body). This option allows filtering facets
in the index. Users can also set a weight for these facets in
the positive decimal range (minimum of zero). The default
weight on all facets is 1.0.
UMLS concepts of topics or document titles and abstracts extracted using Metamap4 can also be optionally included. We set
Metamap to extract concepts with the following semantic types:
Disease or Syndrome, Sign or Symptom, Pathologic Function, Diagnostic Procedure, Anatomical Abnormality, Laboratory Procedure,
Pharmacologic Substance, Neoplastic Process, and Therapeutic or
Preventive Procedure. These are chosen to match the query types
(diagnosis, treatment, or test).
Once users choose their experimental setting, they can submit
the job. These jobs will be assigned a job identifier, queued in the
system, and executed in turn. Since some of the settings such as
running negation detection could take time, the system is equipped
with email notification (Figure 4). Upon completion of an experiment, the user is notified. For each experiment, the results package
includes the following files: (1) queries as submitted to the search
engine (one could potentially modify these queries as needed and resubmit to the system for further investigation); (2) search results in
4 MetaMapLite

3.6, https://metamap.nlm.nih.gov/MetaMapLite.shtml

Demonstration Papers I

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

3

COMPARISON AND EVALUATION

Solr format; (3) search results in TREC format (only includes document ids); (4) TREC evaluation results of trec_eval5 (includes R-Prec,
B-Pref, and P@10); and (5) TREC evaluation results of sample-eval
(includes infNDCG and infAP). If users choose to use their own topics, they have the option to pick which year’s relevance judgements
(qrels) they would like their job to be evaluated on.
Figure 5 shows the A2A system in its software architecture level.
It consists of a user interface module, job controller on SpringMVC,
restful API on Python Tornado, and a search and evaluation core.
An embedded SQLite is used for a job repository, and the user
interfaces are on Bootstrap V4 and jQuery. In the search and evaluation core, Metamap is used to extract UMLS concepts from queries
(base query plus expanded query terms (for example Wikipedia
word embeddings). EdisMax Parser is an Extended Dismax Parser
from Solr which handles boosting factors as weights. We used the
tokeniser and porter stemmer from NLTK.6 The output from the
Solr search engine is then evaluated by trec_eval and sample-eval.
Since the order of execution for these modules is decided by what
options are chosen by the users, we do not show any arrows inside
the search and evaluation module. A rough process is that a raw
topic is passed to Metamap, NLTK, and query expansion (PRF and
Word embeddings) modules; then back to NLTK and Metamap; and
finally to EdisMax Parser. The resulting topic is queried over the
index using the Solr search engine and then retrieved results are
evaluated.

There exist a number of public search engines, such as PubMed,
JournalWatch, ClinicalTrials.gov and eMedicine, that facilitate search
over biomedical literature, clinical trials, or clinical articles. They often allow for different types of queries, from simple keyword search
to advanced search which is mostly Boolean. These search engines
however are for public use and do not allow alterations to the search
settings for IR research. That is, they control how user queries are
reformulated (or not) and how the index is searched. Our system
however, is designed for researchers, providing a number of options
for query reformulations and filtering for its users. In particular, we
were interested in re-implementing most popular methods utilised
by the TREC CDS participants as stated in their reports, especially
for higher scoring systems such as MerckKGaA [4].
There are also some research-oriented prototypes that are proposed in academic papers, however sometimes they are not made
available to the community. The most relevant system proposed
recently is by Koopman et al. [7] where a task-based search engine
is proposed to assist in clinical search. It indexes the documents
together with their UMLS concepts extracted using Metamap, with
their mapping then being related to one of the three types of tasks:
diagnosis, treatment or test. Their search results were tailored to
these three types of tasks as well allowing their users to explore
the retrieved documents based on their potential need. Our system
however does not focus on search result representation at this stage.
Another existing platform is EvALL [1] which allows outputs
of different systems to be evaluated against each other, allowing a
fair comparison amongst systems. It also provides an evaluation
platform where, once output of a system is uploaded, an evaluation
report using different metrics is generated.
Our system, allows researchers to systematically examine the
effect of different query processing methods through turning on
and off various techniques. For example, one experiment could be
evaluating the effect of negation detection in queries. Results for
such experiments are listed in Table 1. This is for running 2016
summary and clinical notes topics with the following settings:
Baseline: No negation handling. Plain BM25 on all the articles.
Negex, Remove: Negated terms identified using NegEx and
then removed.
Negex, Hyphenate: Negated terms identified using NegEx
and then hyphenated.
CLPpsych, Remove: Negated terms identified using CLPpsych
and then removed.
CLPpsych, Hyphenate: Negated terms identified using CLPpsych and then hyphenated.
The results in Table 1 show the positive effect that handling negation had on the summarised topics and how the four alterations also
had different effects on four metrics. On clinical notes we observed
the opposite effect of the summaries, given they are much harder
text to process for any negation detection tool. One could then experiment with adding more topic or document processing options,
such as query expansion using word embeddings created using
MEDLINE. A more complete set of experiments that our system
facilitates can be found in Nguyen et al. [8].7

5 http://trec.nist.gov/trec_eval/

7 Note

Figure 3: Results page listing all the logged jobs and their
status.

Figure 4: An example of email notification.

that some of experimental setup, such as learning-to-rank, is yet to be added to
the online system.

6 http://www.nltk.org/

1279

Demonstration Papers I

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Figure 5: A2A system architecture.

Run

infNDCG

infAP

P@10

R-Prec

Summary
No negation
Negex, Remove
Negex, Hyphenate
CLPpsych, Remove
CLPpsych, Hyphenate

0.1721
0.1726
0.1754
0.1787
0.1822

0.0158
0.0159
0.0162
0.0163
0.0168

0.2067
0.2067
0.2100
0.2233
0.2200

0.1167
0.1171
0.1162
0.1174
0.1148

Clinical notes
No negation
Negex, Remove
Negex, Hyphenate
CLPpsych, Remove
CLPpsych, Hyphenate

0.1080
0.1102
0.1151
0.1087
0.0818

0.0079
0.0088
0.0084
0.0082
0.0048

0.1400
0.1467
0.1500
0.1200
0.1100

0.0749
0.0772
0.0654
0.0748
0.0447

t-test for statistical significance). We also intend to extend this platform to allow for experiments on the TREC Precision Medicine
track which started on 2017.

ACCESSING THE SYSTEM
The A2A system is available to the public at the following hyperlink:
https://www.vizie.csiro.au/trec-eval. Users can create an account
or use guest as username and password. If the guest account is used,
no confirmation email can be issued.
Acknowledgement. The funding for this project is provided
through Decision Sciences Program at CSIRO Data61. The authors
would like to thank Cecile Paris and Stephen Wan for their support.

Table 1: A usecase of the platform: examining the effect of
negation detection.

4

REFERENCES
[1] E. Amigó, J. Carrillo-de Albornoz, M. Almagro-Cádiz, J. Gonzalo, J. RodríguezVidal, and F. Verdejo. 2017. EvALL: Open Access Evaluation for Information
Access Systems. In SIGIR. 1301–1304.
[2] W. Chapman, W. Bridewell, P. Hanbury, G. Coopera, and B. Buchanan. 2001. A
Simple Algorithm for Identifying Negated Findings and Diseases in Discharge
Summaries. J Biomed Inform. 34, 5 (2001), 301–310.
[3] G. Gkotsis, S. Velupillai, A. Oellrich, H. Dean, M. Liakata, and R. Dutta. 2016.
Don’t Let Notes Be Misunderstood: A Negation Detection Method for Assessing
Risk of Suicide in Mental Health Records. In CLPsych at NAACL. San Diego, CA,
95–105.
[4] H. Gurulingappa, A. Bauer, L. Toldo, C. Schepers, and G. Megaro. 2016. SemiSupervised Information Retrieval System for Clinical Decision Support. In TREC.
Gaithersburg, MD.
[5] S. Karimi, S. Falamaki, and V. Nguyen. 2016. CSIRO at TREC Clinical Decision
Support Track. In TREC. Gaithersburg, MD.
[6] S. Karimi, D. Martinez, S. Ghodke, L. Zhang, H. Suominen, and L. Cavedon.
2011. Search for Medical Records: NICTA at TREC 2011 Medical Track. In TREC.
Gaithersburg, MD.
[7] B. Koopman, G. Zuccon, and J. Russell. 2017. A Task-oriented Search Engine for
Evidence-based Medicine. In SIGIR. Shinjuku, Tokyo, Japan, 1329–1332.
[8] V. Nguyen, S. Karimi, S. Falamaki, and C. Paris. 2018. Benchmarking Clinical
Decision Support Search. (2018). https://arxiv.org/abs/1801.09322
[9] K. Roberts, D. Demner-Fushman, E. Voorhees, and W. Hersh. 2016. Overview of
the TREC 2016 Clinical Decision Support Track. In TREC. Gaithersburg, MD.
[10] K. Roberts, M. Simpson, D. Demner-Fushman, E. Voorhees, and W. Hersh. 2016.
State-of-the-art in Biomedical Literature Retrieval for Clinical Cases: A Survey
of the TREC 2014 CDS Track. Inf Retr. 19, 1-2 (2016), 113–148.
[11] K. Roberts, M. Simpson, E. Voorhees, and W. Hersh. 2015. Overview of the TREC
2015 Clinical Decision Support Track. In TREC. Gaithersburg, MD.
[12] C. Schardt, M. Adams, T. Owens, S. Keitz, and P. Fontelo. 2007. Utilization of the
PICO framework to improve searching PubMed for clinical questions. BMC Med
Inform Decis Mak. 7, 16 (2007).
[13] M. Simpson, E. Voorhees, and W. Hersh. 2014. Overview of the TREC 2014
Clinical Decision Support Track. In TREC. Gaithersburg, MD.

SUMMARY AND FUTURE DIRECTION

Our experimentation framework, A2A, creates an opportunity for
researchers to run a large set of experiments in a short amount
of time. Most importantly, it provides a uniform platform to run
many of the existing methods explored independently by different
researchers all in one setting, and therefore enables reproducibility.
This ensures a fair comparison amongst the methods from the
literature as well as novel settings not reported in past work. We
therefore expect this system to help expedite research in clinical
information retrieval.
The choice of implemented methods in this version of A2A was
largely based on the popularity and success of the techniques reported in the TREC CDS. There are a number of extensions underway
for this system, including the addition of learning-to-rank methods which incorporate query types (diagnosis, test, and treatment)
as their features. Adding the option of choosing UMLS concepts,
which should be included in the index or query expansion, is also
under consideration. Processing clinical notes to normalise the
text to what would be found in the literature is another avenue
to explore. That is, for example, to make available the option of
expanding abbreviations. Another extension for the platform is
including statistical analysis over users’ selected runs (e.g., paired

1280


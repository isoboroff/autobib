Doctoral Consortium

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Exploring Potential Pathways to Address Bias and Ethics in IR
Steven Zimmerman

University of Essex
Colchester, United Kingdom
szimme@essex.ac.uk
For users that (agree vs. disagree) with our assumptions about most
desirable consumption behavior, to what extent has their behavior
changed in relation to their information biases? For users that
(agree vs. disagree) with our assumptions about most desirable
consumption behavior, to what extent would they choose to have
information presented in an alternative manner (e.g. re-ranking) to
address their biases?
Probabilistic methods to classify documents, as well as crowdsourced data from previous research, will be used to determine the
factors such as toxicity, deceitfulness, quality and political slant
of documents deemed to be relevant to participants and used to
build their profile. This meta-information will be useful for presentation in a mock-SERP for which participants will interact. We
will investigate behavioral changes through a combination of click,
eye-tracking and survey data.
It is believed our approach has the potential to dampen the
effects of filter bubbles, reduce consumption of misleading and
potentially hateful content, to broaden perspectives and protect the
fundamental human right to freedom of expression.

ABSTRACT
The interplay between human biases and the underlying data collection and algorithmic methods to present users with relevant
information in information retrieval (IR) systems have undesirable
side effects, such as filter bubbles, censorship (a human rights concern with respect to freedom of expression) and development of
beliefs in false information. IR systems and humans that interact
with them both have biases [6], raising ethical concerns [2]. On a
societal level, the current issues in IR systems, as well as proposed
solutions, raise many ethical concerns.
Previous work in the areas of biases in interactive information
retrieval, document classification, behavioral economics and user
profiling (e.g. [1, 5–7] respectively) provide the foundation for our
research. Using existing knowledge about human bias and profile
data, we propose leveraging this information to inform users about
their behavior in the frame of IR systems and inferences made
to allow for the possibility of better decisions. It is our goal to
understand to what extent user behavior is changed in light of such
information.
Our position is that education and awareness are much better
approaches to address the ethical and human rights concerns when
compared to regulatory measures and non-transparent changes
to IR algorithms. Recent work by Fuhr et al. [4] is one of many
possible educational approaches, and provides useful guidance into
potential information to collect about users and how it might be
presented.
Nudge and boost approaches have achieved desirable behavior
in non-IR domains (e.g. health and retirement decision making),
with limited but promising results in IR itself (e.g. [3]). Our research
investigates the possibility to use profiling data about users to
’nudge’ or ’boost’ users towards more desirable behavior in search
and to gain insight into how users would interact and respond to
such an approach.
The research assumes that it is in the interest of society and
the individual to minimize consumption of information that is
toxic, misleading / deceitful, and of low quality. It also assumes
that maximization of exposure to multiple perspectives is a worthy
goal. Thus, an important component of the main study will be to
determine the agreement of participants with this view.
Research Questions: To what extent is cognitive load increased
due to a user being presented with a profile about their behavior?

CCS CONCEPTS
• Information systems → Users and interactive retrieval; •
Social and professional topics → User characteristics;

KEYWORDS
information retrieval, human decision making, human rights

ACKNOWLEDGMENTS
This work was supported by the Economic and Social Research
Council under grant number ES/M010236/1.

REFERENCES
[1] Bin Bi, Milad Shokouhi, Michal Kosinski, and Thore Graepel. 2013. Inferring the
demographics of search users: Social data meets search queries. In Proceedings of
the 22nd international conference on World Wide Web. ACM, 131–140.
[2] Fernando Diaz. 2016. Worst Practices for Designing Production Information Access
Systems. In ACM SIGIR Forum, Vol. 50. ACM, 2–11.
[3] David Elsweiler, Christoph Trattner, and Morgan Harvey. 2017. Exploiting food
choice biases for healthier recipe recommendation. In Proceedings of the 40th
Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 575–584.
[4] Norbert Fuhr, Iryna Gurevych, Andreas Hanselowski, Kalervo Jarvelin, Rosie Jones,
Consultant Yiqun Liu, Wolfgang Nejdl, and Benno Stein. 2017. An Information
Nutritional Label for Online Documents. In ACM SIGIR Forum, Vol. 51. ACM,
46–66.
[5] Amos Tversky and Daniel Kahneman. 1974. Judgment under Uncertainty: Heuristics and Biases. Science 185, 4157 (1974), 1124–1131.
[6] Ryen White. 2013. Beliefs and biases in web search. In Proceedings of the 36th
international ACM SIGIR conference on Research and development in information
retrieval. ACM, 3–12.
[7] Steven Zimmerman, Chris Fox, and Udo Kruschwitz. 2018. Improving Hate Speech
Detection with Deep Learning Ensembles. In Proceedings of the 10th International
Conference on Language Resources and Evaluation (Miyazaki, Japan) (LREC 2018).

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGIR ’18, July 8–12, 2018, Ann Arbor, MI, USA
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5657-2/18/07.
https://doi.org/10.1145/3209978.3210218

1445


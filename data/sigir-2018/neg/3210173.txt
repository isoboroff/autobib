Demonstration Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Sover! Social Media Observer
Asmelash Teka Hadgu

Sallam Abualhaija

Claudia Niederée

teka@L3S.de
L3S Research Center
Hannover, Germany

sallam.abualhaija@uni.lu
Interdisciplinary Centre for Security,
Reliability and Trust
Luxembourg, Luxembourg

niederee@L3S.de
L3S Research Center
Hannover, Germany

ABSTRACT

of the previous Twitter analysis tools, Sover! is not tailored to a
specific application scenario, and can be applied in many settings.
Sover! enables aid organizations to dynamically set up and manage social media observers for events relevant to them, where automated adaptation is combined with the option for human monitoring and interference for the crawling process (human in the loop).
The crawling infrastructure that feeds the Sover! dashboards with
relevant social media content is not restricted to Twitter content.
Linked content from other social media sources, especially, Facebook and YouTube as well as images from news media sites are
incorporated into the dashboards aiming for a comprehensive view
on an unfolding event. The employed adaptive crawling method
uses simultaneously both the public one percent Twitter stream
and the Twitter filter stream in order to filter relevant feeds for the
event we are interested to monitor.
In the following section, we compare our approach and system
with related work. In Section 3, we give an overview of Sover! highlighting its innovative adaptive crawling component. The planned
demonstration is described in more detail in Section 4 illustrated
by screen dumps from Sover!. Finally, we conclude in Section 5.

The observation of social media provides an important complementing source of information about an unfolding event such as a crisis
situation. For this purpose we have developed and demonstrate
Sover!, 1 a system to monitor real-time dynamic events via Twitter
targeting the needs of aid organizations. At its core it builds upon
an effective adaptive crawler, which combines two social media
streams in a Bayesian inference framework and after each timewindow updates the probabilities of whether given keywords are
relevant for an event. Sover! also exposes the crawling functionality
so a user can actively influence the evolving selection of keywords.
The crawling activity feeds a rich dashboard, which enables the
user to get a better understanding of a crisis situation as it unfolds
in real-time.

KEYWORDS
Social Media; Real-time Adaptive Search; Crisis Management
ACM Reference Format:
Asmelash Teka Hadgu, Sallam Abualhaija, and Claudia Niederée. 2018.
Sover! Social Media Observer. In SIGIR ’18: The 41st International ACM
SIGIR Conference on Research & Development in Information Retrieval, July
8–12, 2018, Ann Arbor, MI, USA. ACM, New York, NY, USA, 4 pages. https:
//doi.org/10.1145/3209978.3210173

1

2

RELATED WORK

In the following, we describe previous Twitter monitoring systems
that are closely related to our work and adaptive crawling algorithms that compare to our contribution.

INTRODUCTION

Twitter is a very popular source of information, because of its ability to reflect on-going events in a multi-perspective, fine granular
and real-time fashion. Capturing relevant tweets for analyzing and
monitoring an event is, however, not a trivial task. Initially selected event-related keywords (terms, hashtags), which are used
for collecting tweets via the Twitter APIs, might loose their importance as the event unfolds and new relevant terms may appear.
For this purpose, some adaptive crawling techniques have been
developed [3, 6, 7].
In this paper, we present Sover! a system for observing social
media feeds, which is based on our very effective method for adaptive crawling. The system targets the needs of aid organizations
in crisis situations and was developed in close collaboration with
a team from different aid organizations in Germany. Unlike many

Event Tracking Systems on Twitter. Due to the potential of Social Media especially of Twitter to support the observation of events,
there are already some Twitter monitoring systems for general use
such as OSoMe [2] and for crisis situations. CrisisTracker [5] is an
online real-time system that tracks keywords on Twitter during
disasters and creates stories using clustering. Twitcident [1] is a
framework that relies on the emergency broadcasting services to
enable detecting an incident automatically and monitoring relevant
information diffused on Twitter. The Emergency Analysis Identification and Management system (EAIMS) McCreadie et al. [4] is a
crisis tracking toolkit, that provides a real-time event detection as
well as some other relevant functions like sentiment analysis, information credibility estimation and automatic time-line generation.
Like these systems, Sover! offers a flexible real-time faceted search.
Sover! is unique in that it puts the human in the loop to steer the
crawling when needed. It also brings the major social media and
news media snippets in one seamless interface. Besides, images are
first class citizens on Sover!

1 sover.l3s.uni-hannover.de

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGIR ’18, July 8–12, 2018, Ann Arbor, MI, USA
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5657-2/18/07.
https://doi.org/10.1145/3209978.3210173

Adaptive Crawling. Our adaptive crawler method is the core of
the Sover! system. It is inspired by existing work in the field of adaptive crawling or, as it is also called, adaptive social search. In Wang
et al. [7] the authors proposed an adaptive crawling method that

1305

Demonstration Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Twitter Streams

Real-time index
Observation
Dashboards

Seed keywords /
update keywords

Launch Crawler

Keyword adaptation

Crawler
Management

Enrichment

Figure 1: Sover! System Overview: Crawling infrastructure (left) and Observation front-end (right).
given a seed set of keywords monitors hashtags and rates them by
their similarity to the initial seeds using correlation scores and TFIDF weighting. Magdy and Elsayed [3] developed an unsupervised
adaptive method to track tweets for a dynamic topic. Sadri et al.
[6] proposed the Tweet Acquisition System (TAS), a system that
follows an iterative process to automatically change and adapt the
query representing a temporal topic aiming at maximizing recall.
The key difference in Sover! is that unlike these adaptive crawling
algorithms that use only the Twitter filtering stream for adaptation, Sover! also takes into account the global evolving context of
co-occuring events by simultaneously analyzing the random one
percent sample Twitter stream, e.g., to avoid keyword drift.

3

the event we are interested in, we can make better decisions about
which keywords pertain truly to the event we are trying to track,
which ones just happen to co-occur because of another event or
are just noise. This helps us to avoid keywords coming from other
events thereby mitigating keyword drift and identifying emerging
keywords in our filter stream that are not contained in the query
keywords at the current time-step. The main task of the keyword
adaptation module is to model these changing query keywords.
Let E denote a particular event that we want to monitor. Initially,
the user will use a set of seed keywords to start the crawl. After
each time window, we generate candidate keywords. These are
hashtags and word bi-grams from the set of search tweets returned.
In order to compare keywords for relevance as query keywords,
each keyword is assigned a score that quantifies how good this
keyword is expected to serve as a query keyword to obtain a set of
tweets.
Suppose r is the hypothesis that a given keyword is relevant for
an event. We can quantify how good this keyword is as a search term
for the event E by computing the fraction of relevant tweets that
contain this keyword, P(r ). Similarly if we let o be the hypothesis
that a given keyword is relevant for all other events, other than
the event E that we’re tracking, then P(o) quantifies how good this
keyword is as a search query for any other event but E. Concretely,
we estimate P(r ) using the Filter Stream as the fraction of tweets
containing the query keyword in our search result. In the same
way, we estimate P(o) from the Sample Stream. Finally, we update
these probabilities in order to strengthen useful keywords and to
weaken the keywords that decrease in relevance so that they can
be dropped in subsequent queries.
For a given keyword, after computing the likelihood, we compute
the ratio of the likelihoods to decide if a given keyword should
be included as a query keyword in the next iteration. We set a
threshold, θ = 0.7, experimentally that defines this cut off. The
method has been evaluated against [7] to track relevant tweets on
the Berlin Attack 2016. It achieves a significant improvement with
an average (over five minute windows) F1 score of 0.81 for Sover!
vs. 0.62 for [7].

SOVER! SYSTEM OVERVIEW

In this section, we give an overview of our system (see also Figure 1).
Sover! has two sub systems: (i) a crawling infrastructure and (ii)
interfaces for crawler management and the observation dashboards.

3.1

Crawling Infrastructure

The crawling infrastructure is the backbone of the system responsible for stream ingestion, keyword adaptation (the core of adaptive
crawling) as well as enrichment and indexing of social media feeds.
Stream Ingest. Sover! leverages public Twitter APIs to crawl social
media feeds in order to monitor crisis events. For this purpose,
Sover! uses the real-time Twitter streaming API. This is mainly
done through the Filter Stream.2 The filter parameters can be
changed in real-time to reflect the changing nature of an evolving
event. Sover! also supports crawling past events. This is achieved by
combining the Twitter Advanced Search 3 with the Twitter status
look-up API. 4
Keyword Adaptation. The main component of Sover! is a keyword adaptation module that additionally takes into account the
global context in order to update the query keywords from one
time-step to the next in a coherent fashion, i.e., considering that
other major events may happen at the same time. The key idea is
to use the one percent Twitter sample to get a sample statistic of
the global context (via Sample Stream 5 ). This public stream gives
us a random set of tweets covering all major (big enough) events.
By analyzing simultaneously both the random one percent sample
of the entire Twitter stream and a focused stream of tweets about

Social Media Feed Enrichment. Most URLs on Twitter are shortened either by Twitter for display or users themselves before posting
their tweets to save characters. In order to make sense of the different URLs, we perform URL unshortening and categorization based
on their sources such as: Facebook, YouTube and News Media with
domains harvested from the GDELT project 6 . This forms the basis

2 https://stream.twitter.com/1.1/statuses/filter.json
3 https://twitter.com/search-advanced
4 https://dev.twitter.com/rest/reference/get/statuses/lookup

6 http://www.gdeltproject.org

5 https://dev.twitter.com/streaming/reference/get/statuses/sample

1306

Demonstration Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Figure 2: A snapshot of the main social feeds dashboard of Sover! Feeds are from a past crawler for Berlin attack 2016.
for our social feeds dashboard that displays streams of feeds from
different sources.

it right, the user can update the search keywords at any point as
the system runs. Thus, Sover! provides a way to include a human in
the loop feedback (see Figure 5). The crawler Control also enables
the user to pause and restart a crawling session.

Real-time Index. We index the enriched streams of tweets on
the fly with Elasticsearch 7 . We provide a mapping for tweets that
makes it easily recognize date-time, location fields etc. This helps
provide faceted search over all the Twitter fields as they get indexed
in real-time from a custom dashboard built with Kibana 8 .

3.2

Observation Dashboards. The main interface of Sover! is a dashboard of social feeds (cf. Figure 2). This dashboard provides the
user with content categorized by media: Twitter, Facebook, News
and YouTube. The second observation interface is a feed of images. These are images coming from Twitter but also news pages
linked to by Twitter messages. This component grew out of the
interaction with aid organizations, who found images as the key
ingredient when assessing the relevance of social feeds for a crisis
situation. Figure 3 shows a snapshot of images captured as a user
monitors the event Berlin Attack. Finally, there is a customized
Kibana dashboard that enables a flexible faceted search and sorting
for all the content that gets indexed. This dashboard also contains
histograms of popular hashtags, mentioned and retweeted users
that gets updated dynamically as the user monitors the event.

Observation Dashboards & Crawler
Management

The second major component of Sover! is the front-end that enables
the creation and management of crawlers through the Crawler
control as well as observation of social feeds and images through
dashboards.
Crawler Control. The Crawler control enables the creation of new
crawlers as well as the management of existing crawlers. Sover!
is designed mainly to be used to track events in real-time as they
happen. The user can launch crawlers via the Crawler Control
user interface for this purpose by specifying a set of seed keywords.
In addition, users might find it useful to simulate crisis situations
to train people and to get a sense of the type of content that gets
shared on Social media during crisis situation, it also supports monitoring past events. As the event a user tracks unfolds, the keyword
adaptation module adds new emerging keywords or omits those
that are not relevant anymore. As part of managing the crawler, the
user can inspect those changes and, when the system does not get

4

DEMONSTRATION WALK-THROUGH

In the demonstration we will show the following steps as illustrated
by system screen dumps from monitoring social media feeds about
the Berlin attack 9 :
(1) How to start a crawler for a real-time event using seed keywords and optional parameters such as language, location, user
accounts etc.

7 https://github.com/elastic/elasticsearch

9 https://en.wikipedia.org/wiki/2016_Berlin_attack

8 https://github.com/elastic/kibana

1307

Demonstration Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Figure 3: A screenshot of images dashboard for Berlin attack 2016.
Target Users. Our system is particularly useful to people involved
in aid organizations that need to make sense of a crisis situation as
it unfolds in order to help with their decision making.

Kibana
Crawler Name

Images

Social Feeds

Pause

5
Feed Counter

Update

Delete

CONCLUSION

In this paper, we presented Sover!, a social web observer that provides real-time adaptive event tracking based on an innovative
method for adaptive crawling. Given that the user feeds a crawler
with some seed keywords related to the event of interest, Sover!
adapts to the dynamic changes of the keywords automatically and
semi-automatically. Sover! has been developed in close collaboration with aid organizations and has also shown its usefulness and
usability by testing it in real application settings. For future work,
the system will be extended to include components on top of the
adaptive crawler that are able to flag the relevant tweets from the
end users’ perspective and highlight rumors based on a manual annotation by relief organizations. Furthermore, it would be possible
to use the URLs in the enrichment component as seeds to initiate
crawling on the respective platforms.

Crawler Description

Figure 4: The different dashboards and monitoring tools associated with a crawler on Sover!

(2) How to start a crawler for a past event with a similar set of
parameters
(3) How to inspect a running crawler (Figure 4)
(4) What the dashboards created by the started crawlers look like
(Image View shown in Figure 3, Social Feeds as we saw in
Figure 2 and a custom Kibana dashboard.)
(5) How to update, pause, resume and delete a crawler
(6) How to observe the automatic adaptation of the crawler process
(7) How to correct the crawling process (see Figure 5)

ACKNOWLEDGEMENTS
This work was partially funded by the German Federal Ministry of
Education and Research (BMBF) under project K3 (13N13548).

REFERENCES
[1] Fabian Abel, Claudia Hauff, Geert-Jan Houben, Richard Stronkman, and Ke Tao.
2012. Twitcident: fighting fire with information from social web streams. In
Proceedings of the 21st International Conference on World Wide Web.
[2] Clayton A Davis, Giovanni Luca Ciampaglia, Luca Maria Aiello, Keychul Chung,
Michael D Conover, Emilio Ferrara, Alessandro Flammini, Geoffrey C Fox, Xiaoming Gao, Bruno Gonçalves, et al. 2016. OSoMe: the IUNI observatory on social
media. PeerJ Computer Science 2 (2016), e87.
[3] Walid Magdy and Tamer Elsayed. 2016. Unsupervised adaptive microblog filtering
for broad dynamic topics. Inf. Process. Manage. 52, 4 (2016), 513–528.
[4] Richard McCreadie, Craig Macdonald, and Iadh Ounis. 2016. EAIMS: Emergency
Analysis Identification and Management System.. In SIGIR. ACM, 1101–1104.
[5] Jakob Rogstadius, Maja Vukovic, CA Teixeira, Vassilis Kostakos, Evangelos Karapanos, and Jim Alain Laredo. 2013. CrisisTracker: Crowdsourced social media
curation for disaster awareness. IBM Journal of Research and Development (2013).
[6] Mehdi Sadri, Sharad Mehrotra, and Yaming Yu. 2016. Online Adaptive Topic
Focused Tweet Acquisition.. In CIKM. ACM, 2353–2358.
[7] Xinyue Wang, Laurissa Tokarchuk, and Stefan Poslad. 2014. Identifying relevant
event content for real-time event detection.. In ASONAM. IEEE Computer Society.

Figure 5: A snapshot of updating search keywords: (i) in blue
are seeds and keywords added automatically by Sover! (ii)
in green are keywords added by a user while a crawler is
running.

1308


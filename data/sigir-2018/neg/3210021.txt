Session 5B: Entities

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Automated Comparative Table Generation for
Facilitating Human Intervention in Multi-Entity Resolution
Jiacheng Huang

Wei Hu∗

State Key Laboratory for Novel Software Technology
Nanjing University, China
jchuang.nju@gmail.com

State Key Laboratory for Novel Software Technology
Nanjing University, China
whu@nju.edu.cn

Haoxuan Li

Yuzhong Qu

State Key Laboratory for Novel Software Technology
Nanjing University, China
hxli.nju@gmail.com

State Key Laboratory for Novel Software Technology
Nanjing University, China
yzqu@nju.edu.cn

ABSTRACT
Entity resolution (ER), the process of identifying entities that refer
to the same real-world object, has long been studied in the knowledge graph (KG) community, among many others. Humans, as a
valuable source of background knowledge, are increasingly getting
involved in this loop by crowdsourcing and active learning, where
presenting condensed and easily-compared information is vital to
help human intervene in an ER task. However, current methods
for single entity or pairwise summarization cannot well support
humans to observe and compare multiple entities simultaneously,
which impairs the efficiency and accuracy of human intervention.
In this paper, we propose an automated approach to select a few
important properties and values for a set of entities, and assemble
them by a comparative table. We formulate several optimization
problems for generating an optimal comparative table according to
intuitive goodness measures and various constraints. Our experiments on real-world datasets, comparison with related work and
user study demonstrate the superior efficiency, precision and user
satisfaction of our approach in multi-entity resolution (MER).

e2 [fb:m.01wf_p_]

e3 [wd:Q36804]

e1 [dbp:

– rdf:type : Person, MusicalArtist

– alias : Eric Wright, Eazy-E

– rdfs:label : Eazy-E

– rdf:typ

– rdfs:label : Lil Eazy-E

– date_of_birth : 1963-9-7

– altLabel : Eric Lynn Wright

– owl:sameAs : fb:m.01wf_p_

– gender : male

– date_of_birth : 1963-9-7

– birthDate : 1984-4-23

– genre : gangsta rap, hip hop

– desc : Gangsta rapper, producer

– birthPlace : Compton

– name : Eazy-E

– genre : gangsta rap

– gender

– gender : male

– place_of_birth : Compton

– instance_of : human

– genre

– genre : Gangsta rap, Hip hop

– profession : rapper, producer

– occupation : musician, rapper

…

– givenName : Eric Darnell Wright

– type : person, music.artist

– place_of_birth : Compton

(146 property-values in total)

(391 property-values in total)

– genre : Gangsta rap, Hip hop

2

e

Eric Lynn Wright

1963-9-7

– givenName : Eric Darnell Wright
on3 Research and Development in Information Retrieval, July 8–12,
2018, Ann
– rdfs:label : Lil Eazy-E
Arbor, MI, USA.givenName
ACM, New York, NY,
USA, 10 pages.
https://doi.org/10.1145/
rdf:type
birthDate
– birthPlace : Compton
alias
type
date_of_birth
group?
3209978.3210021
1 🔽

e1

altLabel

instance_of

date_of_birth

Eric Darnell Wright

Person, MusicalArtist

1984-4-23

e
Eric Wright, Eazy-E
person, music.artist
1 2 🔽INTRODUCTION
2

2 🔽

KEYWORDS
Entity resolution; knowledge graph; comparative table; multi-entity
summarization; holistic property matching
ACM Reference Format:
Jiacheng Huang, Wei Hu, Haoxuan Li, and Yuzhong Qu. 2018. Automated
Comparative Table Generation for Facilitating Human Intervention in MultiEntity Resolution. In SIGIR ’18: The 41st International ACM SIGIR Conference
author

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGIR ’18, July 8–12, 2018, Ann Arbor, MI, USA
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00
https://doi.org/10.1145/3209978.3210021

585

Eric Lynn Wright

human

– gender : male

1963-9-7

1963-9-7
Along with the rapid growth of knowledge
graphs (KGs), billions
of entities have been created from diverse sources. Entity resolution
(ER) aims to identify different entities referring to the same realworld object. While a significant number of automated approaches
have been proposed to address the ER problem, they are still being
challenged by large-scale, heterogeneously-described entities. For
example, Figure 1 depicts an ER task with three real entities in DBpedia, Freebase and Wikidata, respectively. Each entity is described
by hundreds of properties and values, and some of them are very
similar, e.g., types, names and genders, which make automated ER
approaches difficult to decide whether all the three entities refer to
the same person or not.
Recent studies have demonstrated great benefits of involving
humans in the ER loop. For instance, crowdsourcing, where human
workers are recruited to solve micro-tasks like verifying the correctness of entity matches, offers a feasible solution to large-scale
ER [8, 25, 32, 34, 38]. Also in some cases, the human workers are
actively engaged to improve the algorithms in automated ER approaches with active learning [21, 27]. Although all these works
request a human to judge which entities in a single ER task refer
to the same, little effort has been made on how to present the critical information (e.g., important properties and values) to help her
complete the task more efficiently and accurately [4, 32].

• Information systems → Entity resolution; Data extraction
and integration;

e3

– rdfs:la

– owl:sa

– birthD

– birthPl

(141 property-values in total)

Figure givenName
1: A motivating
example. For simplicity, entities are
birthDate
denoted alias
by e 1 , e 2 , date_of_birth
e 3 . Properties and values are separated by
altLabel
date_of_birth
e1 [dbp:Lil_Eazy-E]
colons, and multiple values are divided by commas.
Namee1 Eric Darnell Wright
1984-4-23
– rdf:type : Person, MusicalArtist
spaces
are
omitted
except
“rdf:”,
“rdfs:”
and
“owl:”.
e
Eric Wright, Eazy-E
1963-9-7

CCS CONCEPTS

∗ Corresponding

e1 [dbp:Lil_Eazy-E]

e2 [fb:
– type

– genre
– alias

– place

– gend

1963-9-7

– altLabel : Eric Lynn Wright
[dbp:Lil_Eazy-E]
– date_of_birth e: 11963-9-7

rap, hip hop

rdf:type
: Person, MusicalArtist
– desc : Gangsta–rapper,
producer
rdfs:label : Lil Eazy-E
– genre : gangsta– rap

: Compton

pper, producer

music.artist

values in total)

of

alArtist

.artist

– 5B:
owl:sameAs
: fb:m.01wf_p_
Session
Entities
– instance_of
: human
– birthDate
: 1984-4-23
– occupation : musician,
rapper

– place_of_birth–:birthPlace
Compton : Compton
–
gender
(141 property-values in: male
total)
– genre : Gangsta rap, Hip hop
e1– givenName
[dbp:Lil_Eazy-E]
: Eric Darnell Wright

– owl:sameAs : fb:m…

– genre : gangsta rap …

e2 [fb:m.01wf_p_]

…

e3 [wd:Q36804]

e1 [dbp:Lil_Eazy-E]

– birthDate : 1984-4-23

– rdf:type : Person …

– alias : Eric Wright …

– birthPlace : Compton

– rdfs:label : Eazy-E

e3 [wd:Q36804]

– rdfs:label : Lil Eazy-E

– date_of_birth : 1963-9-7

– gender : male

– rdfs:label : Eazy-E

– owl:sameAs : fb:m…

– genre : gangsta rap …

– altLabel : Eric Lynn …

– birthDate : 1984-4-23

e2 [fb:m.01wf_p_]

– alias : Eric Wright, Eazy-E
– date_of_birth : 1963-9-7

– gender : male
– genre : Gangsta rap …

– altLabel : Eric Lynn Wright
– date_of_birth : 1963-9-7

– genre : gangsta rap, hip hop
– desc : Gangsta rapper, producer
…
– date_of_birth : 1963-9-7
– name : Eazy-E

…

– place_of_birth : Compton
– profession : rapper, producer
e–2 type
[fb:m.01wf_p_]
: person, music.artist

SIGIR’18, July
8-12, 2018, Ann Arbor, MI, USA
…

– birthPlace : Compton

– genre : gangsta rap

e3 [wd:Q36804]

– gender : male

– instance_of : human

– rdfs:label : Eazy-E

– genre : Gangsta rap …

– altLabel : Eric Lynn …

– occupation : musician, rapper

…

– date_of_birth : 1963-9-7

Given an MER task, we want …to generate an optimal comparative
– rdf:type
: Person, MusicalArtist
type : property-values
person, music.artist
table for this task. To achieve this, we deal with several challenges:
(146 property-values
in total) –(1,253
in total)
(141 property-values in total)
– genre : Gangsta rap, Hip hop
– genre : gangsta rap, hip hop
Firstly, different entities often use various properties to convey the
givenName
birthDate
e1 [dbp:Lil_Eazy-E]
2 [fb:m.01wf_p_]
– givenName : Eric Darnell Wright
– alias : Eric Wright, Eazy-E
same meaning,eand
property heterogeneity causes the difficulty in
alias
date_of_birth
– rdf:type : Person, MusicalArtist – type : person, music.artist
– rdfs:label : altLabel
Lil Eazy-E
date_of_birth
comparison and the sparseness of the table. We use several similar– genre : Gangsta rap, Hip hop
– genre : gangsta rap, hip hop
– birthPlace
: Compton
– place_of_birth : Compton
⦿ match
e1 Eric Darnell
Wright
1984-4-23
ity measures to find matched property pairs, and derive property
–
givenName
:
Eric Darnell Wright
– alias : Eric Wright, Eazy-E
– gender
: male
– gender : male
◎ nonmatch
e2 Eric
Wright, Eazy-E
1963-9-7
birthDate
cliques by maximizing the overall match probability estimate under
– rdfs:label : Lil Eazy-E
date_of_birth
e
Eric
Lynn
Wright
1963-9-7
3
Figure 2:
Result of a pairwise approach for e 1 , e 2 in Figure 1
a matching cardinality
constraint. Secondly,
we study what factors
date_of_birth
– birthPlace : Compton
– place_of_birth : Compton
⦿ match
contribute
to
the
goodness
of
a
property
clique
and a value, and
1984-4-23
– gender : male
– gender : male
◎ nonmatch
givenName
rdf:type
birthDate
design several scoring functions according to the intuitions related
alias
type
date_of_birth
1963-9-7
altLabel
instance_of
date_of_birth
group?
to how much information they provide and how important they are
1963-9-7
1
e1 Eric Darnell Wright Person, MusicalArtist
1984-4-23
to humans. The challenge is how to measure the commonalities and
2
e2 Eric Wright, Eazy-E
person, music.artist
1963-9-7
differences among multiple entities. Thirdly, the goal of generating
3
e3
Eric Lynn Wright
human
1963-9-7
a comparative table is to help humans attain a quick comparison of
Figure 3: A comparative table for e 1 , e 2 , e 3 in Figure 1
the entities, and thus the comparative table must provide adequate
information in a limited display space. Given the constraints on
Current approaches. Given an ER task to a human, there are
entity coverage and table cell size, we formulate the optimization
two kinds of often-used approaches to present entities and their
problem of generating a comparative table with the best goodness
properties and values for the task. The first kind uses pairwise preand propose efficient algorithms.
sentation, which compares two entities at a time and aligns similar
The main contributions of this paper are summarized as follows:
properties between them [4, 35]. The other kind displays multiple
• We optimize the discovery of matched property cliques with
entities in a form of list [15, 19] (or grid, in particular for images
the highest overall match probability estimate among those
[32]), just like what is typically seen from a Web search engine.
satisfying a global 1:1 matching constraint. (Section 3)
Because the lengthy and heterogeneous entity descriptions, such
• We propose scoring functions to measure the goodness of
as hundreds of property-values in entities like e 1 , e 2 , e 3 in Figure 1,
property cliques and values for a set of entities according to
would overload a human with too much superfluous information,
several intuitions. (Section 4)
the two kinds of approaches both use pairwise or single entity sum• We formulate the problem of optimal comparative table genmarization to help the human focus on a small portion of important
eration with the entity coverage constraint. We propose
properties and values to reduce her workload [4, 16, 17, 19, 31].
an efficient algorithm to obtain approximate solutions and
Arguably, each of the two kinds of approaches has its strengths
prove its approximation ratio. (Section 5)
and weaknesses. The pairwise one allows humans to focus on two
• We conducted extensive experiments, comparison to statespecific entity summaries at each time, but is challenging to scale
of-the-art methods and user study to verify the accuracy of
due to the large number of entity pairs to be judged. For example,
matched properties, effectiveness of goodness measures and
given a task containing
20 20 entities, a human may need to provide
user satisfaction of comparative tables for MER. (Section 6)
answers for up to 2 = 190 entity pairs without using transitivity.
On the other hand, the list-based needs humans to scroll among the
2 APPROACH OVERVIEW
entities and remember and compare their summaries in mind. More
An
entity in the KG is denoted by a URI and described by a set of
importantly, extra identity evidences observed from transitivity
properties
and values, where a value can be another entity, a literal
and grouping would be unseen if a set of entities is broken down
or a blank node. We treat blank nodes as null, and null value is not
to pairs or a list. Figure 2 shows the result of a pairwise approach
comparable or countable. We say that a property instantiates an
[4] for entities e 1 , e 2 in Figure 1. Without seeing the other entity
entity, if it is described by that property with any non-null value.
pairs, a human is very likely to decide that e 1 , e 2 refer to the same
artist (which is wrong in this case!). So, it is natural to ask if there
Definition 2.1 (Human intervention in MER). Let R be an MER
N . A human intervenes in
is any other solution to help human intervene in ER?
task containing a set of entities E = {ei }i=1
Our approach. In this paper, we propose a table-based solution
L ,
resolving E by dividing it into a set of entity groups G = {G j }j=1
that presents an ER task in a condensed, rather simple, and wellsuch that all entities in a group refer to the same real-world object,
structured fashion. Specifically, given an ER task containing a set of
and no two entities in different groups denote the same object.
entities to be resolved, called a multi-entity resolution (MER) task in
To facilitate human intervention in MER, our approach leverages
this paper, we aim to automatically generate a special type of table,
comparative
table, which is defined as follows:
called comparative table, which respectively arranges the entities
and properties in the task as the row and column headers of a table
Definition 2.2 (Comparative table). Given an MER task R containand their corresponding values in the cells. In fact, comparative
ing a set of entities E, let P, V be the sets of properties and values
table is considered suitable to present symbolic information and
of E, respectively. A comparative table for R, denoted by CT , is a
has long been used in decision-makings [33]. For instance, Figure 3
triple CT = (E, Q, W), where Q ⊆ P and W ⊆ V. E, Q respectively
depicts a comparative table for e 1 , e 2 , e 3 in Figure 1. With the help
form the row and column headers of CT and W fills the cells.
of this table, a human would be confident of saying that e 2 , e 3 refer
To generate a comparative table for an MER task, our approach
to the same person, but e 1 does not.
employs three processing steps. Figure 4 illustrates the workflow.
– place_of_birth : Compton

586

Output: comparative table

Session 5B: Entities

Multiple entities
e1 [dbp:Lil_Eazy-E]

e2 [fb:m.01wf_p_]

– rdf:type : Person …

– alias : Eric Wright …
– date_of_birth : 1963-9-7

– owl:sameAs : fb:m…

– genre : gangsta rap …

– birthPlace : Compton

e3 [wd:Q36804]

– desc : CEO NWA …

– rdfs:label : Eazy-E

– gender : male

– altLabel : Eric Lynn …

– genre : Gangsta rap …

– date_of_birth : 1963-9-7

{rdfs:label, name}

0.2 {givenName, alias, altLabel}

{givenName, alias, altLabel}
{rdf:type, type, instance_of}

0.4 {rdf:type, type, instance_of}
0.5 {birthDate, date_of_birth}

…

…

Holistic property matching

Property cliques

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Goodness measurement

Similarity calculation

Discriminability

Prop. clique derivation

Abundance

Property clique comparabilities

Goodness scores

Comparative table generation Comparative table
Prop. clique selection

Diversity

– rdfs:label : Lil Eazy-E

Comparative table generation

Value selection

Semantics

divide into groups

Figure 4: Workflow of our approach
1. Holistic property matching aims to deal with the heterogeneity of properties. Our approach firstly leverages three
similarity measures on properties’ labels, local names and
values for finding matched property pairs, e.g., e 2 .alias ≃
e 3 .altLabel, which are later used to derive matched property
sets, called property cliques, among multiple entities, e.g.,
{e 1 .givenName, e 2 .alias, e 3 .altLabel}. Our approach follows
the widely-used duplicate-free assumption [26, 36] to constrain the global 1:1 matching, and develops an optimization
algorithm to efficiently derive the optimal property cliques
among those satisfying this constraint.
2. Goodness measurement obtains the goodness of property
cliques by combining four factors: (1) discriminability measures how well a property clique reveals the commonalities
and differences among multiple entities; (2) abundance assesses how adequate of information the property clique provides; (3) semantics gives extra scores to the ones particularly
useful for ER, e.g., owl:sameAs; and (4) diversity evaluates the
redundancy between different property cliques. The goodness of values is measured using similar intuitions.
3. Comparative table generation assembles entities, property cliques and values to construct a comparative table. In
addition to greedily pick up several property cliques having
the best goodness, our approach imposes a new entity coverage constraint to make sure that each entity is instantiated
by a least number of properties. Due to the NP-hardness of
optimal property clique selection under this constraint, our
approach develops an approximate algorithm to efficiently
find the solution. Also, value selection is optimized under a
table cell size constraint.

3

Algorithm 1: Holistic property matching

1
2
3
4
5
6
7
8

9
10
11
12
13
14

Input: Set of matched property pairs J
Output: Set of property cliques C
C ← ∅; J′ ← J;
Sort J′ in descending order according to match probability estimates;
repeat
Pop pa ≃ pb ∈ J′ holding the highest match probability estimate;
Find cliques C i , C j ∈ C containing pa , pb , respectively;
if C i = ∅ and C j = ∅ then
Create a new clique {pa , pb } and add it in C;
else if C i has any property from the same namespace as pb or C j
has any property from the same namespace as pa then
Drop pa ≃ pb , due to violate the global 1:1 constraint;
else
Merge C i , C j into a larger clique C k ;
Remove C i , C j from C and add C k in C;
until J′ = ∅;
return C;

between their labels. Furthermore, when two datasets have been
partially aligned (e.g., owl:sameAs relations exist, or a simple entity matching approach is conducted ahead of time), the aligned
entities are treated as the uniquely-selected representative of them.
Besides, a parallel technique is developed for efficiently processing
large sets of property-values. We apply the conventional logistic
regression [14] on S L , S N , SV to compute the match probability estimates of property pairs. Note that our approach is adaptive to other
similarity measures and combination methods (see Section 6.2).
Next, we derive matched property sets, called property cliques,
from the previously-estimated matched property pairs. The properties in each clique are all matched with each other. Following
the widely-used duplicate-free assumption [26, 36], we restrict that
each property under one namespace can match at most one property under another namespace. This global 1:1 matching constraint
serves for improving the accuracy of property cliques and the clearness of column headers in comparative tables. In other words, we
do not want a clique to contain many loosely-related properties.
However, the derivation of property cliques under the global 1:1
matching constraint is not a trivial process, because a property is
often involved in more than one matched property pairs, while simply choosing the pair with the highest match probability estimate
may lead to conflicts. See the example below.

HOLISTIC PROPERTY MATCHING

Given two properties, we compute three different kinds of similarities between them:
• Label similarity, denoted by S L , is obtained by comparing
the labels of properties after normalization. We also extend
labels with synonyms in WordNet.
• Local name similarity, denoted by S N , is measured by comparing the local names of properties’ URIs.
• Value similarity, SV , is computed by comparing all the values
of properties and retaining the highest score.
We employ various similarity measures for strings, numerics, dates
and entities. For strings, we normalize them (via lowercasing, tokenization, stemming, etc.) and use the Soft TF-IDF measure [6] for
similarity calculation, as it repeatedly achieved the best for ontology
matching (OM) [2]. For numerics and dates, we use the maximum
percentage differences in absolute values and days, respectively
[5]. For entities as values, we compute the above string similarity

Example 3.1. Assume that one first compares properties of e 2 , e 3
in Figure 1. As a result, e 2 .alias would form two property matches
with e 3 .label and e 3 .altLabel, due to they have common words in
values, such as “Eric”, “Wright”, “Eazy-E”. It is also reasonable to
assume that e 2 .alias and e 3 .label have a higher match probability
estimate, due to they have one identical value “Eazy-E”. But after

587

Session 5B: Entities

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

comparing properties between e 1 , e 3 and between e 1 , e 2 , one would
end with a conflict involving e 2 .alias ≃ e 3 .label, e 1 .givenName ≃
e 3 .altLabel, e 1 .givenName ≃ e 2 .alias. On the contrary, if e 1 , e 2 , e 3
can be treated as a whole, one can obtain two consistent cliques:
{e 1 .label, e 2 .name, e 3 .label}, {e 1 .givenName, e 2 .alias, e 3 .altLabel}.

1
0.7

Ms X
Mt
I X
I X
X

σ (pas , pbt ) · 1(pas ≃ pbt ),

s=1 t =1 a=1 b=1
s,t
Mt
X
s.t.
1(pas ≃ pbt )
b=1

≤ 1, ∀s, t ∈ [1, I ], s , t, ∀a ∈ [1, Ms ],

3

0
1.0
0

0

proportion of distinct values

= 0.3
= 0.2

0.1

1.0

proportion of
distinct values

0.1

1.0

proportion of
entities

Figure 5: A simulation of property clique goodness measurement. The left part shows a discriminability curve only, and
the right shows its combination with abundance and semantics. Diversity is omitted due to it relates to others. A smaller
score (deeper color) indicates a better goodness.
First, we define the scoring functions for property cliques, where
a lower score indicates a better goodness.
Discriminability. To aid a human to divide the entities in an
MER task into different groups, a property clique that holds completely different or exactly identical values for all the entities may
not be considered informative. For example in Figure 1, all the three
entities have the same value for {birthPlace, place_of_birth}, and
thus it is difficult to distinguish them based on this property clique.
However, a property clique whose values have relative variety or
across a categorical scale may be more useful. To formalize, let E
be a set of entities. For a property clique Ci , we define a scoring
function for its discriminability on E, denoted by discr (Ci ), inspired
by the marginal cost curve known in economics [28]:
S
α
|
norm(val (e, Ci ))|
(3)
discr (Ci ) = P e ∈E
−X ,
e ∈E |norm(val (e, Ci ))|

(1)

(2)

where σ (pas , pbt ) obtains the match probability estimate of pas , pbt
from the trained logistic function that classifies pas , pbt as a matched
property pair. The indicator function, 1(pas ≃ pbt ), equals 1 if pas , pbt
are chosen to form a clique, and 0 otherwise.
Optimal holistic property matching (I ≥ 3) is NP-hard, because
the NP-hard 3-dimensional assignment problem [7] can be reduced
to the simplest case (I = 3). Inspired by the simple and efficient
algorithm for bipartite max-weight matching, we design a greedy
algorithm for holistic property matching (Algorithm 1). Due to
the 1:1 constraint, each property exists in exactly one property
cliques and every property clique contains I properties at most.
Thus, we use an array to record which property clique contains
it for each property. The time complexity of sorting (Line 2) in
is O (J log J ). The selection step (Lines 3–13) must examine O (J )
matched property pairs and each time takes O (|Ci | + |C j |) = O (I )
time to check if adding this pair would violate the 1:1 constraint.
So, the time complexity of selection is O (I J ). In practice, matched
property pairs are few and the match probability estimates are
relatively well-behaved, so Algorithm 1 runs fast.

4

goodness

discriminability

We refer to the process of deriving property cliques as holistic property matching, which takes as input the set of matched
property pairs and returns a set of property cliques. Let I, J be the
numbers of namespaces and matched property pairs from the previous logistic regression based classifier, respectively. For any two
different namespaces ns , nt , the numbers of properties under ns , nt
are denoted by Ms , Mt , and the at h , b t h properties under ns , nt
are denoted by pas , pbt , respectively. We optimize holistic property
matching by maximizing the overall match probability estimate
among all matched property pairs, such that the global 1:1 matching
constraint is satisfied:
max

2

1

= 0.5

where val (e, Ci ) extracts all the values of properties in Ci instantiating e. norm() normalizes the heterogeneous representations of
equivalent value from different sources by reusing the method in
the value similarity measure in Section 3. X is our expectation of
how many distinct values a property clique should best have for
MER. The farther the proportion of distinct values away from X,
the less discriminative the property clique is. We employ a power
function with exponent α to amplify the discriminability margin.
The left part of Figure 5 exemplifies a discriminability curve with
X = 0.25, α = 1.5.
Abundance. A property clique whose values are largely unreported may be less convincing than a clique whose values are all
known. In other words, more values provide more evidences for ER
and increase the confidence of human intervention. Let E be a set
of entities. For a property clique Ci , we define a scoring function
for its abundance on E, denoted by abund (Ci ), by counting the
proportion of entities that Ci has values for them:
X 

1
abund (Ci ) = 1 −
log
1 val (e, Ci ) , ∅ ,
(4)
log |E|
e ∈E


where 1 val (e, Ci ) , ∅ equals 1 if any property in Ci has a value

P
for e, and 0 otherwise. Clearly, we have 1 ≤ e ∈E 1 val (e, Ci ) ,

∅ ≤ |E|. The log function is used to smooth the score.
Semantics. A special kind of properties in the KG is useful for
equivalence reasoning., e.g., owl:sameAs and (inverse) functional

GOODNESS MEASUREMENT

For ER, humans often require “good” properties and values to help
them identify entity matches and non-matches. Different from pairbased ER, an MER task consists of both matched and non-matched
entities, and thus a goodness measure should simultaneously consider the commonalities and differences among multiple entities.
To this end, we propose goodness measures considering four aspects of a set of entities: discriminability, abundance, semantics and
diversity. Furthermore, we compute the goodness based on the information within one MER task instead of the whole dataset, which
eliminates the interference from irrelevant entities and accelerates
the computation process.

588

Session 5B: Entities

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

have cached the “old” results, and a comparison costs O (N ) time to
compute diversity. In total, the time complexity is O (M 2 N ).
Next, we measure the goodness of values. Given an entity, the
number of values of a property w.r.t. the entity can be very large as
well. For example, a film star may be starred in many films, or an
entity has many types. For the goodness measurement, we prefer
the values with longer length (implying more discriminative and
abundant) and reuse MMR to penalize redundant ones. Let L be the
table cell size constraint. The goodness of a value vi w.r.t. a set of
selected values W, denoted by vдood (vi ), is computed as follows:
 lenд(v )

i
vдood (vi ) = max
− δ max SV (vi , v j ), 0 ,
(11)
L
v j ∈W

properties (abbr. IFPs and FPs). For example, the semantics of an
IFP foaf:mbox claims that different entities can be inferred identical
by having the same email address. We assign a boolean score to
this special kind. Given a property clique Ci , due to Ci may contain
several properties and some of them belong to this special kind
while the others do not, the scoring function for the semantics of
Ci , denoted by sem(Ci ), is defined by averaging the scores among
all the properties in Ci :
1 X
sem(Ci ) =
sem(pa ),
(5)
|Ci |
pa ∈C i


 0 pa is owl:sameAs, IFP or FP
sem(pa ) = 
.
 1 otherwise


(6)

where lenд(vi ) counts the number of characters in vi and SV (vi , v j )
measures the value similarity as aforementioned. δ is a weighting
factor in [0, 1]. A larger score indicates a better value goodness.

Diversity. To increase the diversity and reduce the overlap
among different property cliques, we refine the maximal marginal
relevance (MMR) scheme [1] to penalize redundant property cliques.
Every time a property clique is to be selected, we compare it with
those property cliques that have already been selected and decrease
its diversity if it is largely repeating the redundant information. Let
Ci be a property clique to be selected and D be the set of already
selected property cliques. The diversity of Ci given D, denoted by
div (Ci | D), is defined as follows:
div (Ci | D) = max div (Ci | C j ),
C j ∈D
X
max
e ∈Si ∩S j

div (Ci | C j ) =

v x ∈val (e,C i )
vy ∈val (e,C j )

5

The purpose of constructing a comparative table is to help humans
attain a quick comparison of multiple entities, thus the comparative
table must fit into a limited display space (e.g., the maximal number
of table columns). Based on the goodness of property cliques, the
total score is minimized when we greedily select the set of property
cliques with lowest scores (i.e., best goodness). Therefore, the first
method that we use to select property cliques is a greedy method.
Given the maximal number B of property cliques in a comparative
table, we simply select top-B property cliques with best goodness.
Values are selected greedily as well.
However, the greedy method has a shortcoming. It cannot guarantee that each entity is at least described by several properties. In
an extreme case, if an entity is not shown in any property, then
humans cannot provide judgment on it due to lack of information.
Based on this intuition, we impose an entity coverage constraint
to comparative tables and accordingly formulate the optimization
problem of selecting property cliques with the best goodness among
those satisfying the entity coverage constraint.

(7)
SV (v x , vy )

|Si ∪ Sj |

,

(8)

where Si denotes the set of entities instantiated by properties in Ci ,
i.e., Si = {e ∈ E | val (e, Ci ) , ∅}. Sj is defined similarly. SV (v x , vy )
computes the value similarity of v x , vy . Let us revisit our example
in Figure 1. Assume that {e 1 .givenName, e 2 .alias, e 3 .altLabel} has
been selected, the diversity of {e 1 .label, e 2 .name, e 3 .label} would
be weakened due to its redundancy.
Combination. We adopt a two-phase strategy to combine the
discriminability, abundance, semantics and diversity of a property
clique. In the first phase, we combine the discriminability, abundance and semantics, because they reflect the static goodness of a
property clique. In the second phase, we refine the static goodness
with diversity. We rank the static goodness of property cliques in
ascending order and adjust the goodness of a property clique by
considering the cliques ranked in front of it. In both phases, we use
the weighted sum [14] to combine different scores. Let C be a set
of ranked property cliques. For a property clique Ci ∈ C, its overall
goodness, denoted by дood (Ci ), is computed as follows:
дood (Ci ) = γ comb (Ci ) + (1 − γ ) div (Ci | {C j }i−1
j=1 ),

COMPARATIVE TABLE GENERATION

Definition 5.1 (Optimal property clique selection with the entity
coverage constraint). Let E be the set of entities and C be the set
of property cliques, where each clique Ci ∈ C instantiates a subset
Si ⊆ E and has a goodness score. Given an entity least cover times T ,
selecting optimal property cliques for E is to select a subset D ⊆ C,
such that (1) for each e j ∈ E, there are at least T distinct property
cliques that instantiate it, and (2) the total goodness score of D is
minimized.
Optimal property clique selection with the entity coverage constraint is NP-hard, because there exists a reduction from the NPhard set cover problem [12] to it. Thus, we design an approximation
algorithm shown in Algorithm 2. In each iteration, it selects the
property clique having the best goodness effectiveness (Line 4),
which is defined as a tradeoff between the goodness of a property
clique and the size of uninstantiated entities to be instantiated by
that property clique. Let N , M denote the numbers of entities and
property cliques, respectively. In each round, the most costly step is
to examine O (M ) property cliques with each examination involving
O (N ) time to intersect two entity sets. For N entities, the total time

(9)

comb (Ci ) = β 1 discr (Ci ) + β 2 abund (Ci ) + β 3 sem(Ci ),
(10)
P
where βk ≥ 0 (k = 1, 2, 3) are weighting factors and k3 =1 βk = 1. γ
is a weighting factor in [0, 1]. The right part of Figure 5 exemplifies
a combination of discriminability, abundance and semantics.
Let N , M be the numbers of entities and property cliques, respectively. In each round, we only need to compare O (M ) property
cliques with the new one selected in the previous round, since we

589

Session 5B: Entities

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

complexity is O (MN 2 ). We prove the approximation ratio of the
algorithm below.

Algorithm 2: Property clique selection with entity coverage

Theorem 5.2. Algorithm 2 achieves approximation ratio H (N ) for
optimal property clique selection with the entity coverage constraint.1

1
2

Proof. Let us sort the entities in E in the order in which they are
fully instantiated for T times by Algorithm 2, denoted by e 1 , e 2 , . . . ,
e N . Let OPT be the goodness of an optimal solution.
Suppose that entity e j is fully instantiated by property cliques
{C jk }Tk =1 , let Ejk be the set of entities that has not been fully instantiated before C jk is picked, and D∗j be the set of property cliques
k
which the optimal solution uses to fully instantiate Ejk . Before
property clique C jk is selected, e j , e j+1 , . . . , e N are not fully instan-

3

Input: Property clique set C, entity set E, least cover times T
Output: Property clique subset D ⊆ C
D ← ∅; C′ ← C;
foreach e a ∈ E do x a ← T ;
while E , ∅ do
Select C j ∈ C′ such that

4

6
7
8

return D;

дood (C j )

tiated, thus |Ejk | ≥ N − j + 1. Because |S ∩E k | is the minimum,
jk
jk
we have
P
T
T
X
X
C ik ∈D∗j дood (Ci k )
дood (C jk )
k
price (e j ) =
≤
P
|Sjk ∩ Ejk |
C i ∈D∗j |Si k ∩ E j k |
≤

k =1
T
X

k =1

k =1

k

OPT
OPT
.
≤
T |Ejk |
N −j+1

Table 1: Statistical data of MER tasks
Domains
Person
City
Movie
Company
Building

k

Values
53,204
82,934
46,458
17,677
8,578

Domains
Natural place
Edu. institution
Written work
Sport team
Musical work

Props.
326
288
326
226
160

Values
12,937
26,287
18,034
19,756
12,977

Each task consists of 10 entities from DBpedia, Freebase, Wikidata and YAGO.

Wikidata and YAGO via owl:sameAs. Finally, we randomly selected
10 entities to constitute an MER task, as we want to let each task
have a moderate difficulty for humans. In total, we created 250 MER
tasks involving 2,500 entities and referring to 804 distinct objects.
The statistical data are detailed in Table 1.

6.2

Then, given the row and column headers (i.e., entities and selected property cliques, respectively) of a comparative table, we
fill the cells of the comparative table with values. We model the
value selection based on the classic 0/1 knapsack problem and use
a table cell size constraint L to limit the occupied space of each cell.
Let V denote maxe ∈E,Ci ∈C {|val (e, Ci )|}, the dynamic programming
algorithm costs O (V L) time to select values in each table cell. In
practice, table cells whose values need to be selected are few (see
Table 4), so value selection runs fast.
Finally, we generate a comparative table for an MER task.

Experiment on Holistic Property Matching

Quality of matched property pairs. We tried our best to reuse
existing property matches “officially” created by the dataset owners
as our gold standards. As a result, 156 reference property matches in
Freebase–Wikidata3 and 67 in DBpedia (ontology)–Wikidata4 were
found related. We used them as seed properties and complemented
their remaining matches with the other datasets. For non-matched
property pairs, we got them from the pairs having one of label, local
name and value similarities larger than 0.9. In total, 484 property
matches and 1,397 non-matches were labeled by three graduate
students in our group using majority voting. The level of agreement measured by Fleiss’s kappa [18] is 0.82, indicating a sufficient
agreement among the judges.
In addition to the logistic regression (LR) that we used in CTab,
we also tested three other combination methods in scikit-learn5 :
linear regression (LinReg), CART decision tree (DecTree) and SVM.
Furthermore, we employed two off-the-shelf OM tools: Falcon [20]
and LogMap [23], for comparison. Their default parameters were
used. We chose the conventional precision, recall and F1-score as
our metrics and carried out 10-fold cross-validation to calculate the
means of these metrics.
As shown in Figure 6, CTab (LR) obtained the best F1-score, and
the other three combination methods also got comparable results,
indicating the effectiveness of our similarity measures. For example,
CTab found dbo:almaMater ≃ yago:graduatedFrom based on the

EXPERIMENTS AND RESULTS

We implemented our approach, called CTab, on a personal workstation with an Intel Xeon E3 3.3GHz CPU and 64GB RAM, using
Virtuoso 7 to store the data and Tomcat 8 to run the Web interfaces.
In this section, we report our experimental results. The datasets,
source code, gold standards and experimental results are available
online2 .

6.1

Props.
894
499
457
416
200

(12)

As the goodness of each property clique is evenly distributed
among the new fully-instantiated entities, we have
PN
PN OPT
дood (D)
j=1 price (e j )
j=1 N −j+1
=
≤
= H (N ),
(13)
OPT
OPT
OPT
which proves the approximation ratio of Algorithm 2.
□

6

is minimized;

Add C j in D and remove it from C′ ;
foreach e a ∈ E ∩ S j do
x a ← x a − 1;
if x a = 0 then Remove e a from E;

5

9

дood (C j )
| E∩S j |

Multi-Entity Resolution Tasks

To the best of our knowledge, there is no benchmark for MER in the
KG area. We chose 10 popular domains (i.e., upper-level classes) in
terms of entity numbers in DBpedia and sampled 25 testing entities
per domain as seeds to build our own dataset. For each seed entity,
we searched its Wikipedia disambiguation page and identified 2–4
distinct entities. Then, we inferred their matches with Freebase,

3 https://www.wikidata.org/wiki/Wikidata:WikiProject_Freebase/Mapping
1 H (N )

is the N -th harmonic number.
2 http://ws.nju.edu.cn/ctab

4 http://downloads.dbpedia.org/2016-10/dbpedia_2016-10.owl
5 http://scikit-learn.org

590

Session 5B: Entities

0.5

LogMap

between the judges, measured by intraclass correlation coefficient
[30], is 0.67, indicating a good agreement among them. Following
the strategy in [22], when the three judges gave different grades
to the same property clique, we arbitrated the property clique and
assigned a more appropriate grade if the largest difference is 1 point;
otherwise we dropped this clique.
We made a comparison between CTab and two state-of-the-art
systems: FACES [16] and C3D+P [4], each representing a kind of
automatic solution for presenting ER tasks. Here, we only compared their property selection components. We would compare the
original full systems in the next subsection.
• FACES [16] is an entity summarization approach using incremental hierarchical conceptually clustering to select important property-value pairs (called features). We employed
it to provide a summary for each entity in an MER task and
displayed all the entities in a list.
• C3D+P [4] generates several pairs of aligned property-values
as a summary for two entities, by considering the commonality, conflict and informativeness. We refined it for MER by
allowing humans to select any two entities to compare.
We extended FACES and C3D+P to generate property cliques for
multiple entities. For FACES, the reference property cliques were
used to group selected properties and ranked in decreasing order
based on the summation of the score for each property in a clique.
For C3D+P, property cliques were built from the aligned property
pairs based on connected components and ranked by summing up
the scores of the aligned property pairs in a clique. For CTab, we
uniformly used the parameters in the rest of our experiments: X =
0.3, α = 1.5, β 1 = 0.45, β 2 = 0.25, β 3 = 0.3, γ = 0.84, δ = 0.1,T = 6
and L = 100. We would show the analysis of parameter sensitivity
shortly. We also developed an entropy-based scoring function as our
baseline, which measures the value distribution of each property
clique and uses entropy as its goodness.
First, we evaluated the property clique ranking quality by directly
using reference property cliques as input. We used precision at rank
B (B = 1, 5, 10) and normalized discounted cumulative gain at rank 5
(nDCG@5) in IR [22], as our metrics. Second, we assessed the quality
of property clique selection and goodness measurement together.
The evaluation metric is somehow complex, as the property cliques
found by an approach were not the same as the references, and their
rankings were also different. We employed the Hausdorff version
of the Kendall tau distance [10], denoted by K H aus (), which treats
property clique rankings as partial rankings of properties (i.e., the
properties with the same grade and in the same clique are tied):


K H aus (D, Z) = max max min K (µ,ψ ), max min K (µ,ψ ) , (14)

0.791

0.727
0.233
0.066

0.782

Falcon

0.377
0.124

CTab (LR)
0.868
0.983
0.97

SVM

0.791
0.773
0.763

0.727
0.73
0.669

DecTree
0.706

LinReg

0.877

1

0.868
0.824
0.893

CTab (LR)

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

0
Precision

Recall

F1-score

Precision

Recall

F1-score

Figure 6: Results of matched property pairs

0.422

0.648

0.548

0.741
0.55

0.43

0.4

APCluster
0.787

DBSCAN

0.64

0.65

0.558

0.6

0.789

0.8

K-medoids
0.869

CTab
1

0.2
NMI

Purity

V-measure

Figure 7: Results of derived property cliques
involved entities and WordNet sense. In total, CTab (LR) found 4,477
property matches. The two OM tools performed not well, due to: (1)
they are not particularly developed for property matching; and (2)
the complete ontologies of some datasets are unavailable currently,
thus the tools could not fully leverage their matching algorithms,
e.g., the match repair module in LogMap. In fact, property matching
is naturally harder than class matching [3], even for human experts.
Quality of derived property cliques. Based on the reference
property matches in the first experiment, we computed the connected components and derived 135 reference property cliques, excluding isolated cliques containing one property only. We compared
our holistic property matching with three well-known clustering
methods: K-medoids, DBSCAN and APCluster (“AP” means affinity
propagation)4 . The distances used in these clustering methods were
the reciprocals of the match probability estimates of property pairs
from CTab (LR). We employed the widely-used metrics for clustering assessment: NMI (normalized mutual information), purity and
V-measure (the harmonic mean of homogeneity and completeness
[29]). We tested various parameters and used the ones achieving the
best NMI scores. For K-medoids, n_clusters = 135. For DBSCAN,
min_samples = 1, eps = 0.3. For APCluster, dampinд = 0.95.
As shown in Figure 7, CTab achieved the best results according
to all the metrics. In total, CTab derived 343 non-singleton property cliques. We observed that: (1) our holistic matching algorithm
based on the match probability estimates was effective; (2) the clustering methods were not suitable for holistic property matching,
due to matching requires higher accuracy; and (3) DBSCAN was
radical to generate many single-node clusters, while APCluster was
conservative to form several very big clusters.
Running time. The most expensive step in CTab was similarity
calculation, which in average took 27 seconds per task. Other steps,
including property clique derivation, goodness measurement and
comparative table generation, were done in less than one second.

6.3

µ ⪰D ψ ⪰Z

ψ ⪰Z µ ⪰D

where µ is a refined full ranking of the property cliques D found
by an approach (written as µ ⪰ D), and ψ is similarly defined for
the references Z. K () denotes the original Kendall tau distance [24].
Useless property cliques were removed to avoid noises.
As shown in Table 2, the results of CTab are most consistent to the
rankings given by the judges, no matter using the reference property
cliques or its own goodness measurement. For FACES, its ranking
method is based on the idea of TF-IDF, which often ranked a few particular properties with high scores, e.g., fb:notable_for. C3D+P discovered similar properties (e.g., foaf:name and foaf:surname) rather

Experiment on Property Clique Selection

We developed an online system to score the non-singleton property
cliques in each MER task. Highly-useful, fairly-useful, marginallyuseful and useless property cliques in a task were graded 3, 2, 1 and
0, respectively. 24 humans in the KG and database fields, who have
experience in similar gold standard construction, were invited and
each task was scored by three judges. The average rank correlation

591

Session 5B: Entities

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Table 2: Results of selected property cliques

FACES
C3D+P
CTab (entropy)
CTab (greedy)
CTab

Using reference property cliques
P@1
P@5 P@10 nDCG@5
0.176 0.310
0.290
0.239
0.040 0.347
0.511
0.154
0.180 0.178
0.184
0.092
0.632 0.660
0.615
0.684
0.756 0.754 0.643
0.798

Table 4: Statistical analysis of value selection
Scores
Highly-useful
Fairly-useful
Marginally-useful
Total

K H aus
0.753
0.647
0.811
0.647
0.615

Table 3: Ablation study of goodness measurement
Discr.
0.678
0.675

Abund.
0.686
0.633

Sem.
0.673
0.815

w/o Div.
0.655
0.618

6.4

Goodness
0.647
0.615

0.621

0.8

Best KHaus is
achieved at
𝛾=0.84.

0.75

0.619

0.7
0.65

0.617
0.2
0.4
0.6
0.8

0.4
1.0

0

0.6

0.8

1.0

0.615
0.72
0.76
0.8
0.84
0.88
0.92
0.96
1

0.6
0

Experiment on Human Intervention in MER

We recruited real humans to use and compare full CTab, FACES
and C3D+P for MER. We carried out two independent groups of
experiments showing top-5 and top-10 properties and values to
the participants. In the top-5 (top-10) experiment, the number of
features for each entity in FACES was 5 (10), the maximum number
of features for each pair of entities in C3D+P was 10 (20), and the
entity least cover times T for a comparative table in CTab was 3 (6).
If this least cover times could not be satisfied within 5 (10) property
cliques, we only kept the top-5 (top-10) for a fair comparison.
We recruited 60 graduate students in computer science by posting ads and paid each student 15USD for participating in the experiments. Before the experiments, all the students confirmed that they
had no difficulty in English reading and well understood the goal of
the experiments. 30 participants conducted the top-5 experiment,
and the other 30 participants conducted the top-10 experiment.
During the experiments, a participant was instructed to assign a
unique group ID to the entities in an MER task referring to the same
real-world object, by observing the systems but not to use other
external resources like accessing the full information of the entities.
We offered a tutorial to the participant ahead of time and gave
her a warm-up task as a training exercise to help her familiarize
each system. Then, the participant conducted 10 randomly-selected
MER tasks for each system, and all the 30 tasks were orthogonal
to eliminate the learning effect caused by repeating on the same
task. For each system, we guaranteed that the number of tasks in
each domain was the same, e.g., a participant conducted one task
about “movie” for each system. The three systems were arranged
in a balanced order to all the participants, and thus each system
was rotated to different places equally. To further reduce potential
physiological and psychological factors, the participant was given
a one hour break before changing to another system. We recorded
the resolution results and completion time for each participant.
Once the participant completed each task, she was asked to complete a survey about task difficulty and domain familiarity, using
a five-point Likert item from 1 point to 5. We then calculated the
average scores and significance in statistics (one-way ANOVA and
LSD post-hoc) for all the systems. Table 5 shows that the task difficulty is not significantly different in statistics among the three
systems, which excluded this factor to affect the participants’ performance and ensured the fairness of the following experiments.
The participants were relatively familiar with “movie” and “written
work”, while the other domains have no difference.
Human completion time. For each system, the participants’
completion time per task is listed in Table 6, indicating that they
spent much less time on CTab than the other two systems. ANOVA
found that the differences are significant in statistics on both top-5

0.623
0.85

% of cells need to be selected
2.8%
1.4%
10.3%
5.3%

total, where the majority comes from the marginally-useful properties. We leave the validation of selected values to future work.

The best results are marked in bold. The same to the following.

K H aus
CTab (greedy)
CTab

Table cell
5,181
7,430
8,189
20,800

(1–𝛾) for diversity

(a) Weights of discriminability ( β 1 ), abundance ( β 2 ) (b) Weight of diversity (1−
and semantics ( β 3 )
γ)

Figure 8: Analysis of parameter sensitivity
than equivalent ones, which led to some incorrect or conflicting
property cliques. For the entropy-based alternative, it preferred to
pick the cliques with a large collection of values, e.g., {dbo:starring,
wd:cast_member}. The greedy alternative performed slightly worse
than CTab, which indicated the importance of entity coverage. Note
that the average running time per task for C3D+P was more than 6
minutes and much slower than the others, because it generated 45
pairwise summaries per task and some entities have many features,
e.g., fb:m.0k3p (Amsterdam) has 192 properties and 3,330 features.
Next, we conducted an ablation study on goodness measurement.
From Table 3, we observed that, for CTab and its greedy alternative,
combining the discriminability, abundance and semantics achieved
better results than only using a single measure, which were further slightly improved with diversity. Although this improvement
seems not very large, we argue that it is in fact important to the
comparative tables, especially when the number of property cliques
is small. Besides, even for discriminability, it was still better than
entropy, showing that entropy is not a suitable measure for MER.
Also, we carried out an analysis of parameter sensitivity for the
weighting factors in goodness combination (see Eqs. (9, 10)). Under
γ = 1.0, we tested weights β 1 , β 2 , β 3 from 0.0 to 1.0 with step 0.05,
and found the best result at β 1 = 0.45, β 2 = 0.25. Then, we used the
above weights and tested γ from 0.7 to 1.0 with step 0.04, and found
the best result at γ = 0.84. As shown in Figure 8, we observed that
our parameters were relatively stable in a range of parameters.
Based on the reference property clique rankings, we observed
values in each table cell (i.e., values of a property w.r.t. an entity)
exceeding our size constraint (L = 100). Table 4 shows that the
percentage of table cells whose values need to be selected is 5.3% in

592

Session 5B: Entities

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Table 5: Scores of task difficulty and domain familiarity

and top-10 experiments. The reasons are that, at each time, CTab
allowed the participants to observe 10 entities, while C3D+P only
compared two entities and FACES needed the participants to scroll
among the entities. It was surprising that the participants spent
more time on C3D+P in the top-5 experiment. The participants told
that they had to view more entity pairs before making a decision,
due to lack of consistency of features among different entity pairs.
Human precision. We assessed the participants’ precision. Assume that, given a task, x pairs of entities are judged correctly by a
participant (by breaking the entities in each entity group down to
pairs) and the gold standard contains y pairs, her precision on this
task is yx . Table 6 shows that the participants achieved a better average precision on CTab given top-5 property cliques, and ANOVA
showed the significance in statistics. However, for the top-10 experiment, the average precision of the participants all increased,
and the difference between the three systems became insignificant.
Human scoring and comments. We designed an effectiveness
assessment questionnaire to score the three systems from four different aspects, using a five-point Likert item from 1 for “totally
disagree” to 5 for “totally agree”. As depicted in Table 7, CTab presented more adequate (Q1), comparative information (Q3) and was
easier to use (Q4) than FACES and C3D+P, and ANOVA demonstrated the significance in statistics. Also, because FACES did not
well consider the diversity among entities, the scores of C3D+P and
CTab on Q2 are better than FACES.
We collected the participants’ comments. For FACES, most participants complained it not specifically designed for ER. The lack of
property matching was a major weakness. For C3D+P, most complaints were about the increased number of mouse clicks to compare all pairs of entities. For the entities in each task, C3D+P would
change feature pairs with the change of entity pairs, which really
confused the participants. Furthermore, the number of properties
for each entity was sometimes skewed due to its knapsack-based
selection method (e.g., selecting 3 features for one entity and 7 for
the other). For CTab, if the least cover times was not satisfied, a few
entities would have inadequate properties describing them (e.g.,
1.6% entities had less than three properties in the top-5 experiment).
Also, several property matches were observed not exactly identical
(e.g., fb:genre and rdfs:type).

7

Task difficulty
Domain familiarity

FACES
C3D+P
CTab
1.41 (0.38) 1.38 (0.26) 1.39 (0.32)
movie, written work > the others

p-value
77.2%
0.05%

The numbers in brackets are standard deviations. The significance levels of oneway ANOVA and LSD post-hoc were set to 5%. The same to the following.

Table 6: Results of human completion time and precision
Top-5
Time (s)
Prec.

FACES (L)
153 (51.8)
0.63 (0.16)

C3D+P (P)
208 (86.8)
0.69 (0.12)

CTab (T)
96 (27.1)
0.77 (0.14)

p-value
0.01%
0.07%

Post-hoc
P<L<T
L, P < T

Top-10
Time (s)
Prec.

FACES (L)
175 (68.5)
0.79 (0.12)

C3D+P (P)
180 (53.7)
0.77 (0.12)

CTab (T)
131 (53.1)
0.80 (0.09)

p-value
1.13%
69.8%

Post-hoc
L, P < T

mislead humans on seemingly similar entities, because some implicit evidences like transitivity and grouping may be lost during
breaking a set of entities down to pairs and switching between
different pairs (recall Figure 2 for example).
ER has also been extensively studied in other domains [5, 9, 14].
Whang et al. [35] implemented various presentations for image
pair resolution, and analyzed the factors that can improve their
effectiveness for crowdsourcing. CrowdER [34] compared pairwise
and cluster-based ER interfaces, and designed a hybrid method to
generate the minimum number of crowdsourcing tasks. Waldo [32]
proposed a hybrid approach to combine pairwise and multi-item
interfaces for image resolution, and optimized the trade-off between
cost and accuracy of the two interfaces based on task difficulty. But,
the multi-item interfaces developed by [32, 34] are very basic, which
did not consider how to extract important information of multiple
entities and organize it in a proper presentation.
Ontology matching (OM) exploits class and property matches
between different ontologies. CogZ [11] provided cognitive support
and visualization for semi-automatic OM. Fu et al. [13] compared
two common interfaces in OM tools, referred to as indented tree
and node-link graph, which both displayed two ontologies side by
side and used lines or a list to show matches. Generally, ontologies
have richer hierarchies and axioms, while entities are described by
flat property-values; OM mainly focuses on two ontologies, while
ER may involve multiple entities. So, it is difficult to directly reuse
the OM presentation approaches for ER.
Entity summarization aims to extract a small snippet of an
entity as its summary for quick access of the entity-related information. Although the summaries generated by FACES [16] and
LinkSum [31] may be useful for a single entity understanding, as
demonstrated in our experiments, it would be more effective if we
use comparative summaries specifically designed for ER. C3D+P [4]
generated pairwise summaries. REMES [17] created summaries for
multiple entities. Different from our work, its goal is to summarize
several different but context-dependent entities, e.g., Apple Computer and Steve Jobs in the same piece of news. Yan et al. [37] built
preview tables for an entity graph. However, they only focused on
summarizing a schema structure.
To the best of our knowledge, no previous methods have generated comparative tables for MER. We believe that our approach can
be integrated with current crowdsourcing platforms, e.g., Amazon
MTurk and CrowdFlower, to publish MER tasks.

RELATED WORK

Entity resolution (ER), a.k.a. entity linkage or matching, has attracted much attention in the KG community, particularly driven
by the Linking Open Data (LOD) project. While recent studies have
shown great benefits of using crowdsourcing [8, 25, 32, 34, 35, 38]
and active learning [21, 27] for ER, little effort has been made to assist human intervention in a single ER task [4]. Existing ER systems,
e.g., SameAs.org [15] and ObjectCoref [19], simply list entities in
order and show a few property-values (e.g., labels). They bring a human heavy burdens to participate in the MER tasks, because she has
to scroll up and down and compares all entities mentally. To present
entity pairs, C3D+P [4] extracted pairwise summaries with a quadratic knapsack algorithm on matched property-values. However,
ER often involves entities from several sources [32] and pairwise
comparison cannot scale. Moreover, its pairwise comparison may

593

Session 5B: Entities

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Table 7: Results of human scoring for effectiveness assessment
Questions [from 1: “totally disagree” to 5: “totally agree”]
Q 1. The system provided adequate information of entities.
Q 2. The system provided unsuperfluous information of entities.
Q 3. The system helped me easily compare entities of interest.
Q 4. I found the system easy to use.

8

FACES (L)
3.11 (1.25)
2.67 (1.02)
2.43 (1.17)
3.00 (1.11)

CONCLUSION

In this paper, we proposed an automated approach to generating
comparative tables that can facilitate human intervention in MER.
In summary, we presented a holistic property matching method
that combined three kinds of similarity measures and optimized
the discovery of property cliques under constraint. We designed
various goodness functions to score the discriminability, abundance,
semantics and diversity of property cliques. We formulated the optimal comparative table generation problem and designed efficient
algorithms. By comparing with existing methods and conducting
user study, our experimental results showed the superior efficiency,
precision and user satisfaction of our approach in MER. In future
work, we plan to study the feasibility of combining comparative
tables with other presentation enhancements as a hybrid approach.
We also want to extend our work to other areas such as knowledge
base summarization.

[14]

ACKNOWLEDGMENTS

[22]

This work is supported by the National Natural Science Foundation
of China (No. 61772264), and the Collaborative Innovation Center
of Novel Software Technology and Industrialization. Part of this
work was done during Wei Hu’s visit to University of Toronto.

[23]

[15]

[16]

[17]

[18]

[19]
[20]
[21]

[24]
[25]

REFERENCES
[26]
[1] Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based
reranking for reordering documents and producing summaries. In SIGIR. ACM,
Melbourne, Australia, 335–336.
[2] Michelle Cheatham and Pascal Hitzler. 2013. String similarity metrics for ontology
alignment. In ISWC, Part II, Vol. LNCS 8219. Springer, Sydney, Australia, 294–309.
[3] Michelle Cheatham and Pascal Hitzler. 2014. The properties of property alignment.
In ISWC Workshop on Ontology Matching. CEUR-WS, Trentino, Italy, 13–24.
[4] Gong Cheng, Danyun Xu, and Yuzhong Qu. 2015. C3D+P: A summarization
method for interactive entity resolution. Journal of Web Semantics 35 (2015),
203–213.
[5] Peter Christen. 2012. Data matching: Concepts and techniques for record linkage,
entity resolution, and duplicate detection. Springer, Berlin, Germany.
[6] William W. Cohen, Pradeep Ravikumar, and Stephen E. Fienberg. 2003. A comparison of string distance metrics for name-matching tasks. In IIWEB. AAAI
Press, Acapulco, Mexico, 73–78.
[7] Yves Crama and Frits C.R. Spieksma. 1992. Approximation algorithms for threedimensional assignment problems with triangle inequalities. European Journal
of Operational Research 60, 3 (1992), 273–279.
[8] Gianluca Demartini, Djellel Eddine Difallah, and Philippe Cudrè-Mauroux. 2012.
ZenCrowd: Leveraging probabilistic reasoning and crowdsourcing techniques
for large-scale entity linking. In WWW. ACM, Lyon, France, 469–478.
[9] Ahmed K. Elmagarmid, Panagiotis G. Ipeirotis, and Vassilios S. Verykios. 2007.
Duplicate record detection: A survey. IEEE Transactions on Knowledge and Data
Engineering 19, 1 (2007), 1–16.
[10] Ronald Fagin, Ravi Kumar, Mohammad Mahdian, D. Sivakumar, and Erik Vee.
2004. Comparing and aggregating rankings with Ties. In PODS. ACM, Paris,
France, 47–58.
[11] Sean M. Falconer and Margaret-Anne Storey. 2007. A cognitive support framework for ontology mapping. In ISWC/ASWC, Vol. LNCS 4825. Springer, Busan,
Korea, 114–127.
[12] Uriel Feige. 1998. A threshold of ln n for approximating set cover. J. ACM 45, 4
(1998), 634–652.
[13] Bo Fu, Natalya F. Noy, and Margaret-Anne Storey. 2013. Indented tree or graph?
A usability study of ontology visualization techniques in the context of class

[27]

[28]
[29]

[30]
[31]

[32]

[33]
[34]

[35]
[36]

[37]

[38]

594

C3D+P (P)
3.17 (1.06)
3.30 (0.95)
3.37 (1.07)
3.13 (1.22)

CTab (T)
3.70 (1.03)
3.23 (1.30)
4.00 (1.17)
3.70 (1.15)

p-value
0.76%
4.46%
< 0.01%
2.28%

Post-hoc
L, P < T
L < T, P
L<P<T
L, P < T

mapping evaluation. In ISWC, Part I, Vol. LNCS 8218. Springer, Sydney, Australia,
117–134.
Lise Getoor and Ashwin Machanavajjhala. 2012. Entity resolution: Tutorial. In
PVLDB, Vol. 5. VLDB, Istanbul, Turkey, 2018–2019.
Hugh Glaser, Afraz Jaffri, and Ian C. Millard. 2009. Managing co-reference on
the semantic web. In WWW Workshop on Linked Data on the Web. CEUR-WS,
Madrid, Spain, 6.
Kalpa Gunaratna, Krishnaparasad Thirunarayan, and Amit Sheth. 2015. FACES:
Diversity-aware entity summarization using incremental hierarchical conceptual
clustering. In AAAI. AAAI Press, Austin, TX, USA, 116–122.
Kalpa Gunaratna, Amir Hossein Yazdavar, Krishnaparasad Thirunarayan, Amit
Sheth, and Gong Cheng. 2017. Relatedness-based multi-entity summarization. In
IJCAI. IJCAI Organization, Melbourne, Australia, to appear.
Harry Halpin, Daniel M. Herzig, Peter Mika, Roi Blanco, Jeffrey Pound, Henry S.
Thompson, and Thanh Tran Duc. 2010. Evaluating ad-hoc object retrieval. In
ISWC Workshop on Evaluating Semantic Technologies. CEUR-WS, Shanghai, China,
9.
Wei Hu and Cunxin Jia. 2015. A bootstrapping approach to entity linkage on the
semantic web. Journal of Web Semantics 34 (2015), 1–12.
Wei Hu and Yuzhong Qu. 2008. Falcon-AO: A practical ontology matching system.
Journal of Web Semantics 6 (2008), 237–239.
Robert Isele and Christian Bizer. 2013. Active learning of expressive linkage rules
using genetic programming. Journal of Web Semantics 23 (2013), 2–15.
Kalervo Järvelin and Jaana Kekäläinen. 2000. IR evaluation methods for retrieving
highly relevant documents. In SIGIR. ACM, Athens, Greece, 41–48.
Ernesto Jiménez-Ruiz and Bernardo Cuenca Grau. 2011. LogMap: Logic-based and
scalable ontology matching. In ISWC, Vol. LNCS 7031. Springer, Bonn, Germany,
273–288.
Maurice George Kendall. 1938. A new measure of rank correlation. Biometrika
30, 1/2 (1938), 81–93.
Fenglong Ma, Yaliang Li, Qi Li, Minghui Qiu, Jing Gao, Shi Zhi, Lu Su, Bo Zhao,
Heng Ji, and Jiawei Han. 2015. FaitCrowd: Fine grained truth discovery for
crowdsourced data aggregation. In KDD. ACM, Sydney, Australia, 745–754.
Imen Megdiche, Olivier Teste, and Cassia Trojahn. 2016. An extensible linear
approach for holistic ontology matching. In ISWC, Part I, Vol. LNCS 9981. Springer,
Kobe, Japan, 393–410.
Axel-Cyrille Ngonga Ngomo, Klaus Lyko, and Victor Christen. 2013. COALA
– Correlation-aware active learning of link specifications. In ESWC, Vol. LNCS
7882. Springer, Montpellier, France, 442–456.
Arthur O’Sullivan and Steven M. Sheffrin. 2003. Economics: Principles in action.
Pearson Prentice Hall, Upper Saddle River, NJ, USA.
Andrew Rosenberg and Julia Hirschberg. 2007. V-Measure: A conditional entropybased external cluster evaluation measure. In EMNLP-CoNLL. ACL, Prague, Czech
Republic, 410–420.
Patrick E. Shrout and Joseph L. Fleiss. 1979. Intraclass correlations: Uses in
assessing rater reliability. Psychological Bulletin 86, 2 (1979), 420–428.
Andreas Thalhammer, Nelia Lasierra, and Achim Rettinger. 2016. LinkSUM:
Using link analysis to summarize entity data. In ICWE, Vol. LNCS 9671. Springer,
Lugano, Switzerland, 244–261.
Vasilis Verroios, Hector Garcia-Molina, and Yannis Papakonstantinou. 2017.
Waldo: An adaptive human interface for crowd entity resolution. In SIGMOD.
ACM, Chicago, IL, USA, 1133–1148.
Iris Vessey. 1991. Cognitive fit: A theory-based analysis of the graphs versus
tables literature. Decision Sciences 22, 2 (1991), 219–240.
Jiannan Wang, Tim Kraska, Michael J. Franklin, and Jianhua Feng. 2012. CrowdER:
Crowdsoucing entity resolution. In PVLDB, Vol. 5. VLDB, Istanbul, Turkey, 1483–
1494.
Steven Euijong Whang, Julian McAuley, and Hector Garcia-Molina. 2012. Compare me maybe: Crowd entity resolution. Technical Report. Stanford University.
Chuncheng Xiang, Baobao Chang, and Zhifang Sui. 2015. An ontology matching
approach based on affinity-preserving random walks. In IJCAI. IJCAI Organization, Buenos Aires, Argentina, 1471–1477.
Ning Yan, Sona Hasani, Abolfazl Asudeh, and Chengkai Li. 2016. Generating
preview tables for entity graphs. In SIGMOD. ACM, San Francisco, CA, USA,
1797–1811.
Yudian Zheng, Guoliang Li, and Reynold Cheng. 2017. DOCS: A domain-aware
crowdsourcing system using knowledge bases. In VLDB. VLDB Endowment,
Munich, Germany, 361–372.


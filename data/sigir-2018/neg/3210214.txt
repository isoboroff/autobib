SIRIP: Industry Days

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

The City Brain:
Towards Real-Time Search for the Real-World
Xian-Sheng Hua
DAMO Academy, Alibaba Group
969 West Wenyi Road, Hangzhou, Zhejiang Province, China
xiansheng.hxs@alibaba-inc.com

Figure 1: 100-feet view of the City Brain.

ABSTRACT

1 INTRODUCTION

A city is an aggregate of a huge amount of heterogeneous data.
However, extracting meaningful values from that data remains
challenging. City Brain is an end-to-end system whose goal is to
glean irreplaceable values from big city data, specifically from
videos, with the assistance of rapidly evolving AI technologies
and fast-growing computing capacity. From cognition to
optimization, to decision-making, from search to prediction and
ultimately, to intervention, City Brain improves the way we
manage the city, as well as the way we live in it. In this talk,
firstly we will introduce current practices of the City Brain
platform in a few cities in China, including what we can do to
achieve the goal and make it a reality. Then we will focus on
visual search technologies and applications that we can apply on
the city data. Last, a few video demos will be shown, followed by
highlighting a few future directions of city computing.

There have been two golden times of Artificial Intelligence in
the past decades, though eventually we found that they were
only dreams. Today we are experiencing the third wave. Many
people are wondering that whether this time there will be
something different, or it will be a dream again.
Actually, there are indeed quite a few differences in this
wave. First, deep learning techniques have been widely applied
ina large number of AI applications, and have surpassed many
conventional approaches. Second, huge computing capacity is
accessible to public through either cloud services or powerful
computing devices at edge side (such GPU and FPGA). Third,
massive amount of data is available to many algorithms and
applications. In addition, quite a few successful AI applications
have already emerged, such as search engines that we have been
using every day, face verification that allows you to verify your
ID automatically, car license plate recognition so you will never
forget where you parked your car, and recommendation system
that knows what you will purchase next better than yourself.
All these have shown that considerable progresses have been
made on AI technologies, which also enlightened us to start this
challenging project, that is, to create a brain for a city.
A city is a bond of a huge amount of heterogeneous data,
among which, traffic monitoring video data is one of the most
important data type. In a first tier city in China, for example,
there are tens of thousands, or even hundreds of thousands of
video cameras monitoring the traffic of the city. This data is
accumulating endlessly, but how can we get the values from
those data, instead of only using them to catch traffic violations?
That is the primary reason that we come up with the idea to
create a “data brain” for a city, which aggregates, learns, detects,

CCS CONCEPTS
• Information systems → multimedia information systems;
data mining; • Computing methodologies → computer vision

KEYWORDS
City brain, Cloud computing, Artificial Intelligence, Smart City
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full
citation on the first page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the Owner/Author.
SIGIR '18, July 8–12, 2018, Ann Arbor, MI, USA
© 2018 Copyright is held by the owner/author(s).
ACM ISBN 978-1-4503-5657-2/18/07.
https://doi.org/10.1145/3209978.3210214

1343

SIRIP: Industry Days

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

recognizes, searches this data and mines and predicts from data.
The core of a city brain is to compute the data to get
irreplaceable values from it, and based on which we change the
the way we manage the city and change the way live in the city.

Many feature learning approaches can be divided into two
steps. One step is to learn feature by recognition tasks, in which
typically a multi-task learning infrastructure is used to make the
network recognize categories, identities, and attributes of the
objects. The second step is to use pairwise loss or triplet loss to
tune the network. These two steps can also be integrated into
one single-step.
From another point of view, features can be learned in three
different levels: global level, patch level, or key-points level.
Global feature is efficient for finding possible candidates, but
frequently not effective in revealing local characteristics. Part or
patch based feature learning tries to link the corresponding parts
in a pair of related images. One approach is to define a patch
based correlation loss in lower-level feature maps, which is then
added into the global feature based loss. More details about
feature learning can be found in [3].

2 OVERVIEW OF CITY BRAIN
In this project, the challenges we are facing are all about three
keywords: cost, value, and difference. Whether the cost for such
a big computation, storage and network intensive task is
manageable, whether the technology is ready to get the values
from those data, and whether the values are sufficiently
significant. What has been challenged even more is that where
are the differences compared with “smart city”, “video
surveillance”, and “edge computing”.
These questions can be well answered by taking a closer look
at the city brain (Figure 1). Firstly, we have a bunch of data from
the city, including the video data. The first step is to acquire the
data and understand the data. We call this step “Cognition”,
which includes recognizing what are on the road, and what are
happening on the road, such as the cars, the people, the cyclist,
the traffic status, the accidents, and so on [1].
Then, the second step “Decision and Optimization”, we make
decisions or optimize the ways we run the city based on the
cognitive results, for example, automatic accident alerting [2],
traffic light optimization.
Thereafter, in the “Search and Mining” step, we put
everything the cameras have seen into a database and build an
index, thus we can apply search on this data. For example, we
find a suspicious car, or discover patterns among in the data,
such as finding the root cause of a traffic congestion somewhere
in the city [3].
Next, based on current and historic data, we can predict what
is going to happen next, either in a short period of time, such as
the traffic congestion possibility after 20 minutes for an
intersection, or next day’s accident possibility of a road section,
given the weather condition and event information of the city.
Last, based on prediction results, resources can be preallocated to respond those situations more effectively. For
example, if we know the possibility of accident will increase 3
times given the bad weather tomorrow as well as a few events
that will gather a large number of people, we can adjust the
traffic lights and send traffic advice to prevent those bad things
from happening. We call this “Prediction” and “Intervention”.
In the remaining part of this presentation, we will present
more details about the search and mining part, including feature
learning and large-scale search system.

3 LARGE-SCALE VISUAL SEARCH SYSTEM
In the real-world, besides feature learning, large-scale visual
search is more of a problem of scalability, including the indexing
part and searching part.
In the indexing step, images and/or videos are sent into the
system, followed by object detection, recognition and feature
extraction. And then we convert the (high-dimensional) features
into an inverted index and put it into multiple machines. We
often call a group of machines that holds one entire index a
“row”. One particular node in the row is called a searcher. For a
real-world system, we often have multiple rows so we can
balance the workload and back up for each other.
In the search step, a query image will be sent to an online
service to do detection, recognition and feature extraction. And
then the output is sent to one particular row and every searcher
in the row will do the search in the part of index it holds and
return top N results to a higher level aggregator. And then the
aggregated results are re-ranked and returned to the user. More
details about indexing and ranking can be found in [4].

4 CONCLUSIONS
In summary, we introduced the City Brain project, which aims at
extracting meaningful and irreplaceable values from an
aggregate of a huge amount of heterogeneous data, with a focus
on city-scale visual search technologies and applications. As we
have talked before, current new technologies empowered AI and
thus we have the capability to create city brain, and with the city
brain as a platform, we believe, we can incubate, hasten and
solidify many more AI technologies and applications in future.

3 FEATURE LEARNING

REFERENCES

To find an effective representation for the visual objects (car,
people, etc.), a.k.a., feature learning is the primary challenge of
the visual search function (which is called re-identification in
literature) in City Brain. With deep learning technique, we have
the flexibility to design a network structure and loss function to
force the network to converge to a stage that can generate
representative features from the pixels.

[1] W. Chu et al. Multi-Task Vehicle Detection With Region-of-Interest Voting.
IEEE Transactions on Image Processing, vol. 27, no. 1 (2018).
[2] Y. Zhao et al. Spatio-Temporal AutoEncoder for Video Anomaly Detection.
ACM Multimedia 2017.
[3] C. Shen et al. Deep Siamese Network with Multi-level Similarity Perception for
Person Re-identification. ACM MM 2017.
[4] J. Wang et al. A Survey on Learning to Hash. IEEE Transactions on Pattern
Analysis and Machine Intelligence (TPAMI), 2018.

1344


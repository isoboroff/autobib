Short Research Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

CA-LSTM: Search Task Identification with Context Attention
based LSTM
Cong Du

Peng Shu

Yong Li

Sogou Inc.
Beijing, China
ducong@sogou-inc.com

Sogou Inc.
Beijing, China
shupeng203672@sogou-inc.com

Sogou Inc.
Beijing, China
liyong209804@sogou-inc.com

ABSTRACT

are finally resolved. The task identification can be solved via binary
same task classification for all pairs of queries, which is efficient in
linking a new query to the existing task. However, queries in a very
long query chain can potentially fall in different tasks. Clustering
methods, in the contrast, focus on a group of queries instead of
query pairs and extracts the task in a global view. Generally, query
clustering is applied to a certain scope, including search session,
user session, and the entire query logs; thus, the tasks extracted are
of various granularities. However, a major limitation in existing task
extraction methods is that clustering queries using topic cohesion
fails to handle the evolving user’s intention over time. For example,
a query of "avatar"1 may indicate that the user is searching for movie
information if the following query is "best movie" or "movie tickets
avatar." However, if the "avatar" query is followed by queries such
as "blogs upload" and "avatar upload," the user is likely to focus
on web blog settings and change their avatar image. Therefore,
modeling the progressive nature of user’s intention is significant.
To address this problem, we adopt sequential context knowledge
in search query logs which is intuitively crucial to understanding
how queries associate with each other within a period of time.
In this paper, we exploit sequential context knowledge in an
end-to-end model using a long short-term memory (LSTM) with an
attention mechanism to divide a user session into search session
segments. The LSTM network is the most suitable architecture
for sequence processing for its ability for storing context memory.
The model essentially learns which parts of the query context are
important in the session segmentation task. The search session
segments are considered as the user’s atomic intentions. With these
session segments, we use an efficient clustering using a novel query
similarity metric from web-scale query logs to group and extract
search tasks of the user.
The contribution of this paper is a novel technique for search
session segmentation using a LSTM network with attention mechanism. To the best of our knowledge, this is the first work to optimize
search session segmentation for the task identification problem.
We show that accurately segmented search sessions can significantly improve existing search task identification methods using
real-world datasets.

Search task identification aims to understand a user’s information
needs to improve search quality for applications such as query
suggestion, personalized search, and advertisement retrieval. To
properly identify the search task within long query sessions, it is
important to partition these sessions into segments before further
processing. In this paper, we present the first search session segmentation model that uses a long short-term memory (LSTM) network
with an attention mechanism. This model considers sequential context knowledge, including temporal information, word and character, and essentially learns which parts of the input query sequence
are relevant to the current segmentation task and determines the influence of these parts. This segmentation technique is also combined
with an efficient clustering method using a novel query relevance
metric for end-to-end search task identification. Using real-world
datasets, we demonstrate that our segmentation technique improves
task identification accuracy of existing clustering-based algorithms.

KEYWORDS
Search Session Identification, Long Short-Term Memory Recurrent
Neural Network, Attention Mechanism.
ACM Reference Format:
Cong Du, Peng Shu, and Yong Li. 2018. CA-LSTM: Search Task Identification
with Context Attention based LSTM. In SIGIR ’18: The 41st International
ACM SIGIR Conference on Research & Development in Information Retrieval,
July 8–12, 2018, Ann Arbor, MI, USA. ACM, New York, NY, USA, 4 pages.
https://doi.org/10.1145/3209978.3210087

1

INTRODUCTION

Web search engines satisfy a user’s information needs by ranking
webpages in response to a query. Users commonly accomplish multiple tasks using a long sequence of search queries. To understand
a user’s search intentions, it is important to identify the search session that a query belongs to. Search task extraction is increasingly
recognized as valuable for improving downstream search engine
applications such as query suggestion, personalized search, and
advertisement retrieval [7, 19].
Search task identification is challenging because it is difficult to
track how and when a user’s search intentions originate, evolve, and

2

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGIR ’18, July 8–12, 2018, Ann Arbor, MI, USA
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00
https://doi.org/10.1145/3209978.3210087

RELATED WORK

There has been much work focused on the problem of identifying
search sessions and search tasks from the query logs. Many early
works used the idea of a "timeout" cutoff between queries, where
two consecutive queries are considered two different sessions if the
time interval between them exceeds a certain threshold [4, 8, 14].
A 30-min timeout is used to segment sessions frequently [3, 14, 22].
1 Avatar,

marketed as James Cameron’s Avatar, is a 2009 American epic science fiction
film directed, written, produced, and co-edited by James Cameron.

1101

Short Research Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Query Representations

...

ai

ai+1

...

ai+m

LSTM

ai-n

Concatenation
characters

words

time
interval

LSTM Networks

LSTM

LSTM

LSTM

LSTM

renting house

renting in lawton oklahoma

...

The cat sat on the mat

wedding pictures

...

...

ea games

3

Embedding Layer

LSTM

However, the timeout cutting methods have difficulties reaching
higher accuracies.
Jones et al. [10] combined the literature features and employed
binary classifiers including logistic regression and a decision tree
to identify the same-task queries and the hierarchy of the search
tasks. Kotov et al. [1] and Agichtein et al. [11] also applied the
binary same-task classification to the cross-session task extraction,
and found that the different types of tasks demonstrated different
life spans. The same-task classification applies on a pair of queries.
A drawback of the pairwise predictions is that they need postprocessing to obtain the final task partitions.
Instead of the classification approaches, Lucchese et al. [16, 17]
proposed using clustering methods to group the search queries
into tasks. They adopted Levenshtein distance, Jaccard similarity
coefficient and external semantic data to measure the cohesion of
two queries. In order to better evaluate the semantic relatedness
between queries, more advanced models such as Latent Dirichlet
allocation (LDA) model with the Hawkes processes [12] and query
topic transition model [13] were proposed. Mehrotra et al. [20]
focused on extracting the hierarchies of tasks using an efficient
Bayesian nonparametric model. In general, search task identification applies clustering on a search session, which is roughly based
on a timeout criterion. Therefore, an improvement in the search
session segmentation can potentially better support the clustering
task identification approaches.
User session detection methods also provided inspiration for the
search session identification, although these two tasks are relevant.
Mehrotra et al. [18] and Halfaker et al. [6] tried to identify user
session boundaries using the Gaussian mixture model to detect
more precise user session threshold.

Attention & Softmax Layer

Figure 1: The CA-LSTM model for detecting the search session boundary between the query qi and qi +1 with the query
sequence qi−n , ..., qi , qi+1 , ..., qi+m .
vw is the word vocabulary. The length of the vector Wj is sw j which
depends on how many words in query q j .
We adopt LSTM networks to embed query words and characters
separately. Each word w k in the sequence Wj is first embedded into
distributed vector with word/character lookup matrix, and then
conveyed to LSTM network chronologically. The LSTM network
produces the last hidden state as the resulting representation vector
Ŵj ∈ Rmw where mw is the hidden size of LST Mw :
W̄j = LST Mw (Wj )[−1]

(2)

Notably, we use an initialization strategy to embed words during
training process. We introduce pre-trained word vectors from GloVe
data [21] to initialize a word lookup matrix for stable and fast
convergence.
In the same way as the words, we also process the characters of
the queries and generate the sequence of query representation in
character embeddings seqC. Here, these two sequences of query representations seqW̄ and seqC̄ are conveyed to two LSTM networks:

ATTETION BASED SEARCH SESSION
SEGMENTATION

Search session segmentation aims to break a query stream of a
user into session segments by detecting the boundary between
two adjacent queries. Given two adjacent queries in the sequence
qi , qi+1 ∈ Qu where Qu is the query set of user u for a period of
time, the model produces the predicting label ŷi,i+1 ∈ {0, 1} to
identify if qi and qi+1 belong to a same search session segment.
Figure 1 describes the structure of the model. We extract the
sequence of words and the sequence of characters from the query
sequence. We separately feed these two sequences to embedding
layers and LSTM layers to produce corresponding hidden representations. Then we concatenate these two hidden representations
along with the time interval sequence vectors and preserve the time
step of these vectors. An attention mechanism attached on the top
of the LSTM layers learns where and how much to pay attention
to the context of the sequence. The softmax layer generates the
predicting result ŷi,i+1 , which indicates whether qi and qi + 1 cross
a session boundary.
Definition: seqP denotes a common sequential structure of time
step n + m + 1. Each placeholder P j in the sequence represents a
certain category of information corresponding to query j:
seqP = [Pi−n , ..., Pi , Pi+1 , ..., Pi+m ]
(1)
Input sequence of words seqW is a n + m + 1 time step sequence
including n + m + 1 words vectors Wj . Wj = [w 1 , ..., w sw j ] is a
sequence of all one-hot word/character vectors w k ∈ Zv2 w where

w w
w
hw = [hw
i−n , ..., hi , hi,i+1 , ..., hi+m ] = LST M a (seqW̄ )

(3)

hc = [hci−n , ..., hci , hci,i+1 , ..., hci+m ] = LST Mb (seqC̄)
(4)
m
×(n+m+1)
m
×(n+m+1)
a
b
We concatenate hw ∈ R
, hc ∈ R
and vt ∈
R2×(n+m+1) into a n+m+1 time step vector H . Therefore, H contains
full knowledge of every query in the sequence including word,
character and time infomation. ma and mb are the hidden sizes of
LST Ma and LST Mb ; H ∈ R(ma +mb +2)×(n+m+1) ; vt is identical to
seqT , which is a n + m time step sequence including n + m + 1 time
vectors T j , where T j has two time intervals: t 1 is time gap between
query q j and q j−1 and t 2 is time gap between query q j and q j+1 .
H = [hw ; hc ; vt ]

(5)

Similar to Bahdanau’s method [2], the attention layer essentially
learns the importance of each time step in sequence vectors H
with respect to the resulting label ŷi,i+1 , which corresponds to
whether query qi and qi+1 are of the same search session segment.
The output context calculated via the attention layer with H is
described as below:
Õ
context =

aj Hj

n+m+1

The weight at of each annotation H j is computed by

1102

(6)

Short Research Papers II

exp(e j )
,
n+m+1 exp(e j )

at = Í

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

e j = wu tanh(w a H j + ba )

clusters a pre-segmented session by time interval to discover the
search tasks. Rose-Tree [20] is a Bayesian nonparametric model
for extracting hierarchies tasks with Bayesian Rose Trees. LDAHawkes [12] combines the LDA model with Hawkes processes to
solve the identification problem by employing both temporal and
textual features.
Table 1 and 2 illustrate the performances of the following three
baseline methods and the best result of the proposed method for
comparison. Table 1 illustrates that the models accurately predict
search session segmentation on both datasets. With respect to the
session segmentation task, our proposed sequential context model
outperforms the other baselines because it exploits the time factor
along with query cohesion in the context whereas other methods
manipulate the task extraction on pre-segmented search sessions,
typically using a 26-min timeout.
Table 1: Comparison in Session Segmentation

(7)

where e is the score function; wu ∈ Rr , w a ∈ Rr ×(ma +mb +2) and
ba ∈ Rr are the variables in the attention layer; r is the attention
hidden size. The softmax layer computes ŷi,i+1 with the context:
ŷi,i+1 = so f tmax(context)

4

(8)

CLUSTERING ON SEARCH SESSION
SEGMENTS

The model partitions the user’s search query logs into a number
of session segments and these smaller sets of consecutive queries
can be considered as the atomic user’s intentions. Owing to the
user’s behavior of multi-tasking search, a single task is likely to
be interleaved. As a consequence, a search task is composed of
one or more similar search session segments. We address the problem using a query clustering algorithm QC-HTC [16, 17] which is
used in solving fragments clustering with "head and tail" technique
where a distance function µ is a linear combination of µl ex ical
and µ semant ic . Lexical distance captures the literature similarity
between two queries and it is comprised of Jaccard coefficient, edit
distance and cosine similarity between the term sets of the queries.
The meaning in logic and language between the two queries described as the semantic distance is calculated using the following
metrics. First, the cosine of two query embedding vectors obtained
by averaging the vector representations of each of their query
terms [21]. Second, the search query affinity provided by the vector
propagation algorithm [9] trained on web-scale click-through logs.

accuracy
Dataset
Gayo-Avello’s
SogouQ
Rose-Tree
0.885
0.836
QC-HTC
0.862
0.823
LDA-Hawk
0.876
0.828
CA-LSTM
0.907
0.852
All bold numbers indicate statistical significance at p 6 0.05
compared to the baseline Rose-Tree.
Table 2 demonstrates that the proposed clustering method using
the segments in the first step also receives higher F 1 score and F 0.6
score. The improvement brought by the model in the search task extraction is not as remarkable as it performs in session segmentation
task because the errors accumulate in the two-step methods. Minor
error from session segments in the first step can be magnified by
the clustering process in the second step.

5 EXPERIMENT
5.1 DATASET
There are two public corpora available from the major search engines. Gayo-Avello’s corpus [5] consists of 11,484 queries from 215
users sampled from the 2006 AOL query log to be representative
of typical querying behavior (e.g., ratio of repeated queries, clickthrough rate). A sampled SogouQ corpus [15], which consists of
18,600 queries from 532 users that were extracted in April 2017.

5.2

Table 2: Comparison in Task Identification
F1
F 0.6
GayoSogouQ
GayoSogouQ
Avello’s
Avello’s
Rose-Tree
0.878
0.843
0.874
0.836
0.851
0.821
0.855
0.820
QC-HTC
LDA-Hawk
0.871
0.837
0.864
0.828
CA-LSTM
0.883
0.851
0.887
0.846
All bold numbers indicate statistical significance at p 6 0.05 compared to the baseline Rose-Tree.
Dataset

SETTINGS AND EVALUATION

We conducted twofold experiments and evaluations. First, we first
justified the effectiveness of the proposed search session segmentation method. The comparison between our LSTM segmentation
method and state-of-art task identification methods is applicable
because task identification methods naturally partition search logs
into fragments. Here, we used accuracy as the metric indicating
the ability of detecting session boundaries of the models. Second,
we demonstrate evaluation of proposed method compared to other
methods on search task identification and use a general metric F 1
measure (β = 1) and its varient F 0.6 measure (β = 0.6) to lend

Table 3: Session Segmentation Accuracy with Different
Available Context Query Number

Gayo-Avello’s
SogouQ

(1+β 2 )·p ·r

more weight to precision: F β = β 2 ·p+r , where p denotes the
percentage of query pairs in our predicted search tasks that also
appear in the same ground-truth task, and r denotes the percentage
of query pairs in the ground-truth tasks that also appear in the
same predicted task.
We evaluated the proposed predictive model with a 10-fold cross
validation strategy and compared it against three base line algorithms: QC-HTC, Rose-Tree, and LDA-Hawkes. QC-HTC [16, 17]

2
0.863
0.814

available context query number
4
6
8
10
0.878
0.904
0.898
0.903
0.846
0.851
0.855
0.853

To further verify the contribution of context, we conducted experiments in which context queries were substituted for random
noise, as shown in Table 3. For instance, in the 10 time-step setting,
a context window size of 2 denotes that queries at positions 1-4 and
7-10 are replaced by normally distributed random noise vectors,
making only queries at positions 5 and 6 available for the model.
We initially used noise context of size 8, and then reduced the size

1103

Short Research Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

of the noise context and expanded the available context window at
each step. The model predicts better in the case of larger context
window sizes, which demonstrates the effectiveness of introducing
context into session segmentation.
Figure 2a demonstrates the cosine distances of the word embedding vectors from the embedding layer of the CA-LSTM model.
Figure 2b is a scatter plot visualizing high-dimensional data of the
word embedding vectors with the t-SNE algorithm. We particularly
select the point of "paul" to illustrate the top 20 most similar points
of word, such as "michael" and "peter", in the two subfigures.

a

this task can be supported by many additional models producing
new knowledge. Furthermore, we hope to study on an unsupervised model that provides precise session boundary detection with
enormous search query logs from the major search engines.

REFERENCES
[1] Eugene Agichtein, Ryen W. White, Susan T. Dumais, and Paul N. Bennet. 2012.
Search, Interrupted: Understanding and Predicting Search Task Continuation. In
Proceedings of the 35th International ACM SIGIR Conference (SIGIR ’12). ACM.
[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural Machine
Translation by Jointly Learning to Align and Translate. CoRR abs/1409.0473
(2014). arXiv:1409.0473
[3] Huanhuan Cao, Daxin Jiang, Jian Pei, Qi He, Zhen Liao, Enhong Chen, and Hang
Li. 2008. Context-aware Query Suggestion by Mining Click-through and Session
Data. In Proceedings of the 14th ACM SIGKDD International Conference (KDD ’08).
ACM.
[4] Ayse Göker and Daqing He. 2000. Analysing Web Search Logs to Determine
Session Boundaries for User-Oriented Learning. In Proceedings of the International
Conference on Adaptive Hypermedia and Adaptive Web-Based Systems (AH ’00).
Springer-Verlag.
[5] Matthias Hagen, Jakob Gomoll, Anna Beyer, and Benno Stein. 2013. From Search
Session Detection to Search Mission Detection. In Proceedings of the 10th Conference on Open Research Areas in Information Retrieval (OAIR ’13).
[6] Aaron Halfaker, Oliver Keyes, Daniel Kluver, Jacob Thebault-Spieker, Tien T.
Nguyen, Kenneth Shores, Anuradha Uduwage, and Morten Warncke-Wang. 2014.
User Session Identification Based on Strong Regularities in Inter-activity Time.
CoRR abs/1411.2878 (2014). arXiv:1411.2878
[7] Ahmed Hassan Awadallah, Ryen W. White, Patrick Pantel, Susan T. Dumais, and
Yi-Min Wang. 2014. Supporting Complex Search Tasks. In Proceedings of the 23rd
ACM International Conference on CIKM (CIKM ’14). ACM.
[8] Daqing He, Ayse Göker, and David J. Harper. 2002. Combining Evidence for
Automatic Web Session Identification. Inf. Process. Manage. 38, 5 (Sept. 2002).
[9] Shan Jiang, Yuening Hu, Changsung Kang, Tim Daly, Jr., Dawei Yin, Yi Chang,
and Chengxiang Zhai. 2016. Learning Query and Document Relevance from
a Web-scale Click Graph. In Proceedings of the 39th International ACM SIGIR
Conference (SIGIR ’16). ACM.
[10] Rosie Jones and Kristina Lisa Klinkner. 2008. Beyond the Session Timeout: Automatic Hierarchical Segmentation of Search Topics in Query Logs. In Proceedings
of the 17th ACM Conference on CIKM (CIKM ’08). ACM.
[11] Alexander Kotov, Paul N. Bennett, Ryen W. White, Susan T. Dumais, and Jaime
Teevan. 2011. Modeling and Analysis of Cross-session Search Tasks. In Proceedings of the 34th International ACM SIGIR Conference (SIGIR ’11). ACM.
[12] Liangda Li, Hongbo Deng, Anlei Dong, Yi Chang, and Hongyuan Zha. 2014.
Identifying and Labeling Search Tasks via Query-based Hawkes Processes. In
Proceedings of the 20th ACM SIGKDD International Conference (KDD ’14). ACM.
[13] Liangda Li, Hongbo Deng, Yunlong He, Anlei Dong, Yi Chang, and Hongyuan
Zha. 2016. Behavior Driven Topic Transition for Search Task Identification. In
Proceedings of the 25th International Conference on WWW (WWW ’16).
[14] Zhen Liao, Yang Song, Li-wei He, and Yalou Huang. 2012. Evaluating the Effectiveness of Search Task Trails. In Proceedings of the 21st International Conference
on WWW (WWW ’12). ACM.
[15] Yiqun Liu, Junwei Miao, Min Zhang, Shaoping Ma, and Liyun Ru. 2011. How do
users describe their information need: Query recommendation based on snippet
click model. Expert Systems with Applications 38, 11 (2011).
[16] Claudio Lucchese, Salvatore Orlando, Raffaele Perego, Fabrizio Silvestri, and
Gabriele Tolomei. 2011. Identifying Task-based Sessions in Search Engine Query
Logs. In Proceedings of the Fourth ACM International Conference on WSDM (WSDM
’11). ACM.
[17] Claudio Lucchese, Salvatore Orlando, Raffaele Perego, Fabrizio Silvestri, and
Gabriele Tolomei. 2013. Discovering Tasks from Search Engine Query Logs. ACM
Trans. Inf. Syst. 31, 3, Article 14 (Aug. 2013).
[18] Rishabh Mehrotra, Ahmed El Kholy, Imez Zitouni, Milad Shokouhi, and Ahmed
Hassan. 2017. Identifying User Sessions in Interactions with Intelligent Digital Assistants. In Proceedings of the 26th International Conference on WWW Companion
(WWW ’17 Companion).
[19] Rishabh Mehrotra and Emine Yilmaz. 2015. Terms, Topics & Tasks: Enhanced
User Modelling for Better Personalization. In Proceedings of the 2015 International
Conference on ICTIR (ICTIR ’15). ACM.
[20] Rishabh Mehrotra and Emine Yilmaz. 2017. Extracting Hierarchies of Search
Tasks & Subtasks via a Bayesian Nonparametric Approach. CoRR abs/1706.01574
(2017). arXiv:1706.01574
[21] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove:
Global Vectors for Word Representation.. In EMNLP, Vol. 14.
[22] Hongning Wang, Yang Song, Ming-Wei Chang, Xiaodong He, Ryen W. White, and
Wei Chu. 2013. Learning to Extract Cross-session Search Tasks. In Proceedings of
the 22Nd International Conference on WWW (WWW ’13). ACM.

b

Figure 2: visualization of the word embedding vectors.
Figure 3 visualizes attention scores for each contextual query
when predicting whether 5th and 6th queries are of the same search
session segments. Intuitively, queries that are close to the 5th and
6th queries receive more attention than the far-away queries. In
subfigure a, the 5th query "major blue daylily" and the 6th query
"mayday daylily" have the highest attention scores. However, in addition to very middle two queries, contextual queries are significant
in the session boundary decision. For example in subfigure b, the
6th query "are smartest people ..." is highly related to the following
queries from the 7th "smartest in the ..." to the 10th "smartest people" which provide a stronger evidence for the model to distinguish
that the 5th query "jim rome" is quite different from these queries
of "smartest" topic.
google
daily racingform
adobe reader
todays racing digest
jim rome
are smartest people great…
smartest people in the…
what makes up the smartest
math and genious
smartest people

stella supreme daylily
shevim daylily
shevim daylily
major blue daylily
major blue daylily
mayday daylily
gardenweb
charlies greenhouse
gardenweb
gardenweb

a

b

Figure 3: attention distribution. a) 5th and 6th queries are
in a same session segments. b) 5th and 6th queries cross a
session boundary.

6

CONCLUSIONS AND FUTURE WORK

In this paper, we have presented a novel session segmentation
approach to improve search task extraction along with an efficient
clustering method using novel query relevance metric. Experiments
on two real-world datasets demonstrate the effectiveness of the
approach compared with other approaches. We extensively analyze
and justify the contribution of context in the segmentation and
extraction tasks.
In the future, we plan to introduce more advanced model to
understand long-tail querys’ intention with their contextual information. It is extremly difficult to identify long-tail queries’ intention
for they are generally ambiguous even with the context. However,

1104


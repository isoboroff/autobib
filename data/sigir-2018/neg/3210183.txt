Tutorial

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Neural Approaches to Conversational AI
Jianfeng Gao

Microsoft AI & Research
Redmond, WA, USA
jfgao@microsoft.com

Michel Galley

Microsoft Research
Redmond, WA, USA
mgalley@microsoft.com

Google Inc.
Kirkland, WA, USA
lihongli.cs@gmail.org

Table 1: A human-agent dialogue during a process of making
a business decision. (usr: user, agt: agent)

ABSTRACT
This tutorial surveys neural approaches to conversational AI that
were developed in the last few years. We group conversational
systems into three categories: (1) question answering agents, (2)
task-oriented dialogue agents, and (3) social bots. For each category,
we present a review of state-of-the-art neural approaches, draw the
connection between neural approaches and traditional symbolic
approaches, and discuss the progress we have made and challenges
we are facing, using specific systems and models as case studies.

usr: Where are sales lagging behind our forecast?
agt: The worst region is [country], where sales are 15% below projections.
usr: Do you know why?
agt: The forecast for [product] growth was overly optimistic.
usr: How can we turn this around?
Here are the 10 customers in [country] with the most growth potential,
agt:
per our CRM model.
usr: Can you set up a meeting with the CTO of [company]?
Yes, I’ve set up a meeting with [person name] for next month when you are
agt:
in [location].
usr: Thanks.

CCS CONCEPTS
• Computing methodologies → Discourse, dialogue and pragmatics; • Information systems → Document representation;
Information retrieval query processing; Users and interactive retrieval;

made and challenges we are facing, using specific systems and
models as case studies.
This tutorial is a valuable resource for students, researchers,
and the software developers, providing a detailed presentation of
the important ideas and insights needed to understand and create
modern dialogue agents that are instrumental to making the world
knowledge and services accessible to millions of users in the most
natural way.

KEYWORDS
Conversation, dialogue, question answering, task-oriented dialogue,
social chat bot
ACM Reference Format:
Jianfeng Gao, Michel Galley, and Lihong Li. 2018. Neural Approaches to
Conversational AI. In Proceedings of ACM SIGIR conference (SIGIR 2018).
ACM, New York, NY, USA, Article 4, 5 pages. https://doi.org/10.1145/3209978.
3210183

1

Lihong Li

2

THE TUTORIAL

In this tutorial, we start with a brief introduction to the recent
progress on DL and RL that is related to natural language processing (NLP), information retrieval (IR) and conversational AI. Then,
we describe in detail the state-of-the-art neural approaches developed for three types of dialogue systems. The first is a question
answering (QA) agent. Equipped with rich knowledge drawn from
various data sources including Web documents and pre-complied
knowledge graphs (KG’s), the QA agent can provide concise direct
answers to user queries. The second is a task-oriented dialogue
system that can help users accomplish tasks ranging from meeting
scheduling to vacation planning. The third is a social chat bot which
can converse seamlessly and appropriately with humans, and often
plays roles of a chat companion and a recommender. In the final
part of the tutorial, we review attempts to developing open-domain
conversational AI systems that combine the strengths of different
types of dialogue systems.

MOTIVATION AND OBJECTIVES

Developing an intelligent dialogue system that not only emulates
human conversation, but also can answer questions of topics ranging from latest news of a movie star to Einstein’s theory of relativity,
and fulfill complex tasks such as travel planning, has been one of the
longest running goals in AI. The goal remains elusive until recently
when we started observing promising results in both the research
community and industry as the large amount of conversation data
is available for training and the breakthroughs in deep learning
(DL) and reinforcement learning (RL) are applied to conversational
AI.
This tutorial presents a review of state of the art neural approaches to conversational AI that were developed in the last few
years, draws the connection between neural approaches and traditional symbolic approaches, and discusses the progress we have

2.1

A Unified View: Dialogue as Optimal
Decision Making

The example dialogue presented in Table 1 can be formulated as a
sequential decision making process. It has a natural hierarchy: a toplevel process selects what agent to activate for a particular subtask
(e.g., answer a question, schedule a meeting, give a recommendation
or just have a chat etc.), and a low level process, perform by the
selected agent, chooses primitive actions to complete the subtask.
Such hierarchical decision making processes can be formulated
in the mathematical framework of options over Markov Decision

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGIR 2018, July 2018, Ann Arbor, Michigan, USA
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00
https://doi.org/10.1145/3209978.3210183

1371

Tutorial

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Table 2: Reinforcement Learning for Dialogue.
dialogue
QA
task-oriented
chatbot
top-level bot

state
understanding of
user query intent
understanding of
user goal
conversation history
and user intent
understanding of
user top-level intent

action
clarification
questions or answers
dialogue-act and
slot/value

reward
relevance of answer
# of dialogue turns
task success rate
# of dialogue turns

response

user engagement

options

daily/monthly usage

Processes (MDPs) [14], where options generalize primitive actions
to higher-level actions. This is an extension to the traditional MDP
setting where an agent can only choose a primitive action at each
time step, with options the agent can choose a multi-step action
which for example could be a sequence of primitive actions for
completing a subtask.
If we view each option as an action, both top-level and low-level
processes can be naturally mapped to the reinforcement learning
(RL) framework as follows. The dialogue agent navigates a MDP,
interacting with its environment over a sequence of discrete steps.
At step, the agent observes the current state, and chooses an action
a according to a policy. The agent then receives reward and observe
a new state, continuing the cycle until the episode terminates. The
goal of dialogue learning is to find optimal policies to maximize
expected rewards. Table 2 summarizes all dialogue agents using a
unified view of RL.
Although RL provides a unified machine learning (ML) framework for building dialogue agents, applying RL requires training a
dialogue agent by interacting with real users, which can be very
expensive for many domains. Thus, in practice we often use RL
together with supervised learning especially in the cases where
there is a large amount of human-human conversational data. In
the rest of the tutorial, we will survey these ML approaches.

2.2

We then discuss neural text-QA agents. The heart of such systems
is a neural Machine Reading Comprehension (MRC) model that
generates an answer to an input query based on a set of passages.
After reviewing popular MRC datasets, we describe the technologies
developed for state-of-the-art MRC models in two dimensions: (1)
the methods of encoding query and passages as vectors in a neural
space, and (2) the methods of performing inference in the neural
space to generate the answer.
We end this section by outlining our effort of turning Microsoft
Bing from a Web search engine into an open-domain QA engine.

2.3

Task-Oriented Dialogue Systems

In this part, we first introduce the architecture of a typical taskoriented dialogue system. It consists of (1) a natural language understanding (NLU) module for identifying intents of user utterances; (2)
a state tracker for tracking conversation state; (3) a dialogue policy
which selects the next action based on the current state; and (4) a
natural language generator (NLG) for converting the agent action
to a natural language response. While traditionally these modules
are often implemented and optimized individually using statistical
models and/or hand-craft rules [15, 19], there is a growing interest
in applying deep learning and reinforcement learning to automate
the optimization of a dialogue system.
We describe state-of-the-art approaches in two frontiers. The
first is end-to-end (E2E) learning where these modules are implemented using differentiable models like neural networks, so that
they can be jointly optimized from user feedback signals using
backpropagation and RL. The second is the use of advanced RL
techniques to optimize dialogue policies in more complex scenarios. Examples include improved efficiency of exploration for faster
learning, and hierarchical problem solving for composite-task dialogues where the reward signal is particularly sparse. We review
several recent proposals, including the ones based on Bayesian models, curiosity-driven strategy, hierarchical reinforcement learning,
adversarial learning, and the Dyna framework [8, 13] to integrate
planning and learning, etc.
We end this section by presenting a few example task-oriented
systems from some of the leading players in the industry, including
Microsoft’s Cortana, Amazon’s Alexa and Google’s Assistant.

Question Answering and Machine Reading
Comprehension

Recent years have witnessed an increasing demand for question
answering (QA) dialogue agents that allow users to query large scale
knowledge bases (KB) or document collections via natural language.
The former is known as KB-QA agents and the latter text-QA agents.
KB-QA agents are superior to traditional SQL-like systems in that
users can query a KB interactively without composing complicated
SQL-like queries. Text-QA agents are superior to traditional search
engines, such as Bing and Google, in that they provide concise
direct answers to user queries.
In this part, we start with a review of traditional symbolic approaches to KB-QA based on semantic parsing. We show that a symbolic system is hard to scale because the keyword-matching-based
inference used by the system is inefficient for a big KB, and is not
robust to paraphrasing. To address these issues, neural approaches
are developed to represent queries and KB using continuous semantic vectors so that the inference can be performed at the semantic
level in a compacted neural space. We use ReasoNet with shared
memory [11] as an example to illustrate the implementation details.
We also review different dialogue policies for multi-turn KB-QA
agents.

2.4

Fully Data-Driven Conversation Models
and Social Bots

Social bots (also known as chatbots) are of growing importance in facilitating smooth interaction between humans and their electronic
devices. Recently, researchers have begun to explore fully datadriven generation of conversational responses within the framework of neural machine translation (NMT) in the form of encoderdecoder or seq2seq models [10, 12, 16]. Such end-to-end models
have been particularly successful with social bot scenarios, as they
require little interaction with the user’s environment (no need for
API calls) and such models cope well with free-form and open
domain texts.
However, neural responses are often too general to carry meaningful information, e.g., with the common response “I don’t know”
which can serve as a reply to most user questions. A mutual information model is proposed by [5], and is later improved by using

1372

Tutorial

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

deep reinforcement learning [7]. Furthermore, Li et al.[6] presented
a persona-based model to address the issue of speaker consistency
in neural response generation.
Although task-oriented dialogue systems and social bots are
originally developed for different purposes, there is a trend of combining both as a step towards building an open-domain dialogue
agent. For example, on the one hand, [4] presented a fully datadriven and knowledge-grounded neural conversation model aimed
at producing more contentful responses without slot filling. On
the other hand, Zhao et al. [20] proposed a task-oriented dialogue
agented based on the encoder-decoder model with chatting capability. These works represent steps toward end-to-end dialogue
systems that are useful in scenarios beyond chitchat.
We end this section by presenting a few examples of chatbots
that have been made available to the public, including Microsoft’s
XiaoIce, Replika and Alexa Prize systems.

3

4

FORMAT AND DETAILED SCHEDULE

The tutorial consists of four parts. The detailed schedule is as follows.
(1) Part 1 (15 minutes): Introduction
• Who should attend this tutorial?
• Dialogue: what kinds of problem?
• A unified view: dialogue as optimal decision making
• Machine learning basics
• Deep learning leads to paradigm shift in NLP and IR
• Reinforcement learning
(2) Part 2 (45 minutes): QA and MRC
• The KB-QA task
• Semantic parsing
• Embedding-based KB-QA
• Multi-turn KB-QA agents
• Machine reading for Text-QA
• Neural MRC models
• QA in Bing
(3) Part 3 (50 minutes): Task-oriented dialogue
• Overview and architecture
• Review of traditional approaches
• Natural language understanding and dialogue state tracking
• Evaluation and user simulator
• Neural approaches and E2E learning
• RL for dialogue policy learning
• Task-oriented bots in industry
(4) Part 4 (50 minutes): Fully data-driven conversation models
and chatbots
• E2E neural conversation models, e.g., seq2seq, HRED, etc.
• Challenges and remedies
• Grounded conversation models
• Beyond supervised learning
• Data and evaluation
• Chatbots in public
• Future work: toward more goal-oriented E2E conversational systems

RELEVANCE TO THE IR COMMUNITY AND
RELATED TUTORIALS

Conversational AI, which aims to develop intelligent agents for
QA, social chat and task-completion, as presented in this tutorial,
is a rapidly growing field, attracting many researchers in the IR
community. As a result, SIGIR 2018 creates a new track of Artificial
Intelligence, Semantics, and Dialog to bridge research in AI and IR,
especially toward QA, deep semantics and dialogue with intelligent
agents.
Recently, there have been related tutorial and survey papers
on deep learning and dialogue systems. [3, 17, 18] reviewed deep
learning approaches to a wide range of IR and NLP tasks, including
dialogue. [2] is a recent tutorial on dialogue mainly focusing on
task-oriented agents. [9] gave a good survey of public dialogue
datasets that can used to develop dialogue agents. [1] reviewed
popular deep neural network models for dialogue, focusing only
on supervised learning approaches.
This tutorial expands the scope of [1] and [9] by going beyond
data and supervised learning. To the best of our knowledge, it is
also the first tutorial on neural approaches to conversational AI
targeting IR audiences.
The contributions of this tutorial include:

5

(1) We provide a comprehensive survey on neural approaches to
conversational AI that were developed in the last few years,
covering QA, task-oriented and social bots with a unified
view of optimal decision making.
(2) We draw connections between modern neural approaches
and traditional symbolic approaches, allowing us to better
understand why and how the research has been evolved and
shed light on how we move forward.
(3) We present state-of-the-art approaches to training dialogue
agents using both supervised learning and reinforcement
learning methods.
(4) We picture the landscape of conversational systems developed in research communities and released in industry, demonstrating via case studies the progress we have made and the
challenges we are facing.

1373

TYPE OF SUPPORT MATERIALS TO BE
SUPPLIED TO ATTENDEES

We will make the slides deck of the tutorial available for all attendees
to download one or two weeks before the conference, and will make
the full and technical report available for download around one
month after the conference.

REFERENCES
[1] Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang. 2017. A Survey
on Dialogue Systems: Recent Advances and New Frontiers. arXiv preprint
arXiv:1711.01731 (2017).
[2] Yun-Nung Chen, Asli Celikyilmaz, and Dilek Hakkani-Tür. 2017. Deep Learning
for Dialogue Systems. Proceedings of ACL 2017, Tutorial Abstracts (2017), 8–14.
[3] Jianfeng Gao. 2017. An Introduction to Deep Learning for Natural Language
Processing. In International Summer School on Deep Learning, Bilbao.
[4] Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng
Gao, Wen-tau Yih, and Michel Galley. 2018. A Knowledge-Grounded Neural
Conversation Model. In AAAI.
[5] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016.
A diversity-promoting objective function for neural conversation models. In
NAACL-HLT.

Tutorial

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

[6] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016. A
Persona-Based Neural Conversation Model. In ACL.
[7] Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng Gao.
2016. Deep Reinforcement Learning for Dialogue Generation. In EMNLP.
[8] Baolin Peng, Xiujun Li, Jianfeng Gao, Jingjing Liu, and Kam-Fai Wong. 2018.
Integrating planning for task-completion dialogue policy learning. arXiv preprint
arXiv:1801.06176 (2018).
[9] Iulian Vlad Serban, Ryan Lowe, Peter Henderson, Laurent Charlin, and Joelle
Pineau. 2015. A survey of available corpora for building data-driven dialogue
systems. arXiv preprint arXiv:1512.05742 (2015).
[10] Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C Courville, and
Joelle Pineau. 2016. Building End-To-End Dialogue Systems Using Generative
Hierarchical Neural Network Models.. In AAAI. 3776–3784.
[11] Yelong Shen, Po-Sen Huang, Ming-Wei Chang, and Jianfeng Gao. 2017. Traversing
Knowledge Graph in Vector Space without Symbolic Space Guidance. arXiv
preprint arXiv:1611.04642 (2017).
[12] Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji,
Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015. A neural
network approach to context-sensitive generation of conversational responses.
In NAACL-HLT.
[13] Richard S Sutton. 1990. Integrated architectures for learning, planning, and
reacting based on approximating dynamic programming. In Proceedings of the

seventh international conference on machine learning. 216–224.
[14] Richard S. Sutton, Doina Precup, and Satinder P. Singh. 1999. Between MDPs and
semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning.
Artificial Intelligence 112, 1–2 (1999), 181–211. An earlier version appeared as
Technical Report 98-74, Department of Computer Science, University of Massachusetts, Amherst, MA 01003. April, 1998.
[15] Gokhan Tur and Renato De Mori. 2011. Spoken language understanding: Systems
for extracting semantic information from speech. John Wiley & Sons.
[16] Oriol Vinyals and Quoc Le. 2015. A Neural Conversational Model. In ICML Deep
Learning Workshop.
[17] Wen-tau Yih, Xiaodong He, and Jianfeng Gao. 2015. Deep Learning and Continuous Representations for Natural Language Processing. In Proceedings of the 2015
Conference of the North American Chapter of the Association for Computational
Linguistics: Tutorial.
[18] Wen-tau Yih, Xiaodong He, and Jianfeng Gao. 2016. Deep Learning and Continuous Representations for Natural Language Processing. In IJCAI: Tutorial.
[19] Steve Young, Milica Gašić, Blaise Thomson, and Jason D Williams. 2013. Pomdpbased statistical spoken dialog systems: A review. Proc. IEEE 101, 5 (2013), 1160–
1179.
[20] Tiancheng Zhao, Allen Lu, Kyusong Lee, and Maxine Eskenazi. 2017. Generative
encoder-decoder models for task-oriented spoken dialog systems with chatting
capability. arXiv preprint arXiv:1706.08476 (2017).

1374


Short Research Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Robust Asymmetric Recommendation via Min-Max
Optimization
Peng Yang† , Peilin Zhao‡ , Vincent W. Zheng♯ , Lizhong Ding† , Xin Gao†
Saudi Arabia;‡ SCUT, China;♯ Advanced Digital Sciences Center, Singapore
{peng.yang.2,lizhong.ding,xin.gao}@kaust.edu.sa;peilinzhao@hotmail.com;vincent.zheng@adsc.com.sg
† KAUST,

ABSTRACT

are positive instances, indicating that a user viewed or purchased
an item, while the others annotated as 0’s are a mixture of negatives and missing values. However, imbalanced labels and outliers
often occur in the implicit feedback datasets. To tackle these problems, a large number of studies have been conducted, among which
one-class collaborative filtering (CF) model [5, 8] treated all unlabeled values as negatives, which is biased in estimation since some
missing values are positives. Rendle et al. [14] sampled a subset of
negative instances from unlabeled values, which often decreases
the predictive power of the model due to insufficient data coverage.
To address the outlier issue, robust matrix decomposition [9][17]
employed a sparse matrix to capture the noise so that the low-rank
structure can be recovered. However, the proposed L 2 -norm loss
function may be easily misled by the outliers and noisy data.
Although these methods are effective, they mainly rely on nuclear norm for the low-rank approximation. The optimization for nuclear norm minimization can be solved by first-order optimization
methods such as subgradient descent [10] and proximal gradient
descent [11]. Although these methods are guaranteed to converge,
they are inefficient because a singular value decomposition (SVD)
step, which takes O(m 2n) time, is required at each iteration. To reduce the computational complexity, one efficient way is to replace
the full SVD with an approximate SVD [3]. However, those approaches require the loss function to be smooth [7]. The alternative
way relies on the bilinear factorization, which utilizes alternating
direction methods to iteratively optimize the decomposed variables.
However, these approaches break the convexity of the original
problem, which results in no global convergence [8].
In this paper, we propose a robust asymmetric recommendation
method via min-max optimization. To reduce the negative impact of
imbalanced and noisy labels, we propose a capped Lp -norm asymmetric learning model. It derives an iteratively weighted algorithm
to minimize the objective function. By leveraging the capped-norm
and cost-sensitive learning, our model seamlessly integrates them
into a joint framework, where the result of one task reinforces the
other one. To reduce the computational cost of low-rank approximation, we develop an SVD-free optimization algorithm. Based on
the dual characterization of the nuclear norm, we reformulate the
problem with a min-max optimization problem and solve it by a
subgradient method. In each iteration, we only need to compute
the largest singular vector instead of a full SVD, thus reducing the
time complexity from O(m 2n) to O(mn). Finally, the promising experimental results demonstrate the effectiveness of our algorithm
on several benchmark recommendation datasets.

Recommender systems with implicit feedback (e.g. clicks and purchases) suffer from two critical limitations: 1) imbalanced labels
may mislead the learning process of the conventional models that
assign balanced weights to the classes; and 2) outliers with large
reconstruction errors may dominate the objective function by the
conventional L 2 -norm loss. To address these issues, we propose
a robust asymmetric recommendation model. It integrates costsensitive learning with capped unilateral loss into a joint objective function, which can be optimized by an iteratively weighted
approach. To reduce the computational cost of low-rank approximation, we exploit the dual characterization of the nuclear norm
to derive a min-max optimization problem and design a subgradient algorithm without performing full SVD. Finally, promising
empirical results demonstrate the effectiveness of our algorithm on
benchmark recommendation datasets.

CCS CONCEPTS
• Information systems → Collaborative filtering; • Theory
of computation → Semi-supervised learning;

KEYWORDS
Robust Asymmetric Learning; Concave-Convex Optimization
ACM Reference Format:
Peng Yang† , Peilin Zhao‡ , Vincent W. Zheng ♯ , Lizhong Ding† , Xin Gao† .
2018. Robust Asymmetric Recommendation via Min-Max Optimization. In
SIGIR ’18: The 41st International ACM SIGIR Conference on Research and
Development in Information Retrieval, July 8–12, 2018, Ann Arbor, MI, USA.
ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3209978.3210074

1

INTRODUCTION

Recommender systems are attractive for content providers, through
which they can increase sales or views. The user-item matrix, i.e.,
Y ∈ Rn×m , encodes the individual preference of users for items.
In this work, we assume m ≤ n. Most often user preference is not
explicitly but implicitly expressed with binary (0 or 1) values. In
the implicit feedback setting, the observed feedbacks marked as 1’s
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR ’18, July 8–12, 2018, Ann Arbor, MI, USA
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00
https://doi.org/10.1145/3209978.3210074

1077

Short Research Papers II

ALGORITHM
Figure 1: Illustration of robust cost-sensitive loss

We assume that a 0-1 rating matrix Y ∈ {0, 1}n×m with a bounded
nuclear norm ∥Y∥∗ ≤ ϵ, where n and m are the numbers of items
and users, respectively. Generally, only a subset of 1’s of Y are
observed. Let the observations Ω be a subset of positive entries
sampled from {(i, j)|Yi j = 1}. We define the observation matrix as
A where Ai j = 1 if (i, j) ∈ Ω, and Ai j = 0 otherwise. Our objective
is that, given the observation matrix A, we aim to find a low-rank
matrix X to minimize the loss between X and A:
n Õ
m
Õ
ℓ(X i j , Ai j ) + λrank(X),
min
(1)
n×m

Loss Value

2

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

where λ ≥ 0 is a trade-off parameter, ℓ(X, A) is a loss function
between the matrices X and A, and rank(X) constrains X into a
low-rank matrix.

issues and mislead the learning process. To be resistant to outliers,
we propose a robust cost-sensitive loss for 0 < p < 2:


p
ˆ i j ) 2 , ξ α ),
h(ℓα (X i j )) = αI(Ai j =1) + I(Ai j =0) min(ℓ(X
(5)

2.1

ˆ with
where h(ℓα (x)) enforces a capped Lp -norm over the loss ℓ(x)
an upper bound ξ α > 0. As shown in Fig. 1(b) (α = 2, p = 1 and
ξ α = 0.5), no matter how misclassified the data point is, the loss
h(ℓα (x)) is capped by ξ α . This makes the loss function robust to
outliers since their effect to the model is fixed. However, optimizing
Eq. (5) is difficult since h(ℓα (x)) is a concave non-smooth function in
the domain of ℓα (x). Motivated by concave duality [19], Lemma 2
provides an iteratively weighted function to solve it.

X∈R

8

(b) Capped Cost−Sensitive Loss

(a) Cost−sensitive unilateral loss

1.5

Weighted L2−norm loss
L2−norm loss
Hinge loss

7

Loss Value

6
5
4
3

error cost on positives
error cost on unlabels

1

0.5

2
1
0
−1

0

1

2

X

3

0
−0.5

0

0.5

X

1

1.5

i=1 j=1

Framework for Class Imbalance and Outlier

We introduce a framework to tackle class imbalance and outliers.
Class-Imbalance Learning: In the 0-1 rating matrix, a small portion of positives is observed, which may result in biased estimation
by the conventional models that treat each class equally. To address
this issue, we assume that the cost of missing a positive target
is much higher than that of having a false-positive, and study an
appropriate performance metric: weighted cost,
cost = cp × Mp + c n × Mn ,

Lemma 2. Eq. (5) can be relaxed to iteratively minimizing a weighted
L 2 -norm formulation:
Õ
ˆ i j )(αI(A =1) + I(A =0) ),
Xt +1 = argmin
β˜itj ℓ(X
ij
ij
(6)
X

(2)

where Mp and Mn are the numbers of false negatives and false
positives, cp and c n ∈ [0, 1] (cp + c n = 1) denote the predefined
costs of false negatives and false positives, respectively. The lower
the cost value, the better the performance.

i, j

where β˜ = ∇u h(u)|u=ℓ̂(x ) denotes the supergradient of the concave
ˆ for p ∈ (0, 2):
function h(u) at point u = ℓ(x)
(
p
p ˆ t p−2
ˆ t ) 2 ≤ ξα ;
2 ,
ℓ(X
2 ℓ(X i j )
ij
β˜itj =
(7)
0,
otherwise.

Lemma 1. Minimizing the weighted cost in Eq. (2) is equivalent to
minimizing the following objective:
Õ
Õ
αI(X i j <q) +
I(X i j ≥q) ,
(3)
Ai j =+1

Ai j =0

cp
cn

where α =
is a biased coefficient, q ∈ (0, 1) is a threshold and Iπ
is the indicator function that outputs 1 if π holds and 0 otherwise.

ˆ and h(u) = min(u 2 , ξ α ). As ℓ(x)
ˆ is convex
Proof. Let u = ℓ(x)
in the domain of x, h(u) can be rewritten:

Lemma 1 gives the explicit objective for optimization, but the indicator function in Eq. (3) is not convex. Thus, we replace the indicator
function by its convex surrogate,


ˆ i j ),
ℓα (X i j ) = αI(Ai j =1) + I(Ai j =0) ℓ(X
(4)

˜ − h ∗ (β)],
˜
min(u 2 , ξ α ) = inf [βu

p

p

(8)

β˜ ≥0

˜ is the concave dual of h(u) given below:
where h ∗ (β)
p

(8)

˜ = inf [βu
˜ − h(u)] = inf [βu
˜ − min(u 2 , ξ α )]
h ∗ (β)
u

ˆ is a convex unilateral loss for the 0-1 classes,
and ℓ(·)

2
ˆ i j ) = [1 − X2 i j ]+ , Ai j = 1
ℓ(X
[X i j ]+ ,
Ai j = 0

=

u

p

p−2 p 2

 p ( 2 ) 2−p ( 1˜ ) 2−p ,


β

p

if u 2 < ξ α

2
p

p
 βξ
if u 2 ≥ ξ α .
 ˜ α − ξα ,
˜ into Eq. (8), β˜ can be solved as in Eq. (7).
Equipped h ∗ (β)

where [·]+ = max(·, 0) is the hinge loss. We assume that 0 ≤ c n ≤
cp , since we would prefer to improve the accuracy of the positive
class. Fig. 1(a) illustrates the loss ℓα (X i j ) for Ai j = 1 with α = 2.
We observe that for ℓα (X i j ), the slope of the loss function changes
for the positive class, leading to more “aggressive" updating. The
cost-sensitive learning has been widely studied in [15]. Different
from previous techniques, we derive a cost-sensitive unilateral loss
for binary classification with 0-1 label feedback.
Capped L P -norm Loss: A large squared loss occurs in Eq. (4) if
the data point is not correctly classified. Outliers may result in such



From the updating rule (7), we observe that the misclassified points
p
ˆ 2 > ξ α are considered as outliers, and ignored, which is exℓ(x)
pected for robustly learning a model.
Remark: The sequence {Xt } generated by Eq. (6) iteratively minÍ
imizes the upper bound of the concave problem i j h(ℓα (X i j )) +
λrank(X). Since h(ℓα (x)) is a concave function, for any x,
h(ℓα (x)) ≤ h(ℓα (x t )) + ⟨β˜t , ℓα (x) − ℓα (x t )⟩F ,

1078

Short Research Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

where ρ > 0 is a parameter and [·]+ = max(·, 0). Since the above
optimization problem is convex-concave, we can apply the above
standard subgradient method to solve it, which iterates as follows:


Xt +1 = Xt − ηt β˜t ◦ ∂ℓα (Xt ) + λUt ,

Algorithm 1: ROMA: RObust asyMmetric recommendAtion
1 Input: A ∈ Rn×m ;
2 Initialize: X0 = U0 = 0 ∈ Rn×m , η 0 and τ0 ;
3 for t = 1, . . . ,T − 1 do
(
p
p ˆ t p−2
ˆ t ) 2 ≤ ξα
2 ,
ℓ(X
t
˜
2 ℓ(X i j )
ij
4
βi j =
as Eq. (7);
0,
otherwise


5
Xt +1 = Xt − ηt β˜t ◦ ∂ℓα (Xt ) + λUt ;
6
7
8

Ut +1 = Ut + τt (λXt − ρ∂[∥U∥2 − 1]+ ) .
Note that the subgradient ∂[∥U∥2 − 1]+ can be computed efficiently.
We denote σ1 as the leading singular value of U, p1 and q1 as the
corresponding left and right singular vectors. Then we have

Ut +1 = Ut + τt (λXt − ρ∂[∥U∥2 − 1]+ ) ;
end
Í
Output: X̂T = Tt=1 Xt /T ;

p1 q⊤
1 I(σ1 >1) ∈ ∂[∥U∥2 − 1]+ .
In each iteration, we only need to compute the leading singular
vector of Ut with O(mn) time. In contrast, a full SVD takes O(m 2n)
time. The entire procedure is summarized in Algorithm 1.

where β˜t = ∇u h(u)|u=ℓ̂(x t ) . Thus we obtain an upper bound of
Í
t
i j h(ℓα (X i j )) + λrank(X) via a linear approximation at ℓα (X ):

3

∀X ∈ Rn×m : λrank(X) + h(ℓα (X))
≤ λrank(X) + h(ℓα (Xt )) + ⟨β˜t , ℓα (X) − ℓα (Xt )⟩F .

(9)

3.1

Xt +1 = arg min λrank(X) + h(ℓα (Xt )) + ⟨β˜t , ℓα (X) − ℓα (Xt )⟩F
X

= arg min λrank(X) + ⟨β˜t , ℓα (X)⟩F ,
X

which obtains an iterative solution to minimize the upper bound of
the concave objective function.

SVD-free Min-Max Optimization

The objective, λrank(X) + ⟨β˜t , ℓα (X)⟩F , is a nonconvex function
and computationally intractable [1]. To address the issue, we relax
rank(X) to its convex norm,
Xt +1 = arg min ⟨β˜t , ℓα (X)⟩F + λ∥X∥∗ ,
X

(10)

where ∥X∥∗ = i σi (X) is the nuclear norm and σi (X) is a singular
value. The nuclear norm minimization can be solved by subgradient descent (GD) [12] or proximal gradient descent (PGD) [11].
Although GD and PGD are guaranteed to converge, they have to
perform SVD of Xt or Xt − ηt ∇ℓα (Xt ) in each iteration [2], which
takes a high computational cost of O(m 2n). To reduce the computational complexity, we propose an SVD-free min-max optimization
algorithm. According to the dual form of the nuclear norm [16],
Í

∥X∥∗ = max
tr(U⊤ X)
n×m

s.t. ∥U∥2 ≤ 1,

U∈R

where ∥ · ∥2 represents the spectral norm, we can cast Eq. (10) to a
concave-convex optimization problem,
min max ⟨β˜t , ℓα (X)⟩F + λtr(U⊤ X)
X

U

s.t. ∥U∥2 ≤ 1.

Due to the spectral norm constraint, we have to project the intermediate solution onto the unit spectral norm ball, which again
requires a full SVD operation. To address this issue, we replace the
constraint ∥U∥2 ≤ 1 with a regularization term in the objective
function to control the spectral norm of U:

3.2

Comparison Results

The comparison results, in terms of NDCG and F1, are summarized in Table 2. It shows that ROMA always outperforms state-ofthe-art robust MF methods, SPMF and RMF-MM, over all metrics.

min max ⟨β˜t , ℓα (X)⟩F + λtr(U⊤ X) − ρ[∥U∥2 − 1]+ ,
X

Experimental Settings

Datasets: The experiments were conducted on three real datasets:
MovieLens-100K [4], MovieLens-1M, and EachMovie1 . Table 1 summarizes the details of the three datasets. These datasets are classimbalanced due to a small portion of observations. To simulate the
implicit setting on the datasets, we followed previous studies [13]
by treating the ratings larger than 3 as observed positive feedbacks.
Evaluation Metrics: Each dataset was randomly partitioned into
two non-overlapping sets for training and testing: for each user,
80% of its observed feedbacks were randomly chosen as the training
data and the remaining 20% were used for testing. For the sake of
fair comparison, we repeated the random partition for five times. At
each time, we computed the results for each user, then reported the
averaged results over all users. We measured the performance with
two widely-used evaluation metrics: 1) NDCG@N, the normalized
discounted cumulative gain in the ranking; 2) F1@N, the weighted
harmonic mean of precision and recall. We chose the top-N ranked
items for evaluation with N = {5, 15}. Specifically, the higher these
measures, the better the performance is.
Baselines: We compared our algorithm with four state-of-the-art
baselines: 1) BPRMF is a one-class CF approach, which assigns
each example with a heuristic prior [14]. 2) RMF-MM solves the
L 1 -norm based low-rank matrix factorization problem via majorization minimization [9]. 3) SPMF employs a self-paced learning to
resist outliers and noise [20]. 4) MCShift is a cost-sensitive method
for matrix completion [6]. All parameters of the baselines were
tuned according to their recommended instructions. For bilinear
factorization methods, the number of latent factors was tuned from
{10, 20, . . . , 50}. For ROMA, we fixed p = 1, λ = 10 and ξ α = 1. We
let α = 10 for ML-100K and α = 100 for ML-1M and EachMovie.
We tuned√the parameters
η 0 and τ0 from {10−3 , . . . , 102 }, and set
√
ηt = η 0 / t, τt = τ0 / t according to [16].

Since ℓα (Xt ) is constant w.r.t. X, we have

2.2

EXPERIMENTAL RESULTS

We start with experimental data and benchmark setup, and then
present the comparison results.

1 http://www.grouplens.org/

U

1079

Short Research Papers II

SIGIR’18, July 8-12, 2018, Ann Arbor, MI, USA

Table 1: Description of Datasets
Figure 3: Parameter sensitivity analysis of α
#Items
1,682
3,628
1,628

#Ratings
100,000
1,000,209
2,811,983

Data Density
6.30%
4.47%
1.91%

ML−100K

0.78
0.76
0.74

0.66

0.72
0.7

4

x 10

ROMA−MM
ROMA−PSD
ROMA−SD

6.8
6.6
6.4
6.2
6

4

Objective Value

Objective Value

7

40

60

80

CPU time

100

120

F1@5
19.53±0.46
18.74±0.53
18.80±0.77
19.12±0.54
21.32±0.53

BPRMF
SPMF
RMF-MM
MCShift
ROMA

15.81±0.48
16.63±0.46
16.71±0.51
16.52±0.42
17.13±0.42

BPRMF
SPMF
RMF-MM
MCShift
ROMA

31.91±0.46
31.10±0.53
31.14±0.46
31.31±0.38
32.22±0.38

0.63
0.62

1

10

Parameter α

2

10

0

10

1

10

Parameter α

2

10

ML−1M

5

x 10

ROMA−MM
ROMA−PSD
ROMA−SD

4

3.5

3

500

1000

1500

CPU time

2000

F1@15
NDCG@5
ML-100K
27.93±0.34
69.37±0.88
27.72±0.26
68.02±0.51
27.88±0.42
68.13±0.73
29.00±0.29
70.16±0.54
31.15±0.31 72.45±0.57
ML-1M
23.64±0.35
62.44±1.01
23.42±0.44
62.03±0.62
23.81±0.41
62.19±0.78
24.25±0.31
63.07±0.60
25.92±0.33 64.67±0.46
Each-MV
28.30±0.20
60.36±1.02
27.77±0.34
59.65±0.55
27.59±0.36
59.78±0.86
27.32±0.30
59.65±0.51
29.07±0.30 61.68±0.54

CONCLUSION

We proposed a robust asymmetric recommendation via efficient
low-rank approximation. Our proposed model ROMA can well
leverage both cost sensitive learning and capped Lp -norm to solve
the problem. It novelly formulates the objective as an iteratively
weighted convex function, which can be efficiently solved with a
tight bound. To reduce the computational cost of low-rank approximation, we proposed a min-max optimization without performing
full SVD. Finally, we validated the efficiency and effectiveness of
our algorithm in the promising empirical results.

2500

Table 2: Mean and Standard Deviation of Evaluation Metrics
Algorithm
BPRMF
SPMF
RMF-MM
MCShift
ROMA

0.64

0.6
0

10

2.5
20

0.65

0.61

0.66

ML−100K

ROMA
MCShift
BPRMF

0.67

0.68

Figure 2: Objective value versus the CPU time

ML−1M

0.68

ROMA
MCShift
BPRMF

NDGC@15

#Users
943
6,039
72,916

NDGC@15

Datasets
ML-100K
ML-1M
Each-MV

NDCG@15

REFERENCES

68.73±0.62
68.17±0.46
69.39±0.56
71.33±0.49
72.93±0.41

[1] Edoardo Amaldi and Viggo Kann. 1998. On the approximability of minimizing
nonzero variables or unsatisfied relations in linear systems. Theoretical Computer
Science 209, 1-2 (1998), 237–260.
[2] JianFeng Cai, Emmanuel J Candes, and Zuowei Shen. 2010. A singular value
thresholding algorithm for matrix completion. SIAM Journal on Optimization 20,
4 (2010), 1956–1982.
[3] Lizhong Ding and Shizhong Liao. 2017. An approximate approach to automatic
kernel selection. IEEE Transactions on Cybernetics 47, 3 (2017), 554–565.
[4] F Maxwell Harper and Joseph A Konstan. 2016. The movielens datasets: History
and context. TIIS 5, 4 (2016), 19.
[5] Xiangnan He and Hanwang Zhang. 2016. Fast matrix factorization for online
recommendation with implicit feedback. In SIGIR. ACM, 549–558.
[6] Cho-Jui Hsieh, Nagarajan Natarajan, and Inderjit S Dhillon. 2015. PU learning
for matrix completion. In ICML. 2445–2453.
[7] Cho-Jui Hsieh and Peder Olsen. 2014. Nuclear norm minimization via active
subspace selection. In ICML. 575–583.
[8] Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for
implicit feedback datasets. In ICDM. Ieee, 263–272.
[9] Zhouchen Lin, Chen Xu, and Hongbin Zha. 2017. Robust Matrix Factorization
by Majorization Minimization. PAMI (2017).
[10] Yurii Nesterov. 2004. Introductory lectures on convex optimization. Vol. 87. Springer
Science & Business Media.
[11] Yu Nesterov. 2013. Gradient methods for minimizing composite functions. Mathematical Programming 140, 1 (2013), 125–161.
[12] Yurii Nesterov. 2013. Introductory lectures on convex optimization: A basic course.
Vol. 87. Springer Science & Business Media.
[13] Weike Pan and Li Chen. 2013. GBPR: group preference based Bayesian personalized ranking for one-class collaborative filtering. In IJCAI. 2691–2697.
[14] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. BPR: Bayesian personalized ranking from implicit feedback. In UAI. AUAI,
452–461.
[15] Clayton Scott. 2011. Surrogate losses and regret bounds for cost-sensitive classification with example-dependent costs. In ICML-11. 153–160.
[16] Yichi Xiao, Zhe Li, Tianbao Yang, and Lijun Zhang. 2017. SVD-free convexconcave approaches for nuclear norm regularization. In IJCAI. 3126–3132.
[17] Peng Yang, Peilin Zhao, and Xin Gao. 2017. Robust online multi-task learning
with correlative and personalized structures. IEEE Transactions on Knowledge
and Data Engineering 29, 11 (2017), 2510–2521.
[18] Peng Yang, Peilin Zhao, Xin Gao, and Yong Liu. 2017. Robust Cost-Sensitive Learning for Recommendation with Implicit Feedback. arXiv preprint arXiv:1707.00536
(2017).
[19] Tong Zhang. 2010. Analysis of multi-stage convex relaxation for sparse regularization. JMLR 11 (2010), 1081–1107.
[20] Qian Zhao, Deyu Meng, Lu Jiang, Qi Xie, Zongben Xu, and Alexander G Hauptmann. 2015. Self-Paced Learning for Matrix Factorization.. In AAAI. 3196–3202.

63.47±0.62
64.05±0.46
64.09±0.72
64.03±0.47
65.32±0.39
60.92±0.66
60.58±0.47
60.73±0.75
60.67±0.45
62.11±0.48

These MF methods treat imbalanced labels equally, which result
in biased estimation of classification. In addition, ROMA outperforms the cost-sensitive methods, MCShift and BPRMF, over all the
datasets. Although these methods exploit prior weights on imbalanced classes, their performance is degraded due to outliers [18].
To show the efficiency of the proposed min-max (MM) optimization, we compared our method with two classical methods:
subgradient descent (SD)
√ and proximal subgradient descent (PSD).
The same step ηt = η 0 / t is used for SD and PSD. We plotted the
objective value along the running time in Fig. 2. As can be seen,
MM decreases much faster than SD and PSD. This is as expected,
because MM is SVD-free and time-efficient, taking much less time
in each iteration than the other two methods.
We also studied the impact of the parameter α to show how
cost-sensitive weight improves the results. The results in Fig. 3
show that a small value of α would degrade the performance due to
the equal weights on the imbalanced classes. However, increasing
the value of α can reduce the negative impact of imbalanced classes
via more “aggressive" update for the positive class.

1080


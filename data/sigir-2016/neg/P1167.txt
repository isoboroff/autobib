Beyond Topical Relevance: Studying Understandability
and Reliability in Consumer Health Search
Joao Palotti
Vienna University of Technology
Vienna, Austria

palotti@ifs.tuwien.ac.at

ABSTRACT

to better understand how and what users search in the medical domain, as well as to automatically infer user expertise
based on user behaviour [5,8].
The second and third steps are bound to the document
content, and need labor-intensive resources to be done (e.g.,
annotated data, assessments, user preferences). For that, I
take advantage of CLEF eHealth task1 , which proposes to
foster research in the consumer health search domain. In
the 2015 task, besides the topical relevance assessment, we
collected understandability assessments, asking assessors to
judge whether they would recommend documents for their
patients to read based on how technical documents were [6].
Given the success of the task, we are collecting assessments
for reliability as well as topical relevance and understandability in 2016. These assessments provide the grounds for
working in the fourth and fifth steps of the list above.
Our first experiments exploring the potential of integrating understandability in a personalised retrieval model (part
of the fourth step) will be presented at this conference [7].
Finally, I aim to extend and explore the potential of evaluation metrics that integrate understandability and reliability into a single evaluation framework, based on very recent
research [10].

Nowadays people rely on search engines to explore, understand and manage their health. A recent study from Pew
Internet states that one in each three adult American Internet users have used the Internet as a diagnosis tool [2].
Retrieving incorrect or unclear health information poses
high risks as people may dismiss serious symptoms, use inappropriate treatments or escalate their health concerns about
common symptomatology [1,9]. A number of studies have
shown that the average user experiences difficulty in understanding the content of a large portion of the results retrieved by current search engine technology, for example, see
[3]. Other studies have examined how poor the quality of
health information on the web can be, for example, see [4].
In the context of consumer (non-experts) health search,
search engines should not only retrieve relevant information,
but also promote information that is understandable by the
user and that is reliable/trustable and verified [9].
The focus of my Ph.D. is to go beyond topical relevance
and study understandability and reliability as two important
facets of relevance that must be incorporated into search systems to increase user satisfaction, especially in the context
of consumer health search. For ease of comprehension, we
divide this work into five steps to be accomplished:

REFERENCES

1. Estimate the user expertise level.

[1] M. Benigeri and P. Pluye. Shortcomings of health information on the internet. Health Prom. Inter., 2003.
[2] S. Fox and M. Duggan. Health online. Technical report, The
Pew Internet & American Life Project, 2013.
[3] D. Friedman, L. Hoffman-Goetz, and J. Arocha. Readability
of cancer information on the internet. J Cancer Educ, 2004.
[4] F. Hanif, J. Read, J. Goodacre, A. Chaudhry, and P. Gibbs.
The role of quality tools in assessing reliability of the internet
for health information. Inform Health Soc Ca, 2009.
[5] J. Palotti, A. Hanbury, and H. Muller. Exploiting health
related features to infer user expertise in the medical domain.
In Proc. of WSCD, 2014.
[6] J. Palotti, G. Zuccon, L. Goeuriot, L. Kelly, A. Hanbury,
G. Jones, M. Lupu, and P. Pecina. CLEF eHealth Evaluation Lab 2015, Task2: Retrieving Information About Medical
Symptoms. In Proc. of CLEF 2015, 2015.
[7] J. Palotti, L. Goeuriot, G. Zuccon, and A. Hanbury. Ranking
health web pages with relevance and understandability. In
Proc. of SIGIR, 2016.
[8] J. Palotti, A. Hanbury, H. Müller, and C. E. Kahn Jr. How
users search and what they search for in the medical domain.
Information Retrieval Journal, 2016.
[9] R. W. White and E. Horvitz. Cyberchondria: Studies of the
escalation of medical concerns in web search. TOIS, 2009.
[10] G. Zuccon. Understandability biased evaluation for information retrieval. In Proc. of ECIR, 2016.

2. Estimate how hard is to understand a document.
3. Estimate how reliable the content of a document is.
4. Integrate the understandability and reliability estimations in a personalised retrieval model.
5. Evaluate the relevance of documents not only concerning topical relevance, but also taking into account
whether users can understand and rely on the content
of the document.
The first step aims to promote easy-to-read material with
reliable content to non-experts, while experts are not bothered with basic content. This step was completed in the first
years of my Ph.D., using the logs of different search engines
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).

SIGIR ’16 July 17-21, 2016, Pisa, Italy
c 2016 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4069-4/16/07.

1

DOI: http://dx.doi.org/10.1145/2911451.2911480

1167

https://sites.google.com/site/clefehealth/


Dynamically Integrating Item Exposure with Rating
Prediction in Collaborative Filtering
Ting-Yi Shih, Ting-Chang Hou, Jian-De Jiang,
Yen-Chieh Lien, Chia-Rui Lin, and Pu-Jen Cheng
Department of Computer Science and Information Engineering
National Taiwan University, Taiwan

{r02922038, r03922041, r03922057, r03922056, r03944009, pjcheng}@csie.ntu.edu.tw
ABSTRACT

increase the chance of new items to be recommended. Some
studies concerned about items with less training data and
attempted to save such items. In [8, 9], Steck managed to
fix recommendation biases against unpopular items, where
items with less training ratings were treated as a result of
non-randomly missing data. Park et al. [5] clustered unknown items and recommended them based on their clusters.
There have also been studies trying to solve the cold-start
problem by considering additional content-based features [6]
and latent aspects [1].
Although various methods have been developed to recommend unknown items, less investigations paid attention to
the integration of item exposure with user preference as a
critical determinant of recommendation and balanced the
trade-off between them in CF. Here item exposure is defined
as the number of ratings an item gets. Unknown items are
the items with low exposure. More exposure does not always
lead to higher popularity. But more exposure does help us
to determine the true quality of unknown items. It motivates us to investigate the possibility of forcing unknown
items in the user’s recommended pool in the beginning as a
fair treatment. If the promoted unknown item is potentially
good enough, it will become popular soon. Our risk is to
promote the unknown items that have low quality intrinsically. In this case, the users would rate them low and prevent
them from popularity. Promoting bad unknown items can
then be balanced by leveraging user preference.
The goal of this paper is to appropriately promote unknown items by carefully integrating item exposure with
user preference in CF. To put user preference and item exposure together, we define Recommendation Value (RV) to
be how much a system would like to recommend an item to
a user. A novel approach is proposed. First, the RVs are
moved towards user preference (similar to conventional CF).
Secondly, the RVs are appropriately elevated for unknown
items, where two main challenges will be encountered: (1)
how to balance the trade-off between recommending preferable items and unknown items, and (2) how to determine
to which users to promote a given unknown item (not all
of the users would agree to provide ratings for any items
requested by the system). The approach is designed to promote an unknown item to appropriate users until it gets sufficient reliable ratings. We have conducted the experiments
on MovieLens and Netflix data. The result demonstrates
that the proposed approach outperforms state-of-the-art CF
solutions in maximizing the exposure-stratified recall.

The paper proposes a novel approach to appropriately promote those items with few ratings in collaborative filtering.
Different from previous works, we force the items with few
ratings to be promoted to the users who would potentially
be able to give ratings, and then leverage the gathered user
preference to punish the promoted items with low quality
intrinsically. By slightly sacrificing the benefit of recommending the best items in terms of user satisfaction, our
approach seeks to provide all of the items with a chance to
be visible equally. The results of the experiments conducted
on MovieLens and Netflix data demonstrate its feasibility.

CCS Concepts
•Information systems → Recommender systems;

Keywords
Item Exposure; Novelty; Collaborative Filtering

1.

INTRODUCTION

Collaborative Filtering (CF) is a well-known technique
to predict user preference by identifying similar preferences
shared by collaborating users (user-based CF) or similar
items of interest to the same users (item-based CF). As only
popular items are able to collect sufficient rating data and
then be recommended more frequently, CF-based solutions
often face the problem of monopoly: popular items will become more popular while unknown items (those coming with
few ratings) will have less and less chance to get noticed.
Numerous studies on CF have investigated the effect of
item popularity on user preference [7]. Oh et al. [4] found
the phenomenon of personal popularity tendency. Their solution tended not to promote popular items to those who
preferred relatively obscure items. Liu et al. [3] showed
that pushing new items to inactive users could statistically
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

SIGIR ’16, July 17-21, 2016, Pisa, Italy
c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00
DOI: http://dx.doi.org/10.1145/2911451.2914769

813

2.

P
u P (z|u, i)1(u, i)
P (i|z) = P P
,
′
′
i′
u P (z|u, i )1(u, i )

THE PROPOSED APPROACH

The task of a recommendation system is to provide a
user with a ranking list of items. Given a set of users
U = {u1 , u2 , ..., u|U | } and items I = {i1 , i2 , ..., i|I| }, an obobs
served rating of user u for item i, denoted ru,i
, is an actual
rating collected from training data. Unrated user-item pairs
are called unobserved. For each of the unobserved user-item
pairs, the system generates a RV, denoted RV (u, i) ∈ [0, 1],
to indicate how much the system would like to recommend
item i to user u. For each user u, the system sorts the RVs of
all items unobserved by u, denoted Iu∗ ⊆ I, and recommends
the top-k highest RVs, denoted Iu∗,k ⊆ Iu∗ .
The RV of an unobserved user-item pair is defined as:


RV (u, i) = Pp (i|u) + α(i)Pr (i|u) 1 − Pp (i|u) ,
(1)

P P
u
i P (z|u, i)1(u, i)
P
P (z) = P P
,
z
u
i P (z|u, i)1(u, i)

(ru,i )γ
,
′ γ
i′ (ru,i )

Pr (i|u) = P

where Niobs denotes the number of users rating item i in the
training data. βs determines the discriminative power of the
weight (βs = 0 leads to identical weight of each rated item).
Alternatively, there are also other choices able to form the
rating probability such as the preference probabilities obtained from Eq.(2) using MF-preference and AR-preference.
The underlying assumption is that a user tends to rate her
preferable items. All the choices will be evaluated in the
experiments.
In some sense, given an unknown item whose rating probability is equal to the preference probability for a well-known
item, the unknown item generally has higher priority to be
recommended. The details of the proof are omitted here.
To identify whether an item is unknown, we define exposure as the number of users rating this item. In this paper,
function α(i) is simply estimated by a sigmoid function as
follows:

(2)

α(i) = Sigmoid(Nunk − Niobs ),

P
i P (z|u, i)1(u, i)
P
,
′
′
′
u
i P (z|u , i)1(u , i)

(11)

where Nunk is the exposure threshold of unknownness.
To avoid that the recommended pool is full of unknown
items, we limit the number of unknown items for each user
to a predefined value. Overall, as an unknown item i comes
in, no matter how the predicted preference for item i is, the
preference predicted based on unreliable, few ratings of item
i is regarded as untrusted. The RV of item i can, therefore,
be updated due to its low exposure (i.e., big α(i)), especially
for users who may rate it (i.e., high Pr (i|u)). There may be
a great number of unknown items competing. If item i fails
to be promoted, it waits for the next round. If its RV is enriched by update enough, item i will be promoted and earn
more exposure. As the exposure grows, its priority of promotion is eventually removed (i.e., small α(i)). Other unknown
items which failed previously will have more chance to get
promoted in the next iteration.

where z is the random variable for a latent topic or aspect.
The parameters are learned by the EM algorithm as follows.
E-step:

P (u|z) = P

(8)

where s(.) is a weighted indicator function and defined as:
( 1 β
( N obs ) s , if u rates i
i
s(u, i) =
(10)
0
, otherwise,

z

M-step:

P (u, i)
.
P (u, i′ )

i′

There is an explicit drawback due to the nature of EM.
The EM process learns the probability from the observed
data so that the probability of unknown items would be
underestimated owing to the lack of observed ratings. To
solve this issue, we assign a prior to each item when updating
P (i|z) in Eq.(6) as follows:
P
u P (z|u, i)s(u, i)
,
(9)
P (i|z) = P P
′
′
′
i
u P (z|u, i )s(u, i )

where we learn to predict user preference with Matrix Factorization (MF). ru,i for unobserved (u, i) is computed as the
dot product of corresponding user and item vectors. γ ∈ R is
the exponent that controls the discrimination between high
and low ratings. For γ > 1, the distance between high
and low ratings is strengthened. By this transformation,
the preference probability is restricted to the range [0, 1].
The MF-based method proposed in [2] only uses the observed data for predicting the preference probability (called
MF-preference). Except the MF, we also consider AllRank
(AR) [8], which uses the observed data and models the unobserved data, to predict the preference probability (called
AF-preference) as an alternative.
To calculate Pr (i|u), we extend the probability model presented in [1]. The probability of user u to rate item i can be
factorized as:
X
P (u, i) =
P (z)P (u|z)P (i|z),
(3)

P (z)P (u|z)P (i|z)
.
P (z|u, i) = P
z P (z)P (u|z)P (i|z)

(7)

where 1(.) is the indicator function outputting 1 if user u
rates item i and 0 otherwise. To this end, given user u, the
rating probability Pr (i|u) for item i is computed as:

where Pp (i|u) is preference probability indicating the
probability that user u prefers item i. Pr (i|u) is rating
probability indicating the probability that user u would
rate item i. α(i) is the coefficient indicating the condition
of being unknown. It varies from 0 to 1. A larger α(i) value
means the lower exposure for item i. That is, α(i) = 1 if item
i is totally unknown. Initially, the RV moves towards user
preference Pp (i|u), i.e., the first term. For unknown items,
the RV is appropriately elevated. The remainder 1 − Pp (i|u)
is added according to how likely user u will provide a rating
for item i, i.e., Pr (i|u). In other words, the RV is augmented
only when the unknown item (big α(i)) has a low predicted
preference (small Pp (i|u)) and user u has more chance to
rate item i (high Pr (i|u)). If it is not the case, the second
term approaches to 0.
Pp (i|u) is computed based on user preference as follows:
Pp (i|u) = P

(6)

(4)

(5)

814

815

816


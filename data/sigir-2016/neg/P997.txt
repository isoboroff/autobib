SG++: Word Representation with Sentiment and Negation
for Twitter Sentiment Classification
Qinmin Hu, Yijun Pei, Qin Chen and Liang He
Shanghai Key Laboratory of Multidimensional Information Processing
Department of Computer Science & Technology
East China Normal University, Shanghai, 200241, China

qmhu@cs.ecnu.edu.cn, {yjpei, qchen}@ica.stc.sh.cn and lhe@cs.ecnu.edu.cn
ABSTRACT

Keywords

Hence, we are motivated to establish a novel approach, not only
focusing on learning sentiment-specific word embedding efficiently,
but also capturing the negation information. We propose an advanced Skip-gram model which incorporates word sentiment and
negation into the basic Skip-gram model. First, the basic Skip-gram
model is extended by inserting a softmax layer, in order to add the
word sentiment polarity. Then, two paralleled embedding layers
are set up in the same embedding space, one for the affirmative
context and the other for the negated context, followed by their loss
functions. After that, we design the experiments on the SemEval
2013 and 2014 data sets. The results show our advanced Skipgram model is promising and superior. Further more, our proposal
achieves better performance efficiently and can learn much higher
dimensional word embedding informatively on the large-scale data.

Twitter Sentiment Classification; Word Representation; Neural Network; Negation

2.

Here we propose an advance Skip-gram model to incorporate both
word sentiment and negation information. In particular, there is
a a softmax layer for the word sentiment polarity upon the Skipgram model. Then, two paralleled embedding layers are set up in
the same embedding space, one for the affirmative context and the
other for the negated context, followed by their loss functions. We
evaluate our proposed model on the 2013 and 2014 SemEval data
sets. The experimental results show that the proposed approach
achieves better performance and learns higher dimensional word
embedding informatively on the large-scale data.

1.

THE PROPOSED APPROACH

Here we introduce the proposed approach, including the basic
Skip-gram model and the advanced Skip-gram model.

INTRODUCTION

2.1

Twitter sentiment classification is to treat Tweets as positive,
negative and neutral. This will help the stakeholders make proper
decisions, when the public sentiment on topics, such as the newly
released products or services, entertainment news and politics, can
be obtained.
Nowadays, many approaches in Twitter sentiment classification,
utilize a supervised classifier and rely on extensive feature engineering [3, 1, 10, 6, 9, 4, 8, 5]. However, there is an open problem
for feather engineering is that it costs extensive labour work and
specific domain knowledge. Therefore, feature learning is an alternative way to learn discriminative features automatically from data.
The work presented by [12, 16] proves that the features of a sentence/document can be learnt through its word embedding. Current
approaches of learning word embedding [2, 7, 15] focus on modeling the syntactic context. This situation does not take the sentiment information into account. [14] then proposed a complex neural network to learn sentiment-specific word embedding and language model simultaneously. However, it is very time-consuming
to training a big neural network and the negation is not included in
Tang’s proposal as well.

The Basic Skip-gram Model

The basic Skip-gram model we adopt here is introduced by [7] to
learn word embedding from text corpus. The training objective is to
find word representations such that the surrounding words (the syntactic context) can be predicted in a sentence or a document. Mathematically, given a sequence of training words w1 , w2 , ..., wT , the
goal of Skip-gram model is to maximize the log probability
T
1 X
T t=1

X

logp(wt+j |wt )

(1)

−c≤j≤c,j6=0

where c is the size of the context window, p(wt+j |wt ) is defined
using the softmax function:
exp(θwO · vwI )
p(wO |wI ) = PW
w=1 exp(θw · vwI )

(2)

where vw is the vector representation of word w, θw is the parameter vector of word (or class) w, and W is the number of words in
the vocabulary.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

2.2

The Advanced Skip-gram Model

SIGIR ’16, July 17-21, 2016, Pisa, Italy

Model 1 (SG+)..

c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00

The objective of our proposed SG+ is to incorporate word sentiment into the Skip-gram model. We then find word representa-

In order to learn better word embedding for Twitter sentiment
classification, we develop two neural networks based on the Skipgram model for word sentiment and negation.

DOI: http://dx.doi.org/10.1145/2911451.2914718

997

values, one for affirmative context and the other for negated context. During the training process, they are updated for optimizing
the training objective above.

Figure 2: SG++

2.3

Figure 1: SG+
tions to predict both syntactic context and word sentiment. Figure
1 shows there layers, where the first one indicates the training word
wt , the second one is the projection and the third one includes the
surrounding words wt−2 , wt−1 , wt+1 , wt+2 and the sentiment information st . Correspondingly, given a sequence of training words
w1 , w2 , ..., wT , we modify Equation 1 and Equations 2 and then
obtain the goal of SG+ to maximize the log probability
T
1 X
(
T t=1

X

Tweet Representation

In order to obtain tweet representation, we adopt the min, max,
and average convolutional layers for compositionality learning in
vector-based semantics, similar to the work proposed by [14] . Figure 3 shows the compositionality of the input as “I don’t wanna
miss it" and the corresponding tweet representation.

(1 − β)logp(wt+j |wt )) + βlogp(st |wt )

−c≤j≤c,j6=0

(3)
where c is the size of the context window, st is the sentiment label
of word wt , and β is the hyper-parameter that weights the impact
of word sentiment and syntactic context. Similar to p(wt+j |wt ),
p(st |wt ) is defined using the softmax function as well:
exp(θst · vwt )
p(st |wt ) = PS
s=1 exp(θs · vwt )

Figure 3: Tweet Representation

(4)

3.

EXPERIMENTAL SETUP

where vw is the vector representation of w, θs is the parameter
vector of sentiment label s, and S is the number of sentiment labels.

In order to evaluate our proposed approach, we design the experiments on the SemEval 2013 and 2014 data sets.

Model 2 (SG++)..

3.1

The objective of SG++ is to further incorporate negation. Here
we propose to learn the affirmative and negated word embedding simultaneously. Intuitively, affirmative (negated) words are mapped
to the affirmative (negated) representations, which can be used to
predict the surrounding words and word sentiment in affirmative
(negated) context. Figure 2 presents an example... Given a sequence of training words w1 , w2 , ..., wT where negation detection
are already performed, the goal of NSSG+ is to maximize the log
probability

There are multiple subtasks in SemEval 2013 and 2014. Here we
focus on Task B, which is a task of sentiment analysis in Twitter
called “Message Polarity Classification". It is to classify whether
a given message is of positive, negative, or neutral sentiment. The
official evaluation metric is macro-F1 of positive and negative sentiment. Therefore, we remove the neutral tweets in the preprocessing.

T
1 X
β(nt logp(snt |wt ) + (1 − nt )log(sat |wt ))
T t=1
X
+(
(1 − β)logp(wt+j |wt ))

3.2

Task Description

Data Sets

Table 1 shows the statistics of the 2013 and 2014 SemEval datasets.
Here the raining set contains annotated tweets, and the development
set has a few of tweets and is intended to be used as a developmenttime evaluation dataset as the participants develop their systems.
In particular, it’s usually used for tuning parameters. These two
datasets above are shared by SemEval 2013 and 2014.
The rest of the data sets are test sets. LiveJournal2014 contains sentences from LiveJournal in order to determine how systems trained on Twitter perform on other sources. SMS2013 obtains messages from NUS SMS corpus. Twitter2013 and 2014 are

(5)

−c≤j≤c,j6=0

where sat (snt ) is the sentiment label in affirmative (negated) context, and nt is the indicator whether wt is negated or not. Technically, we set two paralleled embedding layers with the same initial

998

tweets, which express sentiment about popular topics in 2013 and
2014. Twitter2014Sarcasm is a small test set of tweets that contain
the sarcasm hashtag to determine how sarcasm affects the tweet
polarity.
Dataset
Training set
Development set
LiveJournal2014
SMS2013
Twitter2013
Twitter2014
Twitter2014Sarcasm

Pos
3199
575
427
490
1572
981
33

Neg
1258
340
304
389
601
202
40

SG
SG++

Total
4457
1654
731
879
2173
1183
73

Table 3: Top 40 neighbor words of good

4.3

Tuning of Parameter β

In the proposed advance Skip-gram model “SG++", parameter β
indicates the importance of the sentiment label. When β equals 0,
it means that only syntactic context is adopted. Otherwise if β is
1, negation dominates the label. Empirically, we draw the figure
in Figure 4 to turn β. The results suggest that it is better to set β
around 0.5. This also confirms our motivation to consider syntactic
context and word sentiment at the same time in Twitter sentiment
classification.

Table 1: Statistics of SemEval 2013 and 2014

4.

good
nice, great, gr8, cool, rough, terrific, harmless
blessed, interesting, testy, familiar, bad
nice, great, cool, :-), funny, special, interesting
fantastic, lucky, :D, =), fair

EXPERIMENTAL RESULTS AND ANALYSIS

We present the experimental results on SemEval 2013 and 2014
in Table 2, where “SG++" is our proposed advanced Skip-gram
model with sentiment and negation, “SG+" denotes the Skip-gram
model with word sentiment and “SG" stands for the basic Skipgram model. We can see that “SG++" outperforms “SG+" and
“SG" on all the datasets besides of “Twitter2014Sarcasm".
Dataset
LiveJournal2014
SMS2013
Twitter2013
Twitter2014
Twitter2014Sarcasm

SG
72.03
74.06
76.16
74.82
52.21

SG+
73.74
77.47
78.91
77.56
54.79

SG++
77.93
80.86
82.21
79.40
52.21
Figure 4: β Tuning of SG++ on SemEval 2013

Table 2: Results on SemEval 2013 and 2014

4.1

4.4

Influence of Sentiment and Negation

In Table 2, we design the experiments to evaluate the influence
of sentiment by comparing the performance of “SG+" with “SG".
At the same way, we investigate negation by testing “SG++" and
“SG+" respectively. We can see that “SG+" outperforms “SG", and
“SG++" is better than “SG+" on the first four data sets. Hence,
we conclude that sentiment and negation play very important roles
in Twitter sentiment classification. Furthermore, our experiments
confirm our motivation and suggest the future work to consider sentiment and negation together.
The performance of Twitter2014Sarcasm is not stable in Table 2,
since our proposed “SG++" deals with the normal tweets and the
sarcasm ones equally.

4.2

Performance Comparisons

In order to evaluate the superiority of our proposed model, we
conduct the experiments in Twitter2013 to compare the performance
with the majority of the existing algorithms and models in the previous work, such as the work proposed by [14] and [13], the DistSuper algorithm [3] and SVM with unigram [11].
Approach
DistSuper
SVM + unigram
MPQA (Append)
NRC-Emotion (Appended)
HL (Appended)
HashtagLex (Appended)
Sentiment140Lex (Appended)
TS-Lex (Appended)
RAE
SSW Eu (unigram)
SG++

Intuitive Insight of SG++

Here we present an example to show the intuitive insight of our
proposed advanced Skip-gram model “SG++". Table 3 shows the
neighbors of the target word “good" under “SG++" and “SG". We
can see that the neighbor words found by “SG++" are more reasonable than those by “SG", considering the sentiment and negation.
In particular, there are some negative words, such as rough, testy
and bad in the list of “SG".
Note that the way to find the neighbors adopts the utility program distance. The distance program computes cosine similarity
between two words in the embedding space, and returns the top 40
closest words.

Macro-F1
68.70
74.50
76.54
76.79
79.40
76.67
80.68
82.36
75.12
82.93
82.21

Table 4: Performance ComparisonsTwitter2013
Table 4 shows the performance with eleven algorithm/model configurations. The first two are based on unigram features. Then the
following six are the work done by [14] and [13] with hand-crafted
features. The last three are based on feature learning through neural

999

networks. We observe that our proposed “SG++" achieves one of
the best results.
Approach
DistSuper
SVM + unigram
MPQA, NRC, HL
HashtagLex,
Sentiment140Lex
TS-Lex
RAE
SSW Eu
SG++

Data Size
large
small
small
large

Data Quality
low
high
high
low

Sentiment
N/A
N/A
shallow
shallow

Syntactic
shallow
shallow
deep
deep

large
small
high
large

low
high
low
low

deep
deep
deep
deep

deep
deep
deep
deep

Table 5: Advantage Analysis
In order to better understanding the advantages of “SG++", we
summarize the characters of all the listed algorithms/models in Table 5. We draw the conclusions that: (1) the proposed “SG++"
makes the best result with automatic feature learning; (2) although
the quality of the hand-crafted labels is high, the amount is less
and the coverage is low; (3) the deep model outperforms the shallow one, since the deep one can capture the latent connections and
comprehensive linguistic phenomenon of words.

5.

CONCLUSIONS AND FUTURE WORK

In this paper, we propose an advanced Skip-gram model (SG++)
to learn better word embedding and negation for Twitter sentiment
classification efficiently. Three layers are presented in SG++, namely
the syntactic layer, the affirmative layer and the negation one. We
also built an SG+ model to show the effectiveness of sentiment
without negation. Our experiments on SemEval 2013 and 2014 indicate that both sentiment and negation play very important roles
in Twitter sentiment classification. Furthermore, we conduct extensive performance comparisons with other similar algorithms/models.
The proposed SG++ obtains the top 3 results with automatic feature
learning.
Based on the analysis in Table 5, the deep neural network is able
to achieve better tweet representation than the shallow one. In the
future, we will focus on developing deep neural network to learn
language models and other possibilities. This is also our ongoing
work.

6.

ACKNOWLEDGMENTS

This research is funded by the National High Technology Research and Development Program of China (No. 2015AA015801),
and the Science and Technology Commission of Shanghai Municipality of China (No.15PJ1401700).

7.

REFERENCES

[1] L. Barbosa and J. Feng. Robust sentiment detection on
twitter from biased and noisy data. In Proceedings of the
23rd International Conference on Computational
Linguistics: Posters, pages 36–44. Association for
Computational Linguistics, 2010.
[2] R. Collobert, J. Weston, L. Bottou, M. Karlen,
K. Kavukcuoglu, and P. Kuksa. Natural language processing
(almost) from scratch. The Journal of Machine Learning
Research, 12:2493–2537, 2011.
[3] A. Go, R. Bhayani, and L. Huang. Twitter sentiment
classification using distant supervision. CS224N Project
Report, Stanford, pages 1–12, 2009.

1000

[4] H. Hamdan, F. Béchet, and P. Bellot. Experiments with
dbpedia, wordnet and sentiwordnet as resources for
sentiment analysis in micro-blogging. In Second Joint
Conference on Lexical and Computational Semantics (*
SEM), volume 2, pages 455–459, 2013.
[5] Y. He, Q. Hu, Y. Song, and L. He. Estimating probability
density of content types for promoting medical records
search. In Advances in Information Retrieval - 38th
European Conference on IR Research, ECIR 2016, Padua,
Italy, March 20-23, 2016. Proceedings, pages 252–263,
2016.
[6] L. Jiang, M. Yu, M. Zhou, X. Liu, and T. Zhao.
Target-dependent twitter sentiment classification. In
Proceedings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies-Volume 1, pages 151–160. Association for
Computational Linguistics, 2011.
[7] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and
J. Dean. Distributed representations of words and phrases
and their compositionality. In Advances in Neural
Information Processing Systems, pages 3111–3119, 2013.
[8] S. M. Mohammad, S. Kiritchenko, and X. Zhu. Nrc-canada:
Building the state-of-the-art in sentiment analysis of tweets.
In Proceedings of the Second Joint Conference on Lexical
and Computational Semantics (SEMSTARÂaÂŕ13),
˛
2013.
[9] S. Mukherjee, P. Bhattacharyya, et al. Sentiment analysis in
twitter with lightweight discourse analysis. In COLING,
pages 1847–1864, 2012.
[10] A. Pak and P. Paroubek. Twitter as a corpus for sentiment
analysis and opinion mining. In LREC, volume 10, pages
1320–1326, 2010.
[11] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?:
sentiment classification using machine learning techniques.
In Proceedings of the ACL-02 conference on Empirical
methods in natural language processing-Volume 10, pages
79–86. Association for Computational Linguistics, 2002.
[12] R. Socher, A. Perelygin, J. Y. Wu, J. Chuang, C. D. Manning,
A. Y. Ng, and C. Potts. Recursive deep models for semantic
compositionality over a sentiment treebank. In Proceedings
of the conference on empirical methods in natural language
processing (EMNLP), volume 1631, page 1642. Citeseer,
2013.
[13] D. Tang, F. Wei, B. Qin, M. Zhou, and T. Liu. Building
large-scale twitter-specific sentiment lexicon: A
representation learning approach. In COLING 2014, pages
172–182, 2014.
[14] D. Tang, F. Wei, N. Yang, M. Zhou, T. Liu, and B. Qin.
Learning sentiment-specific word embedding for twitter
sentiment classification. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Linguistics,
pages 1555–1565, 2014.
[15] H. Yang, Q. Hu, and L. He. Learning topic-oriented word
embedding for query classification. In Advances in
Knowledge Discovery and Data Mining - 19th Pacific-Asia
Conference, PAKDD 2015, Ho Chi Minh City, Vietnam, May
19-22, 2015, Proceedings, Part I, pages 188–198, 2015.
[16] A. Yessenalina and C. Cardie. Compositional matrix-space
models for sentiment analysis. In Proceedings of the
Conference on Empirical Methods in Natural Language
Processing, pages 172–182. Association for Computational
Linguistics, 2011.


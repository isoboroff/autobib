Ordinal Text Quantification
Giovanni Da San Martino

Wei Gao

Qatar Computing Research
Institute
Hamad bin Khalifa University
Doha, Qatar

Qatar Computing Research
Institute
Hamad bin Khalifa University
Doha, Qatar

gmartino@qf.org.qa

wgao@qf.org.qa

ABSTRACT

∗

Qatar Computing Research
Institute
Hamad bin Khalifa University
Doha, Qatar

fsebastiani@qf.org.qa

(and opinion-laden data in general) in digital form. An example of a totally ordered set of classes {VeryNegative, Negative, Fair, Positive, VeryPositive}, according to which customers may be asked to evaluate a product or service; the
case of product reviews evaluated on a scale of 1 to 5 stars
is another such example. More generally, OC is of key importance in the social sciences, since it is well-known that
humans find it cognitively easier to express their judgments
and evaluations on ordinal (i.e., discrete) scales.
In this paper we do not deal with ordinal classification,
but with ordinal quantification (OQ). Quantification [6] is
defined as the task of estimating the prevalence (i.e., relative frequency) pT e (ci ) of the classes ci ∈ C in an unlabelled
set T e, given a set T r of labelled training items. Quantification finds its natural application in contexts characterized
by distribution drift, i.e., contexts where the unlabelled data
may not exhibit the same class prevalences as the test data.
Distribution drift may be due to different reasons, including the inherent non-stationary character of the context, or
class bias that affected the selection of the training data.
A naı̈ve way to tackle quantification is via the “classify
and count” (CC) approach, i.e., classify each unlabelled item
independently and compute the fraction of the unlabelled
items that have been attributed the class. However, a good
classifier is not necessarily a good quantifier: assuming the
binary case, even if (F P + F N ) is comparatively small,
bad quantification accuracy might result if F P and F N are
significantly different (since perfect quantification coincides
with the case F P = F N ). This has led researchers to study
quantification as a task on its own right [1, 4, 6], rather than
as a byproduct of classification.
However, while quantification has been studied both for
the binary case and the SLMC case, no paper has tackled OQ
yet. We do so for the first time by presenting an algorithm
for OQ (dubbed OQT) based on “OQ-trees”.
In §2 we describe OQT, while in §3 we discuss experiments
we have run on a tweet sentiment analysis dataset.

In recent years there has been a growing interest in text
quantification, a supervised learning task where the goal is
to accurately estimate, in an unlabelled set of items, the
prevalence (or “relative frequency”) of each class c in a predefined set C. Text quantification has several applications, and
is a dominant concern in fields such as market research, the
social sciences, political science, and epidemiology. In this
paper we tackle, for the first time, the problem of ordinal text
quantification, defined as the task of performing text quantification when a total order is defined on the set of classes;
estimating the prevalence of “five stars” reviews in a set of
reviews of a given product, and monitoring this prevalence
across time, is an example application. We present OQT,
a novel tree-based OQ algorithm, and discuss experimental
results obtained on a dataset of tweets classified according
to sentiment strength.

Keywords
Ordinal Quantification; Quantification; Sentiment Analysis;

1.

Fabrizio Sebastiani

INTRODUCTION

Ordinal classification (OC – also known as ordinal regression, or rating inference) is the problem of automatically
labelling data items x ∈ X according to a set of classes
C = {c1 , ..., c|C| } such that |C| > 2 and there is a total order
≺ defined on the classes in C. OC is usually viewed as a supervised learning problem, whereby the classifier h : X → C
needs to be generated from training data. OC is different
from standard single-label multi-class (SLMC) classification,
since in SLMC there is no order defined on C.
OC is receiving increasing attention from the sentiment
analysis and opinion mining community, due to the importance of managing increasing amounts of product reviews
∗Fabrizio Sebastiani is currently on leave from Consiglio
Nazionale delle Ricerche, Italy.

2.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

OQ-TREES

In tackling OC our goal has been to design an algorithm
that (a) leverages the information inherent in the class ordering ≺, and (b) performs quantification in the style of the
Probabilistic Classify and Count (PCC) method [1], since
this is the method that has proven the best performer in
our SLMC text quantification experiments of [7]. We first
introduce PCC, since OQT uses it as a subroutine; we will
then move on to presenting OQT itself.

SIGIR ’16, July 17 - 21, 2016, Pisa, Italy
c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4069-4/16/07. . . $15.00
DOI: http://dx.doi.org/10.1145/2911451.2914749

937

1

2
3
4
5
6

7

8
9
10
11
12
13
14
15
16
17
18
19

tree is described in concise form as Algorithm 1, and goes
as follows.
Assume we have a training set T r and a held-out validation set V a of items labelled according to C. The first step
(Line 3) consists of training (|C|−1) binary classifiers hj , for
j ∈ {1, . . . , (|C| − 1)}. Each of these classifiers must separate
C j and C j ; for training hj we will take the items in T rj as
the negative training examples and the items in T rj as the
positive training examples. We require that these classifiers,
aside from taking binary decisions (i.e., predicting if a test
item is in C j or in C j ), also output posterior probabilities,
i.e., probabilities p(C j |x) and p(C j |x) = (1 − p(C j |x)).
The second step (Line 5) is building the OQ (binary) tree.
In order to do this, among the classifiers hj we pick the one
(let us call it ht ) that displays the highest quantification accuracy (Line 12) on V a, and we place it at the root of the
binary tree. Here, quantification is performed according to
the PCC method described in §2.1. We measure the quantification accuracy of hj via the standard measure for evaluating SLMC quantification, i.e., Kullback-Leibler Divergence
(KLD)1 , defined as

Function GenerateTree (C, T r, V a);
/* Generates the OQ-tree */
Input : Ordered set C = {c1 , ..., c|C| };
Set T r of labelled items;
Set V a of labelled items;
Output: OQ-tree TC .
for j ∈ {1, ..., (|C| − 1)} do
Train classifier hj from T rj and T rj ;
end
TC ← Tree(C, {hj }, V a);
return TC ;
Function Tree (C, HC , V a);
/* Recursive subroutine for generating the
OQ-tree */
Input : Ordered set C = {c1 , ..., c|C| } of classes;
Set of classifiers HC = {h1 , ..., h(|C|−1) };
Output: OQ-tree TC .
if C = {c} then
Generate a leaf node Tc ;
return Tc ;
else
ht ← arg min KLD(p, p̂, hj , V a);
hj ∈HC

KLD(p, p̂) =

Generate a node TC and associate ht to it;
HC0 ← {h1 , ..., h(t−1) };
HC00 ← {h(t+1) , ..., h(|C|−1) };
LChild(TC ) ← Tree(C t , HC0 , V a);
RChild(TC ) ← Tree(C t , HC00 , V a);
return TC ;
end

cj ∈C

2.3

p(cj )
p̂(cj )

(3)

Estimating class prevalences via OQT

The algorithm for estimating class prevalences by using an
OQ-tree is described in concise form as Algorithm 2, and
goes as follows. Essentially, for each item x ∈ T e and for
each class c ∈ C, we compute (Line 6) p(c|x); the estimate
p̂T e (c) is computed as the average, across all x ∈ T e, of
p(c|x). The posterior probability p(c|x) is computed in a
recursive, hierarchical way (Lines 13 to 18), i.e., as the probability that, in a SLMC setting, the binary classifiers that
lie on the path from the root to leaf c, would classify item
x exactly in leaf c (i.e., that they would route x exactly to
leaf c). This probability is computed as the product of all
the posterior probabilities returned by the classifiers that lie
on the path from the root to leaf c.
An example quantification tree for a set of |C| = 6 classes
is displayed in Figure 1; for brevity, classes are represented
by natural numbers, the total order defined on them is the

Probabilistic Classify and Count (PCC)

PCC, originally proposed in [1], consists of generating a classifier from T r, classifying the items in T e, and estimating
pT e (c) as the expected fraction of items predicted to belong
to c. If (i) by p(c|x) we indicate the posterior probability, i.e., the probability (as estimated by the classifier) of
membership in c of the unlabelled item x, (ii) by pT e (ĉ) we
indicate the fraction of items in T e predicted to be in c,
and (iii) by E[x] we indicate the expected value of x, this
corresponds to computing
1 X
p̂T e (c) = E[pT e (ĉ)] =
p(c|x)
(1)
|T e|
x∈T e

1
Note that KLD is a measure of error, and not of accuracy; i.e., lower values are better. Note also that KLD is
undefined when one of the p̂(cj ) is 0. To solve this problem, in computing KLD we smooth both p(cj ) and p̂(cj )
via additive smoothing, i.e., we compute

where the “hat” symbol indicates estimation. The rationale
of PCC is that posterior probabilities contain richer information than binary decisions, which are usually obtained
from posterior probabilities by thresholding.

2.2

p(cj ) log

where p̂ is the distribution estimated via PCC using the
posterior probabilities generated by hj . We then repeat the
process recursively on the left and on the right branches of
the binary tree (Lines 14 to 17), thus building a fully grown
quantification tree.

Algorithm 1: Function GenerateTree for generating
an OQ-tree.

2.1

X

Generating an OQ-tree

p(cj ) + 
ps (cj ) = X
(
p(cj )) +  · |C|

We will tackle OQ by arranging the classes in C into an
OQ-tree; we thus dub our algorithm OQT. Given any j ∈
{1, . . . , (|C| − 1)}, C j = {c1 , . . . , cj } will be called a prefix
of C, and C j = {cj+1 , . . . , c|C| } will be called a suffix of C.
Given any j ∈ {1, . . . , (|C| − 1)} and a set S of items labelled
according to C, by S j we denote the set of items in S whose
class is in C j , and by S j we denote the set of items in S
whose class is in C j .
Our algorithm for training such a

(2)

cj ∈C
s

where p (cj ) denotes the smoothed version of p(cj ) and
the denominator is just a normalizing factor (same for the
1
p̂s (cj )’s); the quantity  = 2·|T
is used as a smoothing face|
tor. The smoothed versions of p(cj ) and p̂(cj ) are then used
in place of the non-smoothed versions in Equation 3; as a
result, KLD is always defined.

938

1

2
3
4
5
6
7
8
9
10
11

12

13
14
15
16
17

18

Function QuantifyViaHierarchicalPCC (T e, TC );
/* Estimates class prevalences on T e using
the quantification tree */
Input : Unlabelled set T e;
Quantification tree TC ;
Output: Estimates p̂(c) for all c ∈ C;
for c ∈ C do
p̂(c) ← 0
end
for x ∈ T e do
CPost(x, TC , 1); /* Compute the {p(c|x)} */
for c ∈ C do
p(c|x)
p̂(c) ← p̂(c) +
;
|T e|
end
end
return {p̂(c)}
Procedure CPost (x, TC , SubP );
/* Recursive subroutine for computing all the
posteriors {p(c|x)} */
Input : Unlabelled item x;
Quantification tree TC ;
Probability SubP of current subtree;
Output: Posteriors {p(c|x)};
if TC = {c} then
/* TC is a leaf, labelled by class c */
p(c|x) ← SubP ;
else
CPost(x, LChild(TC ), p(C t |x) · SubP );
CPost(x, RChild(TC ), p(C t |x) · SubP );
/* p(C t |x) and p(C t |x) are the posteriors
returned by the classifier associated
with the root of TC */
end

Figure 1: An example OQ-tree.

quantification algorithm: if there were no order defined on
the classes this policy would make no sense.
A second reason why OQT is a truly OQ algorithm is that
the groups of classes (such as 1234 and 56) between which a
binary classifier needs to discriminate are groups of contiguous classes. It is because of this contiguity that the trees we
generate makes sense: if, say, our classes represent degrees
of positivity of product reviews, with 1 indicating most negative and 6 indicating most positive, group 56 may be taken
to represent the positive reviews (to different degrees), while
1234 may be taken to represent the reviews that are not positive; a group such as, say, 256, would instead be very hard
to interpret, since it is formed of non-contiguous classes that
have little in common with each other2 .

Algorithm 2: Function QuantifyViaHierarchicalPCC
for estimating prevalences via an OQ-tree.

order defined on the natural numbers, and sets of classes are
represented by sequences of natural numbers. Note that, as
exemplified in Figure 1, OQT generates trees for which (a)
there is a 1-to-1 correspondence between classes and leaves of
the tree, (b) leaves are ordered left to right in the same order
as the classes in C, and (c) each internal node represents a
decision between a suffix and a prefix of C.
Point (c) is interesting, and deserves some discussion. In
Figure 1, internal node “1234 vs. 56” is trained by using
items labelled as 1, or 2, or 3, or 4, as negative examples
and items labelled as 5, or 6, as positive examples; however,
by looking at Figure 1, it would seem intuitive that items
labelled as 6 should not be used, since the node is root to a
subtree where class 6 is not an option anymore. The reason
why we do use items labelled as 6 (which is the reason why
the node is labelled “1234 vs. 56” and not “1234 vs. 5”) is
that, during the classification stage, the classifier associated
with the node might be asked to classify an item whose true
label is 6, and which has thus been misclassified high up in
the tree. In this case, it would be important that this item
be classified as 5, since this minimizes the contribution of
this item to misclassification error; and the likelihood that
this happens is increased if the classifier is trained to choose
between 1234 and 56, rather than between 1234 and 5. Note
also that this is one aspect for which OQT is a true ordinal

3.

EXPERIMENTS

The evaluation measure we adopt for our experiments is the
only one known for OQ, i.e., the Earth Mover’s Distance
(EM D) [9], a measure well known in the field of computer
vision and whose use in OQ was proposed in [4]. When there
is a total order on the classes in C, EM D is defined as
|C|−1

EM D(p̂, p) =

j
j
X X
X
|
p̂(ci ) −
p(ci )|
j=1

i=1

(4)

i=1

and can be computed in |C| steps from the estimated and
true class prevalences. Like KLD in Equation 3, EM D is
a measure of error, so lower values are better; EM D ranges
between 0 (best) and |C| − 1 (worst).
The dataset we use is the one released within SemEval
2016 Task 4 “Sentiment Analysis in Twitter” [8], and consists of tweets labelled according to five degrees of sentiment,
from VeryNegative to VeryPositive. The dataset comes broken down into subsets TRAIN (6000 tweets), DEV (2000
tweets), and DEVTEST (2000 tweets); we use them for
training, parameter optimization, and testing, respectively.
2
The code that implements our method is available from
http://alt.qcri.org/tools/quantification/

939

the binary class assignments instead. This seems a further
(albeit indirect) confirmation of the results of [7], where
PCC(SVM) emerged as the best of 8 methods in SLMC
tweet quantification. The good result of PCC(SVM) is even
more striking if we consider that the other 4 methods, which
PCC(SVM) beats by a wide margin, leverage the ≺ class order while PCC(SVM) does not; this seems further evidence
of the value of posterior probabilities in quantification.
A second observation is that ACC, a quantification method
that has been consistently reported to perform better than
CC [1, 5, 7, 6], here performs much worse than CC, in the
context of both SVORIM and -SVR. This is an aspect that
will deserve further investigation.
In Subtask E of the SemEval 2016 Task 4 shared task
(a subtask which deals with ordinal tweet quantification by
sentiment – see [8]), the system described in this paper obtained an EM D score of 0.243, ranking 1st in a set of 10
participating systems, with a high margin over the other
ones (systems from rank 2 to rank 8 obtained EM D scores
between 0.316 and 0.366). Overall, these results are encouraging and preliminary at the same time. For the future we
plan to run more experiments, using more datasets (e.g.,
product review datasets) and more baseline systems from
the world of ordinal classification and SLMC quantification.

PCC(SVM)

CC(SVORIM)

ACC(SVORIM)

CC(-SVR)

ACC(-SVR)

OQT(SVM)

Table 1: EM D values obtained by the six methods (lower is better) and percentage of deterioration
with respect to the best performer.

0.222
+5.71%

0.337
+60.48%

0.653
+210.95%

0.325
+54.76%

0.675
+221.43%

0.210

Each of these three sets is broken down into “topics” consisting of 100 tweets each; i.e., the task is to quantify the
prevalence of a certain class (say, VeryPositive) among the
comments about a certain topic. One thus needs to compute EM D separately on each topic, and then average the
results.
For lack of space (and because it is not the main focus
of this paper) we do not describe the preprocessing steps
we adopt to generate the vectorial representations for our
tweets; the details are given in [7, §4.1].
We evaluate OQT against the following baselines. The
1st is a PCC SLMC quantifier; it does not take order ≺
into account but, as shown in [7] it is a very strong SLMC
classifier anyway. The 2nd is a CC quantifier (see §1) that
uses the SVORIM OC learning algorithm [2]. The 3rd is an
ACC (“Adjusted Classify and Count” – see [6, §2]) quantifier that also relies on SVORIM. The 4th and 5th are again
a CC quantifier and an ACC quantifier, this time using an
adaptation to ordinal regression of the -SVR metric regression algorithm [3]. While OQT and PCC are not inherently SVM-based, we choose SVMs as their base learner,
also for better experimental uniformity with the other four
methods, which are inherently SVM-based; from now on the
two former methods will thus be called OQT(SVM) and
PCC(SVM). We use the implementations of (i) standard
SVMs, (ii) SVORIM, and (iii) -SVR, as available in the
LIBSVM suite3 . For each learning algorithm we have optimized the C parameter (which sets the tradeoff between the
training error and the margin) on the DEV set, performing
a grid search on all values of type 10x with x ∈ {−6, ..., 7}.
Note that both PCC(SVM) and OQT(SVM) (which depends
on PCC(SVM)) require as input not the classifier’s binary
decisions but its posterior probabilities. Since SVMs do not
natively generate posterior probabilities, we use the -b option of LIBSVM, which converts the scores originally generated by SVMs into posterior probabilities according to the
algorithm of [10].
The results of our experiments are given in Table 1. Our
OQT(SVM) method is the best performer, with PCC(SVM)
the second best, with a +5.71% deterioration with respect
to OQT(SVM). Two aspects are interesting to discuss here.
The first is that the two best methods are the ones that
make use of posterior probabilities, i.e., where class prevalences are computed as expected values of the binary class assignments; the other 4 methods are based on CC and ACC,
which do not make use of posterior probabilities and use

4.

REFERENCES

[1] A. Bella, C. Ferri, J. Hernández-Orallo, and M. J.
Ramı́rez-Quintana. Quantification via probability
estimators. In Proceedings of the 11th IEEE
International Conference on Data Mining (ICDM
2010), pages 737–742, Sydney, AU, 2010.
[2] W. Chu and S. S. Keerthi. Support vector ordinal
regression. Neural Computation, 19(3):145–152, 2007.
[3] H. Drucker, C. J. Burges, L. Kaufman, A. Smola, and
V. Vapnik. Support vector regression machines. In
Proceedings of the 11th Annual Conference on Neural
Information Processing Systems (NIPS 1997), pages
155–161, Denver, US, 1997.
[4] A. Esuli and F. Sebastiani. Sentiment quantification.
IEEE Intelligent Systems, 25(4):72–75, 2010.
[5] A. Esuli and F. Sebastiani. Optimizing text quantifiers
for multivariate loss functions. ACM Transactions on
Knowledge Discovery and Data, 9(4):Article 27, 2015.
[6] G. Forman. Quantifying counts and costs via
classification. Data Mining and Knowledge Discovery,
17(2):164–206, 2008.
[7] W. Gao and F. Sebastiani. From classification to
quantification in tweet sentiment analysis. Social
Network Analysis and Mining, 2016. Forthcoming.
[8] P. Nakov, A. Ritter, S. Rosenthal, F. Sebastiani, and
V. Stoyanov. SemEval-2016 Task 4: Sentiment
analysis in Twitter. In Proceedings of the 10th
International Workshop on Semantic Evaluation
(SemEval 2016), San Diego, US, 2016. Forthcoming.
[9] Y. Rubner, C. Tomasi, and L. J. Guibas. The Earth
Mover’s Distance as a metric for image retrieval.
International Journal of Computer Vision,
40(2):99–121, 2000.
[10] T.-F. Wu, C.-J. Lin, and R. C. Weng. Probability
estimates for multi-class classification by pairwise
coupling. Journal of Machine Learning Research,
5:975–1005, 2004.

3
LIBSVM is available from http://www.csie.ntu.edu.tw/
˜cjlin/libsvm/

940


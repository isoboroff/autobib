Transfer Learning for Cross-Lingual Sentiment
Classiﬁcation with Weakly Shared Deep Neural Networks
1

1

2

1

Guangyou Zhou , Zhao Zeng , Jimmy Xiangji Huang , and Tingting He
1

School of Computer, Central China Normal University, Wuhan 430079, China
2
School of Information Technology, York University, Toronto, Canada

{gyzhou, zhaozeng, tthe}@mail.ccnu.edu.cn jhuang@yorku.ca
ABSTRACT

are considered as the most valuable resources for sentiment
classiﬁcation. However, such resources in diﬀerent languages
are very imbalanced. Manually labeling each individual language is a time-consuming and labor-intensive job, which
makes cross-lingual sentiment classiﬁcation essential for this
application.
Cross-lingual sentiment classiﬁcation aims to automatically predict sentiment polarity (e.g., positive or negative) of
data in a label-scarce target language by exploiting labeled
data from a label-rich language. The fundamental challenge
of cross-lingual learning stems from a lack of overlap between
the feature spaces of source language data and that of target
language data. To address this challenge, previous work in
the literature mainly relies on machine translation engines
or bilingual resources to directly translate labeled data from
source language to target language [19, 49, 46, 46, 34, 30,
50]. With the translated resources, one way is to jointly
train the bi-view sentiment classiﬁers on labeled data from
source language and their translations in target language via
ensemble methods. Another way is to ﬁrstly select a subset
of pivot features from source language and their translations in target language, and then use these pivot pairs to
induce the language-independent features by modeling the
corrections between pivot features and non-pivot features in
an unsupervised fashion. Though pivot studies have been
performed to make use of the translated resources for sentiment classiﬁcation in target language, the methods are very
straightforward by directly employing an inductive classiﬁer,
and the classiﬁcation performance is far from satisfactory
because of the language gap between source language and
the translated target language.
Recently, many eﬀorts have been initiated on learning feature representations with deep neural networks (DNNs) in
the context of cross-lingual sentiment analysis [21, 17, 7, 22,
53, 40, 56, 18], inspired by the success of work on monolingual feature representations. Usually, the paired sentences
from parallel corpora are used to learn bilingual feature
representations across languages, eliminating the need of
machine translation systems. By transferring the feature
representations and labeling information from the source
language space, we can learn a semantic-intensive target
language feature representation, which can greatly improve
the performance of target language sentiment classiﬁcation
tasks. In other words, the rich information transferred from
the source language can help train the target language DNNs
even with little labeled target language data. This is contrary to the popular strategy of trading the representation
power of DNNs for better generalization performance in the

Cross-lingual sentiment classiﬁcation aims to automatically
predict sentiment polarity (e.g., positive or negative) of data
in a label-scarce target language by exploiting labeled data
from a label-rich language. The fundamental challenge of
cross-lingual learning stems from a lack of overlap between
the feature spaces of source language data and that of target
language data. To address this challenge, previous studies
have been performed to make use of the translated resources
for sentiment classiﬁcation in the target language, and the
classiﬁcation performance is far from satisfactory because
of the language gap between the source language and the
translated target language.
In this paper, to address the above challenge, we present
a novel deep neural network structure, called Weakly Shared
Deep Neural Networks (WSDNNs), to transfer the crosslingual information from a source language to a target language. To share the sentiment labels between two languages,
we build multiple weakly shared layers of features. It allows to represent both shared inter-language features and
language-speciﬁc ones, making this structure more ﬂexible
and powerful in capturing the feature representations of bilingual languages jointly. We conduct a set of experiments with
cross-lingual sentiment classiﬁcation tasks on multilingual
Amazon product reviews. The empirical results show that
our proposed approach signiﬁcantly outperforms the stateof-the-art methods for cross-lingual sentiment classiﬁcation,
especially when label data is scarce.

Keywords
Cross-lingual; sentiment classiﬁcation; auto-encoders

1.

INTRODUCTION

With the development of Web 2.0, more and more user
generated sentiment data have been shared on the Web.
They exist in the form of user reviews on shopping or opinion sites, in posts of blogs or customer feedback in diﬀerent languages. These labeled user generated sentiment data
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.

SIGIR ’16, July 17–21, 2016, Pisa, Italy.
c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00

DOI: http://dx.doi.org/10.1145/2911451.2911490

245

literature. In this paper, we will present how to use transferred cross-lingual information to train a powerful DNNs
without sacriﬁcing linguistic richness, which will yield much
better performance for cross-lingual sentiment classiﬁcation
tasks.
To this end, we propose a novel DNNs that hierarchically
learns to transfer the semantic knowledge from the source
language to the target language, namely Weakly Shared Deep
Neural Networks (WSDNNs). Our WSDNNs are trained in
a novel way that minimizes the errors incurred by a crosslingual information transfer process. As a hierarchically
non-lineal model, WSDNNs diﬀer from the existing shallow
cross-lingual information transfer algorithms, such as crosslingual mixture model [26], cross-lingual subspace learning [55],
and cross-lingual correspondence learning [34], which learn
the cross-lingual feature representations by linear mathematics models. In WSDNNs, we model two DNNs that
take a pair of parallel bilingual sentences as input respectively, followed by multiple weakly-shared network layers at
the top. The output of the shared layer in WSDNNs yields
the translator function that can be used to transfer crosslingual information. To the best of our knowledge, existing DNNs in the context of cross-lingual sentiment classiﬁcation [7, 22, 53, 56, 18] are representation sharing. In
“representation sharing structure”, a set of common features
are constructed, which usually overestimates the importance
of language-speciﬁc features. While our weakly parametershared scheme makes our networks more robust of representing shared inter-language features as well as languagespeciﬁc ones. To evaluate the eﬀectiveness of the proposed
approach, we conduct extensive experiments on multilingual
Amazon product reviews for cross-lingual sentiment classiﬁcation tasks. The empirical results show the proposed approach is eﬀective for cross-lingual sentiment classiﬁcation,
and outperforms the state-of-the-art methods.
Our contribution in this paper is three-fold: (1) we propose a novel architecture of DNNs to transfer the crosslingual information from a source language to a target language, which can adequately mitigate the problem of insuﬃcient training data in the target language by bringing
in rich sentiment labels from the source language; (2) the
proposed WSDNNs are trained in a novel way that directly
minimizes the loss incurred by a label transfer function via
back-propagation, which can avoid unbalanced tuning of the
source language and the target language DNNs; (3) we show
superior results of the proposed WSDNNs on extensive experiments as compared with several strong baselines and the
other state-of-the-art methods.
The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 presents our
proposed deep neural network transfer learning framework
for cross-lingual sentiment classiﬁcation. Section 4 presents
the experimental results. Finally, we conclude the paper in
Section 5.

2.

RELATED WORK

Sentiment classiﬁcation has gained widely interest in information retrieval (IR) and natural language processing
(NLP) communities, we point the readers to recent books [31,
24] for an in-depth survey of literature on sentiment classiﬁcation. Methods in the literature for sentiment classiﬁcation heavily rely on quality and quantity of the label corpora, which are considered as the most valuable resources in

246

sentiment classiﬁcation task. However, such sentiment resources are imbalanced in diﬀerent languages. To leverage
resources in the source language to improve the sentiment
classiﬁcation in the target language, cross-lingual sentiment
classiﬁcation approaches have been investigated.
Cross-lingual sentiment classiﬁcation aims to automatically predict sentiment polarity (e.g., positive or negative)
of data in a label-scarce target language by exploiting labeled data from a label-rich language. The fundamental
challenge of cross-lingual learning stems from a lack of overlap between the feature spaces of source language data and
that of target language data.
To bridge the language gap, previous work in the literature mainly relies on machine translation engines or bilingual lexicons to directly adapt labeled data from a source
language to a target language. Banea et al. [3] employed
the machine translation engines to bridge the language gap
in diﬀerent languages for multilingual subjectivity analysis.
Wan [46] proposed to use ensemble methods to train Chinese sentiment classiﬁcation model on English labeled data
and their Chinese translations. English labeled data are
ﬁrst translated into Chinese, and then the bi-view sentiment
classiﬁers are trained on English and Chinese labeled data
respectively. Pan et al. [30] proposed a bi-view non-negative
matrix tri-factorization (BNMTF) model for cross-lingual
sentiment classiﬁcation problem. They employed machine
translation engines so that both training and test data are
able to have two representations, one in a source language
and the other in a target language. The proposed model is
derived from the non-negative matrix factorization models
in both languages in order to make more accurate prediction. Prettenhofer and Stein [34] proposed a cross-lingual
structural correspondence learning (CL-SCL) method to induce language-independent features. Instead of using machine translation engines to translate labeled texts, the authors ﬁrst selected a subsect of pivot features in the source
language to translate them into the target language, and
then use these pivot pairs to induce cross-lingual representations by modeling the correlations between pivot features
and non-pivot features in an unsupervised fashion. Recently,
Xiao and Guo [51] used the similar idea with [34] for crosslingual sentiment classiﬁcation. Instead of in a fully unsupervised fashion, Xiao and Guo [51] performed representation learning in a semi-supervised manner by directly incorporating discriminative information with respect to the
target prediction task. Li et al. [37] selected the samples in
the source language that were similar to those in the target
language to reduce the gap between two languages. Other
similar work includes [48, 25, 1, 52, 13, 6, 12, 41, 27, 8, 23,
2, 11, 36]. All these approaches rely on machine translation
or bilingual dictionary to build language connection.
Another group of studies propose to use unlabeled parallel data to ﬁll the gap between two languages. To solve the
feature coverage problem, Meng et al. [26] leveraged the unlabeled parallel data to learn unseen sentiment words. Similarly, Popat et al. [33] used the unlabeled parallel data to
cluster features in order to reduce the data sparsity problem.
Miao and Guo [50] formulated the cross-lingual representation as a matrix completion problem to infer unobserved
feature values of the concatenated document-term matrix in
the space of uniﬁed vocabulary set from the source language
and target language by using unlabeled parallel bilingual
data. Zhou et al. [55] proposed a subspace learning frame-

work by leveraging the partial parallel data for cross-lingual
sentiment classiﬁcation. However, the parallel data is also a
scarce resource. Besides, some other studies addressed the
cross-lingual knowledge transferring using parallel or comparable corpora [29, 15, 28, 47, 45, 43].
Over the past few years, DNNs have gained a lot of attention from the research community and industry for their
ability to automatically learn feature representations for a
give task. Most recently, a number of studies leverage DNNs
to learn bilingual (or multilingual) feature representations
with parallel corpora. Bi-view feature representation has
been successfully applied to many IR and NLP tasks, such
machine translation [57], cross-lingual sentiment analysis [21,
17, 7, 53, 10, 40, 16, 55, 18, 39], cross-lingual information
retrieval [20, 44], question answering [54], etc. The general idea is that they learn bilingual feature representation
with aligned sentences throughout two phases: the languagespeciﬁc feature representation learning phase and the shared
representation learning phase. The key diﬀerence is that
these existing models are “sharing representations”, which
usually overestimates the importance of language-speciﬁc
features. While our proposed WSDNNs are “sharing parameters”, which makes our networks are more robust of representing shared inter-language features as well as languagespeciﬁc ones.

3.
3.1

…

…

…

…

…

Weakly Shared Layers

…

…

…

…

…

…

Source Language

Target Language

Figure 1: Weakly Shared Deep Neural Networks
(WSDNNs).

network with three layers: the input layer, the latent layer,
and the reconstruction layer. An auto-encoder contains an
encoder function h(x) = se (Wx + b) and a counterpart
decoder function h̄(x) = sd (W̄x + b̄) to minimize the reconstruction error of loss function Er (x, h̄(h(x))). se (·) and
sd (·) are the non-linear activation function and decoder’s
activation function respectively. Several auto-encoders can
be used as building blocks to form a Stacked Auto-Encoders
(SAEs) [4, 42]. Once an auto-encoder has been trained, one
can stack another auto-encoder on top of it, by training a
second one which sees the latent representation of the ﬁrst
one as input.
Recently, many eﬀorts have been initiated on learning
feature representations with DNNs in the context of crosslingual sentiment analysis [21, 17, 7, 22, 53, 40, 56, 18].
First, they pre-train two SAEs for the source language and
the target language respectively, which output latent representations of these two languages via the multiple layers
of nonlinear encoding. Assume that these two SAEs have
L1 layers, where they are structured and built separately.
After the ﬁrst L1 layers, the two SAEs begin to share their
structures where L2 shared layers are constructed as shown
in Figure 1. These shared layers provide a way to transfer the information across two languages represented by the
two SAEs. Therefore, the input into the shared layers is
the mixture of outputs of the bottom L1 layers by the two
SAEs.
However, we observe that this kind of representation sharing layers tend to over-mix the features learned from two languages. In other words, although there exist many shared
features across diﬀerent languages, it is diﬃcult to completely ignore the language-speciﬁc features through the shared
layers, since the source language and the target language
often contain many elements that cannot be expressed by
the same set of the neurons in the shared layers. In this
paper, we relax such representation sharing structure, and
propose a novel weakly shared deep neural networks (WSDNNs), whose structure is shown in Figure 1. The advantage of our proposed WSDNNs is the ﬂexibility of representing shared inter-language features as well as languagespeciﬁc ones, making it more powerful in modeling feature
representations of bilingual languages than representation
sharing layers in the literature.
Formally, there are L + 1 layers in WSDNNs, where L =
L1 + L2 . Given a pair of parallel bilingual texts xsj and

DEEP NEURAL NETWORK TRANSFER
LEARNING
Task Description

s
Given a labeled data set Ds = {(xsi , yis )}N
i=1 in source language, in which xsi ∈ Rm is a text data from the source
language and yis ∈ {1, 0} is the positive sentiment label or
negative sentiment label.1 Our goal is to transfer the labels
from the source language to the target language for sentiment classiﬁcation task. To facilitate the label transfer process, we also have another co-occurrence set of parallel bilins
m
c
and x̄tj ∈ Rn
gual pairs C = {(x̄sj , x̄tj )}N
j=1 , where x̄j ∈ R
denote a data from the source language and target language
respectively. By exploring this parallel bilingual set, we can
reveal the alignment between the source language and target
language, which will facilitate the sentiment label transfer
between these two languages.
In this paper, we will jointly learn the bilingual feature
representations to eﬀectively transfer the discriminative information from the source language to the target language.
The key idea of the deep neural network transfer learning
is an eﬃcient cross-lingual translator which can transfer the
sentiment labels from the source language to the target language, even with the challenge of scarcely labeled target
language data. By leveraging the learned deep neural network translator, we can solve the target language sentiment
classiﬁcation with extremely insuﬃcient training data.

3.2

Empirical Loss

Translator Function

Modeling with Deep Neural Networks

An auto-encoder is an unsupervised neural network which
is trained to reconstruct a given input vector from its distributed representation [4]. It can be seen as a special neural
1
Besides positive and negative sentiments, there are also
neural and mixed sentiments in practical applications. In
this paper, we only consider binary (positive, negative) sentiment, but it is not hard to extend the proposed framework
to address multi-class sentiment classiﬁcation problems.

247

(l)

(l)

xtj respectively, we use xsj ∈ Rml and xtj ∈ Rnl to denote the latent representation of a hidden layer l for the two
(s)
(0)
SAEs respectively. At the ﬁrst layer, we set xsj = xj and
(0)

(t)

x tj = xj

Empirical loss on the labeled target language data
set: Usually, we have a small size of labeled data At =
mt
t
t
is the
{(xti , yit )}N
i=1 in the target language, where xi ∈ R
target space and yit ∈ {1, 0} is the sentiment label. We
aim to minimize the training errors incurred by the label
transfer function f on the labeled target language data set.
The empirical loss on At is as follows:

as inputs. For easy of presentation, we drop
(l−1)

(l−1)

the subscripts i of xsj
and xtj
(l = 1, 2, · · · , L) in the
following. For l = 1, 2, · · · , L, the layer-wise processing of
these two inputs through the whole networks are deﬁned as
follows

θ

(l)
s
(l) (l−1)
+ b(l)
x(l)
s = hs (x ) = se (Ws xs
s )
(l)

(l)

(l)

(l−1)

xt = ht (xt ) = se (Wt xt
(l)

arg min = L1 =

(1)

(l)

+ bt )

(l)

L



(l)

(l)

2
Ws(l) − Wt 2F + b(l)
s − bt  2



arg min = L2 =
θ

(2)

3.4

Minimizing this term will minimize the diﬀerence of parameters in the last L2 layers of two SAEs networks. It will be
added to the proposed objective function in the next Subsection. A positive value of balancing coeﬃcient will be
multiplied with it in the objective function, which reﬂects
the above trading-oﬀ for the weakly-shared layers.


(L)
s 
t
yis h(L)
s (xi ) Ms,t ht (x )

Learning Algorithm

arg min = L = L1 + αL2 + ηEr +
θ

β
γ
Λ+ Ψ
2
2

(6)


(l) 2
(l) 2
(l) 2
(l) 2
where Ψ = L
l=1 (Ws F + bs 2 + Wt F + bs 2 ) +
2
Ms,t F is the regularization term. The parameters α, η, β
and γ weigh the importance of diﬀerent term. In particular,
α is the importance weight on alignment between the parallel
bilingual pairs, η is the importance weight of reconstruction
error, β adjusts the weakly-shared structure, and γ weights
the regularization term.
To train the WSDNNs, we ﬁrst pre-train each layer per
time in a greedy fashion by using the unsupervised data
as in conventional auto-encoder algorithms. The pre-train
WSDNNs set up a good starting point that can ﬁne tuned
according to the objective function by employing the available supervision information.
We implement a back propagation process starting from
the top output layers down through the whole WSDNNs to
adjust all parameters. Each parameter in θ is updated by
stochastic gradient descent in back-propagation algorithm
below:
∂L
(7)
Ws(l) = Ws(l) − δ
(l)
∂Ws

The goal of the proposed cross-lingual transfer learning is
to transfer the labels annotated on the source language data
set Ds to annotate an arbitrary test data xt in the target language. Following the literature [5, 38], for an arbitrary test
data xt and a labeled data xsi in Ds , we deﬁne a translator
(L)
(L)
function as (hs (xsi )) Ms,t ht (xt ) between their weaklyshared layer outputs from the two SAEs, where  denotes
transpose operation in this paper, and Ms,t is the translator matrix. This translator function is used to transfer
the sentiment labels from the source language to the target
language as follows:
Ns


(5)

j=1

After the above analysis, we propose the following objective function to learn the parameters of deep semantic
translator as input of the top-layers of WSDNNs:

Transfer Learning with DNNs

f (xt ) =

Nc


 (L) s 
t 2
 hs (x̄j ) Ms,t − h(L)
t (x̄j ) 2

This loss function can be seen as a measurement of misalignment between parallel bilingual pairs caused by the
translator function. Clearly, minimizing this loss function
will ensure the consistency of translator function over the
parallel bilingual pairs C.

l=L1 +1

3.3

(4)

i=1

where (x) = log(1 + exp(−x)) is a logistic loss function,
which is used to measure the cross-lingual label transfer er(l)
(l)
(l)
(l)
ror. The parameters are θ = {Ws , bs , Wt , bt , Ms,t }L
l=1 .
Empirical loss on the parallel bilingual pairs: Given
c
a set of parallel bilingual pairs C = {(x̄sj , x̄tj )}N
j=1 in the
source language and target language, we wish to maximize
the alignment between each pair of bilingual texts in this
set, yielding a translator function that can well capture the
alignment between these bilingual pairs. Speciﬁcally, we
minimize the objective function as follows:

where hs (·) and ht (·) denote the l-th layer feature representations in source language and target language SAEs
(l)
(l) L
(l)
(l)
respectively. {Ws , bs }L
l=1 and {Wt , bt }l=1 are the parameters in the source language and target language respectively.
The ﬁrst L1 layers are expected to learn the feature representations of a source language and a target language respectively, while the last L2 layers provide shared feature
representations. Under weakly-shared assumption, the parameters of the last L2 layers should be set to be close to
each other in order to trade oﬀ the shared inter-language
features as well as language-speciﬁc ones. Inspired by [38],
we propose the following penalty term Λ to quantify such
trading-oﬀ:
Λ=

Nt



 yit · f (xti )

(3)

i

which combines all the labeled data from the source language
weighted by the corresponding translator functions. For the
binary sentiment classiﬁcation task, the distribution f (xt )
is the form of [1, 0] for positive and [0, 1] for negative, whose
sign predicts the label of the target language data xt .
The parameters can be learned by minimizing the loss
with the sentiment label transfer process, as well as minimizing the inconsistency between a set of parallel bilingual
pairs to capture the cross-lingual alignment information. We
model these two criteria as below:

(l)
b(l)
s = bs − δ

(l)

(l)

∂L

Wt = Wt − δ

248

(l)

∂bs

∂L
(l)

∂Wt

(8)
(9)

(l)

∂L

(l)

bt = bt − δ

(l)

∂bt

Ms,t = Ms,t − δ

∂L
∂Ms,t

• CL-LSA: This is the cross-lingual learning method
described in [15], which ﬁrst translates each document
from the source language into the target language via
a bilingual dictionary to produce augmenting features,
and then performs latent semantic analysis (LSA) over
the augmented bilingual document-term matrix.

(10)

(11)

where δ is the learning rate. These parameters can be computed based on the stochastic gradient optimization. The
convergence is guaranteed when the number of iterations
reaches the max or the objective function value is smaller
than a predeﬁned threshold. The overall complexity of our
WSDNNs is similar with an existing SAE [4, 42].
We exploit the supervision information on the labeled target language data set At to directly tune the target language SAE. Similar to [38], we add an additional softmax
layer upon the target language SAE that outputs the sentiment labels of the target language data. Then the labeled
target language data in At are used to compute the backpropagated errors to tune the parameters in the target language SAE. In this paper, the back-propagated errors only
arise from the target language labels that are intended to
enhance the tuning of target language SAE. This can avoid
unbalanced tuning of source language and target language
SAEs when much more labeled data are used in label transfer process.

4.

• CL-SCL: This is the cross-lingual structural correspondence learning method described in [34], which
ﬁrst selects some pivot features and then automatically induces the cross-lingual correspondences with a
bilingual dictionary.
• CL-MT: This is the state-of-the-art machine translation based method described in [46], which ﬁrst translates the source language to the target language, and
then uses the ensembles methods to train sentiment
classiﬁers on labeled data from the source language
and their translations in the target language.
• CL-MM: This is the generative cross-lingual mixture
model (CL-MM) described in [26], which learns previously unseen sentiment words from the large-scale
bilingual parallel data to improve the vocabulary coverage. We implement this method using the 2000 unlabeled parallel reviews.
• CL-OPCA: This is the cross-lingual oriented principal component analysis (OPCA) method described
in [32], which ﬁrst learns cross-lingual representations
with all data from both languages by performing OPCA
and then trains a monolingual classiﬁer with labeled
data from both languages in the induced feature space.

EXPERIMENTS

4.1

Data Sets

We use the multilingual sentiment classiﬁcation data sets
provided by Prettenhofer and Stein [34], which contain Amazon product reviews in four languages (English (E), French
(F), German (G) and Japanese (J)) of three categories (Books
(B), DVD (D), Music (M)). The English product reviews are
sampled from previous cross-domain sentiment classiﬁcation
data sets, while the other three language product reviews are
crawled from Amazon by the authors in November. Each
category of product reviews contains a balanced training set
and test set, each of which consists of 1000 positive and
1000 negative reviews for each of the language. Besides,
we also collect a set of parallel bilingual reviews between
English and each of the other three languages. Following
the literature [50], each review is represented as a unigram
bag-of-words vector representation and each entry is computed with tf-idf. Given the four languages from the three
categories, we construct 18 cross-lingual sentiment classiﬁcation tasks (EFB, EFD, EFM, EGB, EGD, EGM, EJB,
EJD, EJM, FEB, FED, FEM, GEB, GED, GEM, JEB, JED,
JEM) between English and the other three languages. For
example, the task EFB uses English Books reivews as the
source language and uses French Books reviews as the target
language.

4.2

• CL-TS: This is a two-step method described in [50],
which formulates the cross-lingual representation as a
matrix completion problem to infer unobserved feature
values of the concatenated document-term matrix in
the space of uniﬁed vocabulary set from the source
language and target language by using the unlabeled
parallel bilingual pairs.2
• CL-SP: This is the state-of-the-art multiview learning method described in [55], which is achieved by
jointly learning the document-aligned review data and
un-aligned data from the source language and the target language via a non-negative matrix factorization
framework.
In all experiments, we train the sentiment classiﬁcation
model on the learned representations using the linear support vector machine (SVM) [9]. For CL-LSA, CL-OPCA
and CL-TS, we use the same parameter setting as suggested
in the paper [50]: the latent dimension is set to 50. For CLSCL, we use the same parameter setting as suggested in the
paper [34]: the number of pivot features is set as 450, the
threshold value for selecting pivot features is 30, and the reduced dimensionality after singular value decomposition is
100. For CL-SP, we use the same parameter settings as
suggested in the paper [55]: the shared latent dimension is
set to 100 and the normalized parameter is set to 10−2 . We
choose the above parameter values empirically because these

Compared Methods

In our experiments, we compare our proposed WSDNNs
with the several strong baselines and state-of-the-art methods in the literature for cross-lingual sentiment classiﬁcation:
• TB: This is a target bag-of-words baseline method,
which trains a supervised monolingual classiﬁer on the
labeled training data from the target language without using the unlabeled parallel bilingual pairs and the
source language data.

2

There is a slight exception: using the same data set and
parameter setting, our re-implement systems have slight differences with the results reported in [50].

249

Table 1: Average results (accuracy + standard derivation) for the 18 cross-lingual sentiment classiﬁcation
tasks. The bold formate indicates the best results, † indicates that the diﬀerence between our proposed
WSDNNs and stateof-the-art CL-SP is signiﬁcant with p < 0.05 under a McNemar paired test for labeling
disagreements, and ‡ indicates the mildly signiﬁcant with p < 0.08.
Task
EFB
EFD
EFM
EGB
EGD
EGM
EJB
EJD
EJM
FEB
FED
FEM
GEB
GED
GEM
JEB
JED
JEM
avg.

TB
66.89±0.87
67.42±0.91
67.55±0.50
67.31±0.72
66.54±0.73
67.61±0.46
62.91±0.62
65.33±0.58
67.28±0.67
66.77±0.51
65.98±0.57
65.92±0.55
67.05±0.68
66.30±0.60
66.55±0.46
66.72±0.63
66.32±0.49
66.48±0.55
66.50±0.62

CL-LSA
79.38±0.25
77.69±0.54
75.26±0.43
77.60±0.37
79.16±0.26
73.67±0.52
72.55±0.41
72.51±0.32
73.40±0.47
76.61±0.40
76.39±0.34
76.24±0.35
77.43±0.26
77.55±0.30
77.03±0.42
74.49±0.37
75.17±0.24
72.29±0.45
75.80±0.37

CL-SCL
79.86±0.22
78.80±0.25
75.95±0.31
77.77±0.28
79.93±0.23
73.95±0.30
72.91±0.25
72.82±0.28
73.75±0.35
77.26±0.22
76.57±0.20
76.76±0.25
77.85±0.27
77.83±0.33
77.37±0.34
75.25±0.30
75.34±0.27
73.21±0.33
76.29±0.28

CL-MT
78.01±0.45
77.75±0.68
75.86±0.51
77.02±0.60
79.75±0.58
73.69±0.55
72.20±0.80
72.68±0.56
73.33±0.65
77.43±0.55
76.80±0.52
76.19±0.48
77.50±0.66
77.52±0.54
77.63±0.51
74.41±0.47
75.15±0.49
73.16±0.50
75.89±0.56

CL-MM
69.35±0.46
67.47±0.28
69.12±0.38
70.76±0.33
66.93±0.38
69.58±0.40
65.95±0.35
66.20±0.37
67.89±0.34
69.02±0.36
66.93±0.35
70.44±0.30
71.13±0.31
66.55±0.39
69.12±0.35
68.05±0.40
66.22±0.32
67.55±0.41
68.24±0.36

parameter settings have shown superior performance on the
same benchmark [50, 34, 55].

4.3

CL-OPCA
76.47±0.35
70.36±0.43
73.43±0.37
74.65±0.48
74.47±0.56
74.38±0.61
71.17±0.50
71.70±0.45
74.82±0.64
74.29±0.52
72.30±0.57
73.41±0.55
74.66±0.42
74.68±0.54
74.07±0.46
73.38±0.45
75.37±0.48
72.55±0.61
73.68±0.50

CL-TS
81.83±0.25
81.92±0.35
79.06± 0.28
79.30±0.34
81.27±0.26
79.26±0.33
72.40±0.48
76.51±0.37
76.17±0.43
79.29±0.30
77.88±0.34
78.31±0.41
78.45±0.29
79.22±0.28
78.90±0.37
77.11±0.30
78.95±0.46
77.13±0.51
78.50±0.35

CL-SP
82.61± 0.25
82.70± 0.45
80.19± 0.40
79.91± 0.47
81.86± 0.31
79.59± 0.42
73.45± 0.27
77.06± 0.32
76.83± 0.52
80.48± 0.33
78.76± 0.38
79.18± 0.33
78.61± 0.34
80.27± 0.35
79.80± 0.26
77.97± 0.35
80.63± 0.38
77.78± 0.37
79.32± 0.36

WSDNNs
83.45± 0.23
†
83.61± 0.33
†
80.97± 0.38
‡
81.32± 0.36
‡
82.40± 0.25
†
80.65± 0.28
†
74.51± 0.40
†
78.26± 0.38
‡
77.52± 0.40
80.06± 0.27
†
79.84± 0.26
†
80.14± 0.31
‡
79.23± 0.35
‡
80.95± 0.50
79.68± 0.43
†
79.10± 0.48
†
81.89± 0.52
‡
78.22± 0.55
†
80.10± 0.37
†

proach and each of the other methods using a McNemar
paired test for labeling disagreements [14]. The results in
bold formate indicates the best results, the overall results
indicate that they are signiﬁcant with p < 0.05. All these
results demonstrate the eﬃcacy and robustness of the proposed WSDNNs for cross-lingual sentiment classiﬁcation.
Recently, many eﬀorts have been initiated on learning
feature representations with DNNs in the context of crosslingual sentiment classiﬁcation tasks [21, 17, 7, 53, 10, 40,
16, 18, 39]. However, these existing methods in the literature like bilingual SAEs [53, 55, 18] are representation sharing. While our proposed WSDNNs are weakly parametersharing, which makes our networks more ﬂexible, especially
when cross-lingual sentiment classiﬁcation requires more language speciﬁc features are learned. In other words, by sharing parameters, we allow deviation exists between the feature representations of diﬀerent languages. In contrast, in
“representation sharing” structure, a set of common features
are constructed, which usually overestimates the importance
of language-speciﬁc features. Therefore, we also compare
with the following representative representation sharing DNNs
and state-of-the-art DNNs in the literature for cross-lingual
sentiment classiﬁcation: Chandar et al. [7] proposed a predicative auto-encoder for learning shared representation for
cross-lingual tasks. Zhou et al. [53] proposed a two SAEs
to learn feature representation for cross-lingual sentiment
classiﬁcation. Hermann and Blunsom [16] proposed to learn
compositional distributed semantics for multilingual analysis. Zhou et al. [56] proposed to learn bilingual sentiment
word embeddings for cross-lingual language analysis. Jain
et al. [18] leveraged the sentence aligned corpora to develop
a cross-lingual sentiment analysis tool. In this paper, we reimplement these representation sharing DNNs based on the
original papers and train these models with a 5-fold crossvalidation procedure on the training data. The average results are presented in Table 2.
From Table 2, we can see that our proposed WSDNNs
signiﬁcantly outperforms the state-of-the-art representation
sharing DNNs in general with p < 0.05. Among the 18 tasks,
WSDNNs achieves the best performance on 15 tasks. This

Classiﬁcation Accuracy

For each of the 18 cross-lingual sentiment classiﬁcation
tasks, we use all labeled data from the source language. For
the target language, we use the test set as testing data while
randomly choose 100 documents from the training set as labeled data. Thus, for each task, we have 2000 labeled documents from the source language, 100 labeled documents
from the target language as auxiliary data (At  = 100)
and the rest of target language as test data, as well as a
set of parallel bilingual pairs. We run each experiment 10
times with diﬀerent random selections of 100 labeled training documents from the target language. All parameters
in our model are tuned based on a 5-fold cross-validation
procedure on the training data, and the parameters are selected when the best performances are achieved. We train
our model with 5-layers WSDNNs from bottom up. The
last three ones are weakly shared layers. The average sentiment classiﬁcation accuracies and standard deviations are
presented in Table 1.
From Table 1, we can see that our proposed WSDNNs
clearly outperforms the several strong baselines on 16 out
of the 18 tasks. The target baseline TB performs poorly
on all the 18 tasks, which indicates that 100 labeled documents from the target language is far from enough to obtain
an accurate and robust sentiment classiﬁer for sentiment
classiﬁcation. All the other seven cross-lingual sentiment
classiﬁcation methods, CL-LSA, CL-SCL, CL-MT, CL-MM,
CL-OPCA, CL-TS and CL-SP, consistently outperform the
baseline method TB across all the 18 tasks, which demonstrates that the labeled training data from source language
is useful for classifying target language data. Among the
18 tasks, WSDNNs outperforms CL-LSA, CL-SCL, CL-MT,
CL-MM, CL-OPCA and CL-TS across all the 18 tasks, outperforms CL-SP on 16 out of the 18 tasks and achieves the
slight lower performance than CL-SP on the rest two tasks
(FEB and GEM).
We also conduct signiﬁcance tests for our proposed ap-

250

Table 2: Average results (accuracy + standard derivation) for the 18 cross-lingual sentiment classiﬁcation
tasks by using DNNs. The bold formate indicates the best results, † indicates that the diﬀerences between
our proposed WSDNNs and other DNNs are signiﬁcant with p < 0.05, and ‡ indicates the mildly signiﬁcant
with p < 0.08.
Task
EFB
EFD
EFM
EGB
EGD
EGM
EJB
EJD
EJM
FEB
FED
FEM
GEB
GED
GEM
JEB
JED
JEM
avg.

Chandar et al. [7]
78.75±0.37
78.08±0.54
76.43±0.42
77.94±0.37
80.11±0.41
74.87±0.53
73.21±0.62
74.05±0.48
74.66±0.57
78.73±0.45
77.48±0.51
76.96±0.47
77.71±0.62
78.64±0.55
78.02±0.39
75.59±0.44
76.16±0.48
74.83±0.54
76.79±0.49

Zhou et al. [53]
79.68±0.27
78.33±0.41
78.56±0.28
77.87±0.33
78.63±0.52
78.25±0.48
73.08±0.39
75.37±0.55
76.44±0.28
75.58±0.47
77.62±0.50
77.16±0.44
77.32±0.38
79.05±0.33
77.31±0.51
76.67±0.47
78.73±0.38
76.48±0.56
77.17±0.42

Hermann and Blunsom [16]
82.47±0.34
81.51±0.52
79.29±0.37
80.33±0.42
81.67±0.29
80.73±0.36
74.05±0.45
77.68±0.37
77.24±0.40
79.63±0.38
78.47±0.46
78.21±0.32
78.37±0.37
79.15±0.44
79.07±0.35
78.27±0.45
81.20±0.39
77.74±0.27
79.17±0.39

conﬁrms that our proposed weakly shared layers are more
suitable to model the DNNs than the existing representation
sharing layers.

4.4

Zhou et al. [56]
80.37±0.38
79.56±0.41
77.21±0.29
78.94±0.35
80.45±0.31
79.68±0.28
75.53±0.42
76.35±0.57
77.28±0.33
78.15±0.36
76.62±0.37
78.61±0.43
79.15±0.32
79.44±0.38
78.87±0.27
78.05±0.35
79.33±0.34
77.58±0.46
78.40±0.37

Jain et al. [18]
81.33± 0.41
80.68± 0.35
79.05± 0.28
79.47± 0.56
81.39± 0.43
79.86± 0.38
74.70± 0.34
78.43± 0.30
76.91± 0.36
78.57± 0.47
78.35± 0.33
79.28± 0.40
78.44± 0.51
79.61±0.32
79.14± 0.44
78.20± 0.38
80.93± 0.34
77.65± 0.25
78.99± 0.38

WSDNNs
83.45± 0.23
†
83.61± 0.33
†
80.97± 0.38
‡
81.32± 0.36
‡
82.40± 0.25
80.65± 0.28
74.51± 0.40
78.26± 0.38
77.52± 0.40
80.06± 0.27
†
79.84± 0.26
‡
80.14± 0.31
79.23± 0.35
†
80.95± 0.50
79.68± 0.43
†
79.10± 0.48
†
81.89± 0.52
‡
78.22± 0.55
†
80.10± 0.37
†

tasks of EJB and GEM. In addition, we also observe that
WSDNNs achieves high accuracies even when the number
of labeled target language data is small. This is important
for transferring the knowledge from a source language to a
target language in order to reduce the labeling eﬀort.

The Impact of Number of Labeled Target
Language Data

4.5

Next, we look into the performance of all eight approaches
by varying the number of labeled training documents from
the target language. We use the same experimental setting as before, but investigate a range of diﬀerent numbers, nt = {100, 200, 300, 400, 500}, as the number of labeled
training data from the target language. Given a value nt , we
randomly select nt documents from the training set of the
target language as labeled data for each experiment. We
also run the experiments on the same 2000 test data from
the target language. Each experiment is repeated 10 times
based on diﬀerent random selection of the labeled training
data from the target language. Figure 2 shows the average
classiﬁcation accuracies (%) vs. diﬀerent numbers of labeled
target language data on all the 18 tasks.3
From Figure 2, we can see that when the number of labeled
documents from the target language is small, TB performs
poorly. By increasing the number of labeled data from the
target language, TB can greatly increase the classiﬁcation
accuracy and even outperform the CL-MM method. The
CL-MM has a stable performance across the range of diﬀerent numbers. The CL-LSA method has inconsistent performance across the 18 tasks. Its performance is better than
TB when the labeled training data in the target language
is very limited and is poor than TB when the labeled target data reaches 300 on most tasks. By using the machine
translation resources, the CL-MT method outperforms TB,
CL-LSA, CL-SCL and CL-MM. With a more sophisticated
representation, the CL-TS, CL-SP and WSDNNs achieve
the better performance than other ﬁve methods. Our proposed WSDNNs signiﬁcantly outperforms all the other seven
comparison methods across all experiments except on the

Parameter Analysis

In this subsection, we look into the parameters β and γ of
objective function in Eq. (6). We choose β ∈ {0, 0.5, 1.0, 2.0}
and γ ∈ {0.1, 0.5, 1.0, 2.0} via a cross-validation procedure,
respectively. As usual, we set α = η = 1 to equally weigh
the three types of loss functions. Here, we study their impacts on the performances in Figure 3. When β = 0, the
average accuracy is the lowest. The reason may be that in
this case the source language and the target language SAEs
are completely independent without any shared layers. This
structure fails to jointly model the source language and the
target language representations, and is unable of transferring sentiment labels between two languages. The accuracy
increases rapidly when β becomes large. On the other hand,
γ can also improve the accuracy when it is set to a proper
value to regularize the model. The best accuracy on 16
cross-lingual tasks (except on the task of FEB and GEM) is
achieved when β = 1 and γ = 0.5. The accuracies with different values of parameters are not varied very much, which
suggests that our proposed WSDNNs are not very sensitive
to the parameters.

5.

CONCLUSIONS AND FUTURE WORK

In this paper, we propose a novel weakly parameter-shared
deep neural networks (WSDNNs) to transfer cross-lingual
information from the source language to the target language.
To share the sentiment labels between two languages, we
build multiple weakly shared layers of features. It allows to
represent both shared inter-language features and languagespeciﬁc ones, making our networks more ﬂexible and powerful in capturing the feature representations of bilingual languages than the existing representation sharing structure.
The proposed WSDNNs are trained in a novel way that directly minimizes the loss incurred by a label transfer func-

3

In Figure 2, we do not present the results of CL-OPCA
because this method has used all data from both languages
in the original paper.

251

EFD

EFB

82

68
66
200

300

400

#Labeled target data

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

70
68
66
64

500

100

EGD

200

400

#Labeled target data

400

#Labeled target data

72

68
66
100

500

EJB

70
68

64

300

400

#Labeled target data

500

EJD

74

200

300

400

#Labeled target data

70

65
100

500

EJM

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs
200

300

400

#Labeled target data

68

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

67
66
65
64
63
100

500

FEB

84

69

200

300

400

#Labeled target data

70

64

500

100

80

80

80

78

78

68
66
200

300

400

#Labeled target data

74
72
70
68
66
100

500

GEB

84

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs
200

300

400

#Labeled target data

72
70
68
66

500

100

GED

84

80

80

80

78

78

78

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

72
70
68
66
200

300

400

#Labeled target data

76
TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

74
72
70
68
66

500

100

200

300

400

#Labeled target data

Accuracy (%)

82

Accuracy (%)

82

74

300

400

#Labeled target data

500

78
76
TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

74
72

68
66

500

100

200

300

400

#Labeled target data

500

JEB

80
78

76
TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

74
72

66
100

400

FEM

82

68

500

300

#Labeled target data

70

GEM

70

JED

85

200

84

82

76

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

74

200

300

400

#Labeled target data

500

Accuracy (%)

70

76

76

Accuracy (%)

74

Accuracy (%)

82

Accuracy (%)

82

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

200

84

82

72

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

68
66

FED

84

72

76

100

200

76

Accuracy (%)

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

72

75

Accuracy (%)

74

100

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

74

70

76

Accuracy (%)

Accuracy (%)

300

76

70

71

66

Accuracy (%)

200

72

78

Accuracy (%)

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

70

65
100

500

EGM

80

80

300

75

Accuracy (%)

70

72

Accuracy (%)

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

72

Accuracy (%)

Accuracy (%)

74

100

80
78

74

76

EGB

82

80

76

78

100

EFM

78

80

76
TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

74
72
70
68
66
100

200

300

400

#Labeled target data

500

JEM

84
82
80

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

75

70

100

200

300

400

#Labeled target data

Accuracy (%)

Accuracy (%)

80

78
76

TB
CL-LSA
CL-SCL
CL-MT
CL-MM
CL-TS
CL-SP
WSDNNs

74
72
70
68
66
100

500

200

300

400

#Labeled target data

500

Figure 2: Average accuracies (%) vs. diﬀerent numbers of labeled target language data on all the 18 tasks.
tion. This yields a ﬁne tuning strategy to train WSDNNs
from top down with via back-propagation, which can avoid
unbalanced tuning of the source language and the target
language. We conduct extensive experiments on 18 crosslingual sentiment classiﬁcation tasks constructed from the
Amazon product reviews in four languages. The empirical
results show the superior performances as compared with
several strong baselines and state-of-the-art methods.
There are three research directions that we are planning
to investigate in future. First, a straightforward path of the
future research is to use the proposed WSDNNs for other
language pairs, and apply to other tasks such as cross-lingual
information retrieval [44]. Second, another straightforward
extension is to replace the simple feature representations of
SAE with more systematic context-aware learning methods,

such as convolutional neural networks (CNNs) or recursive
neural networks (RNNs). Third, inspired by the successful
application of attention mechanism in multilingual neural
machine translation [35], we will try to model the crosslingual sentiment information with a shared attention mechanism.

Acknowledgments
This work was supported by the National Natural Science
Foundation of China (No. 61303180, No. 61300144 and No.
61573163), the Fundamental Research Funds for the Central
Universities (No. CCNU15ZD003 and No. CCNU16A02024),
and also supported by a Discovery grant from the Natural Sciences and Engineering Research Council (NSERC) of

252

EFM

81

J=0.1
J=0.5
J=1.0
J=2.0

79
0.5

1
E

1.5

81
80

J=0.1
J=0.5
J=1.0
J=2.0

79
78
0

2

0.5

1
E

1.5

78
77
76

J=0.1
J=0.5
J=1.0
J=2.0

75
74
73
0

2

0.5

EJD
EJB

0.5

1
E

1.5

80

81

79

80
79
78

J=0.1
J=0.5
J=1.0
J=2.0

77
76
75
0

2

FEB

0.5

1
E

1.5

78
77
76

J=0.1
J=0.5
J=1.0
J=2.0

75
74
73
0

2

0.5

FED

80

1
E

1.5

2

FEM

80

80

1
E

1.5

J=0.1
J=0.5
J=1.0
J=2.0

72
70
0

2

0.5

1
E

1.5

J=0.1
J=0.5
J=1.0
J=2.0

72
70

2

0

0.5

1.5

80

76

76

74

74

J=0.1
J=0.5
J=1.0
J=2.0

72
70
0

2

GEM

GED

GEB

1
E

78

0.5

1
E

1.5

70
2

0

JEB

80

72
0.5

1
E

1.5

72
2

0

0.5

1
E

1.5

76
J=0.1
J=0.5
J=1.0
J=2.0

74
72

2

0

0.5

1
E

1.5

76
74

J=0.1
J=0.5
J=1.0
J=2.0

72

2

1
E

1.5

70
0

0.5

1
E

1.5

74

70
0

2

J=0.1
J=0.5
J=1.0
J=2.0
0.5

1
E

1.5

2

JEM
78

80
79
78
J=0.1
J=0.5
J=1.0
J=2.0

77

75
0

76

JED

76
2

78

72

81
Accuracy (%)

J=0.1
J=0.5
J=1.0
J=2.0

74

78

Accuracy (%)

J=0.1
J=0.5
J=1.0
J=2.0

Accuracy (%)

Accuracy (%)

74

76

0.5

82

80

78

J=0.1
J=0.5
J=1.0
J=2.0

72

78

76

Accuracy (%)

74

Accuracy (%)

76

74

Accuracy (%)

0.5

76

78
Accuracy (%)

J=0.1
J=0.5
J=1.0
J=2.0

77

75
0

2

78
Accuracy (%)

J=0.1
J=0.5
J=1.0
J=2.0

80

70
0

78

EGM

81

82

78

70

65
0

1.5

79

EJM

78
Accuracy (%)

Accuracy (%)

75

1
E

80

76

Accuracy (%)

78
0

82

Accuracy (%)

80

Accuracy (%)

Accuracy (%)

Accuracy (%)

81

EGD

83

81

79
82

EGB

82

80

83

Accuracy (%)

EFD

84

83

Accuracy (%)

EFB

84

0.5

1
E

1.5

76
74
J=0.1
J=0.5
J=1.0
J=2.0

72
70

2

0

0.5

1
E

1.5

2

Figure 3: Average accuracies (%) vs. diﬀerent values of β and γ on all the 18 tasks.
Canada and an NSERC CREATE award. We thank the
anonymous reviewers for their insightful comments.

6.

[11] T. Ferhan, L. Jimmy, and D. W. Oard. Combining
statistical translation techniques for cross-language
information retrieval. In COLING, pages 2685–2702,
2012.
[12] J. Gao, E. Xun, M. Zhou, C. Huang, J.-Y. Nie, and
J. Zhang. Improving query translation for
cross-language information retrieval using statistical
models. In SIGIR, pages 96–104, 2001.
[13] W. Gao, C. Niu, J.-Y. Nie, M. Zhou, J. Hu, K.-F.
Wong, and H.-W. Hon. Cross-lingual query suggestion
using query logs of diﬀerent languages. In SIGIR,
pages 463–470, 2007.
[14] L. Gillick and S. Cox. Some statistical issues in the
comparison of speech recoginition algorithms. In
ICASSP, pages 532–535, 1989.
[15] A. Gliozzo and C. Strapparava. Exploiting comparable
corpora and bilingual dictionaries for cross-language
text categorization. In ACL, pages 553–560, 2006.
[16] K. M. Hermann and P. Blunsom. Multilingual models
for compositional distributed semantics. In ACL,
pages 58–68, 2014.
[17] J.-T. Huang, J. Li, D. Yu, L. Deng, and Y. Gong.
Cross-language knowledge transfer using multilingual
deep neural network with shared hidden layers. In
ICASSP, pages 137–140, 2013.
[18] S. Jain and S. Batra. Cross lingual sentiment analysis
using modiﬁed brae. In EMNLP, pages 159–168, 2015.
[19] S. James, G. Gregory, Q. Yan, and E. David. Mining
multilingual opinions through classiﬁcation and
translation. 2004.
[20] J. Kim, J. Nam, and I. Gurevych. Learning semantics
with deep belief network for cross-language
information retrieval. In COLING, pages 579–588,
2012.
[21] A. Klementiev, I. Titov, and B. Bhattarai. Inducing
crosslingual distributed representations of words. In
COLING, pages 1459–1473, 2012.

REFERENCES

[1] B. A., A. Joshi, and P. Bhattacharyya. Cross-lingual
sentiment analysis for Indian languages using linked
wordnets. In COLING, pages 73–82, 2012.
[2] S. Artem, J. Laura, H. Felix, and R. Stefan. Boosting
cross-language retrieval by learning bilingual phrase
associations from relevance rankings. In EMNLP,
pages 1688–1699, 2013.
[3] C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan.
Multilingual subjectivity analysis using machine
translation. In EMNLP, pages 127–135, 2008.
[4] Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle,
U. D. Montreal, and M. Quebec. Greedy layer-wise
training of deep networks. In NIPS, pages 153–160,
2007.
[5] A. Bordes, J. Weston, and N. Usunier. Open question
answering with weakly supervised embedding models.
In ECML/PKDD, pages 165–180, 2014.
[6] G. Cao, J. Gao, J.-Y. Nie, and J. Bai. Extending query
translation to cross-language query expansion with
markov chain models. In CIKM, pages 351–360, 2007.
[7] S. Chandar A P, S. Lauly, H. Larochelle, M. Khapra,
B. Ravindran, V. C. Raykar, and A. Saha. An
autoencoder approach to learning bilingual word
representations. In NIPS, pages 1853–1861. 2014.
[8] A. Chen and F. C. Gey. Multilingual information
retrieval using machine translation, relevance feedback
and decompounding. Inf. Retr., 7(1):149–182, 2004.
[9] R. Fan, K. Chang, C. Hsieh, X. Wang, and C. Lin.
Liblinear: A libary for large linear classiﬁcation.
JMLR, 9:1871–1874, 2008.
[10] M. Faruqui and C. Dyer. Improving vector space word
representations using multilingual correlation. In
EACL, pages 462–471, 2014.

253

[22] T. Kočiský, K. M. Hermann, and P. Blunsom.
Learning bilingual word representations by
marginalizing alignments. In ACL, pages 224–229,
2014.
[23] W. Kraaij, J.-Y. Nie, and M. Simard. Embedding
web-based statistical translation models in
cross-language information retrieval. Comput.
Linguist., 29(3):381–419, 2003.
[24] B. Liu. Sentiment analysis and opinion mining.
Synthesis Lectures on Human Language Technologies,
2012.
[25] B. Lu, C. Tan, C. Cardie, and B. K. Tsou. Joint
bilingual sentiment classiﬁcation with unlabeled
parallel corpora. In ACL, pages 320–330, 2011.
[26] X. Meng, F. Wei, X. Liu, M. Zhou, G. Xu, and
H. Wang. Cross-lingual mixture model for sentiment
classiﬁcation. In ACL, pages 572–581, 2012.
[27] S.-H. Na and H. T. Ng. Enriching document
representation via translation for improved
monolingual information retrieval. In SIGIR, pages
853–862, 2011.
[28] X. Ni, J.-T. Sun, J. Hu, and Z. Chen. Cross lingual
text classiﬁcation by mining multilingual topics from
wikipedia. In WSDM, pages 375–384, 2011.
[29] J.-Y. Nie, M. Simard, P. Isabelle, and R. Durand.
Cross-language information retrieval based on parallel
texts and automatic mining of parallel texts from the
web. In SIGIR, pages 74–81, 1999.
[30] J. Pan, G.-R. Xue, Y. Yu, and Y. Wang. Cross-lingual
sentiment classiﬁcation via bi-view non-negative
matrix tri-factorization. In PAKDD, pages 289–300.
[31] B. Pang and L. Lee. Opinion mining and sentiment
analysis. Found. Trends Inf. Retr., 2(1-2):1–135, 2008.
[32] J. Platt, K. Toutanova, and W. Yih. Translingual
document representations from discriminative
projects. In EMNLP, pages 251–261, 2010.
[33] K. Popat, B. A.R, P. Bhattacharyya, and G. Haﬀari.
The haves and the have-nots: Leveraging unlabelled
corpora for sentiment analysis. In ACL, pages
412–422, 2013.
[34] P. Prettenhofer and B. Stein. Cross-language text
classiﬁcation using structural correspondence learning.
In ACL, pages 1118–1127, 2010.
[35] I. V. Serban, A. Sordoni, Y. Bengio, A. C. Courville,
and J. Pineau. Building end-to-end dialogue systems
using generative hierarchical neural network models.
In AAAI, pages 3776–3784, 2016.
[36] S. Shigehiko, H. Felix, S. Artem, and R. Stefan.
Learning translational and knowledge-based
similarities from relevance rankings for cross-language
retrieval. In ACL, pages 488–494, 2014.
[37] L. Shouhan, W. Rong, L. Huanhuan, and H. Churen.
Active learning for cross-lingual sentiment
classiﬁcation. In NLPCC, pages 236–246, 2013.
[38] X. Shu, G. Qi, J. Tang, and J. Wang. Weakly-shared
deep transfer networks for hetergeneous-domain
knowledge propagation. In MM, pages 35–44, 2015.
[39] G. Stephan, B. Yoshua, and C. Greg. Bilbowa: Fast
bilingual distributed representations without word
alignments. In ICML, pages 1–10, 2015.
[40] X. Tang and X. Wan. Learning bilingual embedding

[41]

[42]

[43]

[44]

[45]

[46]
[47]

[48]

[49]

[50]
[51]

[52]

[53]

[54]

[55]

[56]

[57]

254

model for cross-language sentiment classiﬁcation. In
WI, pages 134–141, 2014.
D. Trieschnigg, D. Hiemstra, F. de Jong, and
W. Kraaij. A crosslingual framework for monolingual
biomedical information retrieval. In CIKM, pages
169–178, 2010.
P. Vincent, H. Larochelle, Y. Bengio, and P.-A.
Manzagol. Extracting and composing robust features
with denoising autoencoders. In ICML, pages
1096–1103, 2008.
I. Vulić and M.-F. Moens. A uniﬁed framework for
monolingual and cross-lingual relevance modeling
based on probabilistic topic models. In ECIR, pages
98–109, 2013.
I. Vulić and M.-F. Moens. Monolingual and
cross-lingual information retrieval models based on
(bilingual) word embeddings. In SIGIR, pages
363–372, 2015.
I. Vulić, W. Smet, and M.-F. Moens. Cross-language
information retrieval models based on latent topic
models trained with document-aligned comparable
corpora. Inf. Retr., 16(3):331–368, 2013.
X. Wan. Co-training for cross-lingual sentiment
classiﬁcation. In ACL, pages 235–243, 2009.
Z. Wang, Z. Li, J. Li, J. Tang, and J. Z. Pan. Transfer
learning based cross-lingual knowledge extraction for
wikipedia. In ACL, pages 641–650, 2013.
B. Wei and C. Pal. Cross lingual adaptation: An
experiment on sentiment classiﬁcations. In ACL, pages
258–262, 2010.
K. Wu, X. Wang, and B. liang Lu. Cross language
text categorization using a bilingual lexicon. In
IJCNLP, pages 165–172, 2008.
M. Xiao and Y. Guo. A novel two-step method for
cross language representation learning. In NIPS, 2013.
M. Xiao and Y. Guo. Semi-supervised representation
learning for cross-lingual text classiﬁcation. In
EMNLP, pages 1465–1475, 2013.
Z. Ye, X. Huang, B. He, and H. Lin. Mining a
multilingual association dictionary from wikipedia for
cross-language information retrieval. JASIST,
63(12):2474–2487, 2012.
G. Zhou, T. He, and J. Zhao. Bridging the language
gap: Learning distributed semantics for cross-lingual
sentiment classiﬁcation. In NLPCC, pages 138–149,
2014.
G. Zhou, T. He, J. Zhao, and P. Hu. Learning
continuous word embedding with metadata for
question retrieval in community question answering.
In ACL, pages 250–259, 2015.
G. Zhou, T. He, J. Zhao, and W. Wu. A subspace
learning framework for cross-lingual sentiment
classiﬁcation with partial parallel data. In IJCAI,
pages 1426–1432, 2015.
H. Zhou, L. Chen, F. Shi, and D. Huang. Learning
bilingual sentiment word embeddings for
cross-language sentiment classiﬁcation. In ACL, pages
430–440, 2015.
W. Y. Zou, R. Socher, D. M. Cer, and C. D. Manning.
Bilingual word embeddings for phrase-based machine
translation. In EMNLP, pages 1393–1398, 2013.


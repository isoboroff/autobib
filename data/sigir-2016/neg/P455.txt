When Watson Went to Work - Leveraging Cognitive
Computing in the Real World
Aya Soffer

IBM Research - Haifa
Mount Carmel, Haifa 31905

ayas@il.ibm.com

1.

David Konopnicki

IBM Research - Haifa
Mount Carmel, Haifa 31905

davidko@il.ibm.com

INTRODUCTION

Haggai Roitman

IBM Research - Haifa
Mount Carmel, Haifa 31905

haggai@il.ibm.com

and more. We also elaborate on some of the underlying technologies that are available via APIs on the Watson Developer
Cloud1 . Finally, we discuss some of the challenges of applying this technology in real-world use cases. We specifically
discuss two challenges that we face in leveraging Watson
for tech support and customer support in some more detail.
The first is in the area of technical support, where Watson
is being used to find solutions for relatively complex technical support issues. In this case, we developed extensions to
Watson’s state of the art techniques that can take into account the format and the richness of the problem definition.
The second is in the area of customer support, where Watson is being used to answer customer queries about products
and services. In this case, the sentiment of the person dialoging with the system as well as the system’s responses are
found to be important in being able to satisfy the customer’s
information need.

In February 2011, the world was introduced to Watson,
IBM’s cognitive computing system [1] that defeated Ken
Jennings and Brad Rutter at Jeopardy! It was the first
widely seen demonstration of cognitive computing, and it
marked the end of the so-called “AI winter.” Watson’s ability
to answer subtle, complex, pun-laden questions made clear
that a new era of computing was at hand. An era where
computers can start making sense of the vast amount of unstructured data in the world and apply this understanding
not only to answer trivia questions, but also to tackle some
of the world’s pressing problems and change how people interact with computers.
Indeed, since Jeopardy!, Watson has tackled increasingly
complex data sets, and developed understanding, reasoning,
and learning. Specifically, we have identified five core capabilities of Cognitive Computing: 1. They create deeper
human engagement; 2. They scale and elevate expertise; 3.
They infuse products and services with cognition; 4. They
enable cognitive processes and operations; 5. They enhance
exploration and discovery. The true potential of the Cognitive Era will be realized by combining the data analytics,
and statistical reasoning of machines with uniquely human
qualities, such as self-directed goals, common sense, and ethical values. This is what Watson was built to do, and is in
fact already doing. Banks are analyzing customer requests
and financial data to surface insights to help them make
investment recommendations. Companies in heavily regulated industries are querying the system to keep up with
ever-changing legislation and standards of compliance. And
oncologists are testing ways in which cognitive systems can
help interpret cancer patients’ clinical information and identify individualized, evidence-based treatment options that
leverage specialists’ experience and research. Customer and
technical support are in particular being re-invented, relying
more on cognitive systems for self-help and for agent assist.
In this talk, we highlight some of the applications of Watson that are being pursued by IBM. These include applications in customer and technical support, in Finance, in Legal

2.

FINDING ANSWERS TO COMPLEX TECHNICAL SUPPORT QUESTIONS

As a concrete example, in one of the technical support use
cases, Watson handles problem management records (PMRs)
submitted by various clients and aims to discover technical notes (technote) that contain potential solutions to their
technical problems. Each such record may describe several
aspects of the client’s problem expressed in natural language. For example, a PMR may include multiple problem related issues describing the problem, the impact on the
client’s business, the client’s system characteristics, etc. Figure 1 depicts an example of a real PMR query and its matching technote (both represented in JSON format). PMR
descriptions are highly ambiguous, verbose in most cases,
multi-lingual and their quality spans from detailed problem
descriptions to computer generated error log traces. On the
other hand, technotes (documents) in the corpus describe
technical details of various problem solutions, and may include multiple searchable fields that may be relevant for solving a PMR.
PMRs processing is a challenging task, and Watson’s original question-answering paradigm which is geared more towards factoid queries is insufficient here. In order for find a
relevant solution, the system needs to search over multiple
combinations of PMR problem aspects and technical document and find the best match(es). Alternative solutions
to this challenging problem were explored using a “TREC-

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for prof t or commercial advantage and that copies bear this notice and the full citation
on the f rst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).

SIGIR ’16 July 17-21, 2016, Pisa, Italy
c 2016 Copyright held by the owner/author(s).

1
https://www.ibm.com/smarterplanet/us/en/ibmwatson/
developercloud/

ACM ISBN 978-1-4503-4069-4/16/07.
DOI: http://dx.doi.org/10.1145/2911451.2926724

455

PMR:
{
id:"*****-***-***_***-**-**",
product_desc:"TIVOLI FEDERATED IDENTITY MGR",
component_desc:"SAM WEBSEAL",
os:"Appliance Firmware",
business_impact:"Trying to simplify management
of our WebSEAL environments.",
problem_title:"Curl/JSON scripting assistance",
problem_desc:"I am looking for information and best
practices around using Curl and JSON scripts to do
administrative tasks on WebSEAL..."
}
...
Customer: The mic is not working
Agent: (detecting customer anger - medium) I’m sorry to hear
that. Could you please try to install the Skype app and run an
echo test? ...
Customer: what is an echo test?
Agent: (detecting customer confusion - low) Apologies for the
confusion. Here are some instructions...

Technote:
{
url:http://www-01.ibm.com/support/docview.wss?uid=swg21663434
title:"IBM Security Access Manager for Web API documentation"
}

Figure 1: Example of a PMR query and its relevant
technote

Figure 2: Example of an affective dialog. The actual
UI followed by the rest of the conversation

like” competition, where several different research and development teams within IBM have explored various retrieval
approaches including those that employ both state-of-theart and novel QA, NLP, deep-learning and learning-to-rank
techniques.
To handle such complex retrieval task, based on one of
the leading retrieval strategies that were developed, Watson
employs several state-of-the-art IR and question-answering
methods, spanning from verbose query processing and pseudorelevance feedback to techniques that utilize query performance prediction for selecting ranking strategies and their
fusion. Furthermore, a new “multi-field” retrieval approach
developed as part of this approach further allows Watson to
consider all possible PMR–technote (cross product) querying options, while intelligently focus only on those combinations that are predicted to be the most important for
answering the complex information need expressed in the
PMR. Overall, Watson’s retrieval quality for this domain
has been boosted by more than 30%.

3.

In such a case, computers should identify user emotions
and then take those emotions into account when replying.
Effectively, a computer involved in dialog should be able
to thank, apologize, and be empathetic similar to a human
agent. Such a dialog between a human and a Watson-based
support agent is provided as an example in Figure 2 (showing
which emotions have been detected).
This example is focused on textual interactions between
the user and Watson but clearly other input modalities like
speech and video offer even more opportunities to detect and
act upon user emotions.
In addition to emotions which are naturally transient,
Watson provides capabilities to analyze more static aspects
of a user’s personality based on the language being used.
By combining personality and emotional aspects, the goal
in the longer term is to automatically craft a digital personality personalized to interact with a particular user.
In a recent study, we examined emotions being expressed
in Twitter service conversations between humans [2]. We
show that customer’s and agent’s personality traits combined with the emotion being expressed in the first turn of a
conversation are good predictors of user satisfaction at the
end of the conversation: specifically, our model shows an
improvement of 30% in the F1-score for predicting dissatisfaction. This result enables automatically matching the best
agents to a particular user in a given context.

ADDING AFFECT TO CUSTOMER SUPPORT

One domain in which the concept of Watson has evolved
since Jeopardy! is the domain of dialog. Originally, IBM
Watson was conceived as a question answering system in
which interactions with users were limited to question-answer
pairs. When Watson technology was deployed in different
domains, it became evident that more advanced dialog capabilities are necessary in order to handle more complex tasks
e.g. in order to obtain clarifications from users about their
questions. In this case, Watson becomes a dialog engine with
which users can converse and relies on its question answering
capabilities when necessary as a conversation evolves.
One of the most common implementations of Watson’s
conversation engine is in the area of customer support. In
this case, in addition to being able to converse with the
user, it becomes important to understand the sentiment of
the user as well as tailor the engine’s response based on
this sentiment. In other words, as users start to converse
with computers in very natural ways, they expect computers
not only to address their information needs but also their
emotional needs.

4.

REFERENCES

[1] David Ferrucci, Eric Brown, Jennifer Chu-Carroll,
James Fan, David Gondek, Aditya A Kalyanpur, Adam
Lally, J William Murdock, Eric Nyberg, John Prager,
et al. Building watson: An overview of the deepqa
project. AI magazine, 31(3):59–79, 2010.
[2] Jonathan Herzig, Guy Feigenblat, Michal
Shmueli-Scheuer, David Konopnicki, and Anat Rafaeli.
Predicting customer satisfaction in customer support
conversations in social media using affective features. In
To be published in: User Modeling, Adaptation, and
Personalization, 2016.

456


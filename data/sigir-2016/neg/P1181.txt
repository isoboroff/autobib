Retrievability: An Independent Evaluation Measure
Colin Wilkie
School of Computing Science,
University of Glasgow
Glasgow, United Kingdom

c.wilkie.3@research.gla.ac.uk

ABSTRACT

trievability to aid information retrieval outside of evaluation.
Finally, due to the high cost of computing retrievability, another vein of research which is vital to moving retrievability
more towards mainstream evaluation is to develop more efficient methods of estimating retrievability. Work in each of
these areas will increase both the usefulness of retrievability
by allowing demonstrating it can be applied to various domains and its attractiveness in both evaluation and general
use for information retrieval.

Information Retrieval systems have traditionally been evaluated in terms of efficiency and performance. These aspects
of retrieval systems, whilst very important, do not cover
a crucial aspect of the system, the access it provides to the
documents of the collection. Retrievability, a document centric evaluation measure, introduced by Azzopardi and Vinay,
provides an alternative approach to evaluation [1]. Retrievability is the ease with which a document can be retrieved
using a retrieval system. The more queries which retrieve
the document, and the higher up the document is returned,
the more retrievable it is. It can thus be used to describe
how difficult it is to find documents in the collection given a
particular configuration of a retrieval system. Unlike typical
performance evaluations, performing a retrievability analysis can be done without recourse to relevancy judgements
meaning there is no reliance on a test collection. This has
major advantages when tuning a retrieval systems parameters as the tuning can be performed on the live collection.
Several applications of retrievability have been explored,
however, many areas remain untouched or partially studied.
Thus far, work in this PhD has explored the relationship
between retrievability bias and performance in the context
of ad hoc retrieval [2, 3, 5]. A benefit that would allow researchers in academia and industry to tune their system on
their own collection and would save the resources of creating
a test collection. Other aspects of retrievability also covered
in this PhD have investigated the impact of query length on
the estimation of Gini [6], investigating methods of computing retrievability more efficiently [4] and the application of
various inequality metrics instead of the Gini Coefficient [7]
when estimating the overall inequality of the system.
The remainder of this PhD aims to continue investigating
the relationship between retrievability bias and performance,
specifically to examine whether or not the relationship found
thus far is generalisable to other domains and performance
metrics. Applications of the theory of retrievability are also
to be examined to see if there are alternative uses of re-

Keywords
Retrievability; Bias; Effectiveness; Evaluation

1.

REFERENCES

[1] Azzopardi, L., Vinay, V.: Retrievability: An evaluation
measure for higher order information access tasks. In:
Proc. of the 17th ACM CIKM. pp. 561–570 (2008)
[2] Wilkie, C., Azzopardi, L.: Relating retrievability,
performance and length. In: Proc. of the 36th ACM
SIGIR conference. pp. 937–940 (2013)
[3] Wilkie, C., Azzopardi, L.: Best and fairest: An
empirical analysis of retrieval system bias. Advances in
Information Retrieval pp. 13–25 (2014)
[4] Wilkie, C., Azzopardi, L.: Efficiently estimating
retrievability bias. In: Advances in Information
Retrieval. pp. 720–726 (2014)
[5] Wilkie, C., Azzopardi, L.: A retrievability analysis:
Exploring the relationship between retrieval bias and
retrieval performance. In: Proc. of the 23rd ACM
CIKM. pp. 81–90 (2014)
[6] Wilkie, C., Azzopardi, L.: Query length, retrievability
bias and performance. In: Proc. of the 24th ACM
CIKM. pp. 1787–1790 (2015)
[7] Wilkie, C., Azzopardi, L.: Retrievability bias: A
comparison of inequality measures. Advances in
Information Retrieval pp. 209–214 (2015)

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).

SIGIR ’16 July 17-21, 2016, Pisa, Italy
c 2016 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4069-4/16/07.
DOI: http://dx.doi.org/10.1145/2911451.2911478

1181


SimCC-AT: A Method to Compute Similarity of Scientific
Papers with Automatic Parameter Tuning
Masoud Reyhani Hamedani

Sang-Wook Kim

Department of Computer and Software
Hanyang University, Seoul, Korea

Department of Computer and Software
Hanyang University, Seoul, Korea

masoud@agape.hanyang.ac.kr

wook@agape.hanyang.ac.kr

ABSTRACT

p contributes to s
indirectly via r

q

p contributes to r
directly

p contributes to q directly
and also indirectly via r
and u

u

p

p contributes to u
directly

Figure 1: A sample citation graph.

Keywords
Automatic Weighting, Citations, Content, Contribution Score,
Similarity

1.

r

s

In this paper, we propose SimCC-AT (similarity based on
content and citations with automatic parameter tuning) to
compute the similarity of scientific papers. As in SimCC,
the state-of-the-art method, we exploit a notion of a contribution score in similarity computation. SimCC-AT utilizes
an automatic weighting scheme based on SVM rank and thus
requires only a smaller number of experiments for parameter tuning than SimCC. Furthermore, our experimental results with a real-world dataset show that the accuracy of
SimCC-AT is dramatically higher than that of other existing methods and is comparable to that of SimCC.

INTRODUCTION

Scientific papers are one of primary sources to share information and knowledge among researchers. Recently, computing the similarity of scientific papers became an interesting topic in information retrieval and data mining [1][6][9].
SimCC [6] is state-of-the-art method that considers both
content and citations in computing similarity of scientific
papers. The philosophy of SimCC is that, when paper q
cites paper p, it means p is a valuable paper on some topics
discussed in q and contributes to q for improving the content
of q. Based on this philosophy, SimCC introduces the notion
of a contribution score as a key factor in similarity computation. SimCC dramatically outperforms text-based similarity
measures such as Cosine [5], Dice coefficient [5], BM25 [5],
and Kullback-Leibler Distance (KLD) [5], link-based similarity measures such as SimRank [3], rvs-simRank [11], and
P-Rank [11], and also hybrid methods such as CEBC [1],
Keyword-Extension [8], and WCO [7].
In spite of high accuracy, the parameter tuning is performed manually in SimCC, which is a difficult and timeconsuming task. Consequently, it is not easy to adopt SimCC

for practical applications. We cannot utilize automatic weighting schemes such as SVM rank [4] directly for parameter tuning because SimCC applies a weighted linear combination
to two different feature scores obtained from single paper p
to get a single score as a new feature for p, which is later
utilized in similarity computation. These two combined feature scores of a paper are not calculated in relating to other
paper, thereby making SVM rank unable to be applied to
SimCC for indicating the importance of each feature in combination.
In this paper, we propose a method, SimCC-AT (similarity based on content and citations with automatic parameter tuning), which performs parameter tuning automatically.
In order to utilize automatic weighting schemes, we reformulate SimCC while preserving its philosophy in similarity
computation. In SimCC-AT, only a small number of experiments are required for parameter tuning; therefore, it
is easily adopted for practical applications. Our extensive
experimental results show that the accuracy of SimCC-AT
is dramatically higher than that of other existing methods
and is comparable to that of SimCC.
The contributions of this paper are as follows. (1) We utilize automatic parameter tuning in similarity computation
based on contribution scores; (2) we simplify the adoption
of an accurate similarity computation based on contribution
scores for any similarity measures applicable to vectors; (3)
we evaluate the effectiveness of SimCC-AT extensively with
a real-world dataset of scientific papers.

2. CONTRIBUTION SCORE

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

The contribution score measures how much a paper contributes to another single paper on a specific term via a
specific citation path. Consider the sample citation graph in
Figure 1 where nodes represent papers and edges do citation
relationships among papers. As an example, p contributes
to q directly (via citation path q→p where → denotes a direct citation) and indirectly (via citation paths q→r→p and

SIGIR ’16, July 17-21, 2016, Pisa, Italy
c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00
DOI: http://dx.doi.org/10.1145/2911451.2914715

1005

utilizing an automatic weighting scheme based on SVM rank
[4]. We can utilize SVM rank since, 1) for every paper p, we
consider Rt (p) and At (p) as two separate features in similarity computation; 2) for both p and q, SR(p, q) and SA(p, q)
measure a relatedness (i.e., similarity) between a pair of papers p and q. We only need to conduct 6 experiments as five
different path lengths are considered for computing the contribution scores; then, SVM rank is utilized to automatically
determine the importance of SR(p, q) and SA(p, q) in the
combination to obtain S(p, q). Consequently, we can easily
adopt SimCC-AT for any similarity measures applicable to
vectors in practical applications.

q→u→p); p contributes to u only directly via citation path
u→p. Therefore, p has three contribution scores on a single
term t to q via three distinct citation paths and has only
one contribution score on t to u via a single citation path.

3.

MOTIVATION

SimCC performs both feature extraction and similarity
computation. For feature extraction, every paper p is represented as an n-dimensional vector. The weight of a term
t in the vector of p is calculated as follows [6]:
wt (p) = λRt (p) + (1 − λ)At (p)

(1)

4.1 Authority Score Calculation

where Rt (p) is a relevance score of t to p calculated by applying any weighting factors such as TF, TF-IDF, and BM25.
At (p) is an authority score of p on t calculated by summing
up all contribution scores of p on t to all other papers citing
p. λ (0≤λ≤1) is a relative importance factor. For similarity computation, any similarity measures for vectors such as
Cosine, Dice, BM25, and KLD can be employed.
The best value of λ is found manually, which is difficult
and time-consuming since we have to conduct lots of experiments as follows. For any employed similarity measure, at
least 55 distinct experiments are required [6] as five different
path lengths from 1 to 5 are considered for computing the
contribution scores, and the value of λ is set from 0.0 to 1.0
in steps of 0.1 for each path length. Consequently, it is not
easy to adopt SimCC for practical applications.
We note that it is not possible to perform automatic parameter tuning in SimCC for the following reason. Automatic weighting schemes such as SVM rank can be utilized
to determine the importance (i.e., rank) of each feature in a
set of features, each of which measures a relatedness between
two objects based on its own criteria [4]. In SimCC, however,
Rt (p) and At (p) are two features of single paper p; they do
not measure any relatedness (e.g., similarity) between paper
p and another paper.

At (p) is calculated by the following formula:
At (p) =

d
X

X

i=1 q∈D(p,i)

Ct (π)

(2)

i

π∈q ❀p

where d denotes the maximum length of the path in the
citation graph traversed to compute the contribution score,
D(p, i) does a set of papers that cite p via paths with length
i
i (1 ≤ i ≤ d), and q ❀p does a set of citation paths with
length i from q to p. π denotes a single citation path
q→r1 →...→ri−1 →p with length i from q to p and Ct (π)
does the contribution score of p on t to q via π. For example, in Figure 1, D(p, 1) = {q, r, u} and D(p, 2) = {q, s}.
Only for simplicity of presentation, we assume that there
i
is only one citation path q ❀p with length i from q to p.
Equation (2) is rewritten as follows:
At (p) =

d
X

i

X

Ct (q ❀p)

(3)

i=1 q∈D(p,i)

i

where Ct (q ❀p) denotes the contribution score of p on t to
i
q via the single path q ❀p and is computed as follows:
i

4.

X

i

Ct (q ❀p) = ϕt (q ❀p)Rt (q)

PROPOSED METHOD

(4)

i

where ϕt (q ❀p) denotes the contribution ratio of p on t to q
i
via q ❀p. If q cites p directly (i.e., i = 1), the contribution
ratio is calculated as follows:

Our proposed method, SimCC-AT, has the goal of performing automatic parameter tuning with preserving the philosophy of SimCC in similarity computation. As in SimCC,
the contribution score is a key factor in SimCC-AT which
performs both feature extraction and similarity computation. However, there are two major differences between
SimCC-AT and SimCC as follows.
In SimCC, Rt (p) and At (p) are combined into a single
value, wt (p), for every paper p. The similarity score of a
paper-pair (p, q), S(p, q), is computed by employing a similarity measure on their corresponding vectors. On the contrary, in SimCC-AT, every paper p is represented by two
separate vectors R-vector (relevance vector) and A-vector
(authority vector) containing Rt (p) and At (p) for all terms
t in p, respectively. For computing S(p, q), two distinct
similarity scores are computed based on their corresponding R-vectors, SR(p, q), and their corresponding A-vectors,
SA(p, q). Then, the two scores SR(p, q) and SA(p, q) are
combined into a single score by applying a weighted linear
combination as S(p, q). In this way, we reformulate SimCC
while persevering its philosophy in similarity computation.
In SimCC, the parameter tuning is performed manually;
however, in our method, the importance of SR(p, q) and
SA(p, q) in the combination is determined automatically by

Rt (p)

1

ϕt (q ❀p) =

Rt (q) +

P

r∈citations(q)

Rt (r)

(5)

where citations(q) denotes a set of papers directly cited by q.
i
If q cites p indirectly via other papers (i.e., i≥2), ϕt (q ❀p) is
determined by contribution ratios between all directly connected papers in the citation path. Let q→r1 →...→ri−1 →p
be a citation path with length i from q to p. Then, we have
i

1

ϕt (q ❀p) = ϕt (q ❀r1 )·

 i−2
Y


1
1
ϕt (rj ❀rj+1 ) ·ϕt (ri−1 ❀p) (6)

j=1

4.2 Similarity Computation
In our SimCC-AT, S(p, q) is computed as follows:
S(p, q) = w1 SR(p, q) + w2 SA(p, q)

(7)

where w1 and w2 are weights for controlling the degree of importance of SR(p, q) and SA(p, q) in the combination since
we do not consider them as equally significant in computing
S(p, q). We use SVM rank [4] that is based on the support

1006

vector machine (SVM) to determine best values of w1 and
w2 automatically.
SVM rank solves a maximum-margin optimization problem by finding a hyperplane. In our case, the hyperplane
is a vector of two weights represented as V =<w1 , w2 > that
provides an ideal separation between relevant and irrelevant
papers in a training set by finding the best values of w1 and
w2 . The training set is used for the training process and contains training instances. The training instance represents a
paper in regarding to a query paper as follows:
<r, qid, SR(p, q), SA(p, q)>

MAP

0.00

(8)

(b) Dice

0.15

0.15

0.10

0.10
R@10
0.05
P@10

0.05
MAP

0.00

(c) BM25

R@10
P@10
MAP

0.00

(a) Cosine

R@10
P@10
MAP

0.00

(d) KLD

Figure 2: Accuracy with different values of d.

EVALUATION

denotes the similarity computation based on R-vectors (i.e.,
relevance scores).
For all basic similarity measures, we observe the following
common results. The similarity computation based on authority scores significantly outperforms the baseline method
regardless of the value of d. As a surprising result, the best
value of d is 2 regardless of similarity measures. The accuracy decreases gradually for d≥ 3 since, when we go farther
from each paper in the citation graph, contribution scores
of the paper to other papers tend to be noisier.
For every basic similarity measure, we perform the automatic parameter tuning to determine best values of w1 and
w2 in Equation (7) as follows. We construct the A-vector of
all papers in the dataset based on d=2. Then, we compute
SR(p, q) and SA(p, q) for all paper-pairs (p, q) where p and
q belong to the dataset and ground truth sets, respectively.
Finally, we construct the training set by defining training instances according to Equation (8) for 60% of papers in our
dataset. If both p and q belong to the same ground truth
set, r is set as 1, otherwise 0. SVM rank is executed on the
training set to determine values of w1 and w2 .
Now, we compare the effectiveness of SimCC-AT with
those of other existing methods in Figure 3. For example, Figure 3(a) represents the accuracy of CEBC, KeywordExtension, WCO, and SimCC-AT, each of which is equipped
by Cosine; also, this figure shows the accuracy of the baseline method (Cosine only with R-vectors) and SimRank*.
For link-based similarity measures, we only represent the
result of SimRank* because it is shown to outperform both
SimRank and P-Rank with our dataset. The reason is that
it considers those possible paths between papers in a citation graph, which are neglected by SimRank and P-Rank in
similarity computation.
The following results are commonly observed with all the
employed basic similarity measures. The baseline method
and SimRank* show the worst accuracy since they consider
only content and citations in similarity computation, respectively. However, the baseline method outperforms SimRank*. Hybrid methods significantly outperform the baseline method and SimRank* since they consider both content
and citations in similarity computation. SimCC-AT dramatically outperforms all other methods. The reason is that
SimCC-AT not only considers both content and citations in
similarity computation but also, in contrary to other hybrid

5.1 Experimental Setup
We employed a real-world dataset of scientific papers by
crawling information of 1,071,793 papers from DBLP1 and
their abstract and citation information from Microsoft Academic Search2 . We do not have access to the body of papers
due to the copyright issue. However, the combination of the
title and abstract has been reported to show the better accuracy than the body in computing the similarity [8].
We constructed our ground truth sets based on a famous
data mining textbook [2] where, as in user studies, relevant
papers to research topics addressed in each chapter are categorized by experts (i.e., the authors of the book) in the
bibliographic section of the chapter. We selected eleven research topics as our ground truth sets, each of which contains
its related papers. Also, we utilize MAP, precision at top
10 results (P@10), and recall at top 10 results (R@10) [5] as
evaluation measures.
As in SimCC, we employ Cosine, Dice, BM25, and KLD
as basic similarity measures to be employed with R-vectors
and A-vectors. To employ Cosine and Dice, we utilize the
TF-IDF value as the relevance score. For BM25 and KLD,
we utilize the BM25 weight and the TF value, respectively.

5.2 Results and Analysis
As described in Section 4.1, At (p) depends on d, the maximum length of the path to compute contribution scores.
Therefore, we investigate how the accuracy of a basic similarity measure changes with different values of d to find its
best value for each measure. We set the value of d from 1 to
5 in Equation (2) and construct five distinct A-vectors for
every paper in the dataset. Figure 2 represents the accuracy
of Cosine, Dice, BM25, and KLD with different values of d
in terms of MAP, P@10, and R@10. The baseline method
1

0.15
R@10 0.10
P@10
0.05

0.05

In this section, we compare the effectiveness of SimCC-AT
with those of Cosine, Dice, BM25, and KLD as text-based
similarity measures, SimRank, P-Rank, and SimRank* [10]
as link-based similarity measures, and CEBC, WCO, and
Keyword-Extension as hybrid methods. Also, we compare
the effectiveness of SimCC-AT with that of original SimCC.

2

0.20

0.15
0.10

where r is set as 1 when p is relevant to the query paper
q, and is set as 0 otherwise as described in Section 5.2. qid
denotes a query number. SVM rank indicates the hyperplane
according to pairwise preference constraints, which are included for all pairs of training instances that have different
r but the identical qid.

5.

0.20

http://www.informatik.uni-trier.de
http://academic.research.microsoft.com

1007

0.25

0.25

0.20

0.20

0.15

0.15
R@10
0.10
P@10
0.05

0.10
0.05
MAP

0.00

0.18
0.15
0.12
0.09
0.06
0.03
0.00

R@10
P@10
MAP

0.00

(a) Cosine

Table 1: Relative accuracy (%) of SimCC-AT over
SimCC.
Cosine Dice BM25 KLD
MAP
98.48
96.85 97.22 98.29
P@10
99.40
97.05 98.82 98.36
R@10
98.86
98.85 98.26 98.70

(b) Dice

0.18
0.15
0.12
R@10 0.09
0.06
P@10
0.03
MAP
0.00

(c) BM25

contribution score is a key factor in SimCC-AT. However, to
utilize SVM rank , we reformulated SimCC while preserving
its philosophy (i.e., contribution score) in similarity computation. As a result, it is easy to adopt SimCC-AT for
practical applications since it requires a smaller number of
experiments (i.e., 6) than SimCC (i.e., 55) for parameter
tuning. SimCC-AT dramatically outperforms other existing
methods, and its accuracy is comparable to that of SimCC.

R@10
P@10
MAP

(d) KLD

Figure 3: Accuracy of SimCC-AT and other methods.

Acknowledgment
This research was supported by (1) the Ministry of Science,
ICT and Future Planning (MSIP), Korea, under the Information Technology Research Center (ITRC) support program (IITP-2016-H8501-16-1013) supervised by the Institute for Information & communication Technology Promotion (IITP) and (2) the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP)
(NRF-2014R1A2A1A10054151).

methods, it does not simply combine the content of papers
involved in a direct citation relationship; instead, SimCCAT measures the amount of contribution between papers
involved in a direct or indirect citation relationship as contribution scores to utilize them in similarity computation.
Now, we compare the accuracy of SimCC-AT with that of
SimCC in terms of MAP, P@10, and R@10 in Figure 4. For
all basic similarity measures, SimCC shows slightly (see Table 1) better accuracy than SimCC-AT. The reason is that,
in SimCC, relevance and authority scores are combined into
a single value as a unique feature for similarity computation.
However, in SimCC-AT, these scores are considered as two
separate features for similarity computation.

7. REFERENCES
[1] N. Chiki, B. Rothenburger, and N. Gilles. Combining
Link and Content Information for Scientific Topics
Discovery. In ICTAI, pages 211–214. 2008.
[2] J. Han, M. Kamber, and J. Pei. Data Mining:
Concepts and Techniques, Second Edition. Morgan
Kaufmann, San Francisco, 2006.
[3] J. Jeh and J. Widom. SimRank: A Measure of
Structural-Context Similarity. In SIGKDD, pages
538–543. 2002.
[4] T. Joachims. Optimizing Search Engines using
Clickthrough Data. In SIGKDD, pages 133–142. 2002.
[5] C. Manning, P. Raghavan, and H. Schutze.
Introduction to Information Retrieval. Cambridge
University Press, New York, 2008.
[6] M. Reyhani Hamedani, S. Kim, and D. Kim. SimCC:
A Novel Method to Consider both Content and
Citations for Computing Similarity of Scientific
Papers. Information Sciences, 334-335:273–292, 2016.
[7] K. Sugiyama and M. Kan. Scholarly Paper
Recommendation via User’s Recent Research
Interests. In JCDL, pages 29–38. 2010.
[8] S. Yoon, S. Kim, and J. Kim. On Computing
Text-based Similarity in Scientific Literature. In
WWW, pages 169–170. 2011.
[9] S. Yoon, S. Kim, and P. Sunju. C-Rank: A Link-based
Similarity Measure for Scientific Literature Databases.
Information Sciences, 326:25–40, 2016.
[10] W. Yu, X. Lin, W. Zhang, L. Chang, and J. Pei. More
is Simpler: Effectively and Efficiently Assessing
Node-pair Similarities Based on Hyperlinks. PVLDB,
7(1):2150–8097, 2013.
[11] P. Zhao, H. Han, and S. Yizhou. P-Rank: a
Comprehensive Structural Similarity Measure over
Information Networks. In CIKM, pages 553–562. 2009.

0.30
0.20
0.10
0.00

R@10
P@10
MAP

Figure 4: Accuracy of SimCC-AT and SimCC.
Despite the fact that SimCC-AT shows lower accuracy
than SimCC, we claim that it is a better method than SimCC
for similarity computation by the following aspects: 1) there
is no tangible difference between the accuracy of SimCC-AT
and that of SimCC as shown in Table 1; 2) compared with
SimCC, SimCC-AT requires a much smaller number of experiments (i.e., 6) for parameter tuning; therefore, SimCCAT can be easily adopted for practical applications; 3) the
best value of d in SimCC-AT (i.e, 2) is less than that in
SimCC (i.e, 3 [6]). Therefore, SimCC-AT has a smaller computational overhead in large citation graphs.

6.

CONCLUSIONS

In this paper, we proposed SimCC-AT to compute the
similarity of scientific papers by considering both content
and citations, which utilizes SVM rank for automatic parameter tuning. As in SimCC, the state-of-the-art method, the

1008


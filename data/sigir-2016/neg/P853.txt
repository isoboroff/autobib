How Informative is a Term?
Dispersion as a measure of Term Specificity
Rodney McDonell

Justin Zobel

Department of Computing and
Information Systems
University of Melbourne
Parkville, Australia

Department of Computing and
Information Systems
University of Melbourne
Parkville, Australia

r.mcdonell@
student.unimelb.edu.au

jzobel@unimelb.edu.au

ABSTRACT

∗

Department of Computing and
Information Systems
University of Melbourne
Parkville, Australia

bodob@microsoft.com

information in a distribution ‘has any bearing on the probability of relevance, then we should make use of it’. Typical similarity functions have both a collection-wide measure
and a document-specific measure. The inverse document
frequency (IDF) is arguably the best-known collection-wide
measure, and is a straightforward function of the number
of documents containing a specific term; other measures,
such as language models, use the total frequency of the term
in the collection. Within-document frequency, also known
as term frequency (TF), is a well-known document-specific
measure. RSJ is used in probabilistic retrieval weighting
schemes such as BM25 [7].
In other work from the same year, Salton and Wong [11]
observed that:

Similarity functions assign scores to documents in response
to queries. These functions require as input statistics about
the terms in the queries and documents, where the intention
is that the statistics are estimates of the relative informativeness of the terms. Common measures of informativeness
use the number of documents containing each term (the document frequency) as a key measure. We argue in this paper
that the distribution of within-document frequencies across
a collection is also pertinent to informativeness, a measure
that has not been considered in prior work: the most informative words tend to be those whose frequency of occurrence has high variance. We propose use of relative standard
deviation (RSD) as a measure of variability incorporating
within-document frequencies, and show that RSD compares
favourably with inverse document frequency (IDF), in both
in-principle analysis and in practice in retrieval, with small
but consistent gains.

1.

Bodo Billerbeck

the most useful content indicators are terms whose
overall occurrence frequencies are neither too large
nor too small, and whose frequency distributions
across the documents of a collection are skewed:
they occur with high frequencies in some documents and with much lower frequencies in others.

INTRODUCTION

The effectiveness of a retrieval system hinges on its ability to retrieve relevant documents in response to a query.
The core of retrieval methods are similarity functions, whose
scores are used to construct document rankings and are, in
effect, proxies for statistical estimates of the likelihood of
document relevance. Term weighting schemes are input to
these functions; these are used to allocate values to terms
that represent their significance within the collection and
each document. That is, they represent the informativeness
of words. A common approach to calculation of the informativeness of a term is measurement of the term specificity.
In their development of the Robertson–Spärck Jones relevance weight (RSJ) [10], the authors argued that, if any

We argue that a ‘content indicator’ based on variance in
frequency can indeed make a useful contribution to informativeness. In this paper, we propose a measure based on
statistical dispersion as an estimate of informativeness. This
measure, relative standard deviation (RSD), increases the
weight of terms whose within-document frequency has high
variance. As an intuition, consider a term that is part of the
vocabulary of a particular community; it may only occur in
a small number of documents – and thus have high IDF –
but would be expected to have consistent density of use in
those documents, and not be particularly informative. Variability in density, in contrast, would suggest that the term
relates to a specific topic.
We have directly compared the behaviour of IDF and
RSD, and also explored them in the context of retrieval experiments. These investigations illustrate that RSD is richer
than IDF, and can yield improvements in retrieval effectiveness. With a direct basis in statistical principles, in particular entropy, our work suggests that RSD should be used as
a replacement for simple document frequency.

∗This work was conducted while the author was employed
by Microsoft, Melbourne, Australia.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

2.

SIGIR ’16, July 17-21, 2016, Pisa, Italy

DISPERSIONAL TERM SPECIFICITY

Shannon [13] defined the value of information as proportional to the uncertainty of the information; uncertainty is

c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00
DOI: http://dx.doi.org/10.1145/2911451.2914687

853

proportional to the variability. In the context of document
retrieval, the theory implies that the words that exhibit
the most uncertainty carry the most information and thus
should be the most informative. In information retrieval, entropy has previously been investigated for term weighting,
feature selection, and the building of probabilistic models of
information retrieval [2, 4, 6, 8]. We explore statistical dispersion as a novel method of calculating variability for use
in information retrieval.
Dispersion as used in this paper is the median or mean of
the deviations of the random variable Xt = {x1 , x2 , . . . , xn }
from the the expected value E[Xt ] for some term t with
term frequencies xi over n documents. Here xi are ft,d ,
the frequency of term t in document d, or the relative term
ft,d
, where |d| is the length of d. Equafrequency rf t,d = |d|
tion (1) is thus a measure of the extent to which the actual
distribution differs from the expected (normal) distribution.

DTS (t, Xt , α, β, γ) =

E [{(x − E [Xt ])α |x ∈ Xt }]β
γ

Figure 1: IDF sample size comparison

(1)

where E is the median or mean and α, β and γ together
determine the statistical deviation being calculated.
The difference between the predictor (expected value) and
an observed value is an observation of the predictors uncertainty: the error in the prediction. The mean error of the
predictor is thus a measure of the predictor’s uncertainty.
The uncertainty inherent in dispersion suggests a connection with probability theory and Shannon’s theory of information. Shannon’s entropy determines the value of information by calculating the average self-information of a term t;
the self-information of an item k is the log of the inverse
probability 1/P (k) or the non-likelihood of item k.
As the inverse probability of an event is proportional to
the uncertainty of the event, we may define 1/P (k) as the
uncertainty of an event Ut . Thus Equation (2) gives the
formulation of a slightly different method of self-information,
based on uncertainty:
I0 (Ut ) = log (Ut )

Figure 2: RSD sample size comparison
experiments with retrieval are reported in the next section.
The first part, reported in this section, is to examine how
it relates to IDF as a description of the set of terms in a
collection.
These qualitative experiments use the weighting methods
in Equation (3) and Equation (5). RSD makes use of Equation (1) where parameters α, β and γ are 2, 1/2, and X̄t
respectively. In the experiments and results in this section,
we used the OHSUMED text collection [5], and where applicable the text category used was ohsu30. This collection,
although old, provides a framework for examining the behaviour of terms in the context of classes, and illustrates
the discriminative power of IDF and RSD.

(2)

Equation (3) defines the informativeness of IDF as the selfinformation of the uncertainty of the terms frequency distribution Ut = N/nt + 1.


N
IDF (t) = I0
+1
(3)
nt

(4)
TF -IDF (t) = log rf t,d + IDF (t)

Sample size correlation. We constructed scattergrams to
investigate the estimated informativeness of the terms in two
samples of documents, as determined by IDF and RSD. We
constructed a set of 100,000 documents from the OHSUMED
text collection, and a smaller sample of 1000 documents was
selected from the larger sample. The scattergrams for each
measure of informativeness was constructed by applying the
function to each sample and then plotting the values on the
opposite axis. Thus each scattergram shows the extent to
which a value (IDF or RSD) estimated from 1000 documents
is predictive of the observed value in 100,000 documents.
The behaviour of IDF is well known [12, 14]. If RSD is an
accurate measure of informativeness, a similar difference in
weights, for a given sample size, should be observed.
The two figures show similar overall correlation, with,
therefore, similar levels of predictivity from one sample size
to the other. Figure 1 demonstrates the gaps in the range of

Here, N is the total number of documents and nt is the number of documents containing t. Similarly RSD is a measure
of informativeness calculated from the self-information of
the uncertainty of the terms distribution as given by Equation (1).

RSD (t, Xt ) = I0 DTS t, Xt , 2, 1/2, X̄t
(5)
Here, X̄t is the mean of the distribution of term frequencies
Xt . We now examine the potential for RSD to act as a
measure of term specificity and compare to IDF.

3.

QUALITATIVE EXPERIMENTS

Our investigation of RSD is in two parts. The second
part is its value as a component of similarity measures; our

854

Figure 4: Top 40 IDF Terms

Figure 3: IDF vs Relative SD
values as generated by IDF that are one of the motivations
for use of within-document term frequency. RSD compares
favourably, showing a lack of gaps in the range of values for
the same sample size, suggesting a finer-grained measure of
informativeness.
The shape of the RSD scattergram is strongly similar to
that of IDF. Both exhibit a similar growth in values, particularly at the right-hand side. For Figures 1 and 2, these
values from approximately 4 to 12 and 2 to 6 within a total
value range of 0 to 12 and 0 to 6 respectively. This represents 66% of the total value range of both IDF and RSD,
further demonstrating the similarity between the two.

Figure 5: Top 40 Relative SD Terms
the term weights for the top 40 words of the positive classes
(Figures 4 and 5), relative to the negative classes for IDF
and RSD is approximately 20% and 57% respectively. Similar observations were made by Church and Gale [1], who
explored another form of variance: the relationship between
number of documents and total frequency of occurrence.
The differences alone are not the determining factor in the
measurements. RSD could be weighting terms incorrectly,
but still separating them more so than IDF; but this seems
unlikely given the strong correlations. Thus RSD is likely to
have a higher discriminating value than IDF.

IDF weighting correlation. Measures of term specificity
that produce weights similar to IDF are likely to also be
useful measures of informativeness.
Figure 3 was produced plotting the weights as determined
by the IDF and RSD weighting functions. Then comparative
analysis determined the similarities in the visual properties
between IDF and RSD plot values. Each graph is generated
from a random sample of 1000 documents of the OHSUMED
text collection.
The IDF weighting scattergrams clearly show that RSD
correlates strongly with IDF, supporting results from Section 3. The strong correlation supports the hypothesis that
RSD, like IDF, is a measure of term specificity. This further
supports the hypothesis that IDF and RSD are similar measures of uncertainty, and that these measures can be used
interchangeably.

4.

RETRIEVAL EXPERIMENTS

A term weighting scheme based on RSD was developed
for use in ad hoc information retrieval experiments and compared to TF-IDF.

TF -RSD = log rf t,d × RSD (t, X)
(6)
Tables 1 and 2 present the results for ad hoc retrieval for
MAP over 1000 retrieved documents and the precision at
10 retrieved documents (P@10). Results of FBIS+FR94 are
presented first, followed by WT10G [15]. Each table compares the output of trec_eval for TF-IDF and TF-RSD
where RSD takes term frequency distributions of raw frequencies or relative frequencies denoted by TF-RSD(raw)
or TF-RSD(rel) respectively.
TF-RSD calculated from TF-RSD(raw) shows improved
MAP figures for all experiments except the stopped (wordnet stopword list [3]) and stemmed [9] description-only test.
TF-RSD calculated from TF-RSD(rel) retrieved more relevant documents than TF-IDF and also resulted in higher
MAP scores. For P@10, TF-RSD outperformed TF-IDF in
all experiments, often by a relatively large margin.
Title queries on the WT10G data set for TF-RSD achieve
a significant improvement over TF-IDF. In comparison, description-only queries for TF-RSD rank the top 1000 documents less effectively than TF-IDF. However the top 10 doc-

Term rank comparison. Salton et al. showed that a decrease in the space between like documents in the vector
space and a corresponding increase in the space between unlike documents increases the precision of a retrieval system
[12, p. 617-619].
We define the ‘discriminating power of a function’ as the
distance between term weights of two opposing classes of
documents as generated by a given function. Figures 4 and 5
depict the term weights as determined by IDF and RSD
respectively, of two samples of opposing classes. Then for
IDF and RSD the discriminating power of the weighting
function is determined by analysing the differences between
the weights of the document sample for each class.
Figure 4 depicts the differences between the weights of
the rarest terms for the positive set relative to the same
terms in the negative set. The average difference between

855

Config
raw title
raw desc
ss title
ss desc

#Queries
247
249
248
249

TF-IDF
0.1743
0.1798
0.1973
0.2118

MAP
TF-RSD(raw)
0.1823
0.1856
0.2038†
0.2065

TF-RSD(rel)
0.1818†
0.1845†
0.2001†
0.2156

TF-IDF
0.1834
0.1779
0.1980
0.2072

P@10
TF-RSD(raw))
0.1842
0.1904†
0.2032
0.2076

TF-RSD(rel)
0.1883†
0.1871‡
0.2024
0.2120

Table 1: FBIS+FR94 TF-IDF vs. TF-RSD. Best results in each category are bolded and statistical significance
at the 0.05 and 0.01 levels are indicated by † and ‡, respectively.

Config
raw title
raw desc
ss title
ss desc

#Queries
98
100
97
100

TF-IDF
0.1158
0.1504
0.1296
0.1676

MAP
TF-RSD(raw)
0.1248‡
0.1401
0.1339
0.1667

TF-RSD(rel)
0.1224†
0.1464
0.1341
0.1688

TF-IDF
0.1939
0.2630
0.1938
0.2900

P@10
TF-RSD(raw)
0.2041
0.2610
0.2031
0.2900

TF-RSD(rel)
0.2051
0.2690
0.2082
0.2820

Table 2: WT10G TF-IDF vs. TF-RSD. Best results and statistical significance indicated as above.

ument rankings are not as impacted and thus this is likely
not to affect the user. TF-RSD calculated from relative term
frequencies also shows significant improvement in the MAP
for title-only queries, relative to description-only queries.
These results support the claims that RSD is a useful measure of term specificity, and show that TF-RSD is more effective than TF-IDF for the data sets and queries used.

5.

[5] Hersh, W., Buckley, C., Leone, T. and Hickam, D. [1994],
Ohsumed: An interactive retrieval evaluation and new large
test collection for research, in ‘SIGIR94’, Springer,
pp. 192–201.
[6] Jiao, Y., Cornec, M. and Jakubowicz., J. [2015], An
entropy-based term weighting scheme and its application in
e-commerce search engines, in ‘Proceedings of the first
International Symposium on Web Algorithms’,
International Symposium on Web Algorithms.

CONCLUSIONS

[7] Jones, K. S., Walker, S. and Robertson, S. E. [2000], ‘A
probabilistic model of information retrieval: Development
and comparative experiments, Parts 1 and 2’, Inf. Process.
Manage. 36(6), 779–840.

We have proposed that the informativeness of a word is
proportional to the self-information of the uncertainty of
the word’s occurrence in a set of documents, and defined
new measures of informativeness and corresponding term
weighting schemes, by calculating the self–information of the
statistical dispersion (variability) of a terms frequency across
a set of documents.
We have shown that RSD, a new measure of informativeness, correlates strongly with IDF on essential qualitative
properties of measures of informativeness. We then demonstrated that TF-RSD, a new term weighting scheme for information retrieval, achieves improved results compared to
TF-IDF in 12 of 16 retrieval experiments, seven of which
were statistically significant. The retrieval results for the top
10 ranked documents were equally impressive – where only
two of the 16 experiments failed to perform better than TFIDF. Thus TF-RSD is an effective term weighting scheme
that is a plausible replacement for TF-IDF.

[8] Ke, W. [2013], Information-theoretic term weighting
schemes for document clustering, in ‘Proceedings of the
13th ACM/IEEE-CS joint conference on Digital libraries’,
ACM, pp. 143–152.
[9] Porter, M. [1980], ‘An algorithm for suffix stripping’,
Program 14(3), 130–137.
[10] Robertson, S. and Spärk Jones, K. [1976], ‘Relevance
weighting of search terms’, Journal of the American
Society for Information Science 27(3), 129–146.
[11] Salton, G. and Wong, A. [1976], ‘On the role of words and
phrases in automatic text analysis’, Computers and the
Humanities 10, 291–391.
[12] Salton, G., Wong, A. and Yang, C. [1975], ‘A vector space
model for automatic indexing’, Communications of the
ACM 18(11), 613–620.

References

[13] Shannon, C. [1948], ‘A mathematical theory of
communication’, Bell System Technical Journal
27, 379–423.

[1] Church, K. and Gale, W. [1999], Inverse document
frequency (IDF): A measure of deviations from Poisson, in
‘Natural language processing using very large corpora’,
Springer, pp. 283–295.

[14] Spärk Jones, K. [1972], ‘A statistical interpretation of term
specificity and its application in retrieval’, Journal of
Docmentation 28(1), 11–21.

[2] Cooper, W. S. and Huizinga, P. [1982], ‘The maximum
entropy principle and its application to the design of
probabilistic retrieval systems.’, Information Technology,
Research and Development 1, 99–112.

[15] Voorhees, E. M., Harman, D. K. et al. [2005], TREC:
Experiment and evaluation in information retrieval, Vol. 1,
MIT press Cambridge.

[3] Fellbaum, C. [1998], WordNet: An Electronic Lexical
Database, Bradford Books.
[4] Greiff, W. R. and Ponte, J. M. [2000], ‘The maximum
entropy approach and probabilistic IR models’, ACM
Trans. Inf. Syst. 18(3), 246–287.

856


Visual Recommendation Use Case for an Online
Marketplace Platform - allegro.pl
Anna Wróblewska

Łukasz Rączkowski

Allegro Group
Warszawa, Poland
anna.wroblewska@allegrogroup.com

Allegro Group
University of Warsaw
Toruń, Poland
lukasz.raczkowski@allegrogroup.com
We started our project in a very small agile team consisting of a
data scientist, a software engineer, a UX designer and a product
owner. From the very start our main objective was to create a
data-driven product and deploy it within the Allegro platform. We
were given a strict deadline to deliver business value, so we’ve
decided to utilize readily available open-source projects.

ABSTRACT
In this paper we describe a small content-based visual
recommendation project built as part of the Allegro online
marketplace platform. We extracted relevant data only from
images, as they are inherently better at capturing visual attributes
than textual offer descriptions. We used several image descriptors
to extract color and texture information in order to find visually
similar items. We tested our results against available textual offer
tags and also asked human users to subjectively assess the
precision. Finally, we deployed the solution to our platform.

In the following sections, we describe these topics in detail:
presentation of available offer data stored in the Allegro platform
(section 2), software architecture of our solution, used tools,
image features and similarity metrics (section 3), variety of
techniques to test the solution based on available data (section 4).
In the last section we conclude the paper and discuss future work.

Keywords
visual search; image search; content-based recommendations;
e-commerce; online auctions; image processing; LIRE; OpenCV;
Elasticsearch; CBIR

2. CHARACTERISTICS OF OFFER
DESCRIPTIONS
Offers listed in our marketplace platform can be described by a
limited set of well-defined attributes, short title and a long
description that contains unstructured data with a lot of additional
information, e.g. seller addresses or tailored recommendations.
Each offer is categorized and each should include at least one
photo that shows the offered product.

1. INTRODUCTION
Content based image retrieval (CBIR) has slowly but steadily
been growing in importance as a means to improve search
experience in e-commerce. Several prominent companies have
already deployed their own image retrieval solutions. Pinterest
developed an image search platform and thus they showed that
content recommendation powered by visual search improves user
engagement [10]. At eBay it’s been proven that image-based
information can be used to quantify image similarity, which can
be used to discern products with different visual appearances [2].
Finally, Yahoo built a visual similarity-based interactive search
system, which led to more refined product recommendations [8].

Usually text parameters of offers in our service are high-level
abstractions and as such are not very precise, e.g. a dotted pattern
may describe a large spectrum of dot sizes and configurations.
Furthermore, our traditional textual color tags have only around
10 very general values, e.g. shades of yellow or shades of brown.
In spite of the fact that color and pattern attributes are obligatory,
our sellers often specify them ambiguously as “other color”,
“other pattern” or “multicolor”. Thus recommendations based
only on text attributes are sometimes quite vague and not precise.
A cursory data analysis in a single fashion category (Figure 1)
shows that a large fraction of fashion items listed online lacks
precise color information.

At Allegro [1] our main goal is the satisfaction of our users, so in
order to further push for that objective, we've decided to try our
hand at visual recommendations. The aim of the project was to
develop a system that returns product offers that are visually
similar to the given input image. That similarity is determined
based on several features extracted from offer images. Low-level
image information like that is particularly useful in product
categories for which visual aspects are important and also for
categories that contain products which are hard to describe with
words, e.g. fashion or jewellery items.

Having such a huge disparity in attribute quality drove us to
hypothesize that by extracting image features we can get a better
understanding of offers in our service.
The quality of images attached to product offers varies greatly. In
some categories they’re quite bad, and in others they’re very
professional. To overcome this quality hurdle in the beginning of
our work, we’ve decided to test our algorithms only on images
from a special part of Allegro called Brand Zone. These images
usually have a bright background and the main object/product is
in the middle. Thanks to this we were able to easily crop the
essential part of every image.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’16, July 17–21, 2016, Pisa, Italy.
© 2016 ACM. ISBN 978-1-4503-4069-4/16/07…$15.00.

We came to this conclusion last year, when we tested the offer
image quality in a single fashion product category using our
dedicated tool – Nigel - that marks image quality on the scale
from 0 (bad quality) to 1 (the best quality). In Figure 2 we show a

DOI: http://dx.doi.org/10.1145/2911451.2926722

591

ddensity distributiion plot that sho
owcases how Niigel scores imag
ges
inn the Brand Zon
ne versus Allegro
o as a whole.

Figuree 3. Our test app
plication - Imaggator

F
Figure 1. Color attributes distrribution in the dresses categorry.
A
Almost 50% of
o offers have multi-labeled assignments or
o
vvalues like multticolor / other co
olor.

The inddexer service is a subscriber in oour internal evennts queue. It
receivees all events perttaining to new, deleted and chaanged offers.
We filtter out unnecesssary categoriess and offers outtside of the
Brand Z
Zone and then inndex the images into our ES index.

F
Figure 2. Denssity distribution
n of image qu
uality assessment
w
with the Nigel to
ool.

Figuree 4. Architecturee of our producction-ready systtem.

33. TOOLS AND METH
HODS
33.1 Solution
n Architectu
ure

A publlic visual recom
mmendation AP
PI was needed to interface
betweeen the image rettrieval backend and recommenddation boxes
Allegro frontendd. The results froom our visual seaarch API are
in the A
shown in a separate layyer after clickinng on a Show sim
milar button
in a reccommendation bbox (Figure 5).

W
We developed our
o product in two
t
stages. Firsst, we created th
he
nnecessary backen
nd for the image retrieval systeem and also a teest
w
web application, which we affecctionately named
d Imagator (Figu
ure
33). In the develo
opment of the backend we utilized the followin
ng
oopen-source projects: Elasticsearrch (ES) [6], LIR
RE (Lucene Imag
ge
R
Retrieval) [11],, OpenCV [4]] and elasticsearch-image [5
5].
E
Elasiticsearch seerves as a databaase for image feeature vectors an
nd
aalso as a search engine. The im
mage features can be incorporateed
innto ES index thaanks to the elastticsearch-image plugin and LIR
RE.
T
The latter piece of software inclludes a set of nu
umeric descripto
ors
bbased on MPEG--7 edge detection
n and color histo
ogram algorithm
ms.
W
We extended LIR
RE with new image features and
d mixed them wiith
aan image-croppin
ng utility, which
h was possible th
hanks to OpenCV
V.
W
We used OpenCV
V because of its efficient algorithms and also wiith
thhe hope that in the future we’d be able utilize GPGP
PU
fu
functionality witthin it. Imagatorr’s user interfacee was created ass a
ssingle-page web application in AngularJS. It was
w used to testt a
vvariety of imag
ge features, reg
gions of interest and similariity
m
metrics.
T
The second part of the project was
w to prepare a production-read
dy
ssystem. This required
r
the development
d
off two addition
nal
ccomponents: an indexer
i
service and
a a public APII (Figure 4).

Figuree 5. Screenshott showing the system in acttion within
Allegroo’s production environment.

592

33.2 Image features
f
and
d similarity metrics
T
The LIRE librarry contains an extensive
e
suite of
o image featurees,
ffocusing both on
n color and patttern extraction. In this work we
w
sspotlight the follo
owing ones:





au
uto color correlogram (ACC) [9]]
ed
dge histogram (E
EH) [14]
biinary patterns py
yramid (BPP) [3]][11]
jo
oint histogram (JH) [11]

A
Additionally, wee implemented a new feature, paalette power (PP
P),
aas described in [2
2].
E
Extracting data from
f
an image iss only a first parrt of the equatio
on.
Inn order to comp
pare images and assess their simiilarity, we need to
ccompare the resu
ults that we gett from the abov
ve image featurees.
W
We tried severaal distance com
mparison metricss and in the en
nd
ssettled for threee that gave the best results: Tanimoto Distance
[12], Earth Moveer’s Distance [13
3] and Hellinger Distance [7].

Figuree 7. Mean averaage precisions aat positions 1-110 for color
and paattern parameteer values as a teext benchmark.

44. TESTS
T
To measure th
he precision off our image-baased search, we
w
cconducted both automatic and user-focused
u
tessts. The effects of
thhe deployment to
t production can
n be quantified thanks
t
to the CT
TR
(click through ratte) metric.

44.1 Automa
atic tests based on textu
ual tags
T
To assess the diifference betweeen descriptors (and also betweeen
ssimilarity metriccs), we perform
med automatic teests using textu
ual
ccolor tags as a benchmark
b
on a set of about 1300 images from
ma
ccategory contain
ning dresses. We
W measured th
he mean averag
ge
pprecision (MAP)) for positions 1 through 5 in our
o search listin
ng.
T
Top N selected im
mages similar to
o the query imag
ge are marked ass a
ggood choice wheen they have thee same text bencchmark parameteer.
W
We conducted tests for diffferent sets of text benchmaark
pparameters. We chose among color, pattern or style parameterrs.
H
However, it’s worth
w
mentionin
ng that the resu
ults are not veery
pprecise and may be too high beccause of the low quality of textu
ual
ooffer parameterss and their low relevance to reeal visual produ
uct
ddescriptions, whiich was mention
ned in section 2.

Figuree 8. Mean averaage precisions aat positions 1-100 for color,
patttern and style p
parameter valuees as a text bencchmark.

4.2 S
Subjective u
user assessm
ments
Imagatoor shows a view
w with a large main image annd 5 smaller
imagess (Figure 3), deeemed as similarr by our system
m (5 images
We showed this aapp to about
having the highest rannking in ES). W
10 peoople. We gave thhe users a simpple task to assesss the visual
main image usinng a 5 point
similariity of smaller iimages to the m
scale, w
where 1 means nno correspondennce between the main image
and thee small one and 5 – very similar products in bothh pictures.

T
This automatic test results rang
ged from 100%
% for MAP@1 to
660-70% for MAP
P@5 (Figures 6-8).

These ssubjective tests w
were performed many times - w
we wanted to
gather as much data aas possible in oorder to make ddecisions on
which image feaatures are the m
most suitable
design strategies, i.e. w
for a pparticular domainn and which seggmentation techhnique is the
We chose 66 imaages as main testt images. Each oof them was
best. W
used ass input in the ES
S query to find similar images amongst all
1166 inndexed images. The main test iimages were choosen so that
their ccolor and patttern parameterss must have hhad similar
distribuution as the distrribution of param
meters in all actiive offers in
the dressses category (w
within the Brand Zone).
Resultss for different im
mage descriptorrs settled in the range 2.8 3.2 (Taable 1, Figure 9)..
Many oof the users rem
marked that although the associattion was not
perfect , most of the tiime there were some similar aaspects, e.g.
similar tone of color oor a comparable pattern. They allso said that
such reecommendationss could be veryy attractive forr users who
would browse throughh offers in our sservice with an intention to
buy a ro
roughly similar pproduct.

Figure 6. Mean
n average precissions at position
ns 1-10 for color
para
ameter values as
a a text benchm
mark.

593

Howevver, there are stilll a few challengges ahead of us.. We need a
way too automatically measure the im
mage quality, whhich will in
turn alllow us to approppriately adjust thhe image matchinng methods.
We aree also considerinng mixing textuaal descriptions w
with numeric
feature s extracted from
m images. Finallyy, we would likee to develop
more soophisticated deeep learning methhods to find visuual similarity
betweeen our offers.

Table 1. Useer subjective asssessments (UA)) for different
feature desscriptors (-C sufffix denotes a ceentral ROI).
Test featu
ures

Aveerage
UA
U
1st test phase

UA
StdDeev

UA
Number

2..82

1.09

990

3..26

1.27

750

2..90

1.23

990

2.8
2

1.04

990

ACC-C
users assessed only
color similarity
y
ACC
EH-C
users assessed only
pattern similarrity
ACC-C + EH-C
users assessed both
characteristics (color
milarity)
and pattern sim

6. AC
CKNOWLE
EDGEMEN
NTS
We woould like to sinceerely thank Monnika Cierzniak ((our product
owner) and Maria Boroowy (our UX deesigner) for helpping us with
the depployment to prodduction and withh the UX design of Imagator
respecttively, as well ass for all the greatt ideas and insights.

7. RE
EFERENCES
[1] Alllegro online maarketplace platfoorm: http://allegrro.pl.
[2] Bhhardwaj, A., Dass Sarma, A., Di, W., Hamid, R., Piramuthu,
R.. and Sundaresann, N. 2013. Palettte power: enablling visual
seearch through collors. Proceedinggs of the 19th AC
CM
SIIGKDD Internattional Conferencce on Knowledgee Discovery
annd Data Mining (2013), 1321–13329.
[3] Boosch, A., Zisserm
man, A. and Munnoz, X. 2007. Reepresenting
shhape with a spatial pyramid kernel. Proceedings of the 6th
AC
CM internationaal conference on Image and videeo retrieval
(2 007), 401–408.
[4] Brradski, G. 2000. The OpenCV L
Library. Dr. Dobbb’s Journal
off Software Tools.. 25, 11 (Nov. 20000), 120–126.
[5] Ellasticsearch conttent-based imagee retrieval pluginn:
htttps://github.com
m/kzwang/elasticssearch-image.
[6] Ellasticsearch searrch engine: https://www.elastic.cco.
[7] Haazewinkel, M. 2002. Encyclopaeedia of mathemaatics.
Sppringer-Verlag.
[8] Hssiao, J.-H. and L
Li, L.-J. 2014. Onn visual similariity based
intteractive producct recommendation for online shopping.
20014 IEEE Internaational Conferennce on Image Prrocessing
(IC
CIP) (Oct. 2014), 3038–3041.
[9] Jinng Huang, Kumaar, S.R., Mitra, M
M., Wei-Jing Zhhu and
Zaabih, R. 1997. Im
mage indexing uusing color correllograms.
Prroceedings of IE
EEE Computer So
Society Conference on
Coomputer Vision aand Pattern Reccognition (1997), 762–768.
[10] Jinng, Y., Liu, D., K
Kislyuk, D., Zhaai, A., Xu, J., Doonahue, J.
annd Tavel, S. 20155. Visual Searchh at Pinterest. Prroceedings
off the 21th ACM SSIGKDD Internaational Conferennce on
Knnowledge Discovvery and Data M
Mining (2015), 1889–1898.
[11] Luux, M. 2011. Coontent based imagge retrieval withh LIRE.
Prroceedings of thee 19th ACM Inteernational Confeerence on
M
Multimedia (2011), 735–738.
[12] Roogers, D.J. and T
Tanimoto, T.T. 11960. A Computter Program
forr Classifying Plaants. Science. 1332, 3434 (Oct. 19960), 1115–
11118.
[13] Ruubner, Y., Tomaasi, C. and Guibaas, L.J. 1998. A metric for
disstributions with applications to iimage databasess.
Prroceedings of thee Sixth Internatiional Conferencee on
Coomputer Vision ((1998), 59–66.
[14] W
Won, C.S.W., Parrk, D.K.P. and Park, S.-J.P. 20022. Efficient
Usse of MPEG-7 E
Edge Histogram Descriptor. ETR
RI Journal.
244, 1 (Feb. 2002), 23–30.

2nd tesst phase
JH

3..32

1.05

330

PP

3..08

1.44

465

JH+PP
P

3..05

1.26

575

BPP+JH
H

2..41

1.41

655

F
Figure 9. Mean
n average precision of user asssessments (MA
AP
U
UA) at 1-5 posiition for 4 featture combinatio
ons in subjectiv
ve
tests.

44.3 Producttion results and discusssion

F
Finally, after anaalyzing our test results after the 1st phase of testts,
w
we’ve chosen th
he best image descriptor (ACC
C) and similariity
m
metric for Brand
d Zone images an
nd decided to deeploy our solutio
on
too operate in a production
p
envirronment. We in
ntegrated it with
ha
recommendation
n box on the offfer description page. Initial A//B
c
through raate
teests performed on small user traffic show click
results comparab
ble to other techniques based on
nly on textual tags
(ttaking into account the same cattegory).
T
The subjective reesults from the 2nd test phase an
nd numbers takeen
fr
from the producction environmeent show that our
o product has a
ggreat potential to improve, especially when we consid
der
ccombining the im
mage–based featu
ures with textuall offer tags.

55. CONCLU
USION
T
Thanks to existin
ng open-source tools
t
it is easy to
t create an imag
ge
recommendation
ns system from scratch. The inssight of our teaam
m
members alloweed us to fully utilize this op
pportunity, whicch
resulted in giving
g Allegro users a new way to brrowse the servicce.

594


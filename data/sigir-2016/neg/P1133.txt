PULP: A System for Exploratory Search of Scientific
Literature
Alan Medlar? Kalle Ilves

Ping Wang

Wray Buntine⇧ Dorota Głowacka

Department of Computer Science, University of Helsinki
⇧
⇧

Institute of Biotechnology, University of Helsinki

Faculty of Information Technology, Monash University

alan.j.medlar@helsinki.fi, ? Wray.Buntine@monash.edu first.last@cs.helsinki.fi,

ABSTRACT

lenging for the user and requires additional support from
information retrieval (IR) systems.
Our work addresses the observation that IR systems primarily target lookup search, despite the increasing importance of exploratory search [5]. Most IR systems present a
ranked list of documents in descending order of their relevance to the issued search query. This approach works
very well for lookup tasks where the user has a discrete and
well defined information need. However, retrieving the best
matching results for the search query might trap the user in
their initial query context and contribute to user perceptions
that exploratory search is challenging. Moreover, for users
attempting to acquire information in an unfamiliar domain
where they lack the specific knowledge to formulate search
queries, retrieving the best matching results to those queries
may be counterproductive.
We address the issue of initial query formulation by visualizing what topics are covered by a given dataset and what
keywords are associated with each topic, allowing the user
to directly select a topic as their initial search query. In
order to prevent the user from getting stuck in the context
trap of the initial search query, we use reinforcement learning (RL) to trade o↵ between exploration and exploitation
throughout a search session.

Despite the growing importance of exploratory search, information retrieval (IR) systems tend to focus on lookup search.
Lookup searches are well served by optimising the precision
and recall of search results, however, for exploratory search
this may be counterproductive if users are unable to formulate an appropriate search query. We present a system
called PULP that supports exploratory search for scientific
literature, though the system can be easily adapted to other
types of literature. PULP uses reinforcement learning (RL)
to avert the user from context traps resulting from poorly
chosen search queries, trading o↵ between exploration (presenting the user with diverse topics) and exploitation (moving towards more specific topics). Where other RL-based
systems su↵er from the “cold start” problem, requiring sufficient time to adjust to a user’s information needs, PULP
initially presents the user with an overview of the dataset
using temporal topic models. Topic models are displayed in
an interactive alluvial diagram, where topics are shown as
ribbons that change thickness with a given topics relative
prevalence over time. Interactive, exploratory search sessions can be initiated by selecting topics as a starting point.

Keywords

2.

Exploratory search; topic models; bandit algorithms; scientific literature search; query formulation

1.

?

BACKGROUND

Below, we briefly review the existing approaches to shed
light on some of the open problems in exploratory search.
Relevance Feedback. The first key approach developed
by the IR community was relevance feedback: users mark
documents as relevant or non-relevant and the query model
is updated accordingly. Initial studies showed that interactive IR systems benefited from relevance feedback [15],
though later studies showed these features to be rarely used.
The reasons are two-fold: (1) relevance feedback often leads
to context traps, and (2) the cognitive load of selecting relevant documents is high compared to typing a new query
[15]. Combining relevance feedback with user modelling
techniques, such as reinforcement learning, would allow an
IR system to suggest more relevant results and avoid getting
stuck in context traps.
Faceted Search. Faceted search aims to avoid the context trap by using global features instead of contextual ones
[21]. It organizes information according to a faceted classification system, allowing users to explore collections of
documents by applying multiple filters. Such systems classify information elements along explicit global dimensions,
enabling the classifications to be accessed and ordered in

INTRODUCTION

Exploratory search is defined as a class of search activities
performed to learn or discover new information [16]. Unlike
lookup search, where a discrete set of results achieves a welldefined objective, exploratory search can involve unfamiliar
subject areas and uncertainty regarding search goals. In exploratory tasks users are often uncertain how to formulate
search queries [8] either because they are unfamiliar with the
search topic or they have no clear search goals in mind. For
these reasons exploratory search is considered to be chalPermission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

SIGIR ’16, July 17-21, 2016, Pisa, Italy
c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00
DOI: http://dx.doi.org/10.1145/2911451.2911455

1133

Figure 1: Interactive alluvial diagram showing what topics are present in each year and their relative abundance.
multiple ways. As the number of global features is often
very large, the process, however, can quickly become overly
demanding as users have to assess a large number of options [21]. Assisting the user in formulating the initial search
query in combination with improved modeling of user needs
would allow a reduction in the number of facets and thus
enhance user experience.
Reinforcement Learning. In exploratory search, the
information-needs of a user are constantly evolving, and
hence modeling is crucial for acquiring information on search
intent and query reformulation [20]. Recently, RL techniques have been applied to modeling exploratory search
[14, 10]. RL allows a system to balance exploitation (moving towards more specific topics) and exploration (presenting alternative topics). The main disadvantage is the “cold
start” problem: these systems need a number of sessions to
adjust to a user’s information needs. A recent study showed
that systems employing RL techniques can optimally balance exploitation and exploration for a given set of users [2].
Assisting the user in formulating the initial query in an RLbased IR system would accelerate the user modeling aspect
of such systems.
Exploratory Search Interfaces. The lack of success
of relevance feedback is often attributed to user interface
design failing to conveniently provide feedback at suitable
levels of granularity. In response, a variety of systems were
designed to support user feedback, including intelligent user
interfaces that assist the user in comprehending an information space [7], visualizations that summarize results for
faster relevance judgement [17], as well as interactive visualizations that allow the user to indicate the direction of
exploration [10]. These systems are very useful but they
usually do not take into consideration the evolving nature

of user knowledge in exploratory search tasks and thus either fail to provide a good starting point for the search or
lead to a context trap as the search progresses.
Models of Exploratory Search. Models of user behaviour in information search help us to provide personalized support [1]. Information Foraging Theory is a promising
model of exploration that predicts the information seeker’s
decision from the expectation of information gain [18]. There
are also models that assist the search systems in predicting
user perception of the results from implicit interactions, including search satisfaction, disambiguating exploration and
struggling scenarios [13], and predicting the user’s domain
knowledge [9]. We draw inspiration for the design of our system from models of user behaviour in exploratory search.
Search and Topic Models. While there has been extensive research on topic model visualisation, there has been
less on their use for exploratory search. While there has
been prior work using hierarchical topic models for document summarising and navigation [12], it did not present
the dynamic aspect of time that is critical in scientific literature. Another study presented the graph of connections
(institutions, subject areas, authors, etc.) [11]. In both of
these examples, however, the intrinsic use of topics as an aid
to IR was less developed.

3.

SYSTEM OVERVIEW

PULP can be broadly divided into three parts: visualization of search topics, search engine interface, and search
engine backend containing the document ranking algorithm.
The current version of the system operates on ⇠1 million
documents obtained from the arXiv repository, although the
system can be easily adapted to other domains.
The search starts with the alluvial diagram of broad top-

1134

ics found in the arXiv dataset over the years (Figure 1).
Each year is represented by a vertical list of research topics
covered by papers added to arXiv in that particular year.
Each research topic is labelled with the five most prominent
keywords from that topic. The user can specify which years
of the arXiv data should be visualised by using the slider in
the upper left hand corner of the visualisation. The ribbons
going between di↵erent years indicate how topics in di↵erent
years are related to one another. When the search starts, all
the ribbons representing the flow of the topics from year to
year are light grey. The user can click on any of the existing
topics to see its development over the years, at which point
the ribbon representing that topic model will change colour.
The user can click on as many topics as he likes. By clicking
on the search button next to the slider, the top five keywords
from the topics that the user clicked on will be sent to the
search engine as a query. If none of the topics was selected,
then by clicking on the search button, the user is directed
to the query page of the search engine.
The search engine interface is presented in Figure 2. The
query bar is at the top of the page. The keywords from the
topics that the user clicked on in the alluvial diagram are
shown in the search bar. The user can amend this query
by deleting or adding keywords. If no topics in the alluvial
diagram were selected, then the search bar is empty and
the user can formulate their own query. After typing in the
search query, the user is presented with 10 documents. The
initial set of documents is ranked based on the Okapi BM25
algorithm [19]. Next, to see more documents the user can
indicate which document interests them by clicking on the
circle next to it and thus providing relevance score of 1 to
that document. After clicking the “next” button in the top
right corner of the page, a new set of documents is displayed
based on the feedback provided by the user so far. The user
can provide feedback to as many documents as he wishes.
The right margin of the page contains the topic model display with the distribution of topics in the presented search
results and the rest of the dataset. The top most prominent
topics for each document are shown. Each topic is represented with a consistent colour across all documents. The
length of the bar representing a given topic corresponds to
the relative prominence of this topic in a given document.
By hovering the mouse cursor above a given topic, a tooltip
appears with top five keywords associated with that topic.
The topics representing the currently displayed search results are marked with a blue vertical line on the left side
of the topic display bar. The remaining part of the topic
model display shows how many potentially similar documents in terms of their topic distribution there are in the
dataset. The topic model display can be scrolled down to
cover the entire dataset. Below, we describe how the topic
model visualisation was constructed and how the documents
are ranked.

3.1

tion as well [6]) and labelled with the top 5 ranked words.
Getting an estimate of topic flow is more challenging. The
documents in year Y +1 are fit to the topics from year Y .
The most likely topic for each word is then estimated using
the topics from years Y and Y +1. This produces topic-totopic mapping data from years Y to Y +1 for each word in
year Y +1. We estimate the topic flows from this mapping
data. We found this to be less noisy than heuristic estimates
based on topic word-vector di↵erences.

3.2

Document ranking

In order to help the user explore the document space, we
use LinRel [4]. Suppose we have a matrix D, where each row
di is a tf-idf (term frequency-inverse document frequency)
feature vector representation of documents presented so far.
Let r = (r1 , r2 ...rt )> be the column vector of relevance
scores received from the user up to time t. We estimate
the expected relevance ri of a document di as E[ri ] = di · w,
where the vector w is estimated from user feedback. LinRel
estimates ŵ by solving r = D · w and estimates relevance
score for each di as rˆi = di · ŵ
In order to deal with the exploration-exploitation tradeo↵, we present documents not with the highest score rˆi , but
with the largest upper confidence bound for the relevance
score. Thus, if i is an upper bound on standard deviation of relevance estimate r̂i , the upper confidence bound
> 0 is
of document di is calculated as ri + i , where
a constant used to adjust the confidence level of the upper confidence bound. In each iteration, LinRel calculates
si = di · (D> · D + I) 1 D> , where is the regularization
parameter which is set to 1 if each of the feature vectors
sums up to 1 (following [4]) and the documents that maximize si · r + 2 ksi k are selected for presentation. The first
term si · r e↵ectively ranks all the documents based on their
similarity to the documents the user has selected so far and
thus it narrows the area of the search space (exploitation).
The second term 2 ksi k ensures that the user is presented
with a more diverse set of results. The exploration rate is
controlled by the parameter. The higher the value of ,
the more diverse, or exploratory, the results are. The exploration rate in the current system is = 1, based on results
from a previous experimental study [2].

3.3

Topic Model Representation

The same document preparation and topic model system
discussed in Section 3.1 was used for the global topic representation. However, for the global model, more topics were
used – 300 in the current version of the system. For this, we
needed to estimate topic proportions per document, which
was done using 500 cycles of the Gibbs sampler after an initial 1000 cycles. In the topic model visualisation in Figure
2 we used the top five topics proportions per document.

4.

Temporal Topic Models

SUMMARY OF RESULTS

The search engine components of PULP (search interface
and RL-based backend) were tested in a series of user experiments [2, 3]. The participants were researchers in various areas of computer science. Search results include more
diverse results when users are exploring. Users found more
useful results in exploratory tasks when compared to a baseline system, which was specifically tuned for lookup tasks.
Overall, users gave higher ratings for documents retrieved
during exploratory tasks using PULP compared to the base-

All documents in the dataset were preprocessed to remove
stop-words and made lower case. They were then grouped
by year of last update, with all documents prior to 1993
placed together. The standard, non-bursty, non-parametric
topic model of Buntine and Mishra [6] is run on each group
to produce 20 topics per group. For these topics, words are
then ranked according to their “lift” over the background
(the model estimates a “non-topical” background distribu-

1135

Figure 2: The search engine user interface.
line system. Additionally, in exploratory search tasks, there
is a higher number of interactions, i.e. the number of search
results users clicked or bookmarked in our system than in
the baseline system. Currently, we are in the process of assessing exploratory searches initiated via our topic model
visualisation versus free text search queries.
Acknowledgments. The work was supported by The
Finnish Funding Agency for Innovation (projects Re:Know
and D2I) and by Academy of Finland (project COIN).

5.

[10] D. Glowacka, T. Ruotsalo, K. Konyushkova,
K. Athukorala, S. Kaski, and G. Jacucci. Directing
exploratory search: Reinforcement learning from user
interactions with keywords. In IUI, 2013.
[11] B. Gretarsson, J. O’Donovan, S. Bostandjiev,
T. Höllerer, A. Asuncion, D. Newman, and P. Smyth.
Topicnets: Visual analysis of large text corpora with
topic modeling. ACM Trans. Intell. Syst. Technol.,
3(2):23:1–23:26, Feb. 2012.
[12] A. Haghighi and L. Vanderwende. Exploring content
models for multi-document summarization. In
NAACL, 2009.
[13] A. Hassan, R. W. White, S. T. Dumais, and Y. Wang.
Struggling or exploring?: disambiguating long search
sessions. In WSDM, 2014.
[14] S. Hore, L. Tyrvainen, J. Pyykko, and D. Glowacka. A
reinforcement learning approach to query-less image
retrieval. In Symbiotic Interaction, 2014.
[15] D. Kelly and X. Fu. Elicitation of term relevance
feedback: an investigation of term source and context.
In SIGIR, 2006.
[16] G. Marchionini. Exploratory search: from finding to
understanding. Com. ACM, 49(4):41–46, 2006.
[17] J. Matejka, T. Grossman, and G. Fitzmaurice.
Citeology: visualizing paper genealogy. In CHI
Extended Abstracts, pages 181–190. ACM, 2012.
[18] P. Pirolli and S. Card. Information foraging. Psych.
rev., 106(4):643, 1999.
[19] K. Sparck Jones, S. Walker, and S. E. Robertson. A
probabilistic model of information retrieval:
Development and comparative experiments. Info.
Proc. & Manag., 36(6):779–840, 2000.
[20] R. W. White, P. N. Bennett, and S. T. Dumais.
Predicting short-term interests using activity-based
search context. In CIKM, 2010.
[21] K.-P. Yee, K. Swearingen, K. Li, and M. Hearst.
Faceted metadata for image search and browsing. In
CHI, 2003.

REFERENCES

[1] K. Athukorala, D. Glowacka, A. Oulasvirta,
J. Vreeken, and G. Jacucci. Is exploratory search
di↵erent? a comparison of information search behavior
for exploratory and lookup tasks. JASIST, 2015.
[2] K. Athukorala, A. Medlar, K. Ilves, and D. Glowacka.
Balancing exploration and exploitation: Empirical
parameterization of exploratory search systems. In
CIKM, 2015.
[3] K. Athukorala, A. Medlar, A. Oulasvirta, G. Jacucci,
and D. Glowacka. Beyond relevance: Adapting
exploration/exploitation in information retrieval. In
IUI. ACM, 2016.
[4] P. Auer. Using confidence bounds for exploitation –
exploration trade-o↵s. JMLR, 3:397 – 422, 2002.
[5] N. J. Belkin. Some (what) grand challenges for
information retrieval. In ACM SIGIR Forum,
volume 42, pages 47–54. ACM, 2008.
[6] W. Buntine and S. Mishra. Experiments with
non-parametric topic models. In SIGKDD, 2014.
[7] D. H. Chau, A. Kittur, J. I. Hong, and C. Faloutsos.
Apolo: making sense of large network data by
combining rich user interaction and machine learning.
In CHI, 2011.
[8] S. Chowdhury, F. Gibb, and M. Landoni. Uncertainty
in information seeking and retrieval: A study in an
academic environment. Information Processing &
Management, 47(2):157–175, 2011.
[9] M. J. Cole, J. Gwizdka, C. Liu, N. J. Belkin, and
X. Zhang. Inferring user knowledge level from eye
movement patterns. Inf. Proc. Manag., 2012.

1136


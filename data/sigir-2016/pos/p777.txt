Burst Detection in Social Media Streams for Tracking
Interest Profiles in Real Time
Cody Buntain

Jimmy Lin

Dept. of Computer Science
University of Maryland
College Park, Maryland, USA

David R. Cheriton School of Computer Science
University of Waterloo
Waterloo, Ontario, Canada

cbuntain@cs.umd.edu

jimmylin@uwaterloo.ca

ABSTRACT

This paper describes a simple scoring method that uses burst detection to address this social media tracking problem. By identifying rapid increases (i.e., “bursts”) in relevant social media posts,
one can theoretically rely on the social network to determine interesting data for a given set of interests. We describe this approach, which we call RTTBurst, and its use of real-time burst
detection on Twitter’s social media stream. Besides documenting
our techniques, RTTBurst was one of the systems participating in
the TREC 2015 Microblog track, and we discuss its performance
relative to similarly purposed systems. Lastly, RTTBurst’s architecture is quite different from the other TREC systems, allowing
us to demonstrate its use as an additional filtering step to increase
other systems’ performance.
This work makes the following contributions:

This work presents RTTBurst, an end-to-end system for ingesting
descriptions of user interest profiles and discovering new and relevant tweets based on those interest profiles using a simple model
for identifying bursts in token usage. Our approach differs from
standard retrieval-based techniques in that it primarily focuses on
identifying noteworthy moments in the tweet stream, and “summarizes” those moments using selected tweets. We lay out the architecture of RTTBurst, our participation in and performance at the
TREC 2015 Microblog track, and a method for combining and potentially improving existing TREC systems. Official results and
post hoc experiments show that our simple targeted burst detection
technique is competitive with existing systems. Furthermore, we
demonstrate that our burst detection mechanism can be used to improve the performance of other systems for the same task.

• Presents a real-time streaming algorithm for discovering and
summarizing relevant moments on Twitter,
• Details RTTBurst’s performance relative to similar real-time
systems, and
• Demonstrates that burst detection can enhance other realtime tracking systems.

CCS Concepts
•Information systems → Summarization; Social tagging systems; •Human-centered computing → Social networking sites;

Keywords

2.

burst detection, real-time tracking, twitter

1.

RELATED WORK

Identifying important events from the ever-growing body of digital media has fascinated researchers for over twenty years, starting
from digital newsprint to blogs and now social media [1]. Early
event detection research followed the work of Kleinberg [5] by
identifying bursty keywords from digital newspapers and clustering
those keywords to identify bursty events. These works inspired our
exploration of burst detection, but they often used complex models, were not designed for big datasets, and were not designed for
real-time use.
A recently published survey by Atefeh and Khreich [2] explores
many of the avenues used for modern event detection in social media. They laid out many of the issues in analyzing Twitter (e.g.,
high levels of noise, mixed language, spelling/grammar mistakes,
etc.) and presented a classification of event detection techniques.
The classes cover three dimensions: unspecified vs. specified event
information, new vs. retrospective detection, and unsupervised vs.
supervised learning methods. Our work falls in the new-eventdetection, unsupervised learning classes but represents a hybrid in
the unspecified vs. specified dimension. RTTBurst was originally
developed on an open-domain model and was adapted to the interest tracking domain. It allows the user to pre-specify a topic of
interest but leverages temporal signatures to identify new, unanticipated events related to that topic. This hybridization is well-suited
for the TREC 2015 Microblog track, which focused on identifying
new, topically relevant information on Twitter in real time.

INTRODUCTION

A significant power of social media is the velocity with which
new information is posted and shared. If a user is interested in recent posts about a particular item, event, or topic, she can search for
a few relevant keywords in a social network and track the newest
developments. For instance, one can track tweets mentioning “goal”
on Twitter during the 2014 World Cup to identify when goals are
scored [4]. If a user wants to track these interesting events on current social media platforms, however, she must remain online and
manually filter through many duplicate posts. Many approaches
have been proposed to address this need [3, 7, 8, 9], as explored at
the 2015 Text Retrieval Conference (TREC) [6] organized by the
National Institute of Standards and Technology (NIST).
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

SIGIR ’16, July 17-21, 2016, Pisa, Italy
c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00
DOI: http://dx.doi.org/10.1145/2911451.2914733

777

tokens with scores below a burst threshold γ and any token whose
length is less than four characters.

As mentioned in the track’s 2015 overview paper by Lin et al. [6],
this filtering task’s goal was to identify new tweets relevant to a set
of given interest profiles, each of which was comprised of an identifier, title, a brief description, and a narrative describing the topic
of interest. The evaluation occurred in July of 2015 over ten days
and was broken across two tasks: a mobile notification task that enforced a limit of 10 tweets per topic per day and penalized tweets
based on the delay between posting and reporting (Scenario A),
and a daily digest task with the relaxed constraint of 100 messages
per day and no temporal penalty (Scenario B). For the evaluation,
NIST created 225 topics, 51 of which were later assessed.

3.

Moment Summarization. Every sixty seconds, RTTBurst identified a new (possibly empty) set of bursty tokens, which corresponded to noteworthy moments in the relevant interest profile. For
the TREC Microblog track, however, returning these bursty tokens
was not sufficient for summarizing the moment, since the evaluation was based on judgments over individual tweets. Rather, our
system used tweets to summarize these moments, similar to the
ReDites system [7].
To this end, every sixty seconds, RTTBurst parsed all tweets in
the previous N windows to create a subset of tweets containing
these bursty tokens. We then calculated a Jaccard similarity score
for each tweet in this subset by comparing the tweet to tweets returned to the user in previous windows. Any new tweet whose Jaccard similarity was above our threshold Jt = 0.7 was discarded,
and the remaining tweets were sorted by their similarity scores in
decreasing order. Finally, the top M least similar tweets containing bursty tokens from the past N windows were assigned to the
relevant interest profiles and stored.
Before pushing a tweet to the user, however, RTTBurst performed
one last pass through the tweets to select those that were most relevant to the given interest profile. For each candidate tweet stored
up to this point, RTTBurst then selected only those tweets that contained at least X tokens from the relevant interest profile. All other
tweets were then discarded.
In summary, for Scenario A of the TREC Microblog track, the
top 10 most dissimilar tweets containing bursty tokens and at least
two tokens from the relevant interest profile were returned to the
user per day. Scenario B followed the same pipeline with the additional relaxation of returning the top 100 most dissimilar tweets.

METHODS

RTTBurst’s high-level pipeline is composed of several stages,
from collecting the Twitter stream, to finding bursty tokens, to using these tokens to extract the most interesting tweets. Each of
these stages is described below.
Processing the Twitter Stream. For input, RTTBurst used Twitter’s unfiltered public sample stream, corresponding to approximately 1% of the full stream (though larger samples should also
work), and the user’s interest profiles. After extracting search keywords k ∈ Pi from the set of interest profile titles P , RTTBurst
leveraged Apache Spark’s1 Twitter receiver to collect all tweets
from the public sample stream and tokenized them using CMU’s
ARK TweetNLP tokenizer.2 We then applied a series of filters to
remove non-English tweets and low-quality tweets based on the
number of hashtags, web links, token counts, and whether the tweet
contained the string “follow” (motivated by the large amount of
“follow-me” spam on Twitter).
After this first round of quality-based pruning, RTTBurst then
calculated the intersection between each tweet’s token set and the
set of all search keywords ∪i Pi and kept only those tweets with
a non-empty intersection (i.e., only those tweets that contained at
least one keyword from at least one interest profile). These tokenized tweets were then converted into a time-stamped inverted
index matching tokens to the users who tweeted them.

3.1

Identifying Bursty Tokens. This time-stamped inverted index allowed us to capture changes in a token’s usage over time. We maintained a sliding window over all tweets generated by the Twitter
streaming API within the past two minutes and incremented the
window by 60-second time slices. Each window therefore overlapped with the previous 60 seconds to smooth the input.
For each two-minute window, we calculated the number of users
tweeting with each token and stored this frequency over the previous N windows. We normalized these frequencies by the number
of unique tokens in the past N windows and used add-one additive
smoothing to correct for tokens with zero occurrences in a single
window. Following the features set forth in the paper by Buntain
et al. [3], we then used linear regression to fit a line to the natural
logarithm of this frequency data. By transforming this frequency
data to logarithmic space, exponential curves will appear linear,
simplifying the linear regression step, and the steeper the slope of
the best-fit line, the steeper the exponential growth of the token’s
usage. Based on this fit, we then scored each token by the product
of the slope of the best-fit line and its coefficient of determination
R2 . Since R2 coefficient is in the range [0, 1], this product reduced
scores for highly deviant frequency curves. In this manner, tokens
experiencing large bursts in usage, which we would expect to exhibit exponential growth, were scored highly. We then discarded all
1
2

Ensembles with RTTBurst

While analyzing results after the official TREC 2015 evaluation,
we noticed a significant dissimilarity between the tweets returned
by RTTBurst and those returned by the other systems. This observation led to an interesting question: If we apply the burst detection
approach of RTTBurst to the output of another more traditional
information retrieval system, could we increase the system’s performance? To explore this question, we designed a simple gating
mechanism that, given a set of tweets returned by system A, used
RTTBurst to keep only those tweets that contained a bursty token.
Following from this question of using RTTBurst to filter other
systems, we also investigated whether RTTBurst could be used to
create ensembles of these information tracking and summarization
systems. That is, given the output of two TREC systems A and B,
would applying RTTBurst to their combined output yield higher
scores? For this investigation, we constructed a simple system that
takes the union of any two systems’ returned tweets and then applies RTTBurst’s gating mechanism to filter the results. To ensure
that RTTBurst did not benefit simply from combining multiple systems, we also conducted an experiment that scored the outputs of
each pair of systems, without any gating by RTTBurst. Duplicate
tweets were removed from this paired output, the output was ordered by delivery time, and only the first tweets within the scenario
A daily limits were scored.

4.

RESULTS

We divide our results into two sets: The first covers RTTBurst’s
relative performance results from the real-time Microblog track
tasks as scored by NIST (including some post hoc testing), and
the second covers results from our ensemble experiments.

https://spark.apache.org
http://www.cs.cmu.edu/~ark/TweetNLP/

778

Table 1: Optimized Parameters, Tweets Delivered to Users, and Scores (Best in Bold)
Window
Size (N )
† 30
37
18
37

Parameters
Top M Burst
Tweets
Threshold γ
10
0.07
13
0.036854
34
0.138824
48
0.067306

Delivered
Tweets
1
29
15
6

Scenario A
Unjudged
Tweets
0
15
7
1

ELG

nCG

0.2471
0.2549
0.2525
0.2506

0.2471
0.2464
0.2494
0.2479

Delivered
Tweets
1
29
15
6

Scenario B
Unjudged
Tweets
0
15
7
1

nDCG
0.2471
0.2420
0.2479
0.2489

† – Parameters used for TREC 2015 evaluation

4.1

RTTBurst Performance

increase in ELG over the individual, ungated systems, and five systems performed worse than their unpaired, ungated counterparts.
Differences in single system ELG and paired, gated system scores
are shown in Figure 1b.
For completeness, we also compared the best pairs’ ELG to a
silent system (Figure 2a) and the best gated pairs of systems (Figure 2b). Note that these figures show absolute scores as opposed
to score differences. We see that the best pairs of systems did not
perform as well as a silent system, but applying RTTBurst as an
additional gating filter raised all pairs up to or above the score for a
silent system.

RTTBurst’s TREC evaluation version originally lacked several
tweet quality metrics (i.e., it did not filter out tweets with many
hashtags, many links, or few tokens) and did not include mechanisms for preventing duplicate tweet content from being reported
to the user. This official run crystallized the need for these quality
metrics as our system caught a significant amount of spam in this
early run. For example, while the original RTTBurst implementation did prevent the same tweet ID from being reported twice,
two different tweets with the same content could still be reported,
and many Twitter bots spammed the same tweet content with only
slight differences (one token at the end of the tweet might differ
from one spam tweet to the next).
Following the TREC evaluation period and the release of the
NIST-judged tweets, we implemented these quality metrics and
performed a series of post hoc parameter optimization experiments.
Parameter optimization used a randomized parameter search over
window size N ∈ [7, 43], maximum tweets delivered per minute
N ∈ [10, 50], and burst thresholds γ ∈ [0.015, 0.18]. For each parameter set, we recorded the number of tweets RTTBurst flagged
for delivery to the user (across all topics), the number of these
tweets that did not have associated relevance judgments from NIST
(unjudged tweets), and their scores. Table 1 shows the top-scoring
sets for both scenarios from the official run (indicated by the †) and
our parameter optimization (see the track overview paper [6] for details on the scoring methodology). Official scores placed RTTBurst
11th out of 32 automatic runs in Scenario A (ranked by ELG) and
4th out of 38 in Scenario B. After parameter optimization, RTTBurst would move up one rank in Scenario A and would remain
in fourth in Scenario B. Note that randomized parameter optimization produced more scored tweets than the official run, which was
essentially silent. It is worthwhile to note that RTTBurst is exceedingly conservative in the emission of tweets, and that this approach
occupies a completely different point in the tradeoff space compared to standard retrieval-based systems.

4.2

5.

DISCUSSION

Results from our experiments and the official Microblog track
exhibited a correlation between higher scores and fewer reported
tweets. This link was first apparent given the score for a system that
returns no tweets at all: an ELG, nCG, and nDCG@10 of 0.2471,
which placed in the upper third of rankings in both TREC scenarios. During our parameter optimization experiments, we saw more
evidence of this trend in a strongly negative, nearly linear correlation (R2 = 0.8172) between the more tweets RTTBurst returned
and the score produced by the TREC evaluations. This preference
towards silence might explain why gating with RTTBurst increased
the average score in Scenario A: Summed across all topics, gating
reduced the average number of tweets delivered by two orders of
magnitude (from 1,600 tweets to a mere 57).
Such a significant reduction in the number of delivered tweets
suggested another issue regarding similarity of results returned by
the original systems and their gated counterparts. From Figure 2,
all systems’ scores tended to converge to the same value; this convergence would be easily explained if all systems were converging
to the same set of tweets. To examine this potential issue, we calculated the Jaccard similarity among the returned tweets for each
system and then among the gated systems: For the original systems, the average similarity across all systems was 0.045, and for
our gated systems, average similarity was 0.55. Therefore, gains
made from gating with RTTBurst are not the result of reducing all
output to a common set of tweets. This result suggests bursts provide a valuable relevance signal.
While this convergence is a positive effect for many systems, we
must address why RTTBurst decreases the top performing run [10]
by 19%. One possibility is the absence of query expansion techniques. RTTBurst was originally designed as an open-domain system without tracking capabilities, and the modifications to track
interest profiles did not include data-driven synonyms or identify
related keywords that could expand the filtered data. RTTBurst
therefore potentially discarded many relevant tweets, something
that future versions of the system should address. Another possibility, however, is an imbalance in the “bursty-ness” of some topics;
thresholds for bursts about celebrities may be too high for more
esoteric topics.

Gating with RTTBurst

Applying RTTBurst’s gating mechanism to a single Scenario A
system resulted in an average increase in ELG and nCG by 17%
and 13% respectively but decreased the ELG of the best-performing
system [10] by about 19%. A two-sided t-test on the original scores
and the gated scores determined this increase in ELG was statistically significant (t(33) = 3.28, p < 0.01). In total, RTTBurst
increased the performance of 22 systems and decreased the performance of 13 systems, as shown in Figure 1a. For Scenario B, gating
with RTTBurst resulted in a 9% decrease in nDCG@10.
For system pairs, comparing an individual system with its highest-scoring pair (that is, pairing it to all other systems and taking
the one that achieves the highest ELG) yielded an 11% average
ELG increase. Only three systems achieved higher scores without pairing. Using RTTBurst to gate these pairs yielded a 24%

779

0.20

0.20

0.15

0.15

0.10
¢ ELG

¢ ELG

0.10
0.05

0.05

0.00
0.00

−0.05

−0.10
0

5

10

15
20
System Index

25

30

−0.05
0

35

(a) Single System vs. Gated System

5

10

15
20
System Index

25

30

35

(b) Single System vs. Paired, Gated System

Figure 1: Performance Differences in ELG. Systems arranged alphabetically.
0.34
0.32

0.30

0.28

0.28

0.26

0.26

0.24

0.24

0.22

0.22

0.20
0

5

10

15
20
System Index

25

30

Silent
Mean

0.32

0.30
ELG

ELG

0.34

Silent
Mean

0.20
0

35

(a) ELG of Best System Pairs vs. Silent System

5

10

15
20
System Index

25

30

35

(b) ELG of Best Gated System Pairs vs. Silent System

Figure 2: Average ELG vs. Silent System. Systems arranged alphabetically.

7.

This work is also limited by unjudged tweets in the returned
tweet sets, which makes a true performance comparison between
official and post hoc runs difficult. That is, while the NIST assessors provided relevance judgments for approximately 94k tweets,
the Twitter sample stream over the TREC evaluation period contains around 40 million tweets, so it is highly likely post hoc runs
of RTTBurst may return tweets without these judgments. This limitation may be the driving force behind the connection between returned tweet set size and low scores. Going forward, we need to
explore better methods for scoring these unjudged tweets or comparing judged and unjudged tweets and scores via similarity propagation, self-learning, or a similar method.

6.

REFERENCES

[1] J. Allan, R. Papka, and V. Lavrenko. On-line new event
detection and tracking. SIGIR, 1998.
[2] F. Atefeh and W. Khreich. A survey of techniques for event
detection in Twitter. Computational Intelligence,
31(1):132–164, 2015.
[3] C. Buntain, J. Lin, and J. Golbeck. Discovering Key
Moments in Social Media Streams. CCNC, 2016.
[4] L. Cipriani. Goal! Detecting the most important World Cup
moments. Technical report, Twitter, 2014.
[5] J. Kleinberg. Bursty and hierarchical structure in streams.
KDD, 2002.
[6] J. Lin, M. Efron, Y. Wang, G. Sherman, and E. Voorhees.
Overview of the TREC-2015 Microblog Track. TREC, 2015.
[7] M. Osborne, S. Moran, R. McCreadie, A. Von Lunen,
M. Sykora, E. Cano, N. Ireson, C. Macdonald, I. Ounis,
Y. He, and Others. Real-Time Detection, Tracking, and
Monitoring of Automatically Discovered Events in Social
Media. ACL, 2014.
[8] J. Rogstadius, M. Vukovic, C. A. Teixeira, V. Kostakos,
E. Karapanos, and J. A. Laredo. Crisistracker: Crowdsourced
social media curation for disaster awareness. IBM Journal of
Research and Development, 57(5), 2013.
[9] T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake shakes
Twitter users: real-time event detection by social sensors.
WWW, 2010.
[10] L. Tan, A. Roegiest, and C. L. A. Clarke. University of
Waterloo at TREC 2015 Microblog track. TREC, 2015.

CONCLUSIONS

RTTBurst is a hybrid end-to-end system that uses a simple burstdetection technique to identify tweets a user may find interesting.
This paper laid out RTTBurst’s architecture, our participation in
and performance at the TREC 2015 Microblog track, and a method
for combining and potentially improving the performance of existing TREC systems. While not as effective as the best systems,
RTTBurst did perform well and shows potential in hybrid or combined approaches. Further steps could be taken to integrate modern information retrieval techniques like query expansion and spam
detection to increase RTTBurst’s performance. Given RTTBurst’s
simple model and its stream-oriented processing, it is at least a useful tool that can be easily integrated into other approaches.
Acknowledgments. This work was supported in part by the National Science Foundation under awards IIS-1218043 and CNS1405688. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the sponsors.

780


Identifying Careless Workers in Crowdsourcing Platforms:
A Game Theory Approach
Yashar Moshfeghi

Alvaro F. Huertas-Rosero

Joemon M. Jose

School of Computing Science
University of Glasgow
Glasgow, UK

School of Computing Science
University of Glasgow
Glasgow, UK

School of Computing Science
University of Glasgow
Glasgow, UK

Yashar.Moshfeghi@
glasgow.ac.uk

Alvaro.Huertas@
glasgow.ac.uk

Joemon.Jose@
glasgow.ac.uk

use of “gold standard” data, multiple answers [5], qualification tests, honey pots (i.e. questions whose answers are
known in advance) or a combination of the above. Such quality assurance techniques can potentially increase the general
experiment cost, task completion time, and experimenters’
intervention [2].
We propose a systematic approach to the problem based
on spotting workers who undertake the task as gambling. A
worker taking insufficient time to complete a task is knowingly taking the risk of getting a wrong result [9], so we will
assume that careless workers (gamblers) are risk-inclined [10].
Therefore we formulate our research question as: “Is workers’ inclination towards risk, reflected in low Task
Completion Times (TCT) in a competition scenario,
a good predictor of poor performance?”
We propose a competitive game where we motivate workers to finish their RA task correctly (pushing towards longer
time) and fast (pushing towards shorter time). As a result
of these two opposing forces, TCTs will become sensitive to
the worker’s attitudes towards risk and their perceptions of
the task and payoff, i.e. workers adjust the time they take to
perform a task to be longer or shorter according to whether
they perceive the risk of not taking enough time as more or
less important than being fast.
The rest of the paper is organised as follows: our game
theoretical model is described in section 2, the theorem linking risk inclination with TCT is stated and proved in Section 3. Section 4 describes the empirical experiment where
we link TCT and performance, results and discussion are in
Section 5. Finally we conclude in Section 6.

ABSTRACT
In this paper we introduce a game scenario for crowdsourcing (CS) using incentives as a bait for careless (gambler)
workers, who respond to them in a characteristic way. We
hypothesise that careless workers are risk-inclined and can
be detected in the game scenario by their use of time, and
test this hypothesis in two steps: first, we formulate and
prove a theorem stating that a risk-inclined worker will react
to competition with shorter Task Completion Time (TCT)
than a risk-neutral or risk-averse worker. Second, we check
if the game scenario introduces a link between TCT and performance, by performing a crowdsourced evaluation using 35
topics from the TREC-8 collection. Experimental evidence
confirms our hypothesis, showing that TCT can be used as
a powerful discrimination factor to detect careless workers.
This is a valuable result in the quest for quality assurance
in CS-based micro tasks such as relevance assessment.
Keywords: Game Theory, Crowdsourcing, Relevance Assessment, Chicken Game

1.

INTRODUCTION

Crowdsourcing (CS) platforms offer new ways of collecting relevance assessments for IR evaluation and are already
used widely [4]. The advantages associated with this platform, i.e. low monetary cost and high task completion speed
are, however, entangled with a mixed output quality, making
the effective use of CS a non-trivial problem. Past studies
have shown the importance of careful quality assurance [8],
particularly when the task is ‘micro’, such as relevance assessment (RA), and involves financial incentives [6].
Research in quality assurance for CS has been largely
heuristic and non-generalisable. Zhao reports in 2012 that
only 9 out of 55 studies of crowdsourcing include any kind
of theoretical bases [14]. Quality is usually assured with the

2. THEORETICAL MODEL
We start from a theoretical model based on Game Theory, which builds on a few assumptions and leads us to our
first result, linking TCT with inclination to risk. This result
motivates a CS experiment where we check the correlation
between TCT and performance, completing our argument
for detecting careless workers by their TCT under competition conditions.
Best scenarios, worst scenarios and risk: Attitudes
towards risk can be viewed as ways of perceiving utility [10],
relative to the probabilistic average. A risk-inclined player
perceives uncertain utility as higher than the average, a riskneutral player perceives it exactly like the average, and a
risk-averse player perceives it as lower than the average.
Fig. 1 illustrates these pessimistic and optimistic views.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

SIGIR ’16, July 17-21, 2016, Pisa, Italy
c 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00
DOI: http://dx.doi.org/10.1145/2911451.2914756

857

PERCEIVED PROBABILITY
OF BEST OUTCOME

produced a correct result quicker, he or she also gets an extra
bonus. This is a similar but inverse version of the Chicken
game: in our setting a player needs to choose a time longer
than the minimum, but shorter than the other players, while
in the Chicken game a player needs to choose a time shorter
than a limit (i.e. when they reach the cliff), but longer than
the other players.

1
Perceived

Riskinclined
Riskaverse

0
0

Objective

1

TASK
PROBABILISTIC MODEL

Figure 1:

Perceived probability of getting the highest utility for
different attitudes towards risk. Risk-inclined players will perceive
a higher probability in uncertain situations (convex, upper curve),
risk-neutral players will perceive a probabilistic mean utility (linear,
middle curve) and risk-averse players will perceive a lower probability
in uncertain situations (concave, lower curve).

ENOUGH TIME?

yes
OTHER FACTORS

no

( 1 - PF )

PR

PF

Risk inclined workers are more sensitive to incentives to
compete, because they perceive an uncertain outcome as
more profitable. Risk averse workers, on the other hand, are
more interested in certain aspects of the game, e.g. noncompetitive incentives that do not depend on other workers.
The Mathematical Concept of Game: A game, in
the context of mathematical game theory, consists of three
components: (i) several agents (players), (ii) a set of decisions (actions) they take based on a set of strategies, and
(iii) an outcome (payoff) which is aimed to be maximised
by considering their own and other players’ strategies.
It is important to note that a mathematically defined
game differs from gamification scenarios, even though it
shares common elements. Gamification involve managing
affective incentives, as is the case of image labeling games
(called ESP) or Games With a Purpose [12]. These are not
necessarily game-theoretical approaches, but they do involve
quantifying and managing entertainment rewards in order
to improve the work obtained from volunteers. Gamification has been used for RA tasks in [3], where individuals
were persuaded to assess relevance as entertainment. Our
approach relies entirely on monetary rewards, and models
the motivation of workers as a simple rational principle of
maximising monetary gain.
Chicken Game for RA: The Chicken game, also known
as Hawk-Dove game [11] is a particular game setting based
on time choices, whose characteristics are determined mostly
by competition. In the n-player version, a group of teenagers
compete with each other for the prestige of being the bravest.
They engage in a racing game towards a cliff in their cars as
fast as they can, and the player who jumps out of the car the
last without falling off the cliff is the winner. Each player
chooses the time for an action, and the outcome depends
on the times other players chose. A rational player will aim
to an optimal trade-off between the two opposing forces of
the game, i.e. one preventing them from jumping too quick
(competition) and the other pushing them to jump before it
is too late (survival). When each player is uncertain about
the choices of the other players (i.e. imperfect information),
the chicken game can present a Bayesian Nash Equilibrium
(BE), which is an important solution concept in game theory. In a BE the strategy of a player is optimal according
to their available private knowledge about what the other
players would do. Their expected payoff cannot increase by
changing their strategy.
We propose a game in which an assessor is paid only if
he or she produces a correct RA result. If no other assessor

TOTALLY RANDOM

( 1 - PR )

RIGHT

WRONG

Figure 2:

Graph representation of a probabilistic model of an assessment. The rhomboid represents the condition of taking enough
time, and ellipses represent random processes: left for hidden but deterministic factors, and right for randomness. The arrows with their
probabilities, represent the possible outcomes of each subprocess.

In our model, time is related to payoff through the probability of a correct assessment. If a worker takes an insufficient time, their result will be completely random. In
Fig. 2 we represent our model as a probability graph: the
condition of taking enough time determines whether the result is random (with probability PR of being correct). If
the worker takes enough time to complete an assessment,
then other processes involving knowledge, difficulty, etc. determine whether the worker gets the correct result (with
probability PF ).
The minimum time is uncertain, with a probability distribution D(tmin ). The probability of getting the answer
right when taking time t will be a monotonically increasing
function:
Z t
Pcorrect (t) = PR + (PF − PR )
D(tmin )dtmin
(1)
0

Similarly, given a distribution of times when the quickest
worker will finish the task Q(t):
Z t
Pquickest (t) = 1 −
Q(t′ )dt′
(2)
0

Expected utility is then:
U (t) = KR Pcorrect (t)Pquickest (t) − KP (1 − Pcorrect (t)) (3)
where KR is the value of the quickness reward and KP the
incorrectness punishment. Note that the term with KP is
monotonically increasing, while that with KR has a maximum. This means that the position of the maximum will
only change notably with these paremeters when KP > KR
(small incentive for competing).

3. TCT AND INCLINATION TOWARDS RISK
The following theorem links risk inclination to short TCTs
in the game scenario, assuming rationality and condition of
BE:
Theorem 1. In the BE of our game, optimal times for
risk-inclined players will be shorter than those for risk-neutral
or risk-averse players.

858

4. EXPERIMENTAL METHODOLOGY
Proof. A situation of BE is defined by maximal values
of U (t), i.e. dU (t)/dt = 0. From Eq. 3:
KR (Pquick (dPcorrect /dt) + Pcorrect (dPquick /dt))
+ KP (dPcorrect /dt) = 0

In Section 3 we proved that a risk-averse worker would
tend to take shorter TCT than others in the game scenario,
because of their perception of the competition incentive. In
this section, we devise an between-group study to investigate
the relation between TCT and precision in the competitive
scenario where the independent variable to be competition
setting (with two levels: “Base” and “Game”), differing in
the description and pay conditions given to the participants.
The dependent variables are the accuracy of gathered labels
and corresponding TCTs. We make use of Amazon’s Mechanical Turk (M-Turk), as our crowdsourcing platform. It
provides a convenient participant pool to draw upon to carry
out many tasks, especially relevance assessment labelling.
Data Collection: We used TREC-8, in particular the
LA Times, FT, FR94 and FBIS sub-collections as our test
collection. We randomly selected 35 out of 50 topics in the
TREC-8 test set and used the judged articles as a gold standard set, following previous research in the domain, e.g. [1].
Task: We define two tasks, i.e. Base and Game. In both
tasks the participants were asked to evaluate the relevance
of a set of document-topic pairs. We used plain text to indicate the task rather than the original TREC instructions,
according to the suggestions given in [7] for M-Turk crowds.
We adopt the concept of relevance used in [13] which has
been used in previous work in this domain [1]. We followed
the guidelines provided in [1] to instruct our workers, e.g.
asking for their consistency with their judgement, etc.
Base Task: We asked participants to perform the relevance judgment task for ten document-topic pairs. In order
to ensure quality we highlighted that random assessment
will not work, because we know the answer of a few of the
pairs. If they fail to assess them correctly, their HIT will
not be approved. We also highlighted that presence of topic
terms in the document does not necessary mean that the
document is relevant to the given topic. They need to make
a decision by considering more than solely this criteria.
Game Task: For the game task, in addition to above, we
instructed the worker that they would be competing with a
few other M-Turk workers in completing the task. In order
to create the conditions of the game, we highlighted that
they need to complete the assessment correctly and quicker
than the other workers. We also mentioned that the winner
will be with rewarded with a $2.0 additional bonus.
Relevance Assessment System: For the completion
of the tasks we used a custom-made relevance assessment environment designed to gather the workers’ judgement, while
retaining a minimum of graphical elements and distractions.
The back-end layer of the system created a set of random
ten topic-document pairs from the QRel file and fetched the
associated document and topic information from collections
and topic files, respectively. It also ensured that workers
judge a topic-document pair only once, while each topicdocument pair is judged by no fewer than three workers and
no more than five. The documents were presented without
their title in order to avoid it being used as the only criterion. The user Interface (UI) contained a topic, document
and closed question (binary relevance; yes/no). Workers
were required to log in to the system in order to capture
their Worker ID. After workers log in, the UI layer gets a
set of ten topic-document pairs from the back-end layer and
presents them, one at a time, in the same exact order as

(4)

From explicit expressions for Pcorrect (t) and Pquick we obtain the condition for an optimal time top :
KR (Pquick D(top ) − Pcorrect Q(top )) + KP D(top ) = 0 (5)

negative derivative

Figure 3:

Utility as a function of TCT with objective probabilities
(a) and perceived by a risk-inclined player (b). Optimal time top and
gambler’s perceived optimal time tg−op are marked with dotted lines.

A gambler over-estimates propitious probabilities, which
we represent with a convex function P ′ = F∩ (P ) and underestimate adverse probabilities, which we represent as a concave function P ′ = F∪ (P ). which we represented as a
concave function P ′ = F∪ (P ). These are the monotonic
transforms depicted in Fig. 1. Optimal time for gamblers
tg−op is calculated wit These monotonic transforms are depicted in Fig. 1. Using the chain formula dF (P )/dt =
(dF/dP )(dP/dt) we obtain a gambler’s optimal time:
KR (dF∩ /dPcorrect )Pquick D(tg−op )
−KR (dF∪ /dPquick )Pcorrect Q(tg−op )
+KP (dF∩ /dPcorrect D(tg−op ))
=0

(6)

Since Eq 6 correspond to the maximal gambler utility
U (tg−op ), the derivative will be positive for shorter times
t < tg−op and negative for longer times t > tg−op .
We know that both F∩ and F∪ are monotonously increasing, so their derivatives are always positive. We also know
that in the region of high probabilities of being correct and
quickest (where we expect optimal times) a convex function will have a lower derivative than a concave function, so
dF∩ /dP < dF∪ /dP .
This means that the negative term in Eq 6 has become
larger than that in Eq 5
KR (dF∪ /dPquick )Pcorrect Q(top ) < KR Pcorrect Q(top ) (7)
The positive term in Eq 6, on the contrary, has become
smaller than that in Eq 5
(dF∩ /dPcorrect )(KR Pquick D(top ) + KP D(top ))
< (KR Pquick D(top ) + KP D(top ))

(8)

This means that overall, the derivative will be negative, and
therefore top > tg−op . (this argument is depicted in Fig.
3)

859

however, the values of task completion time did not seem to
bear any relation to performance, as shown in Fig. 4 (a).
Therefore, we confirmed that lower performing players react
to our game competing scenario by lowering their TCT and
hence turning TCT into a powerful discriminative factor.
Normally in settings like the base task, extra information
about users (previous performance, background, etc.) or
hints about their current performances (previously known
judgments, test questions) are used to detect untrustworthy
workers. These strategies, however, require settings that are
potentially more expensive and/or discouraging for workers.

they were obtained. The interface also prevents them from
skipping difficult assessments.
Workers’ actions were monitored and logged by the search
interface, including the log-in and log-out time to the system, workers’ as well as their judgement of each documenttopic pair. The length of time workers spent to judge a pair
was calculated on client side to avoid interference from network delay: it is computed as the time difference between
the moment a topic-document pair was shown until the assessment was submitted.
Procedure: At the beginning of the experiment, participants were instructed that the experiment would take
approximately 10 minutes to complete, though they would
be given 30 minutes between the time they accepted and
submitted the HIT assignment. They were informed that
they could participate in each task more than once.Workers
could only accept the HIT if they agreed to a consent form.
Subsequently, participants were assigned to one of two external surveys (“base” or “game”). At the beginning of the
survey, we describe that all the collected data will be treated
as confidential and anonymous. Payment for HIT completion was $1.0. The total cost of the evaluation was $270,
including the cost of the pilot studies and some of the rejected participants, which we consider to be cost-effective.

5.

6. CONCLUSION
In this paper we hypothesised that it is possible to design a
mechanism based on a game theory model that makes taskcompletion time an effective discriminative factor between
careless (i.e. risk-inclined) and other (i.e. risk-neutral or
risk-averse) workers. We therefore designed a CS relevance
assessment task scenario inspired by an n-player Chicken
game model, where there are two opposing forces: one pushing towards quickness and another pushing towards correctness. We tested our hypotheses with a crowdsourced evaluation using 35 topics from TREC-8 collection. Our findings
show that the proposed framework allows to use task completion time as a powerful discriminative factor to identify
different types of workers. An obvious direction to continue
the research on this promising approach is to explore postfiltering methodologies based in risk attitudes inferred from
TCT and other indirect data.

RESULTS AND DISCUSSION

This section presents the experimental findings of our study.
To fulfil the conditions of a between-group study, we eliminated participants whom we found had taken part in the
experiment under different conditions (e.g. taken part in
the Game task after taking part in the Base task, or vice
versa). Out of 235 workers who started the tasks, 200 workers completed them successfully (100 workers per group).

7. REFERENCES
[1] O. Alonso. Implementing crowdsourcing-based relevance
experimentation: an industrial perspective. Inf. Retr., pages
1–20, 2013.
[2] B. Carterette and I. Soboroff. The Effect of Assessor Error on
IR System Evaluation. In SIGIR ’10, pages 539–546, 2010.
[3] C. Eickhoff, C. G. Harris, A. P. de Vries, and P. Srinivasan.
Quality through flow and immersion: gamifying crowdsourced
relevance assessments. In SIGIR ’12, pages 871–880, 2012.
[4] C. Grady and M. Lease. Crowdsourcing document relevance
assessment with Mechanical Turk. In CSLDAMT ’10, pages
172–179, 2010.
[5] P. G. Ipeirotis, F. Provost, and J. Wang.
[6] G. Kazai, J. Kamps, and N. Milic-Frayling. The face of quality
in crowdsourcing relevance labels: Demographics, personality
and labeling accuracy. In CIKM ’12, pages 2583–2586, 2012.
[7] G. Kazai, J. Kamps, and N. Milic-Frayling. An Analysis of
Human Factors and Label Accuracy in Crowdsourcing
Relevance Judgments. Inf. Retr., 16(2):138–178, Apr. 2013.
[8] J. Le, A. Edmonds, V. Hester, and L. Biewald. Ensuring
quality in crowdsourced search relevance evaluation: The effects
of training question distribution. In SIGIR 2010 workshop on
crowdsourcing for search evaluation, pages 21–26, 2010.
[9] Y. Moshfeghi, A. F. H. Rosero, and J. M. Jose. A Game-Theory
Approach for Effective Crowdsource-Based Relevance
Assessment. ACM Trans. Intell. Syst. Technol.,
7(4):55:1–55:25, Mar. 2016.
[10] T. Straub, H. Gimpel, and F. Teschner. The negative effect of
feedback on performance in crowd labor tournaments.
Collective Intelligence 2014, 2014.
[11] M. Szilagyi. Agent-Based Simulation of the N-Person Chicken
Game. In Advances in Dynamic Game Theory, volume 9,
pages 696–703. Birkhäuser Boston, 2007.
[12] L. Von Ahn and L. Dabbish. Designing games with a purpose.
Communications of the ACM, 51(8):58–67, 2008.
[13] E. Voorhees, D. Harman, N. I. of Standards, and T. (US).
TREC: Experiment and evaluation in information retrieval,
volume 63. MIT press Cambridge, 2005.
[14] Y. Zhao and Q. Zhu. Evaluation on crowdsourcing research:
Current status and future direction. Information Systems
Frontiers, pages 1–18, 2012.

Figure 4:

Distributions of TCT (in minutes) for four ranges of precision, in a non-competitive base scenario (a) and game scenario (b).
Bars represent the quartiles of the distribution, and the red line connects the mean values.

Figure 4 shows the box plot corresponding to the TCTs
of each of four categories according to their fraction of correct results (precision): 0.2 to 0.4, 0.4 to 0.6, 0.6 to 0.8 and
0.8 to 1.0, and show the distribution of TCT in each category by their minimum, first, second (median) third and
maximum quartiles. across data collections and tasks. We
found that distributions of task completion time changed
notably between the Base and Game tasks. As shown in
Fig. 4 (b), we can see that there is a clear tendency of
the lowest performance categories to low values of TCT in
the game (competitive) scenario. In the base task scenario,

860


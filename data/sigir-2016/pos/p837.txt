Exploiting Semantic Coherence Features for
Information Retrieval
Xinhui Tu1

Jimmy Xiangji Huang1,2 Jing Luo3 Tingting He1

1

School of Computer Science, Central China Normal University, Wuhan, China
2
School of Information Technology, York University, Toronto, Canada
3
School of Computer Science, Wuhan University of Science and Technology, Wuhan, China

tuxinhui@mail.ccnu.edu.cn jhuang@yorku.ca luojing@wust.edu.cn tthe@mail.ccnu.edu.cn
two documents are equal in length. When we use “iPhone” as
query, all the retrieval models mentioned above will give
approximately the same score for the two documents. However,
the word “iPhone” is a topical term in document
and a nontopical term in document . Apparently, the document is more
relevant to the query than document . As we can see from the
example, the degree of importance of a term for a document is
dependent not only on the three aspects mentioned before, but
also dependent on the degree of semantic coherence between the
term and the document.

ABSTRACT
Most of the existing information retrieval models assume that the
terms of a text document are independent of each other. These
retrieval models integrate three major variables to determine the
degree of importance of a term for a document: within document
term frequency, document length and the specificity of the term in
the collection. Intuitively, the importance of a term for a
document is not only dependent on the three aspects mentioned
above, but also dependent on the degree of semantic coherence
between the term and the document. In this paper, we propose a
heuristic approach, in which the degree of semantic coherence of
the query terms with a document is adopted to improve the
information retrieval performance. Experimental results on
standard TREC collections show the proposed models
consistently outperform the state-of-the-art models.

Humans can easily identify the topical terms and the non-topical
terms of a document, because they have the knowledge of the
“word association”. In , the term “iPhone” appears with many
other terms such as “Apple”, “iTunes”, which are associated with
the term “iPhone”. In , however, the term “iPhone” seems to be
irrelevant to the other terms such as “woods”and “bear”’. For
computational purposes, this knowledge can be discovered by
analyzing the corpus. Semantic association measures based on
corpus analysis have served this purpose for many applications
related to natural language processing and IR [6].

Keywords
Document ranking; Retrieval model; Term weighting

1. INTRODUCTION AND MOTIVATION
Most of the existing information retrieval (IR) models assume that
the terms of a text document are independent of each other.
Generally, these retrieval models integrate three major variables
to determine the degree of importance of a term for a document:
within document term frequency, document length and the
specificity of the term in the collection [4]. Though these
approaches are reasonably simple and easy-to-use, the coherence
aspect of a term’s saliency in a document cannot be taken into
account by the term independence assumption.

: So let's say you're out for a walk in the woods, with your
iPhone handy, and you run into a grizzly bear ……

In this paper, we study how to efficiently use semantic coherence
features to improve the information retrieval performance. We
propose an approach to use the degree of semantic coherence
between term and document for document ranking. First, each
document is represented as a graph-of-word that corresponds to a
weighted directed graph whose vertices represent unique terms,
whose edges represent the translation probability between two
terms. Then, a graph-based algorithm is adopted to calculate
coherence-based weighting score of a term within a document.
The coherence-based weight score of a term for a document is
determined by the degree of semantic relatedness between the
term and the other terms within the document. Finally, the
coherence-based document score and the frequency-based score
obtained by the existing retrieval function are integrated into a
linear feature-based model for document ranking. Experimental
results on standard TREC collections show the proposed model
consistently outperform the state-of-the-art models.

: Currently, Apple company has had to allocate massive
resources to its iTunes and iPhone ......

2. RELATED WORK

The terms in a document can generally be classified into two
groups: topical term and non-topical term. The topical terms will
be highly associated with each other, while the non-topical terms
will have very low association with the other terms within the
document. Let us consider two arbitrary documents
and
as
follows:

Over the decades, many different retrieval models have been
proposed and studied, including the vector space model [16, 17],
the classic probabilistic model [7, 13, 14] and the language
modeling approach [12, 19]. Most of the existing retrieval models
assume a “bag-of-words” representation of both documents and
queries. A typical effective retrieval function involves a TF part,
an IDF part, and a document length normalization part [4]. The
TF part intents to give a higher score to a document that has more
occurrences of a query term, while the IDF part is to penalize
words that are popular in the whole collection. The document
length normalization is to avoid favoring long documents.

The first document is concerned about “grizzly bear” and the
second document is related to “Apple Company”. Suppose that the
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned
by others than ACM must be honored. Abstracting with credit is permitted. To
copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from
Permissions@acm.org.
SIGIR '16, July 17–21, 2016, Pisa, Italy.
© 2016 ACM. ISBN 978-1-4503-4069-4/16/07…$15.00.
DOI: http://dx.doi.org/10.1145/2911451.2914691

837

document d is initially set to 1 and the following PageRank
function is run for several iterations

Most of the traditional retrieval models employ a single term
frequency normalization mechanism that does not take into
account various aspects of a term saliency in a document [11, 18].
Paik [11] proposes a novel TF-IDF term weighting schema
(MATF) that employs two different within document term
frequency normalizations to capture two different aspects of term
saliency. The experimental results show that MATF achieves
significantly better precision than the start-of-the-art models, such
as BM25 [14] and LMDir (the language modeling approach with
Dirichlet prior smoothing) [19].

1

∗

∗

,

1

∈ ,

where is a damping factor that can be set between 0 and 1,
which has the role of integrating into the model the probability of
jumping from a given vertex to another random vertex in the
graph. In the context of the Web, this graph based ranking
algorithm implements a random walk model, where a user clicks
on links at random with a probability d, and jumps to a completely
new page with probability 1
[10]. We set the damping
factor to 0.85, the convergence threshold to 0.0001, following [9,
10]. Our experiments showed that only a small number of
iterations (< 50) is required to obtain convergence.

Intuitively, the degree of semantic coherence between a term and
a document is an important factor to determine the importance of
the term in the document. However, little work has been done
around coherent-based term weighting. To the best of our
knowledge, the model proposed in [6] is the only work closely
related to ours. In the paper, the authors propose a neighborhood
based document smoothing model by exploiting lexical
association between terms. Different from their work, we adopt a
linear feature-based model for final document ranking instead of
modifying the traditional retrieval functions.

In formula (1),
,
is the translation probability from term
to term
in the graph of document . A simple way to
estimate
,
is as follows:
,
,
2
∑ ∈
,
where
,
is the strength of association between two term
and .

Inspired by the success of graph-based ranking algorithms like
TextRank [9], some researches attempt to adopt graph-based
document representation for improving information retrieval
performance [1, 15]. Generally, a graph based ranking algorithm
is a way of deciding on the importance of a vertex within a graph,
by taking into account global information recursively computed
from the entire graph rather than relying only on local vertexspecific information. Our work is different from the existing
graph-based retrieval methods in two aspects: (1) Each edge is
weighted by the mutual information between the two terms,
instead of by the number of co-occurrences of the two term in
sliding windows; (2) The final ranking score of a document is
determined by the combination of the graph-based term weighting
score and the frequency-based score instead of by the graph-based
term weighting score alone.

,
in formula (2), we adopted a pairwise
To calculate
term similarity score, which is a combination of mutual
information and a distance factor. The distance factor
exponentially decreased as the distance between terms increased.
The assumption behind this work is that semantically related
words are usually located in proximity, and the distance between
two words could indicate the strength of their association. The
pairwise term similarity score of terms and can be calculate
as follows:
,
,
∗
,
3
∗
,
,
4
where
,
is the average distance between terms and
in all the documents in the collection; is the decaying rate for
the exponential function. In our experiments, the decaying rate
is set to 0.8, following [5].

3. PROPOSED APPROACH
In this section, we introduce a graph-based model to calculate
weighting score for terms and then use these score for final
document ranking.

In formula (3),
,
denotes the mutual information between
term and , which can be calculated as follows:

3.1 Coherence-based Term Weighting
The coherence-based weight score of a term for a document is
determined by the degree of semantic relatedness between the
term and the other terms within the document. Let us consider the
example mentioned in section 1 again. Once the semantic
relatedness has been calculated, “iPhone” will have a higher
relatedness with the terms such as “Apple, iTunes, company” than
the terms such as “bear, woods, walk”. Therefore, “iPhone” will
get a higher coherence-based weight score in document d2 than in
document d1. When we use iPhone as query, document d2 will get
a higher coherence-based score.

,

,

,
,

5

,

where and are binary variables indicating whether term or
is present or absent. The probabilities are estimated as follows:
1

1
0

1

1

In this paper, we adopt a graph-based ranking algorithm to
calculate the coherence-based weight score of a term within a
document. Each textual document is represented as a graph-ofword that corresponds to a weighted directed graph whose
vertices represent unique terms, whose edges represent the
translation probability between two terms. We prefer to use term
rather than word because tokenization and feature selection
algorithms (such as stop word removal) have already been applied.
The coherence-based weight score of a term within a document is
determined by the votes that are casting for it and the weight of
the terms casting that votes. The weight of term t within

0
1,

1

1,

0

1,

0

0,

0

1

1
1

1,

1
0,

838

1

1

1

1,

1

1

1,

1

1,
1

1
1,

0

Table 1. Test collection statistics

where
1 and
1 are the numbers of documents
containing term
or , respectively,
1,
1 is the
number of documents that contain both or , and in the total
number of documents in the collection.

Collection

,

S t

∗

t

# of Topics

51‐100

50

TREC8

528,155

301‐450

50

WT2G

247,491

401‐450

50

WT10G

1,692,096

451‐550

100

Table 2. The retrieval models used in the experiments
Model
BM25
LMDir
MATF
ConRank-BM25
ConRank-LMDir
ConRank-MATF

Description
The classical probabilistic model [14]
The language modeling approach with
Dirichlet prior smoothing [19]
A novel TF-IDF model with excellent
retrieval performance [11].
The proposed model using BM25 function
to calculate
,
The proposed model using LMDir function
to calculate
, .
The proposed model using MATF function
to calculate
,

value of
for all of them. For example, the best values on
collection AP88-89 are 0.3, 0.4, and 0.3 for ConRank-BM25,
ConRank-LMDir, and ConRank-MATF, respectively. For all
models on all datasets, we can gain the best retrieval performance
when 0.2 ≤ ≤ 0.4. The proposed models constantly perform
better than the corresponding baseline while range from 0.1 to
0.6. When the value of is too large in the linear feature-based
model, the performance is downward and even worse than that of
the baseline.

7

∈

can be calculated by formula (1);
where
inverse document frequency of term 。

Topics

164,597

3.2 Retrieval Function
Coherence-based term weighting score itself may be not effective
to be used as the only scoring function for retrieval. It’s a
potential way to incorporate coherence-based term weighting
score into the traditional retrieval functions for document ranking.
However, it is not always possible to easily incorporate new
feature into the traditional retrieval functions, which are built
upon some underlying theoretical framework [8]. For example, it
proved non-trivial to include query independent features such as
PageRank into BM25 ranking formula [2]. Therefore we adopt a
linear feature-based model for final document ranking, instead of
modifying the traditional retrieval functions. The linear featurebased model has been proven to be an effective way to
incorporate different features into a united retrieval model [8].
The final retrieval function can be described as follows:
,
,
1 λ ∗
6
,
λ∗
1
,
1
,
where
,
is the document score calculate by the existing
retrieval functions, such as BM25, LMDir, and MATF;
,
is the coherence-based weight scores of all query’s term within a
document, which can be calculate as follows:

# of Docs

AP88‐89

is the

4. EXPERIMENTS
4.1 Test Collections and Baseline Models

4.3

Table 1 summarizes that statistics on test collections used in our
experiments. These collections are different in size and genre.
Each document is processed in a standard way for indexing.
Words are stemmed (using porter-stemmer), and stop words are
removed. In the experiments, we only use title of the queries. In
order to evaluate our model and compare it to other models, we
use the MAP and P@10 measure, which are widely accepted
measure for evaluating effectiveness of ranked retrieval systems.
The methods used in our experiments are as listed in Table 2.

Comparing with the State-of-the-art
Models

In order to make the comparison fair, we need to carefully choose
suitable values for the parameters in all the models. To build
strong baselines, we adopt a method proposed in [3] to find the
optimal parameter settings for BM25 and LMDir. All parameters
in BM25 and LMDir are respectively set to the optimal values in
our experiments. As a parameter free model, MATF does not need
parameter tuning. In the proposed models, parameter and k are
respectively set to 0.8 and 0.85 following [5, 10]. The previous
research work [20] has demonstrated that when a new feature is
integrated into a traditional retrieval function under linear
interpolation, the best retrieval performance can be obtained by
assigning a relatively small weight (0.1-0.2) to the new feature.
As we can see from the experiments presented in section 4.2,
good performance can be archived with parameter are set to 0.3.
Therefore, the parameter in the proposed models is set to 0.3 in
the following experiments.

4.2 Parameter Sensitivity Study
An important issue that may affect the robustness of the proposed
models is the sensitivity of their parameter (in Equation 6). The
parameter controls weight of coherence-based weighting score
in the final ranking function. In this section, we study how
sensitive the parameter is to MAP measure. At the current stage of
our work, the parameter is selected through grid search.

Table 3 present the retrieval results of the six retrieval models on
the four collections respectively. The results indicate that the
proposed models constantly outperform the corresponding
baseline on all collections. In most of the cases, the improvement
of MAP and P@10 was statistically significant. The maximum
average improvement is as high as 7.81% and 7.32% in terms of
MAP and P@10, respectively. It is worth noting that MATF has
obtained significant improvements over BM25 and LMDir, and is
therefore a strong baseline. The significant performance
improvements from such a strong baseline are very encouraging.
The results confirm that semantic coherent features can be used to
improve the retrieval performance.

In order to find the optimal value of parameter , we sweep the
values from 0 to 1 with an interval of 0.1. When λ equals to 0, we
reach the baseline. When λ equals to 1, the retrieval model use
coherence-based weighting score only. The value of λ controls the
influence of coherence-based weighting score. Figure 1 shows the
sensitivity of the value of parameter according to MAP measure.
The experimental results show that parameter can greatly
impact the performance of the proposed models. Generally, the
performance of all models increases at the beginning when the
value of
grows up. The performance of each model starts to
continually drop after a peak. However, this is no unique optimal

839

Figure 1. Sensitivity of parameter to MAP measure
Table 3. Comparison of the performance of the six models in terms of MAP and P@10
(The values in the parentheses are the improvement over the model in the previous row in the table; * indicates a statistically
improvements over the model in the previous row according to the Wilcoxon signed-rank test at the 0.05 level)
AP88‐89
TREC8
WT2G
WT10G
Model
P@10
MAP
P@10
MAP
P@10
MAP
P@10
MAP
BM25
0.4216
0.2702
0.4645
0.2552
0.4957
0.3128
0.3626
0.2107
0.4489*
0.2913*
0.4853*
0.2693*
0.5320*
0.3349*
0.3747*
0.2184*
ConRank‐BM25
(+6.48%) (+7.81%) (+4.48%) (+5.53%) (+7.32%) (+7.07%) (+3.34%) (+3.65%)
LMDir
0.4416
0.2768
0.4753
0.2509
0.5063
0.3057
0.3108
0.2094
0.4595*
0.2936*
0.4918*
0.2615*
0.5409*
0.3211*
0.3154
0.2128
ConRank‐LMDir
(+4.05%) (+6.07%) (+3.47%) (+4.22%) (+6.83%) (+5.04%) (+1.48%) (+1.62%)
MATF
0.4679
0.2994
0.4905
0.2671
0.5481
0.3241
0.3283
0.2226
0.4872*
0.3186*
0.5097*
0.2752*
0.5594*
0.3392*
0.3327
0.2301*
ConRank‐MATF
(+4.12%) (+6.41%) (+3.91%) (+3.03%) (+2.06%) (+4.66%) (+1.34%) (+3.37%)
[6] Goyal, P., Behera, L. and McGinnity, T. M. A novel neighborhood
based document smoothing model for information retrieval.
Information retrieval, 16(3), 391-425, 2013
[7] Jones, K. S., Walker, S. and Robertson, S. E. A probabilistic model of
information retrieval: development and comparative experiments part 1. Information Processing Management, 36(6), 779–808, 2000.
[8] Metzler, D. and Croft, W. B. Linear feature-based models for
information retrieval. Information Retrieval, 10(3), 257-274, 2007.
[9] Mihalcea, R. and Tarau, P. TextRank: bringing order into texts.
EMNLP, 2004.
[10] Page, L., Brin, S., Motwani, R. and Winograd, T. The PageRank
citation ranking: bringing order to the Web. Technical report,
Stanford Digital Library Technologies Project, 1998.
[11] Paik, J. H. A novel TF-IDF weighting scheme for effective ranking.
ACM SIGIR, 343-352, 2013.
[12] Ponte, J. M. and Croft, W. B. A language modeling approach to
information retrieval. ACM SIGIR, 275–281, 1998.
[13] Robertson, S. E. Readings in information retrieval. Chapter The
probability ranking principle in IR, pages 281–286. Morgan
Kaufmann Publishers Inc., 1997.
[14] Robertson, S. and Zaragoza, H. The probabilistic relevance
framework: BM25 and beyond. Foundations and Trends in
Information Retrieval, 3(4), 333–389, 2009.
[15] Rousseau, F. and Vazirgiannis, M. Graph-of-word and TW-IDF: new
approach to ad hoc IR. ACM CIKM, 59-68, 2013.
[16] Salton, G., Wong, A., and Yang. C. S. A vector space model for
automatic indexing. Communications of the ACM, 18(11), 613–620,
1975.
[17] Salton, G. McGill, M. J. Introduction to modern information retrieval.
McGraw-Hill, Inc., 1986.
[18] Ye, Z. and Huang, J. X. A simple term frequency transformation
model for effective pseudo relevance feedback. ACM SIGIR, 323-332,
2014.
[19] Zhai, C. and Lafferty, J. A study of smoothing methods for language
models applied to information retrieval. ACM Transaction on
Information System, 22(2), 179–214, 2004.
[20] Zhao, J., Huang, J. X., and Ye, Z. Modeling term associations for
probabilistic information retrieval. ACM Transactions on Information
Systems, 32(2), 7, 2014.

5. CONCLUSIONS AND FUTURE WORK
In this paper, a new term weighting approach is proposed to
calculate the degree of semantic coherence of the query terms
with a document. The coherence-based term weighting score can
further be used in combined with the existing retrieval functions
for document ranking. Experimental results on standard TREC
collections show the proposed retrieval methods consistently
outperform the corresponding strong baselines. The results
confirm that semantic coherent features can be used to improve
the retrieval performance. At the current stage of our work, only
one type of distance measure is adopted to calculate semantic
similarity between terms, and the values of the parameters in the
proposed models are chosen empirically. For future work, we will
investigate the effectiveness of other distance measures and study
how to find the optimal parameter setting for further improving
the retrieval performance.

6. ACKNOWLEDGMENTS
This work was partially supported by the National Science Foundation of
China under the grant number 61572223, a Discovery grant from the
Natural Sciences & Engineering Research Council (NSERC) of Canada
and an NSERC CREATE award. We thank anonymous reviewers for their
thorough review comments.

7. REFERENCES
[1] Blanco R. and Lioma C. Graph-based term weighting for information
retrieval. Information Retrieval, 15(1), 54–92, 2012.
[2] Craswell N., Robertson S. and Zaragoza H. Relevance weighting for
query independent evidence. ACM SIGIR, 416-423, 2005.
[3] Diaz, F. and Metzler, D. Improving the estimation of relevance
models using large external corpora. ACM SIGIR, 154-161, 2006.
[4] Fang, H., Tao, T. and Zhai, C. A formal study of information retrieval
heuristics. ACM SIGIR, 49–56, 2004.
[5] Gao, J., Zhou, M., Nie, J. Y., He, H., and Chen, W. Resolving query
translation ambiguity using a decaying co-occurrence model and
syntactic dependence relations. ACM SIGIR, 183-190, 2002.

840


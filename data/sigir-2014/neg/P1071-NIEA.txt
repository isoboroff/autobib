Weighted Aspect-Based Collaborative Filtering
∗

YanPing Nie∗ , Yang Liu∗ , Xiaohui Yu∗†

School of Computer Science and Technology, Shandong University, Jinan, Shandong, China
†
School of Information Technology, York University, Toronto, Canada

nieyanping2008@163.com, yliu@sdu.edu.cn, xhyu@sdu.edu.cn

ABSTRACT

and cinematography), she may still give that movie an overall rating of 9/10 as she likes other aspects of the movie (e.g., plot and
acting). Therefore, it is important to take into consideration the
preference information on individual aspects for more accurate rating prediction. Recent work by Wang et al. [10] computes aspect
ratings based on the opinions expressed towards the constituent aspect terms which are extracted by a double propagation method and
organizes both the overall ratings and the ratings on aspects into a
tensor, and takes a tensor factorization approach to exploring the
latent structure. It has been shown that incorporating ratings on
aspects can improve the effectiveness of CF.
However, a major limitation of the work by Wang et al. [10]
is that they assign the same weight to all aspects, while in reality
different aspects are seldom treated equally by users. We argue that
the overall rating of an item is indeed a weighted combination of
the ratings on different aspects, and the different weight put on the
aspects by different users reflect their divergent preference profiles.
For example, consider a movie with two typical reviews by two
users along with overall ratings. The first user assigns a 2/5 rating,
and the review reads “The movie has beautiful music and immaculate direction. However, the story has no memorable lines”. The
second user gives the same movie a 4/5 rating, states “The story
is a bit bland, but I loved the music and the masterful direction".
Both reviews comment on the same aspects, i.e., music, direction
and story, and share similar opinions on those aspects. However,
their numerical ratings are different. One tenable explanation is
that these two users emphasize different aspects when reaching the
overall rating. That is, the first user may put a heavier weight on
story than the second user, whereas the second user weighs music and direction more. Clearly, the weight users put on different
aspects affects the overall ratings.
In this paper, we tackle the problem of weighting the aspects to
achieve more accurate prediction of overall ratings. To keep our
discussion focused, we assume that the ratings on individual aspects can be obtained directly through explicit ratings by the users,
or by performing sentiment extraction from reviews when explicit
ratings are not available [10]. As mentioned earlier, we believe that
the overall rating comes from a weighted combination of the ratings for individual aspects. At a first glance, it appears that given
a dataset, we could easily build a regression model with the aspect
ratings and the overall rating being the variables and the weights
being the parameters. However, this will make the number of free
parameters (one for each combination of user, item, and aspect)
too big to be tractable. In addition, the data could be very sparse,
preventing us from getting well-formed solutions to the regression
problem. The reason is that while there usually exist many different aspects for a set of items, many reviews may touch upon only a
small portion of those. Also, the explicit ratings on individual as-

Existing work on collaborative filtering (CF) is often based on the
overall ratings the items have received. However, in many cases,
understanding how a user rates each aspect of an item may reveal
more detailed information about her preferences and thus may lead
to more effective CF. Prior work has studied extracting/quantizing
sentiments on different aspects from the reviews, based on which
the unknown overall ratings are inferred. However, in that work, all
the aspects are treated equally; while in reality, different users tend
to place emphases on difference aspects when reaching the overall
rating. For example, users may give a high rating to a movie just
for its plot despite its mediocre performances. This emphasis on
aspects varies for different users and different items. In this paper,
we propose a method that uses tensor factorization to automatically
infer the weights of different aspects in forming the overall rating.
The main idea is to learn, through constrained optimization, a compact representation of a weight tensor indexed by three dimensions
for user, item, and aspect, respectively. Overall ratings can then
be predicted using the obtained weights. Experiments on a movie
dataset show that our method compares favorably with three baseline methods.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information filtering

Keywords
Collaborative Filtering; Tensor Factorization

1.

INTRODUCTION

Collaborative filtering (CF), a popular technique used in recommender systems, makes predictions about a user’s interests by
collecting preferences information from other users, usually in the
form of ratings of items. In most existing CF methods, overall
ratings of items are used (e.g. “4.5 out 5 stars for iPhone 5S") .
However, ratings at a finer granularity may provide more detailed
information and thus help improve the effectiveness of CF. For example, while a user dislikes some aspects of a movie (e.g., music
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice
and the full citation on the first page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior specific permission and/or a fee. Request permissions from
permissions@acm.org.
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.
http://dx.doi.org/10.1145/2600428.2609512.

1071

numerically rated or reviewed by a user i, we have wijk = 0.
We use a 3rd-order tensor L = [lijk ]I×J ×K of indictor variables
lijk ∈ {0, 1} to denote whether rijk is known (lijk = 1) or not
(lijk = 0).
With the input of the overall rating matrix R and the aspect rating matrices R1 , R2 , ..., RK , the problem we address in this paper
is to learn the weight that users place on each aspect of each item.
Those weights can be incorporated into the aspect rating matrices
1
2
K
and produce weighted aspect rating matrices R̂ , R̂ , ..., R̂ . Similar to the procedure in [10], we can aggregate the overall rating matrix and the weighted aspect rating matrices into a 3rd-order tensor
R̂, where the size of R̂ is I × J× (K + 1). The ultimate goal is
to predict the overall rating rij for item mj which is not yet rated
by user ui using R̂.

pects as well as the overall rating may be missing for a significant
number of items, as many websites do not force the users to rate
numerically out of user-friendliness considerations.
We hence propose a method based on tensor factorization, which
aims to compute a concise representation of the underlying factors
for weighting, taking into consideration the fact that many aspect
ratings may be missing. Each element of this weight tensor corresponds to the weight a user puts on an aspect of an item. This
weight tensor can therefore be viewed as a three-dimensional array indexed along the dimensions of user, aspect, and item. We
compute the decomposition of this tensor into low rank matrices,
subject to the constraint that the tensor reconstructed from those
matrices has to consist of the optimal parameters to a linear regression problem that regresses the overall rating on aspect ratings.
The weighted aspect ratings can then be used to predict the overall
ratings in cases where those numerical ratings are not available.
The rest of the paper is organized as follows. We review the
related work in Section 2, and define the problem in Section 3. We
present the new model and method in Section 4, and present the
experimental results in Section 5. Section 6 concludes this paper.

2.

4. MODEL AND METHOD
4.1 Computing Aspect Weights
One way to learn the parameters wij is to build a separate regression model for each pair of user i and item j. But since each user
usually gives only one overall rating for an item and/or writes one
review for an item, it is impossible to build a reasonable regression
model with sufficient data. Another problem with this approach is
that we have I ×J ×K parameters to estimate, which is intractable
in general. Also, since each user usually rates/reviews only some
aspects of a small subset of the items, the data is too sparse to obtain
good estimates for those parameters.
We therefore take a tensor factorization approach to solving the
problem of computing the aspect weights. As described in Section 3, the weights can be arranged as a 3rd-order tensor W where
the first, the second, and third dimensions correspond to user, item,
and aspect respectively, and each element in the tensor corresponds
to a particular parameter wijk . Tensor factorization is a good fit
for our problem as it is an excellent way of capturing the intrinsic interactions between the three dimensions: users, items, and aspect weights. Moreover, tensor factorization will greatly reduce the
number of free parameters, overcoming the issues with the aforementioned method.
There are multiple ways of computing the factorization. We
adopt the CANDECOMP/PARAFAC (CP) approach [1], which can
effectively factorize a tensor into a sum of component rank-one tensors. We can decompose the tensor W as

RELATED WORK

Wang et al. [10] consider incorporating the sentiments on the
different aspects of an item into rating prediction for CF. However, in that work, the overall ratings and aspect ratings are considered equally important when they are organized into a tensor,
while in practice, people have different preferences on different aspects. The work presented in this paper improves upon that work
through weighting the aspects to better reflect the reality.
The Latent Aspect Rating Analysis (LARA) model [8] takes a set
of review texts with overall ratings and a specification of aspects as
input, and discovers each individual reviewer’s latent ratings on the
given aspects. A major limitation of LARA model is the assumption of pre-specified aspects by keywords. Wang et al. [9] further
improve LARA by proposing a unified generative model for LARA
that does not need pre-specified aspect keywords. Our work differs
from theirs in that we focus on weighting the aspects for rating prediction, where the aspect ratings can be obtained (if not available in
numerical form) using a variety of methods for sentiment extraction
already proposed in the literature.
[5] uses a linear regression formulation to learn author preferences, but it can only be used to get author specific facet preferences on a particular topic. Li et al. [2] exploit the use of tensor
factorization to generate latent factors, in order to model the association among reviewers, products and text features, but this work
does not consider the aspects.

3.

W≈

R


nr ◦ pr ◦ qr ,

(1)

r=1

where R is the number of rank-one components, and in general,
the best decomposition is achieved when R is equal to the rank of
the tensor W; the symbol ◦ represents the vector outer product; nr ,
pr and qr are the column vectors in the factor matrices N, P and
Q, respectively. The sizes of N, P, and Q are I × R, J × R, and
K × R, respectively. Element-wise, Eq. (1) can be written as

PROBLEM DEFINITION

We assume that there is a set of users U = {u1 , u2 , ..., uI }
writing reviews on a set of items M = {m1 , m2 , ..., mJ }. Let R of
size I × J denote a user-item overall rating matrix, where the entry
rij denotes the rating of ui on mj . Normally, a user would have
only reviewed a subset of items. We use a matrix S = [sij ]I×J of
indictor variables sij to represent whether rij is observed (sij = 1)
or not (sij = 0).
We assume that there are K aspects A = {a1 , a2 , ..., aK } and
correspondingly K aspect rating matrices R1 , R2 , ..., RK , one for
each aspect. We use a vector rij of length K to represent the
aspect-level ratings of user i on item j, where rijk is a numerical rating of aspect ak . Similarly, wij is an aspect weight vector
of length K, where wijk is a numerical measure indicating the degree of emphasis on aspect ak . If an aspect ak of item j is not

ŵijk = ni , pj , qk  =

R


nir · pjr · qkr ,

(2)

r=1

where each row ni , pj and qk of these factor matrices correspond
to the latent factors associated with each particular user, item and
aspect weight. We can see that the same user factor ni is shared
when computing ŵijk for different j and k combinations, which
effectively captures the possible correlations between ŵijk for the
same user. Similarly, the sharing of aspect weight and item factors

1072

J

∂Ω
=
sij · eij ·
∂ni
j=1
I

∂Ω
=
sij · eij ·
∂pj
i=1

∂Ω
=
∂qk

I 
J




K



⊗ pj +

lijk · rijk · qk

K



sij · (vij + ρ · hij ) ·

j=1

k=1



J



lijk · rijk · qk

⊗ ni +

I


eij · lijk · rijk · ni ⊗ pj +

i=1 j=1

I 
J



⊗ pj + λ ·

lijk · qk

sij · (vij + ρ · hij ) ·

K



lijk · qk

⊗ ni + λ ·

lijk · vij · ni ⊗ pj + ρ ·

i=1 j=1



lijk · ρ · wijk − uijk · pj ⊗ qk

I 
K




lijk · ρ · wijk − uijk · ni ⊗ qk

i=1 k=1

k=1
I 
J


J 
K

j=1 k=1

k=1



i=1

k=1

K


lijk · hij · ni ⊗ pj + λ ·

i=1 j=1

I 
J




lijk · ρ · wijk − uijk · ni ⊗ pj

i=1 j=1

Figure 1: Partial derivatives of the objective function Ω
are achieved in the same way when determining ŵijk for different
(i, j) and (i, k) pairs.
The predicted rating r̂ij using the model can be computed as
follows from the weight vector and aspect ratings:
r̂ij = ŵTij rij =

K


ŵijk · rijk .

where the matrix W (:, :, k) denotes the weights users give on the
k
aspect ak of items. That is, each entry of R̂ is computed by r̂ijk =
wijk × rijk .
After the weighted aspect ratings are computed, one can predict the overall ratings for cases where those ratings are available
(e.g., users might have written textual reviews on some aspects but
have not given a numerical overall rating). Similar to the method
proposed in [10], we combine the overall rating matrix R (with
unknown entries for ratings unavailable) with the weighted aspect
1
2
K
rating matrices R̂ , R̂ , · · · , R̂ to form a new 3rd-order tensor R̂.
Then we employ the CP-WOPT method [3] to factorize the tensor
R̂. Suppose that the factor matrices A, B and C are the results from
the CP decomposition of R̂. The predicted rating that ui will give
for mj can be computed by

(3)

k=1

To compute the optimal model parameters N, P, and Q in terms
of prediction error, we seek to minimize the objective function f :
f=

J
I
1 
sij · (rij − r̂ij )2 ,
2 i=1 j=1

(4)

subject to the following constraints:
gijk ≡ −wijk ≤ 0,

r̃ij = r̂ij1 =

D


aid bjd c1d ,

(6)

d=1

hij ≡

K


where the parameter D is a positive integer.

lijk · wijk − 1 = 0,

5. EXPERIMENTS

k=1

for all i=1, 2, · · · , I, j=1, 2, · · · , J, k=1, 2, · · · , K, where gijk and
hijk are shorthands to be used in the sequel.
Using the PHR method [6], we transform the constrained objective function f into the unconstrained objective function Ω:
Ω =f +

J
I 


sij · vij · hij +

i=1 j=1

+

5.1 Setup
Experiments are conducted on a movie dataset including 186,235
reviews on 1,650 movies along with their star ratings crawled from
the Internet Movie Database (IMDB). Each rating is in the range
of 1-10 stars and the free-text reviews typically have a length of
200 to 500 words. Numerical aspect ratings are obtained through
opinion extraction from the reviews using the same method as that
in [10]. To make the computation meaningful and the performance
more robust, we filter out the users who have posted less than 10
reviews, resulting in a smaller and denser dataset. Table 5.1 shows
some statistics about the datasets before and after filtering, where
#reviews
the density is defined as (#users·#movies)
.

J
I
ρ 
sij · h2ij
2 i=1 j=1

J
K
I


1 
lijk · [max (0, uijk + ρgijk )]2 − u2ijk ,
2ρ i=1 j=1 k=1

where vij and uijk are the multipliers of the equality constraints on
hij and inequality constraints gijk , and ρ is the penalty parameter.
Let eij ≡ r̂ij − rij denote the prediction error of the model. The
partial derivatives of the unconstrained objective function Ω with
respect to model parameters ni , pj and qk are shown in Figure 1,
where λ represents whether uijk + ρ · gijk is greater than 0 (λ =
1) or not (λ = 0), and the symbol ⊗ denotes the element-wise
matrix multiplication operation. These gradients allow us to use
the gradient descent algorithm to compute the optimal matrices N,
P and Q.

Dataset
Raw
Filtered

With N, P and Q computed and hence W approximated using
k
Eq. (1), the weighted aspect rating matrix R̂ can be obtained as
follows:
k

Dataset statistics
#movie #review
1650
186235
1507
41128

density
0.13%
3.10%

We carry out our experiments on the filtered dataset. RMSE is
used as the evaluation metric to evaluate the prediction accuracy.
All results reported are the results of 10-fold cross validation. In
order to study the effect of data sparsity, we randomly remove some
data from the dataset, creating a data density from 3.1% to 1.6% at
interval of 0.5%.
We compare our methods with several baselines. We use the
model proposed in [10] (referred to as TF) as the first baseline.

4.2 Rating Prediction

R̂ = W (:, :, k) ⊗ Rk ,

Table 1:
#user
85693
879

(5)

1073



For the second baseline, we use the model proposed by Moshfeghi
et al. [4] (MR), which incorporates the emotion information into
collaborative filtering. The third baseline is a widely used matrix
factorization approach [7] (MF), which only uses star ratings for
collaborative filtering.








Figure 2 shows the experimental results on datasets when we
vary the data density. We can see that the baseline models TF and
MR outperform the baseline model MF, which demonstrates that
incorporating users’ opinions on different aspects can improve the
effectiveness of CF. In addition, our model, referred to as TF-W,
performs better than all three baseline methods. This validates our
hypothesis that considering aspect weighting can improve the prediction accuracy. Figure 2 also shows that the prediction accuracy
of each model decreases as the data becomes sparser. But the rate
of accuracy change is different; the RMSE of TF-W increases at
a lower rate than the baselines, which shows that TF-W can better
adapt to data sparsity than baseline models.























Figure 4: Prediction accuracy with varying R
factorization approach to compute the aspect weights, with the goal
of minimizing estimation errors on overall ratings. The obtained
aspect weights are used in conjunction with the aspect ratings to
form the weighted aspect rating matrices, which are then used to
perform prediction on the overall ratings. We have performed extensive experiments on a movie review dataset, and results show
that the proposed method is indeed effective and outperforms the
baseline methods in terms of prediction accuracy. For future work,
we would like to explore how the latent factors resulting from factorizing the weight tensor can be used to help identify clusters in
the users and show the relationships between aspects.






7. ACKNOWLEDGEMENTS





  

This work was supported in part by NSFC (No. 61272092), NSFSPC (No. ZR2012FZ004), IIFSDU (2012ZD012), the Taishan
Scholars Program, and NSERC Discovery Grants.



Figure 2: Experiment results for different densities

8. REFERENCES

Effect of the number of aspects. In order to study the impact of
parameter K on the prediction quality of TF-W and TF, we carry
out an experiment in which we vary the value of K from 2 to 16
with a step size of 2. We plot the RMSE at different K values in
Figure 3. The data density is set at 3.1%.
We can observe from Figure 3 that the prediction accuracy increases as we increase K from 2 to 8, and then deteriorates as we
increase K further. RMSE is minimal when K = 8. Therefore, K
is set to 8 in our experiments.


[1] E. Acar, D. M. Dunlavy, and T. G. Kolda. A scalable
optimization approach for fitting canonical tensor
decompositions. Journal of Chemometrics, 25(2):67–86,
2011.
[2] F. Li, N. Liu, H. Jin, K. Zhao, Q. Yang, and X. Zhu.
Incorporating reviewer and product information for review
rating prediction. In IJCAI, pages 1820–1825, 2011.
[3] M. Morup, D. Dunlavy, E. Acar, and T. Kolda. Scalable
tensor factorizations with incomplete data. Chemometrics
and Intelligent Laboratory Systems, 106(1):41–56, 2010.
[4] Y. Moshfeghi, B. Piwowarski, and J. M. Jose. Handling data
sparsity in collaborative filtering using emotion and semantic
based features. In SIGIR, pages 625–634, 2011.
[5] S. Mukherjee, G. Basu, and S. Joshi. Incorporating author
preference in sentiment rating prediction of reviews. In
WWW, pages 47–48, 2013.
[6] R. Rockafellar. The multiplier method of hestenes and
powell applied to convex programming. Journal of
Optimization Theory and Applications, 12(6):555–562, 1973.
[7] G. Takács, I. Pilászy, B. Németh, and D. Tikk. Major
components of the gravity recommendation system. ACM
SIGKDD Explorations Newsletter, 9(2):80–83, 2007.
[8] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating analysis on
review text data: A rating regression approach. In SIGKDD,
pages 783–792, 2010.
[9] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating analysis
without aspect keyword supervision. In SIGKDD, pages
618–626, 2011.
[10] Y. Wang, Y. Liu, and X. Yu. Collaborative filtering with
aspect-based opinion mining: A tensor factorization
approach. In ICDM, pages 1152–1157, 2012.










5.2 Results


















Figure 3: Sensitivity to parameter K
Effect of R and D. We vary the value of R (cf. Eq. (1)) from
1 to 10, and see how this affects the performance of the prediction.
We also vary D (cf. Eq. (6)) from 3 to 5. The results are shown
in Figure 4. We can see that there do exist best choices of R and
D. For our dataset, the best results are reached when R is 3 or 4
depending on the value of D.

6.







CONCLUSIONS

We have proposed a model that considers the effect of aspect
weights for the prediction of overall ratings. To alleviate the problems of data sparsity and model complexity, we exploit a tensor

1074


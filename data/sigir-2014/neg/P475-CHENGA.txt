IMRank: Influence Maximization via Finding
Self-Consistent Ranking
Suqi Cheng, Huawei Shen, Junming Huang, Wei Chen, Xueqi Cheng
Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China

{chengsuqi, shenhuawei, huangjunming, chenwei2012, cxq}@ict.ac.cn

ABSTRACT

[Software Engineering]: Metrics—complexity measures,
performance measures

Inﬂuence maximization, fundamental for word-of-mouth
marketing and viral marketing, aims to ﬁnd a set of
seed nodes maximizing inﬂuence spread on social network.
Early methods mainly fall into two paradigms with certain
beneﬁts and drawbacks: (1) Greedy algorithms, selecting
seed nodes one by one, give a guaranteed accuracy relying
on the accurate approximation of inﬂuence spread with high
computational cost; (2) Heuristic algorithms, estimating
inﬂuence spread using eﬃcient heuristics, have low computational cost but unstable accuracy.
We ﬁrst point out that greedy algorithms are essentially ﬁnding a self-consistent ranking, where nodes’ ranks
are consistent with their ranking-based marginal inﬂuence
spread. This insight motivates us to develop an iterative
ranking framework, i.e., IMRank, to eﬃciently solve inﬂuence maximization problem under independent cascade
model. Starting from an initial ranking, e.g., one obtained
from eﬃcient heuristic algorithm, IMRank ﬁnds a selfconsistent ranking by reordering nodes iteratively in terms
of their ranking-based marginal inﬂuence spread computed
according to current ranking. We also prove that IMRank
deﬁnitely converges to a self-consistent ranking starting from
any initial ranking. Furthermore, within this framework, a
last-to-ﬁrst allocating strategy and a generalization of this
strategy are proposed to improve the eﬃciency of estimating
ranking-based marginal inﬂuence spread for a given ranking.
In this way, IMRank achieves both remarkable eﬃciency
and high accuracy by leveraging simultaneously the beneﬁts
of greedy algorithms and heuristic algorithms. As demonstrated by extensive experiments on large scale real-world
social networks, IMRank always achieves high accuracy
comparable to greedy algorithms, while the computational
cost is reduced dramatically, about 10 − 100 times faster
than other scalable heuristics.

General Terms
Algorithms, Experiments, Performance

Keywords
inﬂuence maximization; social network analysis; viral marketing; iterative method; self-consistent ranking

1.

INTRODUCTION

The prosperity of online social networks and social media
invokes a new wave of research on social inﬂuence analysis [18, 8]. Finding inﬂuential individuals is an important
problem for many applications such as expert ﬁnding,
online advertising and marketing. Inﬂuence maximization
is identiﬁed as a fundamental problem for viral marketing
in the area of online marketing. It aims to ﬁnd a ﬁxed-size
set of seed nodes in social network to maximize their inﬂuence spread, i.e., the expected number of activated nodes
triggered by the seed nodes. Ever since being formalized
by Kempe et al. [11], inﬂuence maximization has attracted
much research attention from various ﬁelds, including social
network analysis, data mining and marketing.
Early methods for inﬂuence maximization mainly use
greedy framework, iteratively selecting the node with the
largest marginal inﬂuence spread as seed node. with an
accurate estimation of inﬂuence spread,the greedy framework provides a (1 − 1/e) approximation to the optimal
solution of inﬂuence maximization [11], guaranteed by the
submodularity and monotonicity properties of inﬂuence
spread as a function of seed node set. According to the ways
of estimating the inﬂuence spread, these methods roughly
fall into two paradigms: greedy algorithms [11, 13, 4, 7, 5]
and heuristic algorithms [12, 3, 20, 10]. Greedy algorithms
provide a (1 − 1/e − ϵ) approximation by approximating
inﬂuence spread through Monte Carlo simulation. However,
they have high computation cost, for the calculation of
marginal inﬂuence spread invokes estimating the inﬂuence
spread of nodes from scratch, using time-consuming Monte
Carlo simulation. The latter, in contrast, resorts to estimate
the inﬂuence spread via eﬃcient heuristic methods. The
scalability of these heuristics generally outperforms the
greedy algorithms by several orders of magnitude. Yet, their
high scalability is gained with the pain of unguaranteed accuracy and unreliable performance on various scenarios. To
the best of our knowledge, we lack an eﬃcient and accurate
algorithm of inﬂuence maximization for applications to large
scale social networks in real world.

Categories and Subject Descriptors
F.2.2 [Analysis of Algorithms and Problem Complexity]: Non-numerical Algorithms and Problems; D.2.8
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.
http://dx.doi.org/10.1145/2600428.2609592.

475

Many eﬀorts have been made to improve the scalability
of Kempe’s greedy algorithm for inﬂuence maximization.
“cost-eﬀective lazy forward” (CELF) optimization strategy [13] and CELF++ [7] are proposed to reduce the
times of inﬂuence spread estimation in Kempe’s greedy
algorithm by exploiting the submodularity property of
inﬂuence spread function. To reduce the number of Monte
Carlo simulations, Chen et al. [4] proposed NewGreedy
algorithm and MixedGreedy algorithm. The NewGreedy
algorithm reusing the results of Monte Carlo simulations in
the same iteration to calculate marginal inﬂuence spread for
all candidate nodes. Yet, it increases the computational cost
for a single Monte Carlo simulation because the simulation
is now conducted globally rather than locally as done in
Kempe’s greedy algorithm. As a remedy, the MixedGreedy
algorithm was developed, integrating the CELF strategy
into the NewGreedy algorithm.
Recently, Sheldon et
al. [17] proposed a sample average approximation approach
from stochastic optimization for maximizing the spread of
cascades under budget restriction. Cheng et al. [5] proposed
a StaticGreedy algorithm, remarkably reducing the number
of Monte-Carlo simulations through strictly guaranteeing
the submodularity and monotonicity properties of inﬂuence
spread function. The above two works further improve the
scalability of greedy algorithm eﬀectively. These improvements can speedup the original greedy algorithm in several
orders of magnitude, however, scalability is still a challenge
for greedy algorithms.
Heuristic algorithms, in contrast, mainly reduce the complexity of Kempe’s greedy algorithm through computing
inﬂuence spread heuristically. DegreeDiscount, designed for
uniform independent cascade model, only computes direct
inﬂuence [4]. Community-based greedy algorithm conducted
Monte Carlo simulation within each community rather than
on the whole network [20]. SPM/SP1M algorithms [12]
estimated inﬂuence spread according to shortest paths, while
PMIA algorithm [3] [19] used maximum inﬂuence paths.
SP1N algorithm employed the concept of Shapley value
from the cooperative game theory [15]. IRIE algorithm [10]
eﬃciently estimated marginal inﬂuence spread through an
iterative method. Besides the above heuristics using greedy
approach, Jiang et al. proposed a simulated annealing
approach with several heuristics [9], and Mathioudakis et al.
suggested to speed up inﬂuence maximization using a simpliﬁed inﬂuence network [14]. However, these heuristics cannot
give rise to guaranteed accuracy and their performance is
unstable on diﬀerent networks and diﬀusion models.
Taken together, in existing algorithms for inﬂuence maximization, the estimation of inﬂuence spread and the ranking
of nodes are studied separately. On one hand, without
leveraging the ranking of nodes, greedy algorithms estimate
the inﬂuence spread of nodes from scratch, causing high
computational cost. On the other hand, lacking a reliable
estimation of inﬂuence spread, heuristic algorithms have no
guaranteed accuracy. Hence, in this paper, we improve
the state-of-the-art solution of inﬂuence maximization problem by exploiting the interplay between marginal inﬂuence
spread and the ranking of nodes.

In this paper, we propose an eﬃcient and accurate
algorithm to solve inﬂuence maximization problem under
the widely-adopted independent cascade model [11]. This
algorithm is motivated by the key insight that greedy
algorithms are essentially ﬁnding a self-consistent ranking, where nodes’ ranks are consistent with their rankingbased marginal inﬂuence spread. We prove that such
self-consistent ranking can be obtained directly using an
iterative ranking framework, i.e., IMRank, proposed in this
paper. Starting from an initial ranking, e.g., one obtained
from eﬃcient heuristic algorithm, IMRank eﬃciently ﬁnds
a self-consistent ranking by reordering nodes iteratively
in terms of their ranking-based marginal inﬂuence spread
computed according to current ranking. Diﬀerent from
greedy algorithms computing marginal inﬂuence spread from
scratch, IMRank conducts the computation of rankingbased marginal inﬂuence spread via an eﬃcient last-to-ﬁrst
allocating strategy. As a result, IMRank achieves both high
eﬃciency and high accuracy by leveraging simultaneously
the beneﬁts of greedy algorithms and heuristic algorithms.
To evaluate the performance of IMRank, we conduct
extensive experiments on large-scale social networks with
hundreds of thousands of edges to millions of edges. Experimental results demonstrate that IMRank achieves high
accuracy comparable to greedy algorithms with computational cost reduced dramatically.
Our main contributions are summarized as follows:
• We propose a novel framework IMRank, which uniﬁes the estimation of marginal inﬂuence spread and
the selection of seed nodes. IMRank achieves both
remarkable eﬃciency and high accuracy by exploiting
the interplay between the calculation of ranking-based
marginal inﬂuence spread and the ranking of nodes.
• We prove that IMRank, starting from any initial ranking, deﬁnitely converges to a self-consistent ranking in
a ﬁnite number of steps. This indicates that IMRank is
eﬃcient at solving the inﬂuence maximization problem
via ﬁnding a ﬁnal self-consistent ranking.
• We design an eﬃcient last-to-ﬁrst allocating strategy
to approximately estimate the ranking-based marginal
inﬂuence spread of nodes for a given ranking, further
improving the eﬃciency of IMRank.
• We conduct extensive experiments on several realworld networks under diﬀerent types of independent
cascade model. Through comparing two instances
of IMRank with both greedy algorithm and existing state-of-the-art heuristics, we show that IMRank
always achieves comparable accuracy to the greedy
algorithm, while runs 10 − 100 times faster than other
heuristics with comparable accuracy.

2. RELATED WORK
Inﬂuence maximization problem was ﬁrst studied by
Domingos and Richardson from algorithmic perspective [6,
16]. Kempe et al. then formulated it as a combinatorial
optimization problem of ﬁnding a set of seed nodes with
maximum inﬂuence spread [11]. They proved that this
problem is NP-hard and proposed a greedy algorithm which
can guarantee a (1 − 1/e − ϵ) approximation ratio. Here, ϵ
is caused by the inaccurate estimation of inﬂuence spread.
The biggest problem suﬀered by Kempe’s greedy algorithm
is its low scalability, limiting it to social networks with small
or moderate size.

3.

SELF-CONSISTENT RANKING

For inﬂuence maximization on a social network G =
(V, E), inﬂuence spread function I(S) of a node set S ⊆ V
is deﬁned as the expected number of nodes in G eventually
activated by S under certain diﬀusion model. The function
I(·) is nonnegative, monotone, and submodular, satisfying

476

Notation
vi
ri
S = {v1 , v2 , . . . , vn }
I(S)
M (v|S)
Mr (vri )
p(vi |{v1 , v2 , . . . , vi−1 })
ηr (vi , vj )
d(vj , vi )
dr (vj , vi )
ρr (vi , vj )
l

Table 1: Notations.
Description
a node with index i
the index of node with rank i with respect to a given ranking r
a set of nodes
expected number of nodes eventually activated by set S
marginal inﬂuence spread by adding node v into a seed set S
ranking-based marginal inﬂuence, short for M (v|{vr1 , vr2 , . . . , vri−1 })
probability that vi is activated given that a collection of nodes {v1 , v2 , . . . , vi−1 } are already activated
inﬂuence score that node vi sends to node vj with respect to a given ranking r
a simple path starting from vj and ending at vi , i.e., {w1 = vj , w2 , . . . , wn = vi }
inﬂuence path, which is a simple path where vj is the only node ranked higher than vi on the path
probability that vi is activated by vj through any inﬂuence path, with respect to a given ranking r
maximal length of all inﬂuence paths to account into

• Nonnegative: I(S) ≥ 0;

Theorem 1. Greedy algorithms for influence maximization gives a self-consistent ranking.

• Monotone: I(S) ≤ I(T ), if S ⊆ T ⊆ V ;

Proof. Greedy algorithms iteratively select the node
with maximum marginal inﬂuence spread as seed node.
With a ranking r denoting the order seed nodes are selected,
we have M (vri |{vr1 , vr2 , · · · , vri−1 }) ≥ M (vrj |{vr1 , vr2 , . . . ,
vri−1 }), for i < j. In addition, the submodularity of inﬂuence spread function implies that M (vrj |{vr1 , vr2 , · · · , vri−1 })
≥ M (vrj |{vr1 , vr2 , · · · , vrj−1 }). Using transitivity, we complete the proof with Mr (vri ) = M (vri |{vr1 , vr2 , · · · , vri−1 }) ≥
M (vrj |{vr1 , vr2 , · · · , vrj−1 }) = Mr (vrj ).

• Submodular: I(S ∪ {v}) − I(S) ≥ I(T ∪ {v}) − I(T ),
for all v ∈ V and S ⊆ T ⊆ V .
These properties guarantee that a fair approximation to the
optimal solution of inﬂuence maximization can be obtained
by greedy algorithms, iteratively selecting the node with
maximum marginal inﬂuence spread as seed node.
Definition 1. Marginal influence spread: Given a
node set S ⊆ V and a node v ∈ V , the marginal inﬂuence
spread of v upon S is deﬁned as M (v|S) = I(S ∪{v})−I(S).

For a given social network, however, there are multiple
self-consistent rankings besides the one obtained by greedy
algorithms. Hence it is critical to develop eﬀective algorithms to achieve a desired self-consistent ranking which is
either the very ranking obtained by greedy algorithms or
comparable to it from the point of inﬂuence maximization.

However, the inﬂuence spread function is not extensive,
i.e., I(S ∪ {v}) ̸= I(S) + I({v}) if v ∈
/ S, since the nodes
activated by S may overlap with the nodes activated by
v. Therefore, one has to compute the marginal inﬂuence
spread by computing both I(S) and I(S ∪{v}) from scratch,
resulting in huge computation cost. To remedy this problem,
we further analyze the property of the set of seed nodes
obtained by greedy algorithms. Indeed, greedy algorithms
implicitly give a ranking of nodes, where nodes are ranked
in decreasing order of their marginal inﬂuence spread.
Meanwhile, their marginal inﬂuence spread are computed
based on their ranks in the implicit ranking. Hence, greedy
algorithms obtain a self-consistent ranking of nodes.
Before formally deﬁning self-consistent ranking, we ﬁrst
introduce several related notations for clarity. Without loss
of generality, we index all the nodes into {v1 , v2 , · · · , vn }
where n = |V |. A ranking of nodes, determined by a
permutation (r1 , r2 , · · · , rn ) with ri ∈ {1, 2, · · · , n} denoting the index of node with rank i, is denoted as
r = {vr1 , vr2 , · · · , vrn }. With these notations, for convenience, we now deﬁne the ranking-based marginal inﬂuence
spread of node with respect to a ranking r as Mr (vri ) =
M (vri |{vr1 , vr2 , · · · , vri−1 }). In addition, for clarity, Table 1
lists all important notations used in this paper.

4.

IMRANK

In this section, we develop an eﬃcient iterative framework IMRank to solve the inﬂuence maximization problem
through ﬁnding a desired self-consistent ranking. IMRank
distinguishes itself from greedy algorithms in one key point:
in each iteration, IMRank eﬃciently estimates the marginal
inﬂuence spread of all nodes based on current ranking, while
greedy algorithms compute the marginal inﬂuence spread
from scratch with high computational cost.

4.1

IMRank: iterative framework

IMRank aims to ﬁnd a self-consistent ranking from any
initial ranking. It achieves the goal by iteratively adjusting
current ranking as follows:
• Compute the ranking-based marginal inﬂuence spread
of all nodes Mr with respect to the current ranking r;
• Obtain a new ranking by sorting all nodes according
to Mr .

Definition 2. Self-consistent ranking: A ranking r is
a self-consistent ranking iﬀ Mr (vri ) ≥ Mr (vrj ), ∀1 ≤ i <
j ≤ n.

This iterative process is formally described in Algorithm 1.
It deﬁnitely converges to a self-consistent ranking, starting
from any initial ranking (see Section 4.3 for proof). Intuitively, IMRank iteratively promotes inﬂuential nodes to
top positions in the ranking, always increasing the inﬂuence
spread of top-k nodes during the process until it converges to
a self-consistent ranking. Indeed, diﬀerent initial rankings
could make IMRank converge to diﬀerent self-consistent
rankings. We leave the discussion about initial ranking to
Section 4.4.

For the set of seed nodes obtained by greedy algorithms,
there exists an interplay between the ranks of nodes and
their marginal inﬂuence spread. On one hand, these nodes
are ranked in descending order of their marginal inﬂuence
spread. On the other hand, the marginal inﬂuence spread
of nodes is calculated with respect to the ranks of nodes.
Indeed, the set of seed nodes obtained by greedy algorithms
forms a self-consistent ranking.

477

Algorithm 2 Calculate Mr (r)
1: for i = 1 to n do
2:
Mr (vri ) ← 1
3: end for
4: for i = n to 2 do
5:
for j = 1 to i do
6:
Mr (vrj ) ← Mr (vrj ) + p(vrj , vri ) × Mr (vri )
(
)
7:
Mr (vri ) ← 1 − p(vrj , vri ) × Mr (vri )
8:
end for
9: end for
10: output Mr

Algorithm 1 IMRank (r)
(0)

1: r = r
2: t ← 0
3: repeat
4:
t←t+1
5:
Calculate Mr(t) with respect to the ranking r
6:
Generate a new ranking r(t) by sorting nodes in
decreasing order according to Mr(t)
7: until r(t) = r(t−1)
8: output the self-consistent ranking r(t)

4.2 Calculate ranking-based marginal influence spread

where p(vrj , vri ) is the propagation probability that
node vrj directly activates node vri , known as a priori
for the independent cascade model.

The core step in IMRank is the calculation of rankingbased marginal inﬂuence spread. One straightforward way is
to directly compute Mr (vri ) = M (vri |{vr1 , vr2 , · · · , vri−1 })
using Monte Carlo simulation, as done by greedy algorithms.
However, prohibitively high computational cost makes it impractical for IMRank. To combat this problem, we propose
a Last-to-First Allocating (LFA) strategy to eﬃciently estimate Mr , leveraging the intrinsic interdependence between
ranking and ranking-based marginal inﬂuence spread. We
develop the LFA strategy under the independent cascade
model [11]. For the independent cascade model, when a node
u is activated, it has one chance to independently activate
its neighboring nodes with a propagation probability p(u, v)
if v has not been activated yet. Each node can be activated
for only once.
The LFA strategy is based on the following fact: by deﬁnition, the ranking-based marginal inﬂuence spread Mr (v) is
equal to the expected number of nodes activated by v, given
that when all nodes ranked higher than it have ﬁnished the
propagation of their inﬂuence. This implies two basic rules
under the calculation of Mr (v):

The calculation of the ranking-based marginal inﬂuence
spread Mr is completed after all nodes are scanned. The
LFA strategy is formally depicted in Algorithm 2.
Now we use an example to illustrate the LFA strategy. In
Figure 1, vk denotes the node with rank k for convenience,
and pi,j is the propagation probability along edge ⟨vi , vj ⟩.
Here, the ranking is simply r = {v1 , v2 , v3 , v4 , v5 }. Solid
lines represent the edges where inﬂuence could propagate,
while dashed lines depict the edges where inﬂuence score is
delivered when nodes are scanned. The lack of dashed line
from node v3 to node v2 reﬂects that node v2 is ranked higher
than node v3 . For this case, the LFA strategy computes the
ranking-based marginal inﬂuence spread as follows:
1. Initially, Mr (vi ) = 1,1 ≤ i ≤ 5.
2. Node v5 is then scanned as the last node in the ranking.
According to Equation( 1), v5 delivers p3,5 Mr (v5 ) =
p3,5 to v3 and p4,5 (1 − p3,5 ) to v4 respectively. Accordingly, Mr (v5 ) becomes (1 − p4,5 )(1 − p3,5 ).

1. Each node can only be activated by nodes ranked
higher than it in the given ranking;

3. Then node v4 is scanned. Since Mr (v4 ) is now 1 +
p4,5 (1 − p3,5 ), v4 delivers p2,4 + p2,4 p4,5 (1 − p3,5 ) to v2 .
Note that the second item characterizes the inﬂuence
of v2 to v5 through the path ⟨v2 , v4 , v5 ⟩, reﬂecting that
the LFA strategy could eﬀectively capture the indirect
inﬂuence among nodes. After v4 is scanned, the ﬁnal
value of Mr (v4 ) is (1 − p2,4 )(1 + p4,5 (1 − p3,5 )).

2. When a node could be activated by multiple nodes,
higher-ranked node has higher priority to activate it.
Following the two basic rules, the LFA strategy is described as follows:
• Given a ranking r, the initial value of Mr (vri ) of each
node is setted to be 1, satisfying the fact that the sum
of Mr (vri ) over all nodes is equal to the number of
nodes, since each node can only be activated once.

4. When node v3 is scanned. it delivers p1,3 (1 + p3,5 ) to
node v1 , with (1 − p1,3 )(1 + p3,5 ) remained.
5. Finally, node v2 is scanned. After v2 is scanned, the
ﬁnal scores of Mr (v2 ) and Mr (v1 ) are (1 − p1,2 )(1 +
p2,4 + p2,4 p4,5 (1 − p3,5 )) and 1 + p1,2 (1 + p2,4 +
p2,4 p4,5 (1−p3,5 ))+p1,3 (1+p3,5 ) respectively. The term
p1,2 p2,4 p4,5 (1 − p3,5 ) in Mr (v1 ) captures the indirect
inﬂuence from v1 to v5 through the path ⟨v1 , v2 , v4 , v5 ⟩,
indicating that the LFA strategy does collect inﬂuence
with multiple intermediate nodes on the path. Note
that it is not necessary to scan node v1 since it does
not delivery inﬂuence to other nodes

• Scanning the ranking from the last node to the top one,
a fraction of Mr (vri ) is delivered to the nodes ranked
higher than vri , reﬂecting the ﬁrst rule;
• The delivered inﬂuence score of Mr (vri ) is allocated
among the nodes vj (j < i) in terms of their ranks,
reﬂecting the second rule.
Speciﬁcally, with η(vrj , vri ) denoting the fraction of
inﬂuence score delivered to node vrj from node vri , we
have η(vrj , vri ) =

∏ (
)

1 − p(vrk , vri ) , j < i,
 Mr (vri )p(vrj , vri )

 0,

The above illustration tells us that the LFA strategy
eﬃciently calculates the ranking-based marginal inﬂuence
spread for all nodes, scanning each node only once. Meanwhile, with indirect inﬂuence propagation being eﬀectively
captured, the LFA strategy provides a good delegate to
calculate ranking-based marginal inﬂuence spread. We show
the numerical results of the LFA strategy and 20,000 times

k:1≤k<j

otherwise.
(1)

478

Figure 1: Illustration of the LFA strategy.
(a) Top-50 nodes

Table 2: Estimation on ranking-based marginal
inﬂuence spread.
MC indicates Monte Carlo
simulation, and LAF indicates the LAF strategy.
v1
v2
v3
v4
v5
MC
LAF

1.29846
1.24000

1.38800
1.42400

0.77941
0.76800

0.89406
0.92800

(b) Inﬂuence spread

Figure 2: Convergence of IMRank

0.64007
0.64000

nodes ranked higher than it in ranking r. According to the
submodularity of inﬂuence spread function, we can obtain
Mr (vri′ ) ≤ Mr′′ (vri′ ) for each node vri′ (1 ≤ i ≤ k). Thus,
∑
∑
′′
′
′′
′
there is
1≤i≤k Mr (vri ) ≤ ∑ 1≤i≤k Mr (vri ) = Ir (k).
Note we have proved Ir (k) ≤ 1≤i≤k Mr (vri′ ) and Ir′ (k) =
Ir′′ (k). Taken together, we can obtain Ir (k) ≤ Ir′ (k), and
the equal-sign is tenable iﬀ the sets of the top-k nodes in
ranking r and r′ are the same, otherwise Ir (k) < Ir′ (k).
Based on the above conclusion, as long as the current
ranking is not a self-consistent ranking, in each iteration all
the values of I(k)(1 ≤ k ≤ n) are nondecreasing, and at least
one I(k) increases. Since each I(k) has an upper bound (i.e.,
n), IMRank eventually converges to a self-consistent ranking
within a ﬁnite number of iterations, starting from any initial
ranking.

Monte Carlo simulations in the case of setting pu,v = 0.2 for
all edges as done in uniform independent cascade model. As
shown in Table 2, our strategy oﬀers very close results to
the time-consuming Monte Carlo simulations.
Finally, we sum up the LFA strategy by explaining why
it works remarkably. First, it achieves high eﬃciency by exploiting the interdependence between ranking and rankingbased marginal inﬂuence spread, avoiding the adoption of
Monte Carlo simulations done in greedy algorithms. Second,
it employs the intermediate nodes as delegates, in a last-toﬁrst manner, to capture both direct and indirect inﬂuence
propagation among nodes. In this way, ranking-based
marginal inﬂuence spread could be eﬃciently calculated via
scanning all nodes only once. In addition, the LFA strategy
only oﬀers one eﬀective approximation rather than exact
calculation of inﬂuence spread. This is partly caused by the
restriction that lower-ranked nodes only deliver inﬂuence
score to higher-ranked neighboring nodes. In Section 5,
we further improve the LFA strategy via relaxing this
restriction.

We now empirically illustrate the quick convergence of
IMRank, using a scientiﬁc collaboration network, namely
HEPT, extracted from the “High Energy Physics-Theory”
section of the e-print arXiv website arXiv.org. This network
is composed of 15K nodes and 59K edges. We run
IMRank to select 50 seed nodes. Figure 2(a) shows the
percent of diﬀerent nodes in two successive iterations.
For two widely-used models, weighted independent cascade
(WIC) model [11] and trivalency independent cascade (TIC)
model [3], the set of top-50 nodes becomes unchanged after
5 and 8 iterations respectively. Clearly, IMRank converges
much quicker than greedy algorithms, which requires k
iteration for selecting k seed nodes. Figure 2(b) depicts
the inﬂuence spread of top-50 nodes. We employ the
relative inﬂuence spread, i.e., the ratio of the obtained
inﬂuence spread in each iteration to the obtained inﬂuence
spread when IMRank converges. IMRank only takes 3
and 5 iterations to achieve a stable and high inﬂuence
spread under the two models respectively. The inﬂuence
spread of top-k nodes seems always converges with smaller
number of iterations than the convergence of the set of top-k
nodes. Therefore, one can stop IMRank safely in practice by
checking the change of top-k nodes between two successive
iterations.
In sum, we have theoretically and empirically demonstrated the convergence of IMRank. Indeed, the convergence of
IMRank could be aﬀected by the accuracy of marginal inﬂuence spread estimation. Extensive experiments further show
IMRank with the LFA strategy always quickly converges to
desirable rankings in Section 6.

4.3 Convergence of IMRank
In this section, we ﬁrst theoretically prove the convergence
of IMRank. Then we illustrate the quick convergence of
IMRank empirically using a real-word network as example.
Theorem 2. Starting from any initial ranking of
nodes, IMRank converges to a self-consistent ranking
after a finite number of iterations.
Proof. We ﬁrst prove that, for any k, the inﬂuence
spread of the top-k nodes, denoted as I(k) for convenience,
is nondecreasing in the iterative process of IMRank.
After each iteration of IMRank, a ranking r is adjusted
to another ranking r′ . Since IMRank adjusts all nodes in
decreasing order of their current ranking-based inﬂuence
spread Mr (v), the values of Mr (vri′ )(1 ≤ i ≤ k) are the
largest
k values among
∑
∑all the Mr (v). Hence, there is Ir (k) =
′
M (v ) ≤
Moreover, Ir (k) =
1≤i≤k Mr (vri ).
∑1≤i≤k r ri
′
M
(v
)
iﬀ
the
sets
of
top-k
nodes
in ranking r and
r
ri
1≤i≤k
∑
r′ are the same, otherwise Ir (k) < 1≤i≤k Mr (vri′ ).
Now let’s consider a new ranking r′′ obtained from just
reordering the top-k nodes of ranking r′ in decreasing order
of their ranks in ranking r, and keeping the ranks of other
nodes still. Apparently, the sets of top-k nodes are the
same between ranking r′ and r′′ , thus Ir′ (k) = Ir′′ (k).
Then, for each node vri′ , the set of nodes ranked higher
than it in ranking r′′ is deﬁnitely a subset of the set of

4.4

Analysis of initial ranking

Since IMRank is guaranteed to converge to a self-consistent
ranking from any initial ranking, it is necessary to extend the
discussion to its dependence on the initial ranking: does an
arbitrary initial ranking results in a unique convergence? If

479

not, what initial ranking corresponds to a better result? We
explore those questions by empirically simulating IMRank
with ﬁve typical initial rankings as follows,
• Random: Nodes are initially ranked randomly;
• Degree: Nodes are initially ranked in descending
order of degrees (undirected networks) or out-degrees
(directed networks);
• InversedDegree: Nodes are initially ranked in ascending order of degrees (undirected networks) or outdegrees (directed networks);
• Strength: Nodes are initially ranked in descending
order of node strengths (undirected networks) or node
out-strengths (directed networks). The node strength
is the sum of all weights on its edges. The node outstrength is the sum of all weights on its out-edges;

(a) Inﬂuence spread

• PageRank: Nodes are initially ranked in descending
order of PageRank scores [2], with the default value
0.15 for the damping factor parameter.
Empirical results on the HEPT dataset under the WIC
model are reported in Figure 3, to compare the performance
of IMRank with diﬀerent initial rankings, as well as the
performance of those rankings alone. We also report the
performance of classic greedy algorithm for comparison,
implemented with CELF optimization [13]. Performance of
IMRank with Random initial ranking and Random ranking
alone are averaged over 50 trials.
With the empirical results we conclude:
• With diﬀerent initial rankings, IMRank could converge
to diﬀerent self-consistent rankings. However, IMRank
consistently improves the initial rankings in terms of
obtained inﬂuence spread.

(b) Running time when k = 50
Figure 3:
Comparison between IMRank with
diﬀerent initial rankings under the WIC model.

5.

ADVANCED IMRANK

In the LFA strategy, a node vri is only allowed to allocate
its inﬂuence score to a higher ranked neighboring node vrj ,
implying an assumption that a node can only be activated
by higher ranked neighbors. That assumption ignores the
possibility that, a lower ranked node vrj activates a higher
ranked node vri by playing the role of an intermediate agent
of another node vrk with k < i. Take the path ⟨v1 , v3 , v2 ⟩
in Figure 1 for example. When v1 is selected as a seed, it is
possible that it activates v3 and then v3 as an intermediate
agent activates v2 .
To combat the above problem, we propose a generalized
LFA strategy that trades a slight increase in running time
for better accuracy in estimating Mr , and therefore improves
the performance of IMRank on inﬂuence spread. The
generalized LFA strategy relaxes the above assumption and
explores inﬂuence paths instead of higher ranked neighbors,
which is introduced below to avoid duplicated computation
that a path is contained in another path.

• Comparable with the greedy algorithm, IMRank with
a “good” initial ranking such as Degree, Strength,
and PageRank shows indistinguishable performance,
shown in a single curve in Figure 3(a). A good initial
ranking prefers nodes with high inﬂuence;
• IMRank with a “neural” initial ranking such as Random ranking also shows fair performance, slightly
poorer than the greedy algorithm and IMRank with
a good initial ranking. A neural initial ranking prefers
no nodes;
• IMRank with a “bad” initial ranking such as InversedDegree ranking shows remarkably improvements upon
the initial ranking alone but is dominated by the
greedy algorithm. A bad initial ranking prefers nodes
with low inﬂuence.
Therefore, IMRank is robust to the selection of initial
ranking, and IMRank works well with an initial ranking
prefering nodes with high inﬂuence, which could be obtained
eﬃciently in practice. A possible explanation is the priori
bias that, a high-ranked node earns more allocated inﬂuence
score than a low-ranked node, even with the same topological circumstance. Thus, it helps IMRank to converge to a
good ranking if inﬂuential nodes are initially ranked high.
Among the three “good” initial rankings with indistinguishable performance, Degree oﬀers a good candidate of
initial ranking, since computing the initial ranking consumes
a large part in the total running time of IMRank, as shown in
Figure 3(b). Moreover, Figure 3(b) also shows that, IMRank
runs more than 4 orders of magnitude faster than traditional
greedy algorithm.

Definition 3. Influence path: Given a ranking r, a
simple path dr (vrj , vri ) = ⟨vrj , · · · , vri ⟩ is an inﬂuence path
if vrj is the only node along the path that is ranked higher
than vri .
Lemma 1. A directed edge ⟨vrj , vri ⟩ is an inﬂuence path
if j < i.
Lemma 2. A node vri allocates inﬂuence score to another
node vrj only along an inﬂuence path dr (vrj , vri ).
Proof. Consider a path dr (vrj , vri ). It is not negligible
only when j < i, since vrj has no chance to trigger a
cascade to activate vri immediately or eventually if j > i.
Besides, vrj has no chance to activate vri along this path

480

if there exists an intermediate node vrk with k < j, since
vrk is triggered earlier. The path should also be neglected
if there exists an intermediate node vrk with j < k < i
to avoid duplicated computation, since the inﬂuence score
allocated from vrk to vrj already contains the fraction that
vrj activates vri , as discussed in Section 4.2. Therefore,
inﬂuence score is allocated though a simple path dr (vrj , vri )
if and only if vrj is the only node along the path that is
ranked higher than vri .
We denote ρr (vri , vrj ) to the probability that vri is
activated by vrj through any inﬂuence path. It is equal to
the probability that at least one inﬂuence path dr (vrj , vri )
has all its nodes activated, minus the probability that vri
is already activated before vrj attempts. ρr (vri , vrj ) can be
obtained as follows,
ρr (vri , vrj ) =

∏
1 −

Figure 4:
IMRank.

Impact of l on the performance of

be carefully selected according to the expected accuracy and
aﬀordable computational cost.

(1 − p(dr ))

dr ∈Dr (vrj ,vri )

∏

6.

(1 − ρr (vri , vrk )) ,

EXPERIMENTS

In this section, we evaluate IMRank on real-world networks by comparing IMRank with state-of-the-art inﬂuence
maximization algorithms.

1≤k<i

(2)
∏
where p(dr ) = ⟨vr ,vr ⟩∈dr pvrx ,vry is the joint probabilx
y
ity that vrj activates all nodes on a path dr , and Dr (vri , vrj )
denotes the set of all inﬂuence paths from vrj to vri .
To summarize, the generalized LFA strategy replaces the
allocating method: a node vri delivers a fraction of its
inﬂuence score to each higher ranked node reachable with
an inﬂuence path, instead of each higher ranked neighbor,
while replacing p(·, vri ) with ρ(·, vri ).
In practice, we limit the search range within inﬂuence
paths no longer than l hops, since long paths are expensive
to count but contribute little due to low probability to
propagate inﬂuence. The LFA strategy is a special case of
the generalized LFA strategy with l = 1.
The time and space complexity of IMRank with the
generalized LFA strategy is low. Its space complexity is
O(n), storing the value of Mr (v) for each node. Its time
complexity mainly depends on l. We denote dmax to the
largest number of paths end in an arbitrary node with length
no more than l. The time required for scanning each node
is O(dmax log dmax ), including the time used for searching
candidate nodes, sorting candidate nodes by their ranks, and
allocating inﬂuence. Finally, the time complexity of IMRank
is O(nT dmax log dmax ), where T is the number of iterations
IMRank takes before convergence. According to extensive
experiment results, T is always signiﬁcantly smaller than k.
Besides, dmax is usually much smaller than n, e.g. dmax
equals to the largest indegree among all nodes when l = 1.
Therefore, the running time of IMRank is aﬀordable.
Figure 4 shows the impact of l on the performance of
IMRank, measured with the inﬂuence spread on the NEPT
network with WIC model and k = 50 for example. We
report the results of IMRank with Degree and Random
initial rankings and the results for other initial rankings are
similar. When l increases from 1 to 2, there is an obvious
increase on the performance. It supports that a larger l leads
to more accurate estimation of marginal inﬂuence spread,
and thus a better solution. With l > 2, the performance
increases little, because the propagation probabilities of long
paths decrease exponentially with their length, resulting in
little necessity to count long paths. On the other hand, the
running time of IMRank increases rapidly with l, as shown
in the inset ﬁgure of Figure 4. In that case l = 2 is good
enough and fast, while in future practice a suitable l should

6.1
6.1.1

Experimental Setup
Diffusion models

Experiments are conducted under two widely-used independent cascade models:
• Weighted independent cascade (WIC) model
[11]: Each edge (u, v) is assigned a propagation
probability p(u, v) = 1/dv , where dv is the indegree
of node v.
• Trivalency independent cascade (TIC) model
[3]: Each edge is assigned a propagation probability
selected from {0.1,0.01,0.001} in a uniform random
manner, indicating high, medium and low levels of
inﬂuence.

6.1.2

Baseline algorithms

The compared algorithms include two implementations of
IMRank and two state-of-the-art heuristic algorithms, i.e.,
PMIA and IRIE. Details are as follows:
• IMRank1: This is the IMRank with Degree as initial
ranking and l = 1. According to the analysis of
section 4.3, we set its stopping criteria as when the
sets of top-k nodes are the same during two successive
iterations or the iteration runs 10 rounds.
• IMRank2: This is the IMRank with Degree as initial
ranking and l = 2, with the same stopping criteria as
IMRank1.
• PMIA: This heuristic algorithm estimates inﬂuence
spread based on maximum inﬂuence paths [3]. We use
the recommended parameter setting θ = 1/320.
• IRIE: This heuristic algorithm integrates inﬂuence
ranking with inﬂuence estimation [10]. Its parameters
α and θ are setted to be 0.7 and 1/320 respectively,
and the maximum times of iterations for initial round
and subsequent rounds are 20 and 5 respectively as
recommended.

481

(a) WIC model

(b) TIC model

(c) Running Time

Figure 5: Inﬂuence spread and running time on the PHY dataset

(a) WIC model

(b) TIC model

(c) Running Time

Figure 6: Inﬂuence spread and running time on the DBLP dataset
these ﬁve networks based on the consideration that these
networks possess various kinds of relationships and diﬀerent
sizes ranging from hundreds of thousands edges to millions
of edges. Actually we test these algorithms on many other
networks, and the results are similar. Limited by space,
results on these networks are not included in this paper.
All experiments are conducted on a server with 1.9GHz
Quad-Core AMD Opteron(tm) Processor 8347HEx4 and
64G memory.

Table 3: Statistics of test networks
Datasets
#Nodes #Edges Directed?
PHY
DBLP
EPINIONS
DOUBAN
LIVEJOURNAL

37K
655K
76K
552K
4M

231K
2M
509K
22M
69M

undirected
undirected
directed
directed
directed

6.2
6.1.3 Datasets

Experimental results

We evaluate IMRank on real-world networks by comparing it with state-of-the-art algorithms. Evaluation metrics
include inﬂuence spread and running time. For the comparison of obtained inﬂuence spread, we test the cases of
k = 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50. For the comparison
of running time, we focus on the typical case k = 50. Each
ﬁgure of Figures 5-8 shows the results on a certain network.
The ﬁrst two subﬁgures give the results of inﬂuence spread
under the WIC model and the TIC model respectively, and
the last one gives the results of running time.
Figure 5 shows the experimental results on the PHY
dataset. Under the WIC model, IMRank2 achieves the
best inﬂuence spread, followed by IMRank1, outperforming
PMIA and IRIE. The distinguished accuracy of IMRank2 is
attributed to the fact that, IMRank2 explores more inﬂuence
paths to accurately estimate marginal inﬂuence spread.
PMIA exhibits the worst performance, 6.3% lower inﬂuence
spread than IMRank2 when k = 50. Under the TIC model,
as shown in Figure 5(b), similar results are obtained, and
the gaps between those algorithms become more visible.
For inﬂuence spread, IMRank2 and IMRank1 are the top
two algorithms while PMIA slightly outperforms IRIE. The
inﬂuence spread obtained by IMRank2 is 13.8% and 12.7%

Experiments are conducted on ﬁve real-world networks,
two undirected scientiﬁc collaboration networks and three
directed online social networks. Table 3 gives basic statistics
of those networks. One of the two scientiﬁc collaboration
networks, denoted as PHY, is obtained from the complete
list of papers of the Physics section of the e-print arXiv
website. The other one, denoted as DBLP, is extracted
from the DBLP Computer Science Bibliography 1 . The
three online social networks are EPINIONS, DOUBAN, and
LIVEJOURNAL 2 , respectively extracted from the websites
of epinions.com, douban.com and livejournal.com. In the
EPINIONS dataset, an edge between two users u and v,
denoted as ⟨u, v⟩, represents that user u trusts user v. In
the DOUBAN dataset [8], an edge between two users u and v
represents that user u follows user v. In the LIVEJOURNAL
network [1], an edge between two users u and v represents
that user u declares user v as his/her friend. We choose
1

http://www.informatik.uni-trier.de/∼ley/db/
EPINIONS and LIVEJOURNAL can be downloaded from
http://snap.stanford.edu/data/. DOUBAN can be obtained
on demand via email to the authors.
2

482

(a) WIC model

(b) TIC model

(c) Running Time

Figure 7: Inﬂuence spread and running time on the EPINIONS dataset

(a) DOUBAN

(b) LIVEJOURNAL

(c) Running Time

Figure 8: Inﬂuence spread and running time on the DOUBAN and LIVEJOURNAL datasets
order of magnitude faster. For the TIC model, IMRank2
achieves the best inﬂuence spread and IMRank1 takes the
second place. Both IMRank1 and IMRank2 signiﬁcantly
outperform PMIA and IRIE. Moreover, the running time of
IMRank1 is only 0.1% of the running time of PMIA and
5% of that of IRIE. With similar running time, IMRank2
achieves signiﬁcant higher inﬂuence spread than that of
PMIA and IRIE.
Figure 8 shows the results on the DOUBAN and LIVEJOURNAL datasets. The number of edges of DOUBAN and
LIVEJOURNAL is 22 millions and 69 millions respectively.
Here we only give the results under the WIC model.
On the DOUBAN network, the four algorithms achieve
comparable inﬂuence spread. However, IMRank1 runs
more than two orders of magnitude faster than PMIA and
more than one order of magnitude faster than IRIE. On
the LIVEJOURNAL network, IMRank2 and IRIE have
similar inﬂuence spread, while IMRank1 follows and PMIA
achieves the lowest inﬂuence spread. Note that IMRank2
runs faster than IRIE, and IMRank1 runs much faster
than PMIA. We do not show the results under the TIC
model since no visible diﬀerence is observed among the four
tested algorithms. This is due to the fact that selecting
one inﬂuential node always achieves a very large inﬂuence
spread on DOUBAN and LIVEJOURNAL networks, and no
increase of inﬂuence spread can be gained by adding a new
seed. Such phenomenon has been observed and discussed
in [11] and [3]. The possible reason is that the inﬂuence
networks generated by the TIC model on the two networks
have a relatively large strongly connected component.
These experiments show that, in diﬀerent scenarios, IMRank consistently perform well while PMIA and IRIE perform unstable. IMRank1 always runs more than one order

higher than that obtained by IRIE and PMIA respectively.
Moreover, as shown in Figure 5(c), IMRank1 and IMRank2
run faster than the competing algorithms under both the two
models. IMRank1 is the fastest one followed by IMRank2
,while PMIA takes the third place and IRIE runs slowest. In
particular, the running times of IRIE and PMIA are 30 times
and 10 times longer than the running time of IMRank1 under
the WIC model respectively, and 18 times and 9 times longer
than that of IMRank1 under the TIC model. With the
running time dramatically reduced, IMRank1 still achieves
better inﬂuence spread which is about 5.5% and 4.5% higher
than that of IRIE and PMIA respectively. The consistent
performance of IMRank1 and IMRank2 demonstrates the
eﬀectiveness of IMRank. The inconsistent performance of
PMIA and IRIE under the two diﬀusion models illustrates
that both PMIA and IRIE are unstable.
Figure 6 shows the results on DBLP dataset. The
four algorithms performs similar on this dataset as on the
PHY dataset. For the WIC model, IMRank2 achieves the
highest inﬂuence spread and IMRank1 is the fastest one.
In particular, when k = 50, the highest inﬂuence spread is
achieved by IMRank2 and its running time is less than PMIA
and IRIE. IMRank1 obtains similar inﬂuence spread to
PMIA and its running time is one order of magnitude smaller
than that of PMIA. For the TIC model, IMRank1, IMRank2
and PMIA achieve very similar inﬂuence spread, which is
signiﬁcantly higher than the inﬂuence spread achieved by
IRIE. Moreover, IMRank1 runs nearly 8 times and 13 times
faster than PMIA and IRIE.
Figure 7 gives the results on EPINIONS dataset. For the
WIC model, IMRank1 and IMRank2 run faster than PMIA
and IRIE. In particular, compared to PMIA, IMRank1 runs
two orders of magnitudes faster and IMRank2 runs one

483

[3] W. Chen, C. Wang, and Y. Wang. Scalable inﬂuence
maximization for prevalent viral marketing in
large-scale social networks. In KDD’10, pages
1029–1038, 2010.
[4] W. Chen, Y. Wang, and S. Yang. Eﬃcient inﬂuence
maximization in social networks. In KDD’09, pages
199–208, 2009.
[5] S. Cheng, H. Shen, J. Huang, G. Zhang, and
X. Cheng. Staticgreedy: Solving the
scalability-accuracy dilemma in inﬂuence
maximization. In CIKM’13, 2013.
[6] P. Domingos and M. Richardson. Mining the network
value of customers. In KDD’01, pages 57–66, 2001.
[7] A. Goyal, W. Lu, and L. V. Lakshmanan. Celf++:
optimizing the greedy algorithm for inﬂuence
maximization in social networks. In WWW’11, pages
47–48, 2011.
[8] J. Huang, X.-Q. Cheng, H.-W. Shen, T. Zhou, and
X. Jin. Exploring social inﬂuence via posterior eﬀect
of word-of-mouth recommendations. In WSDM’12,
WSDM ’12, pages 573–582, 2012.
[9] Q. Jiang, G. Song, C. Gao, Y. Wang, W. Si, and
K. Xie. Simulated annealing based inﬂuence
maximization in social networks. In AAAI’11, 2011.
[10] K. Jung, W. Heo, and W. Chen. Irie: Scalable and
robust inﬂuence maximization in social networks. In
ICDM’12, pages 918–923, 2012.
[11] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing
the spread of inﬂuence through a social network. In
KDD’03, pages 137–146, 2003.
[12] M. Kimura, K. Saito, R. Nakano, and H. Motoda.
Extracting inﬂuential nodes on a social network for
information diﬀusion. Data Mining and Knowledge
Discovery, 20(1):70–97, 2010.
[13] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos,
J. VanBriesen, and N. Glance. Cost-eﬀective outbreak
detection in networks. In KDD’07, pages 420–429,
2007.
[14] M. Mathioudakis, F. Bonchi, C. Castillo, A. Gionis,
and A. Ukkonen. Sparsiﬁcation of inﬂuence networks.
In KDD’11, pages 529–537, 2011.
[15] R. Narayanam and Y. Narahari. A shapley
value-based approach to discover inﬂuential nodes in
social networks. IEEE Transactions on Automation
Science and Engineering, 8(1):130–147, 2011.
[16] M. Richardson and P. Domingos. Mining
knowledge-sharing sites for viral marketing. In
KDD’02, pages 61–70, 2002.
[17] D. Sheldon, B. Dilkina, A. N. Elmachtoub, R. Finseth,
A. Sabharwal, J. Conrad, C. P. Gomes, D. Shmoys,
W. Allen, O. Amundsen, and W. Vaughan.
Maximizing the spread of cascades using network
design. In UAI’10, pages 517–526, 2010.
[18] J. Tang, J. Sun, C. Wang, and Z. Yang. Social
inﬂuence analysis in large-scale networks. In KDD’09,
pages 807–816, 2009.
[19] C. Wang, W. Chen, and Y. Wang. Scalable inﬂuence
maximization for independent cascade model in
large-scale social networks. Data Mining and
Knowledge Discovery, 25(3):545–576, 2012.
[20] Y. Wang, G. Cong, G. Song, and K. Xie.
Community-based greedy algorithm for mining top-k
inﬂuential nodes in mobile social networks. In
KDD’10, pages 1039–1048, 2010.

of magnitude faster than PMIA and IRIE, and achieves
similar inﬂuence spread as them. IMRank2 consistently
provides better inﬂuence spread than PMIA and IRIE, and
runs faster than them. In addition, under the two diﬀerent diﬀusion models, IMRank shows similar improvements
on inﬂuence spread from the relative improvement angle.
However, the improvements of IMRank seems more visible
under the TIC model. With respect to this model, the
links between inﬂuential nodes have high probability to be
assigned a relative high propagation probability(p = 0.1),
which counts against heuristic methods to accurate estimate
inﬂuence spread. Hence, we speculate that, IMRank has
more advantages than PMIA and IRIE to handle such cases.

7. CONCLUSIONS
In this paper, we investigated inﬂuence maximization
from a novel ranking perspective. We proposed an eﬃcient
iterative framework IMRank to explore the beneﬁts of
accurate greedy algorithms and eﬃcient heuristic estimation
of inﬂuence spread. This framework eﬀectively tunes any
initial ranking into a self-consistent ranking in an iterative
manner through fully leveraging the interplay between the
ranking of nodes and their ranking-based marginal inﬂuence
spread. A last-to-ﬁrst allocating strategy is further proposed
to eﬃciently estimate the ranking-based marginal inﬂuence
spread under the independent cascade model. This strategy
is elaborately designed according to the characteristics
of the independent cascade model and the ranking-based
marginal inﬂuence spread. We further generalize the lastto-ﬁrst allocating strategy in order to achieve more accurate
estimation. We also prove the convergence of IMRank and
analyze the impact of initial ranking. Moreover, IMRank
always works well with simple heuristic rankings, such as
degree, strength. Extensive experiments on large scale realworld social networks demonstrate the eﬃciency of IMRank.
Its scalability outperforms the state-of-the-art heuristics
while its accuracy is comparable to the greedy algorithms.
For future work, we will try to analyze the accuracy of
IMRank theoretically. Moreover, we believe our proposed
iterative framework is of generality for some cases which
greedy algorithm is suitable for, and it can also be adapted
in some re-ranking applications. We will try to extend it
to other problems beyond inﬂuence maximization, such as
diversity problem in information retrieval.

8. ACKNOWLEDGMENTS
This work was funded by the National Basic Research
Program of China (973 program) under grant numbers
(2012CB316303, 2013CB329602), and the National Natural
Science Foundation of China with Nos 61202215, 61174152,
61232010, 61202213, and 11305219. The authors thank Wei
Chen for providing the codes of the PMIA algorithm, and
thank Kyomin Jung for providing the codes of the IRIE
algorithm. The authors also thank to the members of the
group NASC (www.groupnasc.org) for helpful discussions.

9. REFERENCES
[1] L. Backstrom, D. Huttenlocher, J. Kleinberg, and
X. Lan. Group formation in large social networks:
membership, growth, and evolution. In KDD’06, pages
44–54, 2006.
[2] S. Brin and L. Page. The anatomy of a large-scale
hypertextual web search engine. In WWW’98, pages
107–117, 1998.

484


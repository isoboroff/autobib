Coarse-to-Fine Review Selection via Supervised Joint
Aspect and Sentiment Model
Zhen Hai, Gao Cong, Kuiyu Chang, Wenting Liu, Peng Cheng
School of Computer Engineering, Nanyang Technological University
50 Nanyang Avenue, Singapore 639798

{haiz0001, gaocong, askychang, wliu7, pcheng1}@ntu.edu.sg
ABSTRACT

1. INTRODUCTION

Online reviews are immensely valuable for customers to make
informed purchase decisions and for businesses to improve
the quality of their products and services. However, customer reviews grow exponentially while varying greatly in
quality. It is generally very tedious and difficult, if not impossible, for users to read though the huge amount of review
data for decision-making. Fortunately, review quality evaluation enables a system to recommend automatically the
most helpful reviews to users. Previous studies predict only
the overall review utility about a product, and often focus on
developing different data features to learn a quality function
for the problem. In this paper, we aim to select the most
helpful reviews not only at the product level, but also at a
fine-grained product aspect level. We propose a novel supervised joint aspect and sentiment model (SJASM), which is a
probabilistic topic modeling framework that jointly discovers aspects and sentiments guided by a review helpfulness
metric. One key advantage of SJASM is its ability to infer
the underlying aspects and sentiments, which are indicative
of the helpfulness of a review. We validate SJASM using
publicly available review data, and our experimental results
demonstrate the superiority of SJASM over several competing models.

Nowadays, customers readily create textual reviews to
share their hands-on experiences and opinions on the purchased products or services on websites such as Amazon 1 .
Online reviews are immensely valuable because: 1) They
have become an inevitable part of the decision making process on product purchases, hotel bookings, etc. According
to a survey, a massive 88% of respondents agreed that they
â€œsometimes or alwaysâ€ consult customer reviews prior to
making a purchase 2 ; and 2) They collectively form a lowcost and efficient feedback channel for businesses to keep
track of their reputation and customer sentiments, which
can be used to improve the quality of their products and
services.
However, customer reviews are constantly growing in quantity, while varying greatly in quality or helpfulness. A popular product can easily accumulate hundreds or even thousands of online reviews within a very short period of time.
For instance, the book â€œHarry Potter and the Half-Blood
Princeâ€ on Amazon had received 4,193 customer reviews by
January 24, 2014. Among the large number of reviews, the
helpful and high-quality reviews are usually intermixed with
the useless ones. It is thus practically impossible for users to
read through such large number of reviews for good decisionmaking.
Some existing e-commerce websites already provide a crowdsource mechanism to evaluate review quality. For instance,
Amazon allows customers to vote each product review as
helpful or unhelpful. As a matter of fact, a good many of
reviews of the unpopular products receive very few or no
votes at all. As a result, decisions made using the online
sparse voting information alone tend to suffer from bias,
and are perhaps unreliable. Moreover, no websites currently
provide a mechanism for assessing the review utility at the
fine-grained aspect level.
By formulating the review utility prediction simply as a
regression or classification problem, previous studies mainly
focus on defining data features, on which a review utility
function can be then learnt [7, 20, 11, 13, 3]. Further, all
the existing approaches are proposed for review utility prediction at the product level. In other words, the approaches
cannot be used to detect product aspects and therefore to
select the most useful reviews at the fine-grained product
aspect level. In reality, savvy consumers not only want to
read the most helpful reviews for a product, but also are

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Text Mining;
I.2.7 [Artificial Intelligence]: Natural language Processingâ€”Text Analysis

General Terms
Algorithms, Experimentation

Keywords
review selection; review helpfulness; supervised joint topic
model; sentiment analysis
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIRâ€™14, July 6â€“11, 2014, Gold Coast , Queensland, Australia.
Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.
http://dx.doi.org/10.1145/2600428.2609570 .

1

http://www.amazon.com/
http://www.reevoo.com/about-us/press-releases/halfconsumers-find-social-content-useful-when-shopping-online
2

617

eager to know what aspects are evaluated in reviews, and
which reviews are the most useful for learning the individual
aspects of the reviewed product. Such fine-grained review
utility information may very well tip the balance in customer
purchase decisions. Additionally, in opinion summarization
system, incorporating the selected useful reviews with the
summarized compact sentiment analysis results could provide much more informative first-hand experiences to users.
In this work, we focus on the problem of review helpfulness/utility prediction and review selection from coarse
grain (product-level) to fine grain (aspect-level), namely,
coarse-to-fine review selection. In particular, we study three
closely related problems as described below:

model called SJASM. One key advantage of SJASM is
its ability to infer the hidden aspects and sentiments
which are indicative of the helpfulness voting of a review.
â€¢ We employ SJASM to address the coarse-to-fine review
recommendation problem. As far as we know, our approach is the first to apply topic modeling technique
to the problem of review helpfulness/utility prediction
and review selection.

2. RELATED WORK
2.1 Review Utility Prediction

1. Overall review helpfulness prediction. We predict the
overall review helpfulness scores at the product level,
and select the most helpful reviews for each product
in terms of the scores.

Previous work typically focuses on manually coming up
with data features, and then formulating review helpfulness/utility prediction as a regression or classification problem on these features.
Kim et al. [7] proposed to utilize five classes of textual
features to estimate the helpfulness of a review. They found
that the most useful features were the length of review, unigrams, and ratings. Zhang and Varadarajan [20] built regression models by incorporating a diverse set of textual
features. They claimed that the shallow syntactic features
turned out to be the most influential predictors, which indicates that the utility of a review highly depends on its
linguistic style. To predict the helpfulness of online reviews,
Liu et al. [12] used a regression model based on the data features like the reviewerâ€™s expertise, the review writing style,
and the timeliness of a review. Ghose and Ipeirotis [3] proposed to exploit the text-related features, such as subjectivity, readability, and linguistic correctness, to estimate the
helpfulness of product reviews. Two other classificationbased approaches were developed to recommend the most
helpful reviews by filtering out the low-quality ones in [11,
16]. Further, to improve the textual feature based review
quality predictor, Lu et al. [13] proposed to exploit social
contextual information about reviewersâ€™ identities and social
networks.
All of the aforementioned existing studies focus on only
predicting the review helpfulness/utility/quality with regard
to a whole reviewed product, with the objective to recommend/select the most helpful reviews at the product level.
However, when faced with fine-grained aspect-level helpful
review selection problem, the previous studies may become
useless.

2. Aspect detection. We detect the individual product aspects that are evaluated in customer reviews, in order
to address the fine-grained review selection problem.
3. Aspect-based review utility estimation. For each detected product aspect, we estimate the aspect-based
review utility scores, and then recommend the most
useful reviews for the aspect in terms of the scores.
It is observed that online customer reviews often come
with helpfulness voting, for instance, in the form of â€œx of y
people found the following review helpfulâ€ on Amazon. Typically, a customer review is helpful in the sense that the
review: 1) mentions the particular attributes, components,
or aspects of a commented product, and 2) expresses pertinent sentiments, opinions, and evaluations on such specific
aspects. We propose to model the helpfulness voting of a
review in a unified framework to supervise the inference process of underlying aspects and sentiments in the review. In
addition, the vast majority of existing topic modeling approaches use the bag-of-words (BOW) representation of a
document. Differently, we reduce each review document as
a bag of opinion pairs (BOOP), and then model each pair of
aspect term and its associated opinion word simultaneously
in the unified framework.
We propose a novel supervised joint aspect and sentiment model (SJASM), which is a probabilistic topic modeling framework that jointly detects aspects and sentiments
from reviews under the supervision of the helpfulness voting
data. One key advantage of SJASM is that it can discover
the underlying sentimental aspects which are predictive of
the review helpfulness voting. We then apply it to the review helpfulness/utility prediction to address the coarse-tofine review selection problem. We evaluate SJASM using
three publicly available review collections, and experimentally show the improved effectiveness of the proposed model
against benchmark models.
We summarize our contributions as follows:

2.2 Probabilistic Topic Models

â€¢ We define a new problem in opinion mining field, namely,
aspect-based review selection. To the best of our knowledge, this is the first work that addresses the review
utility prediction and helpful review selection with regard to individual aspects of a reviewed product.
â€¢ By incorporating the helpfulness voting into a unified
framework, we propose a novel supervised joint topic

618

Topic modeling algorithms aim to uncover the hidden topical structure of a document collection [2, 5]. Blei et al.
[2] proposed the first latent Dirichlet allocation (LDA), in
which a document is modeled as a mixture over a latent set
of topics, where each topic is modeled by a distribution over
words. Based on LDA, many other topic models have been
developed to address review mining problems.
Titov and McDonald [17] developed a joint topic model of
text and aspect ratings, called multi-aspect sentiment model
(MAS). MAS can identify latent topics in customer reviews
and extract textual evidence from the reviews supporting
each of the aspect ratings. But the assumption of MAS that
every aspect-based sentiment rating is present in review data
may lead to its limited use in reality. This is because a large
quantity of online reviews have not been annotated with

aspects as well as the aspect-specific sentiment ratings by
customers.
Lin and He [9] extended LDA by designing a new sentiment layer, and proposed a joint sentiment-topic model
(JST), which is based on the assumption that topic generation depends on sentiments, and word generation is dependent on the sentiment-topic pairs. Lin et al. [10] then
extended JST by incorporating sentiment priors, and introduced a weakly supervised joint sentiment-topic model. The
supervision knowledge comes from a domain independent
sentiment lexicon. The weakly supervised JST model may
yield improved performance compared to the unsupervised
one, however suffers from two problems: 1) The inference
of the sentiment labels for the out-of-lexicon expressions becomes unsupervised, negating the supervised advantage; and
2) The detection of underlying topics is completely unsupervised.
Jo and Oh [6] proposed a sentence-LDA model, and then
extended the model to an aspect and sentiment unification
model (ASUM), which detects sentiments toward different
aspects in a unified framework. A sentiment lexicon was
also incorporated in the model. One limitation of ASUM is
its assumption that each review sentence contains exactly
one aspect is often violated when modeling the long and
complicated real-world reviews. Moghaddam and Ester [15]
developed an interdependent LDA model (ILDA) to jointly
detect hidden aspects and sentiments from product reviews.
Wang et al. [19] proposed a latent aspect rating analysis
model (LARAM) to discover latent aspects and their sentiment ratings. But one challenge that remains in LARAM
is the aspect segmentation, which may provide inaccurate
segments for the subsequent aspect-specific rating analysis
task.
All of the topic models mentioned above were introduced
primarily for classifying the sentiments on the latent aspects
in each review, but not for predicting the helpfulness of the
review. Though benefitting from the modeling of the subjective and objective information in individual reviews, they
cannot model the review helpfulness voting information in
their frameworks, and will be thus less successful for discovering the topical structure of review data for the review
helpfulness analysis tasks.
Blei and McAuliffe [1] developed a supervised latent Dirichlet allocation model (sLDA), a statistical model of labelled
documents. Though sLDA can be used to model the review
document and helpfulness voting pairs, it cannot discover
the sentiments expressed towards the hidden topics in reviews, simply due to no sentiment analysis module designed
in the structure.
Our supervised joint topic model SJASM is related to but
different from the aforementioned topic models. The incorporation of review helpfulness voting into the modeling
framework enables SJASM to exploit the supervision information to guide the inference process of underlying aspects
and aspect-specific sentiments in each review. One key advantage of our proposed model is the identified sentimental
aspects are predictive of review helpfulness response.

3.

appears typically as noun or noun phrase in customer reviews. For example, in this review sentence, â€œThe price is
too expensive for meâ€, the noun â€œpriceâ€ is an aspect term.
Opinion Word: An opinion word o refers to the word
used to express subjectivity, opinion, and sentiment in a review. It occurs typically as an adjective in review sentences.
The adjective â€œexpensiveâ€ in the above example is an opinion
word.
Aspect: An aspect a refers to a unique ratable attribute
or component of an entity. In our model setting, it is also
known as an underlying topic, and typically clusters a set
of semantically related aspect terms and opinion words. For
instance, we can infer a hidden aspect â€œpriceâ€ via the opinion
word â€œpriceyâ€ in this sentence â€œIt is really too priceyâ€.
Sentiment: A sentiment s refers to the opinion/sentiment
orientation expressed on the aspects of an entity or the entity itself. In our work it also indicates a sentimental cluster
which groups the opinion words with the same sentimental orientation. Typically, the sentiment orientation can be
represented in sentimental labels such as positive, negative,
and neutral, or in sentimental ratings like 1-to-5 star ratings. For instance, a negative sentiment is expressed on the
underlying aspect â€œpriceâ€ via the opinion word â€œpriceyâ€ in
the above example.
Opinion Pair: An opinion pair op = ht, oi is defined as
a pair of aspect term t and its corresponding opinion word
o extracted from a customer review. For instance, we can
extract an opinion pair hprice, expensivei from this review
sentence â€œThe price is really expensive for meâ€.
Helpfulness: The helpfulness h of a review indicates the
utility or usefulness of the review to fellow users for making
decisions.
Next, given a product from a category, there is a collection
of M customer reviews R = {r1 , r2 , . . . , rM } for the product,
where each review rm is reduced to a set of Nm opinion
pairs rm = {ht1 , o1 i, ht2 , o2 i, . . . , htNm , oNm i}. We define the
problems to be addressed in this work below:
Overall Review Helpfulness Prediction: This task
is to predict the overall helpfulness score hm of a review
rm with regard to a reviewed product. The most helpful
reviews will be then selected in terms of the scores hm for
the product itself.
Aspect Detection: This task aims to discover the K ratable product aspects ak evaluated in the collection of reviews
R, typically by clustering the synonymous or semantically
related keywords (aspect terms or opinion words) appearing
in the reviews. For example, the aspect â€œpriceâ€ can be inferred from such semantically related keywords like â€œpriceâ€,
â€œcostâ€ â€œpriceyâ€, and â€œexpensiveâ€.
Aspect-based Review Utility Estimation: This task
is to estimate the fine-grained aspect-based utility score hmk
of the review rm with regard to a particular aspect ak . Then,
a list of useful reviews will be recommended based on the
utility scores hmk for the detected aspect ak .

4. PROPOSED MODEL
By incorporating the review helpfulness voting information into a unified framework, we propose a novel probabilistic graphical model called Supervised Joint Aspect and
Sentiment Model (SJASM) to address the problems defined
above. SJASM simultaneously models the pairwise aspect
terms and their corresponding opinion words in a review,
and jointly detects the underlying aspects and sentiments

PROBLEM DEFINITION

We define some terminologies, followed by the definitions
of the problems that we will address in this paper.
Aspect Term: An aspect term t indicates an attribute,
a component, or a feature of an entity (e.g., product), which

619

È˜

Table 1: Notations of SJASM
M
Nm
K
L
tmn
omn
amn
smn
hm
Î¸m
Ï€mk
Ïˆk
Ï†kl
Î±
Î³
Î»
Î²
Î·
Ïƒ2
U
V
am,âˆ’n
sm,âˆ’n
n(k)
m
(l)
nm,k

ÈŸP
DPQ

È

WPQ

È¯N

KP
Èª

È¢
.

RPQ

VPQ

QÏµ>1P@

È­NO

È™

. /

È§PN
.

PÏµ>0@

Èš
Figure 1: Graphical model representation of Supervised Joint Aspect and Sentiment Model.
under the supervision of the helpfulness voting of the review. One key advantage of SJASM is that it can identify
the sentimental aspects that are predictive of the helpfulness
of a customer review.
We make the following assumptions for the generative process of SJASM:

(u)

nk
(v)
nk,l

number of review documents in a corpus
number of opinion pairs in review rm
number of aspects
number of sentiments
aspect term in the nth opinion pair of review rm
opinion word in the nth opinion pair of review rm
aspect assignment to tmn and omn
sentiment assignment to opinion word omn
helpfulness of review rm
aspect distribution in review document rm
sentiment distribution on aspect k in review rm
aspect word distribution for aspect k
opinion word distribution for aspect k and sentiment l
Dirichlet parameter for aspect distribution
Dirichlet parameter for sentiment distribution
Dirichlet parameter for aspect word distribution
Dirichlet parameter for opinion word distribution
helpfulness response parameter
helpfulness response parameter
number of unique aspect words in vocabulary
number of unique opinion words in vocabulary
all aspect assignments except for amn
all sentiment assignments except for smn
count of aspect k being assigned to words in review rm
count of sentiment l being assigned to words
that are also assigned to aspect k in review rm
count of unique aspect word u assigned to aspect k
count of word v assigned to aspect k and sentiment l

1. For each aspect k âˆˆ {1, . . . , K}
(a) Draw aspect word distribution Ïˆk âˆ¼ Dir(Î»).

â€¢ Sentiment generation depends on aspects. We first
generate a hidden aspect, on which we subsequently
generate the associated sentiment orientation. This is
because different product aspects have different utility
quality, and thus leads to different sentimental experiences and evaluations.

(b) For each sentiment orientation l âˆˆ {1, . . . , L}

i. Draw opinion word distribution Ï†kl âˆ¼ Dir(Î²).

2. For each review rm and its helpfulness response hm
(a) Draw aspect distribution Î¸m âˆ¼ Dir(Î±).

(b) For each aspect k under review rm

â€¢ Opinion word generation depends on both sentiment
and aspect, while aspect term generation depends on
the aspect itself. For instance, the generation of an
opinion word â€œexpensiveâ€ is dependent not only on the
sentiment orientation â€œnegativeâ€ but also on the aspect
â€œpriceâ€.

i. Draw sentiment distribution Ï€mk âˆ¼ Dir(Î³).

(c) For each opinion pair htmn , omn i, n âˆˆ {1, . . . , Nm }
i.
ii.
iii.
iv.

â€¢ The generation of helpfulness voting of a review depends on the generated hidden aspects and sentiments
in the review. It is intuitive, since the helpfulness of
a review will be voted high if the review describes the
particular aspects of a product and also expresses the
pertinent sentiments on the aspects.

Draw
Draw
Draw
Draw

aspect amn âˆ¼ Mult(Î¸m ).
sentiment smn âˆ¼ Mult(Ï€mamn ).
aspect term tmn âˆ¼ Mult(Ïˆamn ).
opinion word omn âˆ¼ Mult(Ï†amn smn ).

(d) Draw helpfulness hm âˆ¼ N(Î· T zÌ„m , Ïƒ 2 ), where we
define
1X
(amn Ã— (Ï‰ T Ã— smn ))
C n=1
Nm

zÌ„m =

Based on the assumptions, to generate a review document
and the helpfulness response by SJASM, underlying aspects
are first generated conditioned on the document-specific aspect distribution. The sentiments are then generated conditioned on the generated aspects as well as the documentspecific sentiment distribution. Next, the aspect term and
opinion word in every opinion pair of the review are generated conditioned on their corresponding aspect and sentiment. Review helpfulness response is finally generated conditioned on the realized aspect and sentiment assignments
in the review.
The graphical model representation of SJASM is shown
in Figure 1, and the notations used in this model are listed
in Table 1. The generative process of the graphical model is
as follows:

(1)

In Equation 1, zÌ„m represents the combined empirical frequencies of the underlying aspects and sentiments in a review rm , where C is a normalization constant, and Ï‰ is
a weight vector for sentiment orientations (labels/ratings),
which can be obtained experimentally from data.
The real-valued helpfulness response hm is drawn from a
normal linear model, where the quantity zÌ„m works as the
covariates, and Î· indicates the regression coefficients, while
the parameters Î· T zÌ„m and Ïƒ 2 are the mean and variance
of the normal distribution. We regress the helpfulness response on the empirical frequencies of the hidden aspects
and sentiments generated in the review. This means that
the aspect terms and opinion words as well as their aspect
and sentiment assignments in the review are generated first,

620

The document-aspect sentiment distribution is computed
by:

then, based on the aspects and sentiments of the review, the
helpfulness response is generated.
The formulation agrees with the intuition that reviews
that clearly convey positive or negative evaluations on the
specific aspects of a product could be more constructive and
informed, and should be selected for use.

(l)

Ï€m,k,l = PL

nm,k + Î³
(lâ€²)

lâ€²=1

nm,k + LÎ³

.

(5)

The aspect word distribution is computed by:
(u)

5.

INFERENCE AND PREDICTION

Ïˆk,u = PU

In this section, we describe the approximate inference and
parameter estimation procedure for SJASM. We also describe how to apply SJASM to review helpfulness prediction
and review selection problem.

(l)

(v)

(u)

{nk }âˆ’n + U Î»

Ã—

{nk,l }âˆ’n + Î²

(vâ€²)

nk,l + V Î²

.

Î·Ì‚ â‰ˆ (Z T Z)âˆ’1 Z T h,

(6)

(7)

(8)

where h indicates the helpfulness response vector.
We approximate Ïƒ 2 as follows:

(3)

{nk,l }âˆ’n + V Î²

ÏƒÌ‚ 2 â‰ˆ

2

1
(hm âˆ’ Î· T zÌ„m )
Ã—âˆš
exp{âˆ’
}.
2Ïƒ 2
2Ï€Ïƒ 2

1 T
[h h âˆ’ hT Z(Z T Z)âˆ’1 Z T h].
M

(9)

5.2 Review Helpfulness Prediction and Review
Selection

where am,âˆ’n and sm,âˆ’n are all aspect and sentiment assign(k)
ments, excluding am,n and sm,n , respectively, nm is the
count of aspect k assigned to words in review document rm ,
(l)
nm,k is the count of sentiment l allocated to words that are

Next, we apply SJASM to the review helpfulness prediction and review selection problem.

5.2.1 Product-level Review Selection

(u)

also assigned to aspect k in review rm , nk is the number
of times unique aspect word u is assigned to aspect k, and
(v)
nk,l is the number of times unique opinion word v is assigned to sentiment l as well as to aspect k. The subscript
â€œâˆ’nâ€ in a quantity indicates that the quantity excludes the
(u)
data at the index of n. For example, {nk }âˆ’n indicates the
count of the unique aspect word u being assigned to aspect
k, excluding the aspect term instance of the word u and
the corresponding aspect assignment at the index n. The
notations in Equation 3 are listed in Table 1.
Based on the samples from the full conditional distribution, we compute document aspect distribution as below:

Given a new unlabeled review rmâ€² and a fitted model
{Ïˆk , Ï†kl , Î±, Î³, Î», Î², Î·, Ïƒ 2 }(k : 1, . . . , K; l : 1, . . . , L), our idea
for the overall review helpfulness prediction is to first infer
all the evaluated aspects of the product and their associated sentiments in the review, and then approximately form
the regression function on the posterior mean zÌ„mâ€² , as shown
below:
hÌ‚mâ€² â‰ˆ Î· T zÌ„mâ€² .

(10)

Note that we approximate the posterior mean of zÌ„mâ€² by
applying Gibbs sampling as described in the previous section. However, the terms relying on the helpfulness response
are removed from the sampling formula, as testing reviews
contain no helpfulness annotations.
We estimate the overall helpfulness scores of all the testing
reviews using Equation 10, and recommend the most helpful
reviews for the commented product to users for decisionmaking.

(k)

nm + Î±k
Î¸m,k = PK
.
(kâ€²)
kâ€²=1 nm + Î±kâ€²

.

Previous work has shown that an asymmetric Dirichlet
prior over the document topic distribution has substantial
advantages over a symmetric prior, while an asymmetric
prior over the topic word distribution provides no real benefit [18]. We thus use an asymmetric prior Î± for the document
aspect distribution, while using symmetric priors Î» and Î² for
the aspect word distribution and aspect-sentiment opinion
word distribution, respectively. Note we use symmetric prior
Î³ for the sentiment distribution. In particular, we apply a
fixed-point iteration scheme [14] for the estimation of the
prior Î±. The symmetric prior Î³ is set as 1/L, while both
priors Î» and Î² are specified as the same value 0.01.
We follow Blei and McAuliffe [1] to approximately evaluate the normal linear model parameters Î· and Ïƒ 2 .
Let Z be the M Ã— K matrix whose rows are the vectors
T
zÌ„m
. Then Î· is approximated as follows:

P (amn = k, smn = l | am,âˆ’n , sm,âˆ’n , tm , om , hm , Î±, Î³,

{nk }âˆ’n + Î»

nk,l + Î²

vâ€²=1

The exact inference for this distribution is intractable, due
to the difficulty in the denominator of Equation 2.
At this point, the Gibbs sampling technique comes into
play. Following Griffiths and Steyvers [4] we use a collapsed
Gibbs sampling algorithm for the approximate inference of
SJASM.
We compute the full conditional distribution as follows:3

Ã—

+ UÎ»

(v)

Ï†klv = PV

(2)

(k)
{nm,k }âˆ’n + Î³
{nm }âˆ’n + Î±k
Ã—
PK
{nm,k }âˆ’n + LÎ³
{nm }âˆ’n + kâ€²=1 Î±kâ€²

nk

We compute the aspect-sentiment opinion word distribution as follows:

Our goal of inference is to evaluate the posterior distribution P (a, s | t, o, h), as shown below (parameters are omitted):

Î», Î², Î·, Ïƒ 2 ) âˆ

(uâ€²)

uâ€²=1

5.1 Inference and Parameter Estimation

P (a, s, t, o, h)
P (a, s | t, o, h) = P P
.
a
s P (a, s, t, o, h)

nk + Î»

(4)

3
Derivation of the conditional distribution is omitted due to
page limitation.

621

5.2.2 Aspect-level Review Selection

Table 2: Some Statistics of Review Data Sets

As for the fine-grained aspect-level review selection, we
need to fix two problems, one is to detect aspects, the other
is to estimate the aspect-based utility score of each review.
The aspects are recognized via the aspect word distribution and aspect-sentiment opinion word distribution. Then,
for each aspect, we estimate the aspect-based review utility
score based on two criteria: document aspect distribution
and the predicted review helpfulness. This is because the
reviews to be recommended for an aspect are required to be
not only useful but also relevant to the aspect.
In particular, we approximate the aspect-based utility score
hmâ€²k of the review rmâ€² for the aspect k by weighting the document aspect distribution Î¸mâ€²k with the predicted review
helpfulness hÌ‚mâ€² , as given in the function below:
hÌ‚mâ€²
hÌ‚mâ€²k â‰ˆ Î¸mâ€²k âˆ— P
.
m hÌ‚m

Category
# Reviews
# Words
Vocabulary size
Average # words/review

Video Games
650
129,838
10,733
199

Books
2,500
535,040
20,686
214

Amazon users are allowed to vote whether a review is helpful or not, and the helpfulness voting is represented in the
form â€œx of y people found the following review helpfulâ€. In
our experiments, we used only the reviews with at least 10
votes (i.e., y â‰¥ 10) in order to conduct a fair and reliable
evaluation. We simply estimated the helpfulness h of a review as: h = x/y, and used the score as a golden standard
for the evaluation of overall review helpfulness prediction.
All reviews in each of the three data sets were analyzed
and parsed using the Stanford Parser [8]. We then simply applied the grammatical dependency relations adjectival modifier (â€œamodâ€), direct object (â€œdobjâ€), and nominal subject (â€œnsubjâ€) to opinion pair extraction from each
parsed review. We then extended the extracted set of opinion pairs via applying the dependency relations negation
modifier (â€œnegâ€) and conjunct (â€œconjâ€).
For each corpus we held out 20% of the data for testing
and trained all the models on the remaining 80% of the data.

(11)

We then recommend the most useful reviews for each aspect in terms of the estimated aspect-based utility scores.

6.

Audio CD
1,480
282,477
15,122
190

EXPERIMENT RESULTS

We evaluated SJASM on the problem of review utility
prediction and coarse-to-fine review selection. In particular,
we conducted three types of experimental evaluations:
â€¢ Overall review helpfulness prediction. We predicted
overall helpfulness via SJASM, and selected the most
helpful reviews for a product in terms of the scores.

6.2 Overall Review Helpfulness Prediction
The fitted supervised SJASM and sLDA models were directly employed to form the overall review helpfulness prediction for unlabeled testing reviews. Since JST is weakly
supervised, we relied on a separate regression procedure on
the detected JST topics to do the prediction. We utilized
unigram textual features to learn LR model for prediction.

â€¢ Aspect detection. The aspects commented on in reviews were detected via SJASM, and were then evaluated qualitatively against baseline models.
â€¢ Aspect-based review utility estimation. The aspectbased review utility was estimated based on the review helpfulness and document (review) aspect distribution. The most useful and relevant reviews were
recommended for each detected aspect in terms of the
aspect-based utility scores.

6.2.1 Evaluation via Correlation
We first evaluated SJASM and the baseline models via
Pearson correlation versus the number of aspects (K) while
keeping the sentiment orientation count at 3 (L = 3).

We compared SJASM against three well-established benchmark models: a supervised topic model called supervised
latent Dirichlet allocation (sLDA) [1], a weakly supervised
topic model called joint sentiment-topic (JST) model [10], as
well as a classic linear regression model (LR). Note that: 1)
JST is weakly supervised in the sense that it incorporates a
pre-compiled sentiment lexicon to supervise the generation
of sentiment label, but for the topic/aspect detection, it is
unsupervised; and 2) LR is used only for the evaluation of
overall review helpfulness prediction, as it cannot discover
the latent topical structure of data.

-

"%
"%
"%&

5.,,+6748.9

"%&
"%$
"%$
"%#
"%#
"%!

6.1 Data Sets

:;0:<
1=>0
;:?
=@

"%!
"%" -

We tested SJASM against the baselines using publicly
available review data from three product categories, namely,
Audio CD, Video Games, and Books, which were collected
from Amazon 4 . Some statistics of review data sets are listed
in Table 2. Note each data set contains only the reviews of
one product from each category 5 .

!"

!
#"
'()*+,-./-012+341

#

$"

Figure 2: Correlation versus number of aspects on
Audio CD reviews.
Figure 2 plots the correlation curves against the aspect
number on Audio CD reviews. Only one correlation value
was shown for LR as it cannot mine the hidden topical structure of data.

4

http://liu.cs.uic.edu/download/data/
Audio CD: â€œAmerican Idiotâ€; Video Games: â€œGrand Theft
Auto: San Andreasâ€; Books: â€œHarry Potter and the HalfBlood Princeâ€.
5

622

6.2.2 Evaluation via MSE

SJASM outperforms benchmark models sLDA, JST, and
LR across all the numbers of aspects. The average correlation of SJASM over all the observations is 43.79%, which is
7.23%, 10.86%, and 25.36% better than that of sLDA, JST,
and LR, respectively. The curve of SJASM overall improves
with increasing number of aspects. The largest performance
gain of SJASM over sLDA is 12.47% at aspect number 30,
while the largest gain of SJASM over JST is 15.99% at aspect number 10.

Next, we used mean squared error (MSE) to evaluate
SJASM against baseline models for overall review helpfulness prediction, as shown in Table 3.
SJASM leads to consistently better prediction performance
in MSE (the lower, the better) across all six observations
on the Audio CD reviews. The largest performance gap
between SJASM and sLDA is found at aspect number 15,
where the MSE of sLDA increases by 7.8% with respect to
SJASM. The largest gap between SJASM and JST is located
at aspect number 10, where the MSE of JST increases by
15.2% over SJASM.
On the Video Games review category, the best performance gains of SJASM against the sLDA and JST are located at the same aspect number of 30, where the MSE values of sLDA and JST exceed by 15.3% and 23.4% compared
to the MSE of SJASM.
The best performance gaps of SJASM over sLDA and JST
on the Books category are found at the aspect numbers of
10 and 15, where the MSE values of sLDA and JST exceed
by 8.6% and 8.4% over SJASM, respectively.
The LR model results in MSE scores 0.0639, 0.0609, and
0.1862 on the Audio CD, Video Games, and Books categories, respectively, and loses out to SJASM for the overall
helpfulness prediction.
The experimental results again demonstrated the improved
effectiveness of SJASM compared to the benchmark models
sLDA, JST, and LR on the three review categories. The
main reasons for the improvement of SJASM over the benchmark models may lie in:

0.55
0.5
0.45

Correlation

0.4
0.35
0.3
0.25
0.2
0.15

SJASM
sLDA
JST
LR

0.1
0.05

5

10

15
20
Number of Aspects

25

30

Figure 3: Correlation versus number of aspects on
Video Games reviews.
Figure 3 plots the correlation of SJASM versus the benchmark models on Video Games reviews. SJASM again performs better than the baseline models. As the number of
aspects grows, the SJASM curve increases, exhibiting a similar trend as Figure 2. The average correlation of SJASM
across all the six observations is 46.53%, which is 8.65%,
11.30%, and 25.92% better than that of sLDA, JST, and
LR, respectively.
"%

:;0:<
1=>0
;:?
=@

"%
"%&

â€¢ By jointly modeling the aspects and the aspect-associated
sentiments, we can figure out which positive or negative aspects contribute to the final overall review helpfulness, while sLDA cannot mine such constructive
sentimental topics, simply due to the lack of sentiment
analysis module in its model structure.
â€¢ By modeling helpfulness voting as supervision information, the detected sentimental aspects by SJASM are
predictive of review helpfulness response, compared to
the weakly supervised model JST.

-

5.,,+6748.9

"%&
"%$

â€¢ SJASM benefits from supervised dimensionality reduction, while LR cannot gain from this.

"%$
"%#

Next, we selected the most helpful reviews for each product in terms of the predicted review helpfulness scores. Example results (from testing review data) were listed in Table
4. Due to page limitation, we just showed the major sentences and URLs for the selected reviews (note online review
data may be updated).

"%#
"%!
"%!
"%" -

!"

!
#"
'()*+,-./-012+341

#

$"

6.3 Aspect Detection

Figure 4: Correlation versus number of aspects on
Books reviews.
Figure 4 plots the results on the Books review data. Again,
SJASM results in better performance compared to sLDA,
JST, and LR. The average correlation score of SJASM across
all the observations is 28.13%, which is 5.79%, 9.59%, and
18.78% larger than that of sLDA, JST, and LR, respectively.
The proposed SJASM outperforms the state-of-the-art topic
models sLDA and JST, as well as one classic linear regression model for the overall review helpfulness prediction.

623

In this section, we qualitatively evaluated the aspect detection of SJASM against sLDA and JST on the Audio CD,
Video Game, and Books categories. For every category, we
showed one same aspect detected by each model, given the
aspect number K at which the minimum MSE was achieved
for that model.
Table 5 lists an example aspect â€œlyricsâ€ on Audio CD reviews. Note for SJASM we showed the aspect terms and
opinion words semantically related to the aspect in column
1 and column 2 (first 5 opinion words are positive, the follow-

Table 3: MSE of SJASM versus Benchmark Models
Aspects 5
10
15
20
25
30
Audio CD
SJASM 0.0380Â±0.0002
0.0356Â±0.0003
0.0357Â±0.0005
0.0344Â±0.0004
0.0356Â±0.0002
0.0361Â±0.0010
sLDA
0.0384Â±0.0001(1.1%) 0.0377Â±0.0001(5.9%) 0.0385Â±0.0010(7.8%) 0.0362Â±0.0003(5.2%) 0.0356Â±0.0005(0.0%) 0.0383Â±0.0007(6.1%)
JST
0.0403Â±0.0006(6.1%) 0.0410Â±0.0006(15.2%) 0.0393Â±0.0004(10.1%) 0.0357Â±0.0005(3.8%) 0.0389Â±0.0009(9.3%) 0.0401Â±0.0007(11.1%)
LR
0.0639
Video Games
SJASM 0.0242Â±0.0003
0.0264Â±0.0010
0.0243Â±0.0006
0.0223Â±0.0002
0.0245Â±0.0008
0.0248Â±0.0005
sLDA
0.0270Â±0.0003(11.6%) 0.0276Â±0.0004(4.6%) 0.0256Â±0.0002(5.4%) 0.0249Â±0.0003(11.7%) 0.0250Â±0.0006(2.0%) 0.0286Â±0.0003(15.3%)
JST
0.0292Â±0.0005(20.7%) 0.0277Â±0.0005(4.9%) 0.0268Â±0.0004(10.3%) 0.0245Â±0.0006(9.9%) 0.0293Â±0.0009(19.6%) 0.0306Â±0.0010(23.4%)
LR
0.0609
Books
SJASM 0.0414Â±0.0002
0.0406Â±0.0003
0.0403Â±0.0005
0.0408Â±0.0005
0.0409Â±0.0005
0.0395Â±0.0005
sLDA
0.0433Â±0.0003(4.6%) 0.0441Â±0.0001(8.6%) 0.0430Â±0.0001(6.7%) 0.0415Â±0.0001(1.7%) 0.0418Â±0.0003(2.2%) 0.0418Â±0.0001(5.8%)
JST
0.0437Â±0.0001(5.6%) 0.0435Â±0.0001(7.1%) 0.0437Â±0.0003(8.4%) 0.0437Â±0.0005(7.1%) 0.0434Â±0.0001(6.1%) 0.0422Â±0.0005(6.8%)
LR
0.1862

Table 4: Product-level Review Selection Results
Products
â€œAmerican Idiotâ€
@ Audio CD
â€œGrand Theft Auto:
San Andreasâ€
@ Video Games
â€œHarry Potter and the
Half-Blood Princeâ€
@ Books

Reviews
â€œA True Masterpiece... With this album, Green Day has made their opus. From the title track â€œAmerican Idiotâ€
to the final act in â€œWhatsernameâ€ Green Days is able to bring the listener the closest to aural bliss... I highly
recommend this album to anyone.â€ http://www.amazon.com/review/R9SZB2VH39N9K/ref=cm_srch_res_rtr_alt_2
â€œDIDNT LIVE UP. GTA: San Andreas did not live up to its expectations... PROBLEMS: 1. Even though the
map is HUGE it is way to hard to find your way around... GOOD STUFF 1. The freedom is great... 2. YOU
CAN GO TO CASINOâ€™S AND PLAY...â€ http://www.amazon.com/review/R6KVMDRC2JAGR/ref=cm_srch_res_rtr_alt_2
â€œA book to just fill in the gap. This has been a below par effort by Rowling... The story does not move... Also the
mention of Quidditch now and then was an irritation with the games having no real meaning... The death of a key
character...deserved a more fitting end...â€ http://www.amazon.com/review/R172CBMAV010JS/ref=cm_srch_res_rtr_alt_1

Table 5: Example Aspect on Audio CD Reviews
SJASM
lyrics
views
life
government
Bush
messages
kid
Republican
bush
losers

â€œlyricsâ€ @ Audio CD
sLDA
lyrical
lyrics
bad
real
serious
Bush
true
enjoyable
contemporary
rock
idea
rebel
conservative
messages
unoriginal
conservative
metal
bashing
mindless
liberal

Table 6: Example Aspect on Video Games Reviews
â€œgameplayâ€ @
SJASM
map
graphic
fan
played
features
greatest
gameplay
realistic
game
real
vehicles
hard
driving
terrible
weapons
boring
level
bloody
action
dull

JST
great
lyrics
political
best
fan
CD
conservative
kids
Republican
masterpiece

ing 5 are negative), respectively, since SJASM models separately both types of words in its unified framework. Both
sLDA and JST fail to do this, the aspect terms and opinion
words recognized for the aspect by the two models are mixed
together, as shown in column 3 and 4, respectively.
In particular, the aspect terms recognized for the aspect
â€œlyricsâ€ by SJASM (column 1), such as â€œlyricsâ€, â€œviewsâ€,
â€œlifeâ€, â€œgovernmentâ€, â€œBushâ€, etc., reflect the content of lyrics,
and the keywords are coherent as well as are indicative of
the aspect â€œlyricsâ€. The opinion words (column 2), such as
â€œlyricalâ€, â€œrebelâ€, and â€œconservativeâ€, are also semantically
related to the â€œlyricsâ€ aspect.
sLDA identifies some relevant keywords like â€œlyricsâ€, â€œBushâ€,
â€œconservativeâ€, etc., however, it also recognizes incorrectly
the keywords like â€œrockâ€ and â€œmetalâ€ which are typically
mentioned in the aspect â€œgenreâ€. The keywords recognized
for the aspect by JST contains non-specific terms like â€œCDâ€
and â€œmasterpieceâ€ which usually indicate the audio CD itself.
Table 6 lists a typical example aspect â€œgameplayâ€ on Video
Games category. SJASM again detects a coherent â€œgameplayâ€ aspect which covers the aspect terms, such as â€œmapâ€,
â€œfeaturesâ€, and â€œgameplayâ€, as well as the semantically re-

Video Games
sLDA
JST
missions
big
map
fan
nice
gamer
lose
played
features
greatest
fine
excellent
big
comic
gameplay
gameplay
action
dull
muscle
muscle

lated opinion words, such as â€œgraphicâ€, â€œplayedâ€, â€œrealisticâ€,
and â€œbloodyâ€. sLDA recognizes the semantically related
words like â€œmissionsâ€, â€œmapâ€, and â€œfeaturesâ€, but mixes together the general terms like â€œniceâ€ and â€œfineâ€. Similar to
sLDA, the aspect keywords clustered by JST are not as specific as that by SJASM.

Table 7: Example Aspect on Books Reviews
SJASM
story
life
events
ending
death
fear
climax
scene
world
magic

â€œstoryâ€ @ Books
sLDA
real
life
strong
real
serious
magical
greatest
world
imaginative
right
dark
sense
evil
horrible
sad
tragic
shocking
atmosphere
dramatic
death

JST
ending
Book
shorter
dull
pathetic
shocking
death
potion
matured
killed

Table 7 lists an example aspect â€œstoryâ€ on Books reviews.
The aspect detected by SJASM is specific and coherent enough
in itself, which contains aspect terms, such as â€œstoryâ€ itself,

624

â€œlifeâ€, â€œeventsâ€, â€œendingâ€, and â€œclimaxâ€, as well as the semantically related opinion words like â€œrealâ€, â€œimaginativeâ€,
â€œdarkâ€, and â€œevilâ€, compared to the aspect detection results
by both sLDA and JST, which recognize some non-specific
words like â€œrightâ€, â€œsenseâ€, and â€œBookâ€.
The improvement of SJASM over sLDA and JST for underlying aspect detection is mainly attributed to:

All the models achieve 100% precision at top-1 selected
review for the aspect â€œstoryâ€ on Books category. sLDA results in 40% and 60% precision at top-5 and top-10 selected
reviews, while JST leads to 60% and 50% precision, respectively. Overall, SJASM achieves the best performance with
100% and 80% precision at top-5 and top-10 selected useful
reviews for the aspect.

â€¢ The incorporation of review helpfulness voting information into the modeling framework enables SJASM
to exploit the supervision knowledge to guide the aspect inference process. But JST does not benefit from
such guidance for aspect detection.

Table 9: Aspect-based Review Utility Estimation
Performance on Books Reviews
Aspects
â€œcharacterâ€
@Books

â€¢ SJASM separates and simultaneously models the aspect terms and their corresponding opinion words in
individual opinion pairs to detect the underlying aspects, while both slDA and JST do not gain from this.

â€œplotâ€
@Books
â€œwritingâ€
@Books

Models
SJASM
sLDA
JST
SJASM
sLDA
JST
SJASM
sLDA
JST

P@Top-1
100%
100%
0%
100%
0%
100%
100%
0%
0%

P@Top-5
100%
40%
40%
80%
20%
40%
80%
40%
40%

P@Top-10
70%
60%
50%
70%
50%
50%
80%
50%
60%

6.4 Aspect-based Review Utility Estimation
Further, we evaluated the aspect-based review utility estimation for three more aspects â€œcharacterâ€, â€œplotâ€, and â€œwritingâ€ on Books category, as shown in Table 9. SJASM again
achieves the best performance (P @T op âˆ’ N ) compared to
sLDA and JST.
The improved effectiveness of SJASM over sLDA and JST
for the aspect-based review utility estimation can be attributed to the following reasons:

The recommendation of the most useful reviews for each
detected product aspect is required to satisfy two conditions:
the review must be helpful, and the aspect must be relevant
to the helpful review.
For each aspect, the aspect-based review utility score was
estimated using Equation 11, which incorporates two criteria corresponding to the aforementioned requirements: the
predicted review helpfulness and document-specific aspect
distribution. We selected the most helpful and relevant reviews for each aspect in terms of the aspect-based review
utility scores.
We tested the aspect-based review utility estimation of
SJASM using precision at top N (P @T op âˆ’ N ) selected reviews for each detected aspect, as shown in Table 8.

â€¢ SJASM leads to more coherent and clean aspect detection compared to sLDA and JST.
â€¢ SJASM outperforms the two benchmark models for
review helpfulness prediction on the review corpora.
â€¢ Benefitting from the supervised joint topic modeling
nature, SJASM discovers better the hidden topical structure of review data.

Table 8: Aspect-based Review Utility Estimation
Performance
Aspects
â€œlyricsâ€
@Audio CD
â€œgameplayâ€
@Video
Games
â€œstoryâ€
@Books

Models
SJASM
sLDA
JST
SJASM
sLDA
JST
SJASM
sLDA
JST

P@Top-1
100%
100%
100%
100%
100%
100%
100%
100%
100%

P@Top-5
100%
60%
40%
80%
40%
60%
100%
40%
60%

In addition, we listed the example results for aspect-based
review selection in Table 10.

P@Top-10
80%
50%
50%
80%
40%
40%
80%
60%
50%

7. CONCLUSIONS
In this paper, we focus on selecting the most helpful reviews not only for a reviewed product itself but also for the
evaluated aspects of the product. We propose a novel supervised joint topic model called SJASM to address the coarseto-fine review selection problem. SJASM jointly discovers
underlying aspects and sentiments guided by review helpfulness voting information. One key advantage of SJASM
is that it can detect the sentimental aspects which are predictive of review helpfulness. The evaluation results on the
three publicly available review data sets demonstrated the
superiority of SJASM over a supervised topic model sLDA, a
weakly supervised model JST, as well as a classic LR model.
For future work, we plan to evaluate SJASM on other different product categories for coarse-to-fine review selection
problem.

For the aspect â€œlyricsâ€ on Audio CD category, all evaluated
models achieved 100% precision at the top-1 selected review.
SJASM achieves 100% precision, while both sLDA and JST
have precision of 60% and 40%, respectively, at the top-5
recommended reviews. For the top-10 selected review for
the aspect, SJASM achieves 80% precision, while the two
baseline models sLDA and JST have only 50% precision.
That is, 8 out of top-10 reviews selected by SJASM are truly
useful for the aspect, while only 5 out of 10 reviews selected
by sLDA or JST are useful.
On the Video Games reviews, all models achieve 100%
precision at top-1 recommended review for the aspect â€œgameplayâ€. SJASM reaches 80% precision at top-5 and top-10 selected reviews, while sLDA has only 40% precision for both
cases. JST reaches 60% precision for its top-5 reviews, then
decreases to 40% precision at its top-10 selected reviews for
the aspect.

8. ACKNOWLEDGMENTS
We would like to thank Dr Chenghua Lin and Dr Yulan
He for providing the code of joint sentiment-topic model
(JST). This work was supported in part by a grant awarded
by a Singapore MOE AcRF Tier 2 Grant (ARC30/12) and
a Singapore MOE AcRF Tier 1 Grant (RG 66/12).

625

Table 10: Aspect-based Review Selection Results
Product Aspects
â€œlyricsâ€ @ Audio CD
â€œgameplayâ€ @ Video Games

â€œstoryâ€ @ Books

9.

Reviews
â€œTrue Green Day fans understand that their political views are just that - THEIR political views... Green
Day lyrics are poignant, honest and thought-provoking, itâ€™s the combination of those intelligent lyrics with
their punk attitude music...â€ http://www.amazon.com/review/R1FHPGZ4Q2J162/ref=cm_srch_res_rtr_alt_1
â€œThe Honest Truth... I noticed in playing the first few missions and walking around town, that in trying
to bring realism to this game, the designers left out some of the comic element... I mean, you hear some
of the characters of San Andreas say some funny things, but overall, theyâ€™re silent or too serious, which
makes for dull gameplay... San Andreas is really difficult... designers probably wanted to bring more of a
challenge... Iâ€™m really having a hard time getting to the next level...getting frustrated...â€ (URL not found)
â€œIâ€™ll forgive Rowling for making the story so dark... I could go on and on about death and murders...
But my problem is that very little of this dark imagery has much to do with the story... No action...
The plot is just weak...â€ http://www.amazon.com/review/R16J3QKI1L37LT/ref=cm_srch_res_rtr_alt_3

REFERENCES
[13]

[1] D. M. Blei and J. D. McAuliffe. Supervised topic
models. In Proceedings of the 21st Annual Conference
on Neural Information Processing Systems - Volume 7,
pages 121â€“128, Vancouver, Canada, 2007.
[2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent
dirichlet allocation. J. Mach. Learn. Res., 3:993â€“1022,
March 2003.
[3] A. Ghose and P. Ipeirotis. Estimating the helpfulness
and economic impact of product reviews: Mining text
and reviewer characteristics. IEEE Trans. on Knowl.
and Data Eng., 23(10):1498â€“1512, 2011.
[4] T. L. Griffiths and M. Steyvers. Finding scientific
topics. In Proceedings of the National Academy of
Science, volume 101, pages 5228â€“5235, Jan 2004.
[5] T. Hofmann. Probabilistic latent semantic analysis. In
Proceedings of the 15th Conference on Uncertainty in
Artificial Intelligence, pages 289â€“296, Stockholm,
Sweden, 1999.
[6] Y. Jo and A. H. Oh. Aspect and sentiment unification
model for online review analysis. In Proceedings of the
4th ACM International Conference on Web Search and
Data Mining, pages 815â€“824, Hong Kong, China, 2011.
[7] S.-M. Kim, P. Pantel, T. Chklovski, and
M. Pennacchiotti. Automatically assessing review
helpfulness. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
pages 423â€“430, Sydney, Australia, 2006.
[8] D. Klein and C. D. Manning. Accurate unlexicalized
parsing. In Proceedings of the 41st Annual Meeting on
Association for Computational Linguistics - Volume 1,
pages 423â€“430, Sapporo, Japan, 2003.
[9] C. Lin and Y. He. Joint sentiment/topic model for
sentiment analysis. In Proceedings of the 18th ACM
Conference on Information and Knowledge
Management, pages 375â€“384, Hong Kong, China, 2009.
[10] C. Lin, Y. He, R. Everson, and S. Ruger. Weakly
supervised joint sentiment-topic detection from text.
IEEE Trans. on Knowl. and Data Eng.,
24(6):1134â€“1145, June 2012.
[11] J. Liu, Y. Cao, C.-Y. Lin, Y. Huang, and M. Zhou.
Low-quality product review detection in opinion
summarization. In Proceedings of the Joint Conference
on Empirical Methods in Natural Language Processing
and Computational Natural Language Learning, pages
334â€“342, Prague, Czech Republic, 2007.
[12] Y. Liu, X. Huang, A. An, and X. Yu. Modeling and
predicting the helpfulness of online reviews. In

[14]
[15]

[16]

[17]

[18]

[19]

[20]

626

Proceedings of the 8th IEEE International Conference
on Data Mining, pages 443â€“452, Pisa, Italy, 2008.
Y. Lu, P. Tsaparas, A. Ntoulas, and L. Polanyi.
Exploiting social context for review quality prediction.
In Proceedings of the 19th International Conference on
World Wide Web, pages 691â€“700, Raleigh, North
Carolina, USA, 2010.
T. Minka. Estimating a dirichlet distribution. In
Technical report, MIT, 2000.
S. Moghaddam and M. Ester. Ilda: Interdependent lda
model for learning latent aspects and their ratings
from online product reviews. In Proceedings of the
34th International ACM SIGIR Conference on
Research and Development in Information Retrieval,
pages 665â€“674, Beijing, China, 2011.
M. P. OMahony and B. Smyth. Learning to
recommend helpful hotel reviews. In Proceedings of the
3rd ACM Conference on Recommender Systems, pages
305â€“308, New York, USA, 2009.
I. Titov and R. T. McDonald. A joint model of text
and aspect ratings for sentiment summarization. In
Proceedings of the 46th Annual Meeting of the
Association for Computational Linguistics, pages
308â€“316, Columbus, Ohio, USA, 2008.
H. M. Wallach, D. M. Mimno, and A. McCallum.
Rethinking lda: Why priors matter. In Proceedings of
the 23rd Annual Conference on Neural Information
Processing Systems, pages 1973â€“1981, Vancouver,
Canada, 2009.
H. Wang, Y. Lu, and C. Zhai. Latent aspect rating
analysis without aspect keyword supervision. In
Proceedings of the 17th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining,
pages 618â€“626, San Diego, California, USA, 2011.
Z. Zhang and B. Varadarajan. Utility scoring of
product reviews. In Proceedings of the 15th ACM
International Conference on Information and
Knowledge Management, pages 51â€“57, Arlington,
Virginia, USA, 2006.


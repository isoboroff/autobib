Latent Community Discovery Through Enterprise User
∗
Search Query Modeling
Kevin M. Carter, Rajmonda S. Caceres, and Ben Priest
MIT Lincoln Laboratory
244 Wood St
Lexington, MA 02420

{kevin.carter, rajmonda.caceres, benjamin.priest}@ll.mit.edu
ABSTRACT

to their job functions. Although enterprise stakeholders have access
to categorical organizational data separating users into the internal
hierarchy of the enterprise, such data often proves insufficient to the
task of characterizing and classifying the actual behavior of users.
For instance, users with very similar job functions (and therefore
similar professional needs and interests), in practice may be separated into different partitions of the enterprise. Additionally, the
network behavior of enterprise users is often multi-modal; activities performed arise from both business and non-business related
interests. These factors make it difficult to infer user communities of interest, which has implications to situational awareness and
collaborative recommendations within the enterprise.
In this paper, we present a framework for inferring communities of business interest within an enterprise computer network by
modeling user behaviors. For the purpose of this study, we leverage
web search queries as a well understood mechanism for expressing
topics of interest [10]. We characterize both group and individual
behavior on an enterprise network with a latent topic model, specifically Latent Dirichlet Allocation (LDA) [1], effectively treating
the history of activity for a user as a bag-of-words document.
Given a model of user behavior and a representation of each user
as a vector in the corresponding topic space, we discover the business-related topics of interest through a feature selection mechanism. We demonstrate the inferential power of these filtered topics
in identifying latent user communities of interest. Furthermore, the
characterization of these communities points to non-trivial and useful insights on latent self-organization within an enterprise.

Enterprise computer networks are filled with users performing a variety of tasks, ranging from business-critical tasks
to personal interest browsing. Due to this multi-modal distribution of behaviors, it is non-trivial to automatically discern which behaviors are business-relevant and which are
not. Additionally, it is difficult to infer communities of interest within the enterprise, even given an organizational
mapping. In this work, we present a two-step framework
for classifying user behavior within an enterprise in a datadriven way. As a first step, we use a latent topic model on
active search queries to identify types of behaviors and topics of interest associated with a given user. We then leverage
the information about user’s assigned role within the organization to extract relevant topics which are most reflective
of self-organizing communities of interest. We demonstrate
that our framework is able to identify rich communities of
interest that are better representations of how users interact
and assemble in an enterprise setting.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

Keywords
topic modeling; clustering; business intelligence; Latent Dirichlet
Allocation

1.1

1. INTRODUCTION

Related work

Some previous works using latent models over search queries
treat each of these queries as individual observations [9] or as individual documents themselves [12], towards the goal of improving
search. We are principally interested in the complete distribution
of query terms of an enterprise’s users, and take an aggregation of
microtext approach similar to [8]. While they pool terms over tweet
content to reduce noise, we aggregate over individual users.
Latent topic models have been used for document classification
and information retrieval in the past [1, 13]. While we aim to group
users according to their topic distributions, we are more interested
in identifying the latent communities of interest rather than some
super-imposed or pre-determined organization. We show that the
discovered communities differ greatly from the imperfect oracle
that is an org chart.
Our work is an extension of [10], where we demonstrated the
efficacy of using latent topic models to perform inference of user
behaviors and interests by modeling network artifacts. While that
work focused on the collective interests of an enterprise, in this
work we aim to discover the self-organization of its individuals.

As enterprises become more diversified, it is increasingly difficult for stakeholders to characterize the body of work taking place
on their computer networks and accurately cluster users according
∗This work is sponsored by the Department of Defense under
Air Force Contract FA8721-05-C-0002. Opinions, interpretations, conclusions and recommendations are those of the
author and are not necessarily endorsed by the United States
Government.
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice
and the full citation on the first page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is
permitted. To copy otherwise, or republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee. Request permissions
from permissions@acm.org.
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
Copyright © 2014 ACM 978-1-4503-2257-7/14/07…$15.00.
http://dx.doi.org/10.1145/2600428.2609462.

871

from a user’s search history. The complete process resulted in
|T |=34621 unique tokens across 3491 users.
Each user ui is additionally assigned to a class yi according
to the organizationally-defined identifier. For this enterprise, we
consider 7 distinct groups, which we will refer to by the set
Y={A, B, C, D, E, F, G}, yi ∈Y. The number of users in each
group in Y ranged from 192 to 371.

K

z

w

N

U

3.

Figure 1: The standard LDA plate model used to model
topics, z, from the observed words, w, of a set of users, U .

2.

MODELING USER SEARCH QUERIES

Search queries are an imperfect observation of a particular user’s
latent “interest” space. However, they are an active expression of
interest in a particular topic by the user, making them quite interesting. In order to efficiently model user interests, we will leverage
latent topic models over the collection of search queries that users
issue on an enterprise computer network, as we did in [10].
Latent Dirichlet Allocation [1] is a generative Bayesian topic
model where observations are conditioned on latent hidden variables with Dirichlet priors. Assume that there are W unique query
tokens (e.g. individual words within a query) and U users, where
each user u is represented as a “document” with Nu tokens collected over their entire search history. Furthermore, each user has
a multinomial distribution θu over the K topics, and each topic z
has a multinomial distribution φz over the W tokens. These distributions have a Dirichlet prior with fixed hyperparameters α,β ,
(u)
respectively. For each token wn from user u, LDA asserts that a
(u)
(u)
topic zn is drawn from θu , and that wn is in turn sampled from
(u)
zn . A plate diagram for this model is shown in Fig. 1.
Training an LDA model to data entails estimating both the usertopic Θ and topic-word φ distributions from the observed users,
given the fixed hyperparameters of the Dirichlet priors and the number of topics K. Exact inference is intractable, so we perform inference utilizing Gibbs sampling [6]. We implement LDA with the
Matlab Topic Toolbox 1.4 [4] on commodity hardware and set the
hyperparameters β=200/W ≈ 0.05 and α=0.25, which biases
the method towards sparse topics. This will become important in
identifying clusters of users.
We take a basic quantitative approach at measuring model fit
by computing the model perplexity of the trained models against
a held out test set [1]. We trained on 90% of the users, holding out
10% as a test set, and used Laplace smoothing to account for outof-vocabulary words encountered in the test set. Varying over the
number of topics K, we discovered that the best model fit occurred
at K=100, which will be used for the remainder of this paper.

2.1

INFERRING LATENT STRUCTURE

There are several issues which make it difficult to discover an
organizational structure from network behavior. Of the totality of
user’s network activity, only a subset is directly related to their role
within the enterprise. Many organizations have policies which allow limited personal use of the company network, and there is little reason to believe the non-business behaviors are strongly correlated with business activities. Additionally, an organizational
mapping does not necessarily correspond directly with the day-today activities and tasking of enterprise users. Individuals with the
same interests and skill sets may self-organize into communities
that cross organizational boundaries. We explore these factors in
subsequent sections.

3.1

Naïve User Clustering

It may seem intuitive to cluster all user behaviors according to
their pre-defined class labels, Y, which implies that the organizational mapping is a perfect oracle of actual user behavior and interests. We can demonstrate this is not the case by measuring the
natural separation of clusters in Y in the topic space. Let us define
each user u ∈ RK as a K-dimensional vector for which each of the
K topics is a feature. Given their multinomial nature, we measure
the cosine distance between user vectors to determine similarity.
We use the Average Silhoutte Width (ASW) [11] as an external clustering quality measure, which is defined as:
1 !
ASWC =
s(i),
U i

where C is the defined clustering. The silhouette, −1 ≤ s(i) ≤ 1,
measures how well a certain data point ui fits within its cluster yi
by comparing the average distance to other members of yi to the
closest average distances to data from another cluster yj , j &= i.
Large values of s(i) correspond to a ui that is appropriately clustered, while negative values suggest the data would be better served
being clustered elsewhere. Utilizing the organizational cluster definition, Y, we measure ASWY = − 0.0038, which suggests significant overlap and little-to-no separation between clusters.
Network activity that falls under the non-business regime complicates the inference process of discovering business-based latent
relationships and can be viewed as noise, even if the topics themselves are coherent. To filter such noise, we must identify the topics
which are business relevant rather than simply evaluating individual topic quality based on unsupervised metrics (e.g. topic entropy).
While this can be done manually through domain expertise, it may
also be viewed as an automated feature selection problem.

Search Query Data

We collected web proxy logs aggregating the activity of 3715
users of a mid-sized enterprise network from September 1, 2011
to May 15, 2012, anonymizing the logs to protect user privacy. We
capture user search history by mining user HTTP request lines from
web proxy logs for search query strings.
We select the set T of acceptable tokens in the corpus by counting all strings of concurrent words of size 1 to n within each query
for each user, for some integer n. We then filter tokens following
a basic algorithm used to identify common n-grams, while also removing from T unigram tokens which are composed of stop words
or are shorter than 3 characters. At the end of the tokenization
stage, each user “document” consists of all of the tokens mined

3.2

Topic Selection

Using a random forest classifier [2], which performs classification through an ensemble of decision trees, we perform topic selection by measuring the impact each topic has on classification performance. While the organization mapping is an imperfect oracle
of the latent communities, it does represent some level of intentional discrimination, such as product groups or areas of expertise.
We aim to identify the topics which best characterize this intent and
use those topics to infer the latent community structure.

872

x 10
6

1

4

0

2

−1
0

20

40
60
Ranked Topics

80

Gini Decision Split Criterion

OOB Permuted Variable Error

−5

2

0
100

Figure 2: Measures used to evaluate feature importance in
discriminating business from non-business topics.

Figure 3: Clustering quality as a function of the number
of discriminating topics. The dotted line represents quality
when all topics are considered, with the optimal nc = 2.

Most Discriminating Topics (Business Related)
1: aluminum; nasa; stress; adhesive; epoxy
2: aircraft; faa; flight; uav; radar
3: temperature; gold; quantum; physics; silicon
4: satellite; space; nasa; telescope; observatory
5: python; ubuntu; vim; ruby; couchdb

A: 9%

G: 29%

Least Discriminating Topics (Non-business Related)
100: <redacted location>; gear; rei; climbing; aol mail
99: review; best; ipad; video; price
98: cache; real; kayak; frame; code
97: stock; aapl; dow jones; djia; apple stock
96: apple; iphone; mac; logo; wireless

B: 41%
F: 7%
E: 1%
D: 7%

Table 1: The 5 most and least discriminating topics
w.r.t. business vs. non-business activities of the enterprise.

C: 6%

Figure 4: An example cluster of users characterized by the
10 most discriminative topics. Each color represents one of
the organizational-defined subgroups.

The random forest classifier offers two means of determining
feature importance: Out of Bag Permuted Variable Error (PVE)
and the Gini Impurity measure [2]. PVE of a given feature quantifies the sensitivity of the out of bag (e.g. held out sample) error
estimate to random permutations of the feature values. High sensitivity indicates the feature is critical for discriminating the different
class labels. The Gini measure computes on average the increase in
information gain by splitting the data based on the values of a given
feature; similarly with large values indicating high discriminative
power. Agreement between the two measures indicates robustness
of the feature selection results.
In Fig. 2 we illustrate the values of both the PVE and Gini measures, ranked in descending order. We note that they have very
similar profiles, including the discovery of topics which have a negative impact on classification performance. There was an overlap
of 8 of the top 10 topics between the two measures, while the two
non-agreeing topics were still ranked in the top 15 of each of the
other measures. Hence, the topics that we identify as businessrelated do indeed possess discriminative power. As an illustration,
in Table 11 we present the 10 most frequent words in the 5 most and
least discriminating topics. Noting that this enterprise focuses on
technology and engineering, the resultant topics clearly represent
topics that are of business and non-business interests respectively;
this has been confirmed by subject matter experts.

3.3

to discover two properties of the network: Does topic selection improve the quality of identified clusters? Does the clustering offer
non-obvious insights into latent communities in the enterprise?
(M )
Let us first represent each user ui
∈ RM , M ≤ K, the subspace defined by the M most discriminating topics according to
the PVE measure. Each vector is then re-normalized, such that all
elements sum to unity, in order to maintain a multinomial inter(M )
pretation. We cluster each distribution vector ui
with a robust
version of the k-means algorithm which iterates over several initial
center sets to avoid convergence to local optima [5]. This version
of the algorithm automatically selects the number of clusters by
optimizing an external clustering quality measure (e.g. ASW).
Fig. 3 shows ASW as a function of number of discriminating
topics M . Since the optimal number of clusters differed as we varied M , we plot results for a range of numbers of clusters nc and
compare the clustering quality with the optimal clustering (nc=2)
corresponding to the entire topic space. We observe a consistent
trend of improvement in clustering quality across the range of different numbers of discriminative topics, becoming substantial for
small M . The significant improvement in quality suggests that
our hypothesis of a multi-modal distribution is correct, where noisy
topics complicate the community inference process.
The improvement in clustering quality is inherent in the data and
not an artifact of the clustering technique or the quality measure.
In Table 2 we show clustering results from an additional clustering algorithm, PAM [7], which is considered to be more robust in

Improving Clustering Quality

We now look to identify communities of business interest and
discover how they relate to the organizational mapping. By leveraging standard clustering algorithms on user topic vectors, we aim
1

Locations have been redacted for privacy considerations

873

4.

0.12

In this paper we have demonstrated the ability to discover topics
and communities of business relevance within an enterprise computer network, based on modeling user search queries with a latent
topic model. We have shown that users conduct both business and
non-business activities on the network, the latter of which acts as
a substantial source of noise when trying to infer clusters of users.
By performing feature selection in the topic space, we were able to
filter this noise and discover self-organized communities of business interest. These inferred communities showed significant differences from the pre-defined organizational structure leading to a
more truthful representation of users’ shared interests.
This work has many potential applications, such as developing
recommendation systems within the enterprise. While this is common in many social networking domains, it has not been thoroughly
explored for internal business intelligence. In future work, we aim
to discover communities based on other network artifacts, such as
website visits and server authentications.

Mean Cluster PMF

0.1

0.08

0.06

0.04

0.02

0
0

5

10
15
Ranked Business Topics

20

25

Figure 5: The probability mass function (PMF) of various clusterings, with top 25 topics ranked by discriminative
power. The solid line is the cluster presented in Fig. 4, while
the dashed lines represent the pre-defined subgroups Y.
Method
k-means

Metric
ASW
CH
ASW

PAM

CH

Business
0.15 (2)
0.38 (10)
329 (2)
627 (10)
0.14 (2)
0.36 (9)
255 (2)
589 (9)
603 (11)

Non-business
0.10 (2)
0.06 (10)
89.9 (2)
59.7 (10)
0.01 (2)
0.05 (9)
32.7 (2)
53.9 (9)
50.2 (11)

CONCLUSIONS

5.

All
0.07 (2)
0.07 (10)
110 (2)
57.9 (10)
0.07 (2)
0.04 (9)
52.6 (2)
49.7 (9)
46.4 (11)

REFERENCES

[1] D. M. Blei, A. Y. Ng, M. I. Jordan, and J. Lafferty. Latent
Dirichlet allocation. Journal of Machine Learning
Research, 3:993–1022, 2003.
[2] L. Breiman. Random forests. Machine Learning,
45(1):5–32, 2001.
[3] T. Calinski and J. Harabasz. A dendrite method for cluster
analysis. Communications in Statistics, 3(1):1–27, 1974.
[4] T. Griffiths and M. Steyvers. Finding scientific topics. In
Proc. of the National Academy of Sciences, 101
(suppl. 1), pages 5228–5235, 2004.
[5] C. Hennig. Flexible procedures for clustering, 2010.
http://cran.r-project.org/web/packages/fpc/index.html.
[6] M. Jordan, editor. Learning in Graphical Models. MIT
Press, Cambridge, MA, 1999.
[7] L. Kaufman and P. Rousseeuw. Clustering by Means of
Medoids. Fac., Univ., 1987.
[8] R. Mehrotra, S. Sanner, W. Buntine, and L. Xie. Improving
LDA topic models for microblogs via tweet pooling and
automatic labeling. In Proc. of 36th Intl. ACM SIGIR
Conference, pages 889–892, July 2013.
[9] B. Peng, Y. Wang, and J.-T. Sun. Mining mobile users’
activities based on search query text and context. In Proc. of
Advances in Knowledge Discovery and Data Mining,
pages 109–120, 2012.
[10] B. Priest and K. M. Carter. Characterizing latent user
interests on enterprise networks. In Proc. of the 27th Intl.
FLAIRS Conference, May 2014.
[11] P. Rousseeuw. Silhouettes: a graphical aid to the
interpretation and validation of cluster analysis.
Computational and Applied Mathematics, 20(1):53–65,
Nov. 1981.
[12] W. Song, Y. Zhang, T. Liu, and S. Li. Bridging topic
modeling and personalized search. In Proc. of the 23rd
International Conference on Computational
Linguistics: Posters, pages 1167–1175, 2010.
[13] X. Wei and W. B. Croft. LDA-based document models for
ad-hoc retrieval. In Proc. of the 29th Intl. ACM SIGIR,
pages 178–185, 2006.

Table 2: Clustering quality when 10 most discriminative
topics are considered as business-related, with the remainder
considered non-business. The numbers in parenthesis indicate the number of clusters used within each algorithm, highlighting the optimal values across the different topic spaces.

handling noise and outliers than k-means. We also evaluated algorithms with the Calinski-Harabasz (CH) index, which computes the
ratio of within cluster dispersion to across cluster separation [3].
Fig. 4 illustrates how the inferred latent clustering relates to the
organizational mapping Y. We selected one of nc=10 clusters
produced by the M =10 most discriminative topics. A trivial result would have been a strong overlap with Y, yet we observe a
much more rich and diverse composition of users in this cluster.
This becomes even more clear when we examine the topic distribution of users as presented in Fig. 5. We see the users in this
cluster are overwhelmingly driven by the 2nd most discriminative
topic (see Table 1), accounting for more than 10% of their total
search queries. This is a larger proportion of activity than any of
the organization-defined subgroups has for any other topic (dashed
lines), as it is identifying a community interested in aircraft-related
items, pulled from across many groups. This was especially true
for groups B and G, which have the mission goals of supporting
domestic air travel and airborne surveillance, respectively. These
types of results were common amongst our inferred clusters.
We tested cluster quality with k-means clustering over all topics
pre-processed via tf-idf feature weighting. The resultant performance ASW = 0.226 was maximized with nc = 100 clusters
(ASW = 0.087 for nc = 10). The overall lower retrieved quality demonstrates the necessity of filtering topics rather than simply
re-weighting them with a scheme such as tf-idf.

874


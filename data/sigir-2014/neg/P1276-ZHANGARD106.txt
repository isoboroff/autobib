Graph-based Large Scale RDF Data Compression
Wei Emma Zhang
The University of Adelaide, Australia

wei.zhang01@adelaide.edu.au

ABSTRACT
We propose a two-stage lossless compression approach on
large scale RDF data. Our approach exploits both Representation Compression and Component Compression techniques to support query and dynamic operations directly on
the compressed data.

Categories and Subject Descriptors
H.3.2 [Information Systems Applications]: Information
Storage and Retrieval—Information Storage; E.2 [Data]:
Data Storage Representations

Keywords
RDF Graph, Semantic Web, Compression

1.

PROJECT OVERVIEW

The movement of Linked Open Data aims at providing
Web data in a standard format (i.e., Resource Description
Framework) which can be accessed, manipulated and understood automatically by machines. With increase of data
providers taking actions on publishing their data in RDF
format, the volume of RDF data is booming. As a result,
eﬃciently managing scalable RDF datasets becomes a critical challenge. Reducing the size of RDF datasets is one
approach to achieve scalability. Most current RDF storage
systems (i.e., triple-stores) are developed based on relational
database (e.g., [4]). Recently, graph-based RDF systems are
proposed (e.g., [6]). However, few eﬀorts have been devoted
to compressing RDF datasets. Current RDF compresssion
approaches can be classiﬁed into two groups: i) Representation Compression (e.g., [1]), which focuses on reducing the
size of RDF datasets by modifying their representations; and
ii) Component Compression (e.g., [2]), which concentrates
on eliminating redundant triples.
We propose a two-stage lossless compression approach that
exploits both compression techniques. Our method supports
querying and dynamic operations directly on the compressed

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage, and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the owner/author(s). Copyright is held by the
author/owner(s).
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
ACM 978-1-4503-2257-7/14/07.
http://dx.doi.org/10.1145/2600428.2610377.

datasets. To the best of our knowledge, there is no existing solution that achieves both compression and dynamic
operations on very large RDF datasets.
In the ﬁrst stage, we compress the representations of RDF
triples. Inspired by [1], we leverage Dictionary Encoding
principles and decompose an RDF dataset into two components: Dictionary and Triples. We propose to use Dynamic FM-Index [5] to represent the dictionary and choose
the graph-based representation of the RDF dataset for the
triple part. Two-level adjacency lists will be used to represent triples. Speciﬁcally, subject representation is omitted
by ordering its corresponding predicates list and objects list
sequentially. A succinct data structure, wavelet tree [3], can
be used to represent the predicates and objects sequences,
as this data structure can achieve nH0 (S) + O(n) bits storage and O(1 + lg|Σ|/lglgn) query time, where H0 (S) is the
zero-order empirical entropy of sequence S, n and Σ are the
length and alphabet of S respectively. The output of the
ﬁrst stage is a collection of numerical values, which serves
as the input of the component compression stage. We propose to use rule-based inference methods to ﬁnd the redundant triples. Speciﬁcally, we will leverage the frequent itemset mining technique: FP-Growth algorithm to ﬁnd frequent
triple items. Thus the association rules are generated and redundant triples can be eliminated according to the rules. Decompression process simply uses rules and remaining triples
to recover the eliminated ones. By leveraging the characteristics of self-index and succinct data structure, querying
can be eﬃciently performed directly on the compressed representation of RDF dataset without decompressing it ﬁrst.

2. REFERENCES
[1] M. A. Martı́nez-Prieto et al. Exchange and
Consumption of Huge RDF Data. In Proc. of the 9th
European Semantic Web Conference (ESWC), 2012.
[2] A. K. Joshi, P. Hitzler, and G. Dong. Logical Linked
Data Compression. In Proc. of the 10th European
Semantic Web Conference (ESWC), 2013.
[3] G. Navarro. Wavelet trees for all. Journal of Discrete
Algorithms, 25:2–20, 2014.
[4] T. Neumann and G. Weikum. The RDF-3X Engine for
Scalable Management of RDF Data. The VLDB
Journal, 19(1):91–113, 2010.
[5] M. Salson et al. Dynamic extended suﬃx arrays.
Journal of Discrete Algorithms, 8(2):241–257, 2010.
[6] K. Zeng, J. Yang, H. Wang, B. Shao, and Z. Wang. A
Distributed Graph Engine for Web Scale RDF Data.
The VLDB Endowment (PVLDB), 6(4):265–276, 2013.

1276


Item Group Based Pairwise Preference Learning for
Personalized Ranking
Shuang Qiu, Jian Cheng, Ting Yuan, Cong Leng, Hanqing Lu
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences

{shuang.qiu, jcheng, tyuan, cong.leng, luhq}@nlpr.ia.ac.cn
ABSTRACT
Collaborative ﬁltering with implicit feedbacks has been steadily receiving more attention, since the abundant implicit feedbacks are more easily collected while explicit feedbacks are
not necessarily always available. Several recent work address this problem well utilizing pairwise ranking method
with a fundamental assumption that a user prefers items
with positive feedbacks to the items without observed feedbacks, which also implies that the items without observed
feedbacks are treated equally without distinction. However, users have their own preference on diﬀerent items with
diﬀerent degrees which can be modeled into a ranking relationship. In this paper, we exploit this prior information of a user’s preference from the nearest neighbor set
by the neighbors’ implicit feedbacks, which can split items into diﬀerent item groups with speciﬁc ranking relations. We propose a novel PRIGP(Personalized Ranking with
Item Group based Pairwise preference learning) algorithm
to integrate item based pairwise preference and item group
based pairwise preference into the same framework. Experimental results on three real-world datasets demonstrate the
proposed method outperforms the competitive baselines on
several ranking-oriented evaluation metrics.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information
Filtering

Keywords
Collaborative ﬁltering; Implicit feedback; Pairwise preference; Item group

1. INTRODUCTION
Recommender systems, as an increasingly critical tools in
dealing with information overload on the Internet, have attracted immense amounts of research recently. Collaborative

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.

1219

Filtering(CF) [5, 7, 9], which is a content-free recommendation technique, widely performs as a core in recommender
systems. The underlying assumption of CF is that users
with common interests in the past would behave much more
similarly on items in the future. Most recent literature of CF
is focused on improving the accuracy of regression on users’
ratings [3, 9] or personalized ranking of items [10] by eﬀectively exploiting explicit feedbacks (e.g., typically numerical
ratings).
However, in most real-world scenarios, explicit feedbacks
are not necessarily always available while the abundant implicit or one-class feedbacks [5, 7] are more easily collected
such as “clicks” on web pages or “bought” in e-commercial
websites. Some pointwise methods [2, 5] regard the observed
implicit feedback on an item as a user rating 1 and the unobserved as 0 such that the problem can be addressed by
utilizing CF algorithms for explicit feedbacks with various
weighting or sampling strategies. Recently, some pairwise
methods [7, 12] are proposed with a more proper assumption that a user prefers items with observed feedbacks to
items without feedbacks. Note that the assumption of pairwise preference essentially attempts to cope with the issue
of personalized ranking directly, which leads to better recommendation performance than pointwise methods. One of
the most widely studied pairwise methods is bayesian personalized ranking(BPR) [7] which shows a promising result
in handling problems of recommendation with implicit feedbacks. And with its success, various extended methods from
distinct aspects for BPR are proposed, e.g., it is extended
from two dimensions to three dimensions in [8] by adopting
the concept of tensors and scenarios of multiple domains are
handled in [4] applying collective matrix factorization.
However, there still exists a challenging problem, which
lies in the assumption of pairwise preference over two items.
Previous pairwise methods (e.g., BPR) are simply built on
the assumption that a user prefers an item with a positive
feedback to an item without an observed feedback, which also implies that items without observed feedbacks are treated
with no distinction or preference. Nevertheless, a user would
have his/her own preference on diﬀerent items though the
items were not observed by him/her before. As a matter of
fact, it is reasonable to believe that a user’s preference on different items is usually presented in speciﬁc ranking relations,
which indicates that a user has individual prior preference
on diﬀerent items with diﬀerent degrees. A recommender
system should tend to rank higher those items with greater
prior preference for a user. Thereby, prior information for a
user should be exploited for a better recommendation.

In this paper, we propose a novel approach which incorporates users’ prior preference, which were not considered
before, into the algorithms based on the pairwise preference
assumption of item level and construct an uniﬁed framework. In a typical CF system, a user’s nearest neighbors
(most similar users according to historical feedbacks) usually share similar interests with that user. Then the items
with more positive implicit feedbacks from a user’s nearest neighbor set could be more possibly liked by him/her,
such that a user’s prior preference on items can be discovered. The core concept item group is deﬁned in our work
as a subset of items with the same cumulative number of
implicit feedbacks from nearest neighbor set. Thus, ranking
relations of items for a user from his/her prior preference
can be reﬂected by the item groups with diﬀerent positive
feedback numbers. Our approach constructs an item group
based pairwise preference for the speciﬁc ranking relations
of items and combine it with item based pairwise preference to formalise a novel framework PRIGP(Personalized
Ranking with Item Group based Pairwise preference learning). Experiments on three real-world datasets demonstrate
the eﬀectiveness of our model.

Figure 1: Illustration of Item Group Based Pairwise Preference. The set {un1 , ..., un4 } are the nearest
(0)
(1)
(2)
neighbor set of u0 . Items are split into gu , gu , gu
(4)
(3)
and gu while gu = ∅, according to implicit feedbacks from neighbors. Thus we have the relationships r̂ug(0) < r̂ug(1) < r̂ug(2) < r̂ug(4) .
u

u

u

u

where x̂uij (Θ) is computed as r̂ui (Θ) − r̂uj (Θ) with Θ to
be parameters for representing r̂ui and σ(x) = 1+e1−x is
the logistic sigmoid function deﬁning the likelihood of pairwise
More generally, by denoting L(Iu+ , I\Iu+ ) =
∑ preference.
∑
− i∈Iu+ j∈I\Iu+ ln(σ(x̂uij (Θ))), we can further formulate
the item based pairwise preference learning as
∑
(2)
min
L(Iu+ , I\Iu+ ) + R(Θ)

2. OUR APPROACH
2.1 Problem Statement

Θ

In a real world scenario, we have a set of users U with size
n and a set of items I with size m. Each user u ∈ U has
expressed their positive feedbacks on a set of items Iu+ ⊆ I.
Moreover, in a user based system, a user u can have fairly similar behaviors with a set of users who constitute the
nearest neighbor set denoted as Nu with size of |Nu |. Consequently, based on the implicit feedbacks of users and information from neighbors, our goal is to recommend a personalized ranking list of items to a user from the item set,
I\Iu+ , that have no observed feedbacks.

u∈U

L(Iu+ , I\Iu+ )

where
is regarded as a loss function that measures the item based pairwise ranking loss for user u and
R(Θ) a regularization term to prevent overﬁtting.

2.3

Item Group Based Pairwise Preference

Previous item based pairwise methods improperly assume
that items in the unobserved subset are treated without differences. However, a user may show his/her own preference
on diﬀerent sets of items with diﬀerent degrees, though the
items were not observed by him/her before. Since the recommender system will provide a ranking list of the unobserved items to the users for personalized recommendation,
it should tend to rank these items higher for that user. For
each user, there can exist a nearest neighbor set that consists of users who behave similarly with that user. Therefore,
eﬀectively exploiting the collaborative information from the
nearest neighbor set can serve to discover users’ prior preference information. In this section, we will show how to infer
this prior preference information of a speciﬁc user from nearest neighbor set and propose a framework to make personalized ranking by incorporating item group based pairwise
preference and the item based pairwise preference.
We deﬁne item group of a user u as the set of items that
have the same number of observed feedbacks from his/her
nearest neighbors, which can be formulated as follows

2.2 Item Based Pairwise Preference
The basic assumption of pairwise preference of two items
can be formally represented as
r̂ui > r̂uj , i ∈ Iu+ , j ∈ I\Iu+
where r̂ui denotes preference of a user u on an item i and the
relation r̂ui > r̂uj indicates user u could have more interests
on the item i with a positive feedback than on the item j
without an observed feedback. By this item-level assumption, we can further infer the ordinal relations for items in
I\Iu+ and recommend top-K ranked items to user u.
There are various methods [7, 12] based on the assumption
of pairwise preference over two items, which are developed from diﬀerent perspectives of classiﬁcation [7] or regression [12]. In our framework, to model the item based pairwise preference, we adopt a similar formulation employed in
BPR [7]. Note that our approach is a framework that is not
limited to applying BPR.
BPR attempts to maximize the joint probabilities of users’
preference on items in their corresponding Iu+ more than
in I\Iu+ . By derivations in BPR [7] with the negative log
likelihood loss, we can eventually formalize the item based
pairwise preference as minimizing the following criterion
∑ ∑ ∑
BPR-Opt = −
ln σ(x̂uij (Θ)) + R(Θ) (1)

gu(k) = {i|Ou (i) = k, i ∈ I, k ∈ Z},
(k)
gu

(3)

where
is u’s item group with k feedbacks for each member in it, Ou (i) denotes the number of feedbacks from u’s
nearest neighbor set, Z is the set of integers and k varies
from 0 to |Nu |. Thereby, we assume that a user u is likely to express more preference on an item group with more
observed feedbacks from neighbors than an item group with
(0)
(1)
(|N |)
less. We denote Gu = {gu , gu , ..., gu u } where Gu is the
set of item groups for user u. Then, the preference relations

u∈U i∈I + j∈I\I +
u
u

1220

among item groups w.r.t. a user u ∈ U can be formalised as
r̂ug(0) < r̂ug(1) < ... < r̂ug|Nu |
u

u

3.

(4)

3.1

u

where r̂ug(k) denote the preference of u on his/her k

th

item

u

(k)

group. If there exists a gu whose size is 0, we can just ignore
that item group in Eq. 4. For the above method, we can
approximate a user’s prior preference with diﬀerent degree
on diﬀerent item groups via implicit feedbacks of nearest
neighbors. The item group based pairwise preference can be
explained by a toy example illustrated in Fig. 1. Speciﬁcally,
nearest neighbors are determined by cosine similarity of two
users’ implicit feedbacks.
Then, we will show how to model item group based pairwise preference of a user. For a user u ∈ U , we can deﬁne u’s
∑
(k)
preference on the kth item group as r̂ug(k) = i∈g(k) r̂ui /|gu |
u

(k)

u

(k)

where |gu | is the size of gu . Then, we can formulate Eq. 4
into a likelihood probability form of pairwise preference over
item groups for each user as
∏
P (Gu ) =
p(r̂ug(s) > r̂ug(t) )
(5)
u

u

s,t:t>s

where p(r̂ug(s) > r̂ug(t) ) is the likelihood probability between
u

u

(s)

(t)

item groups gu and gu . By introducing the negative log
likelihood loss function, we construct an item group based
pairwise ranking loss in the following form
L(Gu ) = − ln P (Gu )
∑
=−
ln σ(x̂ug(t) g(s) (Θ))
u

Datasets and Baselines

To empirically evaluate our method on the recommendation with implicit feedbacks, we perform experiments on
three real-world datasets: MovieLens100K1 , Douban2 and
Ciao3 . MovieLens100K is a widely used benchmark dataset
for CF. Douban is a well-known website for users to express their preference on movies, books and music, where
we crawled users’ feedbacks on movies. A subset of published Ciao dataset is also collected. To simulate the implicit
feedbacks, we keep the ratings larger than 3 as observed positive feedbacks [11] and then we obtain 55,375 observations
from 943 users and 1,682 items in MovieLens100K, 276,619
observations from 4,184 users and 2,069 items in Douban
and 43,966 observations from 1,296 users and 3,008 items in
Ciao.
Two popular baseline methods are used for empirical comparison, which is PopRank [6] and BPR [7]. (1)PopRank is
a basic algorithm for the problem of CF with implicit feedbacks, which makes the recommendation to users in terms
of global popularity of items. (2)BPR is a strong pairwise
method for our comparison and is also a particular case of
our method. For the pointwise methods [5, 2], they perform much worse than the pairwise methods (e.g., BPR) and
comparisons are not made with them.

3.2

Metrics and Experimental Setup

Considering the real-world scenarios where new users are
usually only willing to check a few top-ranked recommended items, to measure the recommendation performance, we
adopt the widely used evaluation metrics in top-K recommendation: N DCG, 1-call [1], F 1-score, P recision, Recall
and with setting K = 5. Higher values on above metrics
correspond to better recommendation performance.
In our experiments, we randomly select 50% observations
as training data and the rest 50% as test data. The dimension of the latent factor vector is d = 10. The regularization parameters of our model are set as λu = λv = µv =
0.02, 0.02, 0.1 for MovieLens100K, Douban and Ciao respectively. And we vary α ∈ {0.01, 0.1, 1, 10, 30} to look for the
optimal tradeoﬀ parameter. In addition, we set the size of
the nearest neighbours |Nu | from 0 to 200 with a step 20 to
study its impact. We choose the best parameters based on
the N DCG@5 performance on the test set.

(6)

u

s,t:t>s

where x̂ug(t) g(s) (Θ) = r̂ug(t) (Θ) − r̂ug(s) (Θ).
u
u
u
u
Combining the item based and item group based pairwise
ranking loss, we can eventually get our uniﬁed framework as
∑
[L(Iu+ , I\Iu+ ) + αL(Gu )] + R(Θ)
(7)
min
Θ

EXPERIMENTS

u∈U

where α is a tradeoﬀ parameter used to control the conﬁdence of the pairwise preference among item groups w.r.t.
a user and R(Θ) is a regularization term. Therefore, our
model PRIGP are obtained. Note that our model is a general framework and it will reduce to the original item based
pairwise methods if α = 0 or |Nu | = 0.
More speciﬁcally, in our model, the parameter Θ = {Uu· ∈
R1×d , Vi· ∈ R1×d , bi ∈ R, u ∈ U , i ∈ I} where Uu· , Vi· are
the user and item latent factor vectors respectively and bi
is the item bias. And the
regularization term is
∑ parameter
∑
computed as R(Θ) = 12 u∈U i∈I [λu ||Uu· ||2 + λv ||Vi· ||2 +
µv ||bi ||2 ]. Thereby, the preference on the item i of a user u is generated by r̂ui = Uu· Vi·T + bi . Moreover, we can
compute u’s preference on the kth item group as r̂ug(k) =
u
∑
T
(k)
Uu· V gu(k) · + b̄g(k) where V g(k) · = ( i∈g(k) Vi· /|gu |) and
u
u
u
∑
(k)
b̄g(k) = i∈g(k) bi /|gu |. Once the parameter Θ are learned,
u
u
we can predict the preference scores of user u on item i ∈
+
I\Iu as r̂ui = Uu· Vi·T + bi , and a personalized ranking list of
items can be recommended to u by sorting predicted scores.
For obtaining a better optimization and boosting the training speed, bootstrapping based stochastic gradient descent
method is introduced to learn our model in Eq. 7. We omit
the detailed iteration algorithm due to the space limit, and
the similar updating method is described in [6, 7].

3.3

Results and Analysis

Firstly, we compare the performance of our PRIGP approach with other baseline methods as illustrated in Table 1. The optimal parameters we obtain for PRIGP are
{k = 1, |Nu | = 140} for MovieLens100K, {k = 10, |Nu | =
200} for for Douban, {k = 1, |Nu | = 40} for Ciao, and detailed discussion will presented in this paper. We observe
that our proposed PRIGP framework consistently outperforms all the other baselines. Note that PopRank strategy
has a worse performance than BPR and PRIGP and, as a
matter of fact, PopRank is not a personalized algorithm for
recommendation, which shows the necessity of designing an
appropriate personalized recommendation model. A trend
1

http://grouplens.org/datasets/movielens/
http://movie.douban.com/
3
http://www.public.asu.edu/ jtang20/datasetcode/
2

1221

Table 1: Prediction performance(mean ± std.) of PopRank, BPR and PRIGP on MovieLens100K, Douban
and Ciao datasets. By setting fixing d = 10 and K = 5. The results in bold indicate the best ones.
Dataset
MovieLens100K

Douban

Ciao

Method
PopRank
BPR
PRIGP
PopRank
BPR
PRIGP
PopRank
BPR
PRIGP

N DCG@5
0.3007 ± 0.0021
0.4289 ± 0.0073
0.4452 ± 0.0013
0.3672 ± 0.0014
0.4152 ± 0.0016
0.4389 ± 0.0031
0.1259 ± 0.0003
0.1482 ± 0.0010
0.1533 ± 0.0015

0.45

0.45

0.156

NDCG@5

NDCG@5

NDCG@5

0.43

0.43

0.42

0.42

0

40

80

120

160

0.41

200

4.

0.154

0.44
0.44

1-call@5
0.6777 ± 0.0196
0.8558 ± 0.0120
0.8647 ± 0.0083
0.8028 ± 0.0020
0.8430 ± 0.0043
0.8700 ± 0.0042
0.3862 ± 0.0027
0.4498 ± 0.0054
0.4730 ± 0.0076

0.15
0.148

0

40

80

120

160

0.146

200

0

40

80

120

|Nu|

|Nu|

D

E

F

0.45

0.45

0.156

0.44

0.152

160

200

0.43

NDCG@5

0.44

NDCG@5

NDCG@5

0.445

0.435

0.43

0.42

0.148

0.144

0.425
0.42

0.01

0.1

1

10

30

0.41

0.01

0.1

1

10

30

0.14

0.01

0.1

1

a

a

a

G

H

I

10

Rec@5
0.0581 ± 0.0038
0.1043 ± 0.0029
0.1076 ± 0.0016
0.0597 ± 0.0003
0.0689 ± 0.0002
0.0724 ± 0.0002
0.0400 ± 0.0008
0.0449 ± 0.0005
0.0470 ± 0.0007

F 1@5
0.0872 ± 0.0041
0.1478 ± 0.0037
0.1522 ± 0.0019
0.0984 ± 0.0005
0.1135 ± 0.0002
0.1195 ± 0.0003
0.0578 ± 0.0010
0.0650 ± 0.0008
0.0680 ± 0.0009

CONCLUSIONS

In this paper, we propose a novel recommendation algorithm PRIGP for CF problems with implicit feedbacks. In
our model, we integrate item based pairwise preference and
item group based pairwise preference into the same framework with leveraging the observed feedbacks from neighbors.
The experimental results on three real-world datasets show
our proposed method performs a better top-K recommendation than baseline methods. Noting that our work provides
a framework which can be ﬁt for any personalized ranking
method, we plan to generalize it to other pairwise methods
in the future.

0.152

|Nu|

P rec@5
0.2833 ± 0.0006
0.4180 ± 0.0074
0.4283 ± 0.0013
0.3450 ± 0.0010
0.3981 ± 0.0011
0.4188 ± 0.0015
0.1236 ± 0.0007
0.1414 ± 0.0012
0.1471 ± 0.0021

30

Figure 2: Parameter Study of |Nu | and α. (a)(b)(c)
study the |Nu | on MovieLens100K, Douban and Ciao
while (d)(e)(f ) study α on MovieLens100K, Douban
and Ciao.

5.

ACKNOWLEDGMENTS

This work was supported in part by 973 Program (Grant
No. 2010CB327905), National Natural Science Foundation
of China (Grant No. 61170127, 61332016).

6.

of our PRIGP methods can be observed that it always outperforms BPR, which proves the eﬀectiveness of our methods for personalized recommendation issues with implicit
feedbacks. Moreover, since our method adopts BPR into
its framework, the comparison of PRIGP and BPR could
demonstrate that by discovering the prior information of a
user’s preference from nearest neighbor set, our method can
deﬁnitely improve the pairwise personalized ranking method
the recommendation performance.
Then, the impact of parameter |Nu | is studied explicitly
with the metric NDCG@5. As illustrated in Fig. 2(a),(b),(c),
by ﬁxing optimal α for all datasets, we can observe that the
recommendation performance will ﬁrstly increase rapidly as
the size gets larger because more information from neighbors can be obtained. Then with |Nu | becoming larger, the
curves in Fig. 2(a),(c) reach an optimal point and turn to
decrease, and the curve in Fig. 2(b) increases much slower.
That is because a larger nearest neighbor set will include
more users with a lower similarity such that the information from neighbors will not increase or even more noisy
than helpful ranking information will be involved from that
neighbor set. Speciﬁcally, the optimal |Nu | for MovieLens100K, Douban and Ciao are at 140, 200, 40 respectively.
Finally, to understand the eﬀect of diﬀerent nearest neighbor set sizes, we study the inﬂuence of the tradeoﬀ parameter α which balances the item based and item group based
pairwise preference in ranking. As illustrated in Fig. 2(d),
(e), (f), we can observe that α = 1, 10, 1 are the most proper
tradeoﬀ parameters empirically with setting |Nu | to be the
best one in each dataset.

REFERENCES

[1] H. Chen and D. R. Karger. Less is more: probabilistic
models for retrieving fewer relevant documents. In SIGIR,
2006.
[2] Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering
for implicit feedback datasets. In ICDM, 2008.
[3] Y. Koren. Factor in the neighbors: Scalable and accurate
collaborative filtering. ACM TKDD, 4(1), 2010.
[4] A. Krohn-Grimberghe, L. Drumond, C. Freudenthaler, and
L. Schmidt-Thieme. Multi-relational matrix factorization
using bayesian personalized ranking for social network
data. In WSDM, 2012.
[5] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz,
and Q. Yang. One-class collaborative filtering. In ICDM,
2008.
[6] W. Pan and L. Chen. Cofiset: Collaborative filtering via
learning pairwise preferences over item-sets. SDM, 2013.
[7] S. Rendle, C. Freudenthaler, Z. Gantner, and
L. Schmidt-Thieme. Bpr: Bayesian personalized ranking
from implicit feedback. In UAI, 2009.
[8] S. Rendle and L. Schmidt-Thieme. Pairwise interaction
tensor factorization for personalized tag recommendation.
In WSDM, 2010.
[9] R. Salakhutdinov and A. Mnih. Probabilistic matrix
factorization. In NIPS, 2007.
[10] Y. Shi, M. Larson, and A. Hanjalic. List-wise learning to
rank with matrix factorization for collaborative filtering. In
RecSys, 2010.
[11] V. Sindhwani, S. Bucak, J. Hu, and A. Mojsilovic. A family
of non-negative matrix factorizations for one-class
collaborative filtering problems. In RecSys, 2009.
[12] G. Takács and D. Tikk. Alternating least squares for
personalized ranking. In RecSys, 2012.

1222


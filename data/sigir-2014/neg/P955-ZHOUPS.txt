Detection of Abnormal Profiles on Group Attacks in
Recommender Systems
Yun Sing Koh

Wei Zhou

Chongqing University
Chongqing, China

University of Auckland
New Zealand

ykoh@cs.auckland.ac.nz
zhouwei@cqu.edu.cn
Shafiq Burki
Gillian Dobbie
Junhao Wen

Chongqing University
Chongqing, China

jhwen@cqu.edu.cn

University of Auckland
New Zealand

University of Auckland
New Zealand

sala038@aucklanduni.ac.nz gill@cs.auckland.ac.nz

ABSTRACT

malicious raters that inject proﬁles consisting of biased ratings. These attacks are carried out in order to inﬂuence the
system’s behavior and have been termed “shilling” or “proﬁle injection” attacks. Shilling attacks can be divided into
push and nuke attacks to make a target item more or less
likely to be recommended respectively. Since attackers try
to make their proﬁles look similar to genuine ones, it is a
diﬃcult task to correctly identify shilling attacks. Attacks
can cause diﬀerent losses to unprotected systems depending
on the purpose of the attackers. They can push or nuke
some speciﬁed items by injecting some proﬁles into the system; in some ways, they can ruin the system by injecting a
large number of proﬁles, which lead to a breakdown of the
system. Lam [1] analysed the inﬂuence of diﬀerent types of
attacks on prediction shift in recommender systems.
Many attack proﬁles are based on random and average
attack models which were introduced originally in Lam and
Reidl [1]. Both of these attack models involve the generation
of attack proﬁles using randomly assigned ratings to the ﬁller
items in the proﬁles. In a random attack the assigned ratings
are based on the overall distribution of user ratings in the
database, while in an average attack the rating for each ﬁller
item is computed based on its average rating for all users.
In addition to these standard attack models, several more
sophisticated models have been studied. In this work we
have evaluated group attack models, including segment and
bandwagon attack models [2]. There are four parts in a
group attack proﬁle, including target item, selected set, ﬁller
set and unrated set. Selected items in malicious proﬁles are
a set of items that make the proﬁle look normal and makes
them harder to detect. There are common attributes in a
selected set, for example, items that are most rated, those
with common topics, those with special interests, and so on.
A target item is an item that attackers want to promote.
Since items in a select set are rated with the same score
as the target item, we see target item as an element in the
select set. Unrated items are items that are not rated. The
more attack proﬁles that are statistically identical to genuine
proﬁles, the harder they are to detect. We generated the
ﬁller ratings in the same way as the average attack model in
this paper.
The main contribution of this paper is an unsupervised
approach to attack detection that does not rely on proﬁle
classiﬁcation, called Target Item Analysis (DeR-TIA). The

Recommender systems using Collaborative Filtering techniques are capable of make personalized predictions. However, these systems are highly vulnerable to proﬁle injection attacks. Group attacks are attacks that target a group
of items instead of one, and there are common attributes
among these items. Such proﬁles will have a good probability of being similar to a large number of user proﬁles, making
them hard to detect. We propose a novel technique for identifying group attack proﬁles which uses an improved metric
based on Degree of Similarity with Top Neighbors (DegSim)
and Rating Deviation from Mean Agreement (RDMA). We
also extend our work with a detailed analysis of target item
rating patterns. Experiments show that the combined methods can improve detection rates in user-based recommender
systems.

Categories and Subject Descriptors
H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval; K.4 [Computers and Society]: K.4.4 Electronic Commerce—Security

Keywords
Recommender Systems, Group Attack, Attack Detection

1. INTRODUCTION
Recently, recommender systems have become an eﬀective
tool for information retrieval, and has played an important role in many popular web services, such as Amazon,
YouTube, Netﬂix, Yahoo! etc. However, due to the open nature of CF (Collaborative Filtering) recommender systems,
they suﬀer signiﬁcant vulnerabilities from being attacked by
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.
http://dx.doi.org/10.1145/2600428.2609483.

955

on the average Pearson Correlation of the proﬁle’s k nearest
neighbours and is calculated in Equation 2:
k
u=1 Wuv
DegSim =
(2)
k
where Wuv is the Pearson correlation between user u and
user v, and k is the number of neighbours.
RDMA measures the deviation of agreement from other
users on a set of target items, combined with the inverse
rating frequency for these items. RDMA can be calculated
in the following way:

other contribution of this research is that we propose a novel
metric DegSim to detect group attacks. The rest of the
paper is organized as follows. In the next section, we examine previous work in the area of attack detection in recommender systems. Section 3 introduces the background work
on which our approach is based. Section 4 introduces the
detailed formulation of our approach. Our experimental results are presented in Section 5. Finally we summarize our
research contributions in Section 6.

2. RELATED WORK

Nu |ru,i −ri |

The word “shilling” was ﬁrst termed in 2004 [1]. There
have been some recent research eﬀorts aimed at detecting
and reducing the eﬀects of proﬁle injection attacks [3, 4].
These attacks consist of a set of attack proﬁles, each containing biased rating data associated with a ﬁctitious user
identity. Since “shilling” proﬁles look similar to authentic
proﬁles, it is diﬃcult to identify them. A lot of research has
been undertaken to employ supervised learning for shilling
attack detection such as [5]. Three classiﬁcation algorithms
[6], k NN-based, C4.5-based and SVM -based, are used to improve the robustness of the recommender system. These supervised algorithms need a large number of labeled users to
enhance the accuracy. Classiﬁcation-based methods require
balanced numbers of attack and normal proﬁles to train the
classiﬁers. Work by Zhang et al. [7] has shown singular
value decomposition (SVD) techniques can also help reduce
the eﬀects of attacks. It is obvious that unsupervised learning based detectors do not make use of the labeled data
which indeed exists and is signiﬁcant for detection. An unsupervised shilling attack detection algorithm using principal component analysis (PCA) is proposed in [8]. Hurley
et al. [9] utilize Neyman-Pearson theory to construct both
supervised and unsupervised detectors. Statistical detection
techniques [10] are also used to detect shilling attacks.

RDM Au =

i=0

N Ri

Nu

(3)

where Nu is the number of items user u rated, ru,i is the
rating given by user u to item i, N Ri is the overall number
of ratings in the system given to item i.

4.

OUR APPROACH

There are diﬀerent metrics that have been proposed to
measure the features of proﬁles. In [12] a number of algorithm independent qualitative factors are used in analyzing the inﬂuence of a user on a recommender system.
Chirita [11] proposed several metrics for analyzing rating
patterns of malicious users and evaluate their potential for
detection. Considering the fact that attackers should have a
high inﬂuence in the system in order to eﬀectively promote
the target items, we use the metrics RDMA and DegSim to
reveal distinctive features in the rating patterns. Overall
attackers should have a high inﬂuence in the system in order to promote the target items eﬀectively. There are three
diﬀerent features in attack proﬁles, which enable us to differentiate between genuine and attack proﬁles. Firstly in
group attack proﬁles, ﬁller items are randomly chosen thus
the similarity based on these ﬁller items between attack and
genuine proﬁles should be lower. Secondly, since shilling attacks usually try to push items with low ratings, the users
mounting such an attack will assign a rating that deviates
from the average rating value assigned by the genuine proﬁles. Last but not least, all target items are assigned a highest or lowest value, the count number of this value should
be greater than other values among items. Attackers should
therefore have relatively high values for RDMA, as well as
low values in DegSim. Based on these reasons, RDMA and
DegSim are used to reveal these distinctive features in the
rating patterns. This metric are suitable to detect random
and average attacks, but is ineﬀective in group attacks because the select set in attack proﬁles can make them more
similar with the genuine proﬁles. So we propose a new metric
called DegSim that calculates the similarity of ratings independently. DegSim can be calculated using Equation 4:


DegSimr − DegSimr 
(4)
DegSim =

3. BACKGROUND
There are item-based CF systems and user-based CF systems, in this paper, we consider only user-based CF algorithms. A kNN -based algorithm is the most popular CF
algorithm. Rating data is represented as a user × item Matrix R, with R(u, i) representing the rating given by user u
for item i, if there exists a rating on item i, or otherwise
there will be a null value. Similarity between users is then
computed using the Pearson correlation:

i∈I (Rui − Ru )(Rvi − Rv )
Wuv = 
(1)

2
2
i∈I (Rui − Ru ) (Rvi − Rv )
where I is the set of items that users u and v both rated,
Rui is the rating user u gave to item i, and Ru is the average
rating of user u.
It is impractical to apply a supervised learning approach
to the raw data because of its sparsity. As a result, some
researchers focused on proﬁle analytics data and attribute
reduction techniques to lower the dimensionality of the data.
In [11] some generic detection attributes and model-speciﬁc
detection attributes are proposed. In this paper, we use two
generic attributes to detect group shilling attacks.
As researchers have hypothesized attack proﬁles are likely
to have a higher similarity with their top 25 closest neighbors than real users [11]. The DegSim attribute is based

r∈R

R is the rating scale of the rating database and r is a rating score. DegSimr is the mean value of DegSimr . When
calculating DegSimr , all ratings not equal to r are replaced
with 0. DegSimr is then calculated with Equation 2 using
the new transform rating matrix. There maybe no diﬀerence
between attack proﬁles and genuine proﬁles in DegSim, but
there would be diﬀerences in DegSim . Using this method
DegSim of attack proﬁles will be relatively greater than

956

genuine proﬁles, as long as there are diﬀerences in each rating scale.
There are two phases in DeR-TIA. In the ﬁrst phase, we
extract proﬁle attributes using Equation (3) and Equation
(4); use k -means(with k equals to 2) to split each group of
attributes; choose the two greater parts, and we consider the
intersection between the two parts as the output of Phase 1.
From this process, we get a pool of suspicious proﬁles. The
pseudocode is in Algorithm 1.

Table 1: Datasets used in the experiments
Dataset
#Users
#Movies
#Ratings
Sparseness
Rating scale

5.1

ML1M
6,040
3,952
1,000,209
95.81%
12345

Netflix
4,334
3,558
552,054
94.42%
12345

Eachmovie
2,000
1,623
137,425
95.77%
123456

Experimental setup

We now describe datasets we have used in the experiments, and the metrics we have used to evaluate attributes,
followed by experimental results. We use four publiclyavailable datasets, including MovieLens 100K Dataset, MovieLens 1M Dataset, subset of Netﬂix Dataset and subset of
Eachmovie Dataset. Information of the four datasets is as
Table 1.
To evaluate the performance of our technique we used two
metrics: Detection Rate and False Positive rate, which are
used in similar experiments [13]. Detection rate is deﬁned
as the number of detected attacks divided by the number of
attacks.
#Detection
Detection Rate =
(5)
#Attacks

Algorithm 1 DeR-TIA Phase 1: Find suspicious proﬁles
Input: Rating Matrix M;
Output: Suspected proﬁles, SU SRD ;
1: RDM Au ← Calculate RDM A(M );
2: DegSim u ← Calculate DegSim (M );
3: {R1 , R2 } ← kmeans(RDM Au );
4: {D1 , D2 } ← kmeans(DegSimu );
5: D = max(D1 ,D2 ), R = max(R1 ,R2 );
6: SU SRD ← {SU SRD |D ∩ R };
7: return suspected proﬁles SU SRD .
In the second phase, genuine proﬁles are ﬁltered out in
SU SRD using target item analysis. An item is considered
a target item, when it is rated proportionally higher than
the rest. For example, if 80% of the proﬁles in the suspicious pool rated an item with the highest possible rating,
we consider that item as a target item. We then move all the
proﬁles that rated the suspected target item with the highest (or lowest) rating into the DetectedResult Set. These
proﬁles are considered to be attackers. The intuition behind this is that we believe the attackers will target one
speciﬁc item many times if they want to push the item to
the recommendation list. To detect the proportion, we use
an absolute count threshold θ. Attack proﬁles should occur
at least 20 times for a considerable prediction shift [4]. On
the other side, there will be more false positives if θ is too
small. Considering these factors, we don’t consider attacks
that number less than 6 and set θ equals 6. If the count
(highest rating r) for an item is greater than 6, then itemi
is regarded as a target item. Proﬁles that rated itemi with
the highest rating r are considered as attackers, and moved
to the DetectedResult pool. The pseudocode is in Algorithm
2.

False positive rate is the number of genuine proﬁles that
are predicted as attacks divided by the number of genuine
proﬁles.
F alse P ositive Rate =

5.2

#F alse P ositives
#Genuine P rof iles

(6)

Experiment results

Three tests were done, all of them were push attacks. In
the ﬁrst test, we evaluate our technique in four datasets.
Attack proﬁles are generated as follow: in select set, 1% of
the most rated items in the datasets are chosen, these items
are rated as maximum rating; the ratings for ﬁller items are
distributed around the average rating for each item.

Algorithm 2 DeR-TIA Phase 2, Filter out genuine proﬁles.
Input: The set of suspected proﬁles SU SRD ; highest rating
r; item set I;
Output: Final detect result set DetectedResult;
1: DetectedResult = ∅;
2: ∀i ∈ I, counti ← number of ratings in itemi equal r;
3: while max(count) > θ do
4: itemt ← {itemi |counti = max(count) };
5: ∀p ∈ SU SRD , P ← p rate itemt with r;
6: DetectedResult ← P ∪ DetectedResult;
7: SU SRD ← SU SRD − P ;
8: end while
9: return DetectedResult.

5.

ML100K
943
1,682
80,000
94.96%
12345

Figure 1: Detection rate and false positive rate in
diﬀerent datasets when the attack size is 5% and
ﬁller size varies.

EXPERIMENTS

Figure 1 shows the detection and false positive rates of
the proposed method while facing group attacks on diﬀerent datasets. Figure 1(A) is the detection rate when the

In this section, we conduct extensive experiments on different datasets and a benchmark detection method.

957

attacks. In our method, the detection rate reaches almost
100%. The false positive rates are below 0.5%, which is low.

6. CONCLUSIONS
In this paper, we propose an unsupervised group detection
method De-TIA. We improved a metric of proﬁles called
DegSim , which measures the diﬀerence in similarity between genuine proﬁles and attack proﬁles better. Tests show
that a detection method using the new metric can improve
the performance of detection. As for future work, we will
further study attack detection methods on more complicated
attack models using the new metric DegSim .

7. ACKNOWLEDGMENTS
This research work was funded by the National Natural
Science Foundation of China under Grant No. 61379158,
the Ph.D. Programs Foundation of Ministry of Education of
China No. 20120191110028.

Figure 2: Detection rate of single target attack when
attack size and ﬁller size varies.

8. REFERENCES

[1] Shyong K Lam and John Riedl. Shilling recommender systems
for fun and profit. In Proceedings of the 13th international
conference on World Wide Web, pages 393–402. ACM, 2004.
[2] Chad Williams and Bamshad Mobasher. Profile injection attack
detection for securing collaborative recommender systems.
Technical report, Technical report, DePaul University, 2006.
[3] Bhaskar Mehta, Thomas Hofmann, and Wolfgang Nejdl. Robust
collaborative filtering. In Proceedings of the 2007 ACM
conference on Recommender systems, pages 49–56. ACM,
2007.
[4] Bhaskar Mehta and Wolfgang Nejdl. Attack resistant
collaborative filtering. In Proceedings of the 31st annual
international ACM SIGIR conference on Research and
development in information retrieval, pages 75–82. ACM,
2008.
[5] Robin Burke, Bamshad Mobasher, Chad Williams, and Runa
Bhaumik. Classification features for attack detection in
collaborative recommender systems. In Proceedings of the 12th
ACM SIGKDD international conference on Knowledge
discovery and data mining, pages 542–547. ACM, 2006.
[6] Chad A Williams, Bamshad Mobasher, and Robin Burke.
Defending recommender systems: detection of profile injection
attacks. Service Oriented Computing and Applications,
1(3):157–170, 2007.
[7] Sheng Zhang, Yi Ouyang, James Ford, and Fillia Makedon.
Analysis of a low-dimensional linear model under
recommendation attacks. In Proceedings of the 29th annual
international ACM SIGIR conference on Research and
development in information retrieval, pages 517–524. ACM,
2006.
[8] Bhaskar Mehta and Wolfgang Nejdl. Unsupervised strategies
for shilling detection and robust collaborative filtering. User
Modeling and User-Adapted Interaction, 19(1-2):65–97, 2009.
[9] Neil Hurley, Zunping Cheng, and Mi Zhang. Statistical attack
detection. In Proceedings of the third ACM conference on
Recommender systems, pages 149–156. ACM, 2009.
[10] Runa Bhaumik, Chad Williams, Bamshad Mobasher, and
Robin Burke. Securing collaborative filtering against malicious
attacks through anomaly detection. In Proceedings of the 4th
workshop on intelligent techniques for web personalization
(ITWP’06), 2006.
[11] Paul-Alexandru Chirita, Wolfgang Nejdl, and Cristian Zamfir.
Preventing shilling attacks in online recommender systems. In
Proceedings of the 7th annual ACM international workshop
on Web information and data management, pages 67–74.
ACM, 2005.
[12] George Karypis Al Mamunur Rashid and John Riedl. Influence
in ratings-based recommender systems: An
algorithm-independent approach. In Proc. of the SIAM
International Conference on Data Mining. SIAM, 2005.
[13] Chen-Yao Chung, Ping-Yu Hsu, and Shih-Hsiang Huang. βp: A
novel approach to filter out malicious rating profiles from
recommender systems. Decision Support Systems, pages
314–325, 2013.

Figure 3: Detection rate of group attack when the
attack size and ﬁller size varies.

attack size is 5% and ﬁller size varies. Figure 1(B) shows
the false positive rate of the detection. We ﬁnd that the
detection rates increase very fast along with an increase in
ﬁller size. The detection rates reach close to 100% when
ﬁller size reaches 4%. The false positive rates, on the other
hand, consistently stay below 0.5% when the ﬁller size is
greater than 2%, regardless of attack size.
In the second test, we compare our method with the stateof-art unsupervised βρ-based method [13] using ML100k
Dataset when the select set is zero, that is, there is only
one target item in an attack proﬁle, and the ﬁller size is 5%
and the attack size varies from 1%, 3%, 5%, 7% and 9%.
Figure 2 shows the detection rates of βρ-based method (A)
and our method (B) when facing single target push attack.
In our method (B), detection rate reaches almost 100% when
the ﬁller size is greater than 4%. The false positive rates are
relatively low.
In the third test, we compare βρ-based method and our
method using ML100k Dataset when the select set varies
from 2 to 10. Figure 3 shows the detection rates of βρ-based
method (A) and our method (B) when facing group Push

958


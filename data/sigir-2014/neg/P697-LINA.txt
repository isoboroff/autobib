A Mathematics Retrieval System for Formulae in Layout
Presentations
∗
Yingnan Xiao
Xiaozhong Liu
Xiaoyan Lin, Liangcai Gao ,
School of Software
Department of Information and
Xuan Hu, Zhi Tang
Engineering, Beijing University
Library Science, Indiana

Institute of Computer Science
& Technology, Peking
University, Beijing, China

{linxiaoyan, glc, xuan.hu,
tangzhi}@pku.edu.cn

of Posts and
Telecommunications, Beijing,
China

lxyxynt@bupt.edu.cn

ABSTRACT

liu237@indiana.edu

Engineering, and Mathematics) research and education.
For flexible display of mathematical concepts with high
quality in various environments, mathematical formulae are
usually presented in layout presentations, such as LATEX,
Presentation MathML, or PDF documents. Due to the
lack of semantic structures, the math formulae are difficult
to be indexed, retrieved and consumed. Meanwhile, it is
difficult for users to input formulae as queries to address
their information need. Mathematics retrieval, targeting
at facilitating the access, retrieval and discovery of math
resources, becomes increasingly needed in many scenarios.
For example, many traditional courses or massive open
online courses (MOOCs) release the course resources (books,
lecture notes and exercises, etc) in PDF or HTML. In
these resources, mathematical formulae could be the most
challenging part [8]. However, it is difficult for students
to find useful complementary materials according to the
formula that they encounter in the learning materials. On
the other hand, users cannot directly obtain the formulae as
queries by text copy&paste from PDF documents, which is
an important search behavior in classic web search engines
[1]. Even after users take efforts to type out the LATEX codes
of the formulae, they might not probably get the ideal results
from the traditional text-based search engines. In that,
classic search engines cannot properly index and retrieve
mathematical formulae.
Although mathematics retrieval is useful for different
applications, practical systems are still quite sparse. It is
mainly because mathematical formulae are highly structured
and domain-specific, while most math formulae available in
existing information system are either in layout presentation
or unstructured format (e.g., PDF). This problem challenges
the construction of mathematics retrieval systems in query
interface, normalization, indexing and ranking [16]:
Query interface: Unlike text-based search, mathematics
retrieval system usually takes math formulae as queries. A
query interface, which needs to concern how to input the
highly structured formulae into the search engine, is essential
to popularize the system. The current search engines require
users to know the classification, or name of a formula or
using an editor or string encoding (e.g., LATEX) to enter
formulae [7]. However, these interfaces would cost extra
time and efforts of users to input query formulae. Moreover,
for the junior users, learning encoding query language is a
challenging task.
Normalization: Normalization is essential to ensure all

The semantics of mathematical formulae depend on
their spatial structure, and they usually exist in layout
presentations such as PDF, LATEX, and Presentation
MathML, which challenges previous text index and retrieval
methods. This paper proposes an innovative mathematics
retrieval system along with the novel algorithms, which
enables efficient formula index and retrieval from both
webpages and PDF documents. Unlike prior studies, which
require users to manually input formula markup language
as query, the new system enables users to “copy” formula
queries directly from PDF documents. Furthermore, by
using a novel indexing and matching model, the system is
aimed at searching for similar mathematical formulae based
on both textual and spatial similarities. A hierarchical
generalization technique is proposed to generate sub-trees
from the semi-operator tree of formulae and support
substructure match and fuzzy match. Experiments based
on massive Wikipedia and CiteSeer repositories show that
the new system along with novel algorithms, comparing with
two representative mathematics retrieval systems, provides
more efficient mathematical formula index and retrieval,
while simplifying user query input for PDF documents.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

Keywords
Mathematical Information Retrieval; Structure Matching;
Layout Presentation; Scientific Information Extraction

1.

University, Bloomington, IN,
USA

INTRODUCTION

Mathematical
formulae
are
commonly
used
in various disciplines, such as STEM (Science, Technology,
∗Liangcai Gao is the corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’14, July 6–11, 2014, Gold Coast, Queensland, Australia.
Copyright 2014 ACM 978-1-4503-2257-7/14/07 ...$15.00.
http://dx.doi.org/10.1145/2600428.2609611.

697

the equivalent math formulae with different presentations
or transformations can be recalled. Different from word
stemming and thesaurus operation in text retrieval, formula
normalization should overcome variation in variables,
constants, spatial layouts or even semantics among
equivalent formulae. For instance, “a+b/c” and “y/z+x”, “ ab ”
and “a/b”, “x−2 ” and “ x12 ” have different layout presentations
while presenting the same meaning.
Indexing and ranking: Intuitively, spatial layouts or
semantics of math formula can be expressed or understood
in tree-structures.
In order to accurately calculate
the structural similarities of formulae, attributes of tree
structures are commonly considered, such as sub-trees and
levels. For example, formulae containing the same main
structure with different sub-trees (e.g., a + b × y vs. x + y),
and formulae containing different main structure with the
same sub-trees (e.g., a + b × y vs. b × y). A major
difficulty with extracting structural attributes from formulae
in layout presentation is that, the layout presentation
usually contains limited semantics about the formulae. Take
the three expressions as mentioned previously, the LATEX
presents all symbols linearly without denoting the priority
of operators. Moreover, how to calculate the similarity score
according to the attributes of tree structures remains an
open problem, because the motivations of different users of
the mathematics retrieval systems vary according to their
background and specific tasks [18].
In order to solve the aforementioned challenges, in this
study, we propose a publicly available mathematics retrieval
system1 towards formulae in layout presentations. The
contribution of this study is threefold: 1) Query interface:
A novel query input interface is proposed to enable users
to “copy” formula queries directly from PDF documents;
2) Normalization: A semantic enrichment technique is
proposed to extract the structural and semantic information
from the layout presentations of formulae. Additionally,
normalization of operand orders and hierarchical structure
generalization are proposed to support more reasonable
fuzzy matching and similarity calculation; 3) Indexing and
ranking: Effective online query is implemented by proposing
the indexing technique towards both original and generalized
sub-structures of formulae. In addition, we propose the
novel similarity function, which addresses hierarchical and
fuzzy matching between formulae. Moreover, the relevant
score between query formula and a document (webpage or
PDF) is calculated based upon the hybrid of a representative
formula and a set of relevant formulae.

2.

retrieving formulae and related information in the function
library. This interface requires users to know well about
the name or category of the query formula. 2) The
second category designs specially defined query language
to capture users’ information needs (e.g., set wildcards
for subexpressions or variables)[4]. 3) The third category
provides an graphic equation editor for users to input
formulae [5, 12].
Recently, handwritten methods are
proposed to enable users to input handwritten formulae
on smartphones or tablets [7]. These methods still cost
users’ extra efforts to obtain the formula query and seems
unbearable when the formula happens to be complicated.
4) The last category of interface requires users to input
specific encodings of formulae such as LATEX or MathML.
This is used by most of the existing systems [9, 15] and
is considered as the most convenient interface given the
markups of query formula are already available to the user.
Similarly with handwritten input, typing out the markups
of the query formula manually is quite time-consuming and
troublesome, especially for the users know little grammars
of these markups. To settle this problem, a query input
interface is proposed to support users to input query formula
via clipping the formula region from PDF documents.

2.2 Formula Presentation
Formula presentation denotes the internal format of
formulae of a mathematics retrieval system. It is important
since it determines the compatibility of a mathematics
retrieval system to the existing data sources.
Early
researches of mathematics retrieval focus on semantic
presentations (e.g., Content MathML, OpenMath) [5], which
mark up the semantic meanings of formulae. However,
in practice, most math formula resources are presented in
layout presentations (e.g., Presentation MathML, LATEX)
in the webpages or in unstructured forms (e.g., PDF) in
documents. For instance, Wikipedia encodes formulae in
webpages using LATEX. In digital libraries, math concepts
are encoded as unstructured symbols in PDF documents.
Meanwhile, formula presentation determines the amount
of information that the mathematics retrieval system can
rely on. Since Presentation MathML, LATEX or PDF only
contain limited spatial layouts and few semantic information
of formulae, existing mathematics retrieval systems based on
these layout presentations can only support exact matching
[11] or consider little about the structure matching [2, 14,
15]. To address this problem, this paper proposes to enrich
structural and semantic information of formulae in layout
presentations, so as to realize structure and fuzzy matching
in mathematics retrieval.

RELATED WORK

Mathematics retrieval has been researched since 2003 [9],
and more than ten systems are reported. We summarize
these systems according to the essential aspects of
constructing a mathematics retrieval system in Table 1 and
analyze the relevant approaches on query interface, formula
presentation, indexing and ranking techniques as follows.

2.3 Indexing
The main indexing techniques of mathematics retrieval
include text-based and tree-based, as classified in Table 1.
The idea of text-based indexing techniques [9, 10, 11] is
to convert math formula markups into plain text strings, so
that they can be indexed using existing text-based indexing
tools like Lucene. Because mathematical formulae are
highly symbolic and structured, the transformation from
structural formulae into plain text strings mainly focuses
on how to encode structures in text strings and normalize
different presentations of formulae. Miller et al. convert
all non-alphanumeric symbols in LATEX into alphanumeric
symbols and normalize the order of operands into a

2.1 Query Interface
The existing user interfaces can be classified into four
categories: 1) The first type of interface provides detailed
taxonomy of mathematics (e.g., Wolfram2 ) to support
1
2

http://www.icst.pku.edu.cn/cpdp/wikimirs2/
http://mathworld.wolfram.com

698

Table 1: Comparison of Mathematical Information Retrieval Systems1
Systems/Methods

Interface

Presentation

LATEX
PMML
LATEX,text

LATEX
PMML
PMML

Editor
LATEX,PMML

CMML
PMML

[14]

LATEX

LATEX

WikiMirs[2]

LATEX

LATEX

CMML

DLMF[9]
Mathdex[10]
EgoMath[11]
MathWebSearch[5]
MIaS[15]

[13]
MASE[12]
[4]
1 “Order” denotes

Normalization
Matching
Text-based indexing
Order
Exact
Variables
Similar
Variables,constants
Exact
Tree-based indexing
/
Similar
Order,variables,
Similar
constants
Order,variables
Similar
Similar

CMML

Variables
Other
Variables

Editor,text

LATEX

/

Similar

PMML,query
language

PMML

/

Similar

Similar

Ranking

Corpus

tf-idf
tf-idf & weights
tf-idf

DLMF
arXiv; Wikipedia
Wikipedia

/
tf-idf & weights

Connexions;Wolfram
arXiv

Similarity
of
matched sets
tf-idf & weights

arXiv

Similarity
of
feature sets
tf-idf
with
learned weights
Edit
distance,
pattern match

Constructed dataset

Wikipedia

Math Overflow
Wikipedia; DLMF

the order of operands. “PMML” and “CMML” denote Presentation and Content MathML, respectively.

canonical form [9]. A similar method is proposed by
Misutka et al. [11] with improvement via normalization of
variables and constants. The structures of formulae are lost
in those methods. Aimed at matching formula structures
in the text-based indexing methods, Miner et al. [10] index
n-gram terms, which are substructures with no more than n
successive tags, meaning only substructure with no more
than n nodes are indexed, and high-level structures or
complex structures in the formula are rarely considered.
In tree-based methods, attributes of formula tree
structures (e.g., substructures or paths) are extracted as
index terms. In order to support substructure and fuzzy
matching, a straightforward way is to index all substructures
of formulae with term attributes (e.g., frequency, level) [15]3 .
However, fuzzy match between expressions sharing highlevel structures cannot be realized.
In order to
better support fuzzy match, Hu et al. [2] propose to
extract substructures from the LATEX markups considering
hierarchical generalization of substructures. Since this
method is based on formulae’s layout presentations,
the structural match between formulae encoded in onedimensional markups cannot be supported (will be detailed
in Section 3.4.1). In order to avoid explosive growth of
index space when indexing all substructures of formulae,
Kohlhase et al. [5]apply a substitution tree indexing
technique to index substructures of semantic formula
presentation. A substitution tree represents the structure
of all the indexed first-order logic terms. Exact or similar
matches can be found by backtracking all nodes of the
substitution tree using different strategies. However, the
substitution tree in [5] is built upon operator tree of
formula, which is difficult to extract from formulae in layout
presentations. To overcome this, Schellenberg et al. [14]
employ the substitution tree indexing technique to index
layout presentations of formulae. However, the insertion
bias introduced in their paper has a significant impact
on the results. To address the problem of supporting
meaningful substructure and fuzzy match of formulae in
layout presentations, a novel index technique with semantic
enrichment and fine-grained hierarchical generalization is
proposed in this paper.

There are other indexing methods, which are not textbased or tree-based. Based on Formal Concept Analysis,
Nguyen et al. [13] extract math features and index them
via constructing a mathematical concept lattice of these
features. However, the construction of concept lattice relies
on the semantic structures of formulae which are difficult to
obtain from formulae in layout presentations. LATEXSearch4
and Symbolab5 are related commercial systems whose
schemes are not reported publicly.

3

5

2.4 Ranking
Most text-based methods use tf-idf to calculate
similarities of formulae. Miner et al. [10] introduce weights
for terms according to their levels, lengths and complexities.
However, as only limited structure information of formulae is
indexed in text-based models, the structure matching score
is difficult to calculate properly. Some tree-based methods
also use the modified tf-idf to calculate the matching scores
of substructures. Sojka et al. [15] introduce weights to
discriminate substructure matches in different levels based
on the assumption that structures in higher level are more
important than those at lower levels. Hu et al. [2] introduce
weights based upon the distance of matched terms in query
and the matched formulae. A main problem with this
method is that substructures in lower level contribute more
to the similarity score while a common sense of user is to
understand a formula from high level to low level.
Besides tf-idf , some methods evaluate the similarities of
formulae according to the similarity of feature sets. Nguyen
et al. [13] index formulae in the mathematical concept
lattice structure based on similarities of feature sets of each
formula. To search for a formula, the query is inserted
into the mathematical concept lattice and similar formulae
are ranked according to their distances from the query.
However, the system is only tested upon a small dataset
including less than 500 formulae, and its query efficiency
has not been analyzed. In the literature [14], each formula
can be presented by a set of sub-expressions with their
attributes (e.g., contents, neighbours) presented in a 5-tuple.
Retrieved formulae are ranked according to the set similarity
4

https://mir.fi.muni.cz/mias/

699

http://www.latexsearch.com/
http://symbolab.com/

Figure 1: Workflow of the proposed system (Dotted lines denote online query flows and solid lines denote
offline index flows).
between formulae. However, the insertion bias introduced in
their paper has a significant impact on the retrieval results.
Kamali et.al. [4] calculate the formula similarity using tree
edit distance, which cannot evaluate the structure similarity
in different levels. Kamali et.al. [4] also propose to find
relevant formulae using pattern matching. This method
requires users to learn specific query language to input
query “pattern” and also requires to predefine many patterns
manually in advance.
Different from the existing methods, this paper proposes
a method to calculate similarity between a query formula
and a document containing multiple relevant formulae.
The proposed similarity calculation considers not only the
relevance of substructures in original forms or generalized
forms, but also distance between sub-structures.

3.

Figure 2: User interface of the proposed system

THE PROPOSED SYSTEM

experienced or advanced users [7]. However, this interface
turns to be clumsy and less helpful when users are searching
formulae in PDF documents. Meanwhile, this querying
strategy is not useful when users have little experience
in using LATEX. To overcome the difficulty of obtaining
formula query from non-structural documents like PDF, a
novel query input interface is proposed in this paper. It
enables users to obtain query formula directly from PDF via
clipping the formula region in the document. Concretely, a
plugin (as shown in Figure 2(a)) is implemented in a PDF
reader to obtain the user’s action of clipping the formula
region in the document. After the formula region is selected
using mouse, a formula structure recovering method refined
from the literature [17] is deployed to analyze the layout
structure of the formula and output it as Presentation
MathML. It is worth noting that the performance of this
structure analysis method [17] is improved by utilizing
precise character information obtained from PDF. The
reader plugin is released as a publicly available tool6 .

3.1 Overview
Figure 1 illustrates the workflow of the proposed system,
including six modules: user interface, preprocessor, tree
constructor, tokenizer, indexer and ranker. The solid
lines denote the offline workflow: Firstly, preprocessor
converts different data sources into uniform internal format
(Presentation MathML). Secondly, semantics of formulae in
Presentation MathML are enriched and semi-operator trees
of formulae are constructed by tree constructor. Thirdly,
terms are extracted by tokenizer with normalization and
generalization. Lastly, the indexer calculates and stores the
statistical data (e.g. tf-idf , term level) of each term in the
inverted index files.
The dotted lines indicate the workflow how a user searches
a formula (online computation): The user can input the
query by either pasting the LATEX markups or clipping the
formula region using a PDF reader plugin. Then, the query
is preprocessed into Presentation MathML and enriched
with semantics. Next, the semi-operator tree is tokenized
into terms and passed through ranker to find the matched
terms in the index files. The relevance scores between
query and documents are calculated based on the matched
formulae in documents. Lastly, a list of ranked documents
with relevant formulae are returned to the user.

3.3 Preprocessor
The goal of the preprocessor is to identify and convert
formula markups from different sources into uniform internal
storing formats, namely Presentation MathML. The data
sources concerned in this paper include webpages and PDF
documents. For webpages, the preprocessor extracts formula
markups via identifying the pre-defined markup tags. For
instance, in Wikipedia, formulae are presented as LATEX
and tagged by “<math>”. In the preprocessor, the LATEX
markups are converted into Presentation MathML using
SnuggleTeX7 . For PDF documents, formula recognition
techniques are employed to identify the formula regions and

3.2 User Interface
In our system, two user interfaces are implemented to
facilitate users to input query formulae from webpages or
PDF documents. Firstly, users can input the query formula
via manually typing or pasting the LATEX markups into
the search box at the front page of the proposed system
(as shown in Figure 2(b)). For now, the system only
accepts LATEX markups, which are more easily recognized by

6
7

700

http://www.icst.pku.edu.cn/cpdp/Co-Reader/
http://sourceforge.net/projects/snuggletex/

recognize their layout structures. Concretely, characters
and their attributes (e.g., baselines) are extracted from
documents via parsing the documents using the PDF
parser (e.g., PDFBox). The precise boundaries of the
math formulae are then detected using the refined formula
identification method proposed in [6]. Lastly, the layout
structures of formulae are analyzed and outputted as
Presentation MathML using the refined formula structure
analysis algorithm proposed in [17].

3.4 Tree Constructor
A layout presentation tree can be extracted directly based
on Presentation MathML. See an example in Figure 3 c).
As discussed in Section 2.2, the drawback of mathematics
retrieval system based on Presentation MathML or LATEX
is that many useful semantic contents of formulae are lost
in layout presentations. In this paper, we firstly compare
and analyze the main differences of layout presentations
and semantic presentations of formulae, and then propose
a semantic enrichment technique in the semi-operator tree
construction process to overcome this limitation.

Figure 3:
Layout presentation
presentation of (x + y) ∗ ab

and

semantic

semantic analysis are required. However, for the same
conversion problem, mathematics retrieval has a different
goal from that of the existing formula understanding
methods [16]. Mathematics retrieval only needs to make use
of the structures and semantics of formulae (e.g., operator
priority, tree level) as much as possible and has a relatively
high tolerance of ambiguities. In addition, as discussed
above, the main problem with mathematics retrieval systems
towards formulae in layout presentations is caused by the
lost of the semantics in one-dimensional presentations.
It is found that the one-dimensional expressions can be
interpreted into the corresponding operator trees using
classic expression calculation algorithm if disambiguation is
not taken into account. The extracted operator trees are
helpful for mathematics retrieval, since the semantics (e.g.,
hierarchical structures) are recovered.
Based on the aforementioned analysis, the semantic
enrichment is carried out as follows: Firstly, one-dimensional
presentations are found in MathML via identifying the
“<mrow>” tags. All children under “<mrow>” tags are
analyzed using classic one-dimensional expression calculator
algorithm as described as follows: 1) The contents under
“<mrow>” tags are identified as the Infix Notations of
the formula.
The operators, variables and constants
can be detected by tags “<mo>”, “<mi>” and “<mn>”,
respectively. 2) A list is defined to describe the priority
of operators and the Infix Notations are converted into
Reverse Polish Notations (RPN) based on this list. Since
the algorithm of converting Infix Notation into RPN is wellknown, details of the algorithm is not given here.
The contents under “<mrow>” tags are replaced with a
tree, which is the semantic presentation of these contents
and is obtained by the aforementioned process. After
executing this process from the lowest level to the highest
level of the layout presentation tree recursively, a “semioperator” tree is obtained, as shown in Figure 3 d). In this
paper, we call it semi-operator tree rather than operator tree
because there still exists a few ambiguities. For instance,
implicit multiplication is not identified, such as xy may
represent x × y or a single variable. In this paper, only
later interpretation is taken. Equivalent transformation is
also not considered, e.g., x−1 is equivalent to x1 , but the
conversion from x−1 to x1 is not carried out here.

3.4.1 Presentation Tree vs. Semantic Operator Tree
Before discussing the difference between layout and
semantic presentations, we first classify the relations in
presentation tree of formulae into two categories: onedimensional relations and two-dimensional relations. Onedimensional relations denote the symbols are horizontally
connected, such as, expressions connected by “+”, “-”, “×”,
etc. Two-dimensional relations describe the symbols
P are
√
connected in non-linear relations, such as, “
”, “ ”. In
layout presentations, most of two-dimensional relations are
equivalent to the semantic structures of the formula. In
other words, most of the two-dimensional layout relations
can be mapped or converted into semantic structures
directly. However, symbols in one-dimensional relation is
connected using the same horizontal tag (e.g., “<mrow>”
tag in Presentation MathML). And the semantic meanings
(e.g., operator priority, operands) are unknown in the layout
presentations. Therefore, the structures and semantics in
one-dimensional relations cannot be utilized in mathematics
retrieval. This is why semantic interpretation is needed to
convert layout presentation in one-dimensional relation into
corresponding semantic presentation.
Take “(x + y) ∗ ab ” as an example, its layout and
semantic presentations is illustrated in Figure 3 a)-b).
The layout presentation of a fraction (in two-dimensional
relation) can be converted into its semantic presentation
using straightforward tag conversion as denoted in green
nodes in Figure 3 a)-b), while the rest of structures
(in one-dimensional relation) cannot be converted without
special semantic interpretation. In this paper, we propose
to convert layout presentations in a one-dimensional
relations into corresponding semantic presentations using
the following semantic enrichment technique.

3.4.2 Semantic Enrichment
Conversion from layout presentation to semantic
presentation has been widely researched in the area of
formula understanding [16], but satisfactory methods or
conversion tools have not been proposed yet. How to
disambiguate the meaning of symbols or structures in
semantic presentation is quite difficult since contexts and

3.5 Tokenizer
3.5.1 Normalization
The goal of normalization is to convert different formulae

701

with the same meaning into a uniform format, so as to
ensure the high recall of relevant formulae. The objects
of normalization generally includes variables, constants
and order of operands. Values of variables or constants
need to be normalized, since they have little effect on
the structures of expressions. Similarly, operand order of
commutative operator (e.g., +, ×) needs to be normalized
in order to ensure that the relevant formulae with different
order of operands can be retrieved. Most mathematics
retrieval systems towards formulae in layout presentation
can only normalize variables or constants, since there is
little information about the order of operands in layout
presentations. In this paper, the semi-operator tree obtained
in previous steps can be used to normalize not only
the variables or constants, but also the operand orders.
Concretely, order of operands is firstly normalized as follows:
A list of commutative operators (e.g., +, ×) is predefined
and the operand order of commutative operators are
normalized as follows: The semi-operator tree is traversed
level by level from bottom to top. For each internal node
(non-leaf) in each level, if it is a commutative operator,
sort the node’s children according to lexicographical order
of the linear markups of the children. In this way, the
order of operands is normalized. For instance, “C+V×C”
and “C×V+C” will be normalized to the same expression,
“C+C×V”, where “C” and “V” are the aliases of constant
and variable, respectively.
Variables and constants are encoded in “<mi>” and
“<mn>” tags in the semi-operator tree.
They are
normalized during the generalization process in term
extractor. Specifically, the contents under these tags are
removed in the generalization process, which is detailed in
the following section.

and generalized terms. The original terms are generated
directly from the original sub-expressions of the formulae.
The generalized terms are generated from the fuzzy subexpressions, so as to describe the sketch of the expression.
For each term, two attributes are extracted and recorded in
a pair, namely (content, level). The content describes the
MathML markup of the term and the level denotes the level
of the term in the semi-operator tree whose root’s level is 1.
Algorithm 1 Tokenizer
1: Let cc(exp) be contents of exp including its descendants
2: Let tag(exp) be the tag of exp node itself
3: Let text(exp) be the text inside the tag of exp node
4: procedure Tokenize(exp, lev)
5:
if exp is not a leaf then
⊲ original term
6:
term set ← (cc(exp), lev)
7:
gen str ← tag(exp)
8:
for each child ci of exp do
9:
Insert tag(ci ) as child of gen str
10:
Tokenize(ci , lev + 1)
11:
end for
12:
term set ← (gen str, lev)
⊲ generalized term
13:
else if length of text(exp) > 1 then
14:
term set ← (cc(exp), lev)
⊲ original term
15:
end if
16: end procedure
Table 2 illustrates eight terms extracted from (x + y) × ab .
The level(L), original and generalized terms are described in
the first three columns. For limited space, only the contents
of the generalized terms are given in the last column.
Table 2: Terms of (x + y) ×

3.5.2 Term Extractor with Generalization
Term extractor aims at extracting the index terms from
the semi-operator tree of formula. Before introducing the
term extraction method, the conventions how people read or
understand formulae are firstly analyzed: Because operator
trees of mathematical formulae are naturally hierarchical,
they are conventionally read or understood in a hierarchical
way with generalization step by step. More specifically, most
of the formulae can be viewed as expressions containing an
operator with a list of operands. Generalizing the content
of operands as an alias is commonly applied to simplify
complex
structure into a concise expression.
For example,
√
√
a+b
can be viewed as ∗∗ , and then as ∗2∗ , step by step. It
(c+d)2
is seen that generalization is an important behavior when
people understand formulae. Additionally, generalization
of substructures in low level can avoid overrating for the
substructures in low level, which is a common problem
occurring in tree-based indexing methods.
Based on the aforementioned analysis, a term extraction
algorithm with generalization is proposed towards the semioperator trees of formulae. In order to mimic the formula
understanding process of users and support the substructure
matching and fuzzy matching in mathematics retrieval,
each substructure and its generalized forms are extracted.
Through extracting generalized terms, formulae, which
share substructures in high level, can be matched and their
similarities can be calculated properly.
The tokenizing algorithm is described in Algorithm 1. It
generates two categories of terms, namely original terms

a
b

L
1

Original
(x + y) × ab

Generalized
(∗) × ∗∗

Generalized (contents)

2

(x + y)

(∗)

2

a
b

∗
∗

<mfrac> <mi> </mi>
<mi> </mi> </mfrac>

3

x+y

∗+∗

<mo o=’+’> <mi> </mi>
<mi> </mi> </mo>

<mo
o=’&times;’>
<mfenced>
</mfenced>
<mfrac> </mfrac> </mo>
<mfenced>
<mrow>
</mrow> </mfenced>

3.6 Indexer
3.6.1 Problem Analysis
In order to return a list of ranked documents containing
the relevant formulae, the relevance between the query
formula and the document should be calculated. The
existing mathematics retrieval methods mainly focus on how
to calculate the relevance between formulae. They cannot be
directly applied to calculate the relevance between a formula
and a document because the formulae and the documents
are in many-to-many correspondences. A document may
contain many formulae and one formula may appear in
many different documents. To our best knowledge, how to
calculate the relevance of a query formula and a document
is rarely investigated in the previous studies. Some methods
[11] simply combine the formula relevance score with the
text relevance score without considering the combination of
the scores of multiple relevant formulae in the document.

702

Terms
t1
iff(t1 )
...
ti
iff(ti )

Table 3: Index of Terms and Formulae

Table 4: Index of Terms and Documents

Inverted index file
f1 [tff (t1 , f1 ), tl(t1 , f1 )] → f5 [tff (t1 , f5 ), tl(t1 , f5 )] →
. . . → fj [tff (t1 , fj ), tl(t1 , fj )]
...
f3 [tff (ti , f3 ), tl(ti , f3 )] → f6 [tff (t1 , f6 ), tl(t1 , f6 )] →
. . . → fk [tff (ti , fk ), tl(ti , fk )]

Terms
t1
idf (t1 )
...
ti
idf (ti )

Inverted index file
d1 [tfd (t1 , d1 ), tl(t1 , d1 )] → d2 [tfd (t1 , d2 ), tl(t1 , d2 )] →
. . . → dj [tfd (t1 , dj ), tl(t1 , dj )]
...
d3 [tfd (ti , d3 ), tl(ti , d3 )] → d5 [tfd (t1 , d5 ), tl(t1 , d5 )] →
. . . → dk [tfd (ti , dk ), tl(ti , dk )]

are generated from a query, because generalized terms can
only be matched by generalized terms of the query.
Index of terms and documents: To calculate the
composite score, the index file (See Table 4) of terms and
documents is constructed and this index file is referred to
as indext d hereafter. For each term ti , idf (ti ) describes
the inverted document frequency of ti : idf (ti ) = 1 +
Number of document
log 1+Number
. For each pair of term
of document containing ti
ti appears in document dj , tld (ti , dj ) records all unique
levels of ti appearing in different formulae in document
dj and tfd (ti , dj ) describes the frequency of ti occurring in
Number of ti in dj
document dj : tfd (ti , dj ) = Number of terms
.
in dj

In this paper, we propose a more sophisticated indexing
method to characterize the relevance of the document
containing a number of relevant formulae. A straightforward
way is to select the most relevant formula as the
representative of the document and rank the documents
according to their representatives [4]. However, this method
ignores the relevances of the formulae in the document
other than the selected representative, highly depends on
the accuracy of the similarity calculation between the query
formula and representative formula, and might miss the
documents containing a lot of other relevant formulae.
Another way is to calculate a relevance score between query
formula and the document according to all the formulae
in this document. In other words, we take all the terms
of the query formula and all the terms extracted from all
formulae in this document to calculate an overall relevance
score between the formula and the document. This method
combines all the relevance scores of the relevant terms
appearing in different formulae in the document, and might
overate the documents which are not really relevant. We
find those two strategies are contrary and complementary
to each other. In order to construct a reasonable strategy, a
hybrid score based on those two strategies is proposed.

3.7 Ranker
When a user searches a formula, the system will
firstly convert the query into Presentation MathML. Next,
semi-operator tree of the query is obtained by tree
constructor, and then it is tokenized into original terms
and generalized terms. After the terms are generated, the
inverted index files will be looked up and all the matched
terms will be returned to calculate similarity in ranker. The
similarity score between a query Q and a document D is
defined in Equation 1,
sim(Q, D) = α∗simidp (Q, D)+(1−α)∗simcmp (Q, D), (1)

3.6.2 Index Method

where sim(Q, D) is a weighted sum of the independent score,
simidp , and the composite score, simcmp . The independent
score, simidp , denotes the similarity score between the query
and the most similar formula in the document. For a
document, the formula with the highest similarity score
with the query is selected and its similarity score is taken
as the independent score, simidp , between the query and
the document. The composite score, simcmp , describes
the similarity score between the query and all the relevant
formulae in the document. α and 1 − α denote the weights
for the independent score and the composite score. In our
experiment, α is set as 0.7. Definitions of simidp and simcmp
are given in Equation 2 and Equation 4, respectively.
A document may contain many relevant formulae and
the f ormula similarity score between the query, Q, and
each formula in the document, Fi , can be calculated. The
simidp (Q, D) chooses the formula with the highest similarity
score as its document similarity score:
X
simidp (Q, D) = max{Wcover (Q, Fi ) ∗
(tff (t, Fi ) ∗ iff 2 (t)∗

In order to support efficient online query, we calculate the
statistics of each term offline and store them in the inverted
index files. Two index files are built to calculate a hybrid
similarity score of a query and a document: 1) Index file
for terms and formulae is built to calculate the independent
score, which denotes the similarity between the query and
a single formula; 2) Index file for terms and documents
is built to compute composite score, which describes the
similarity between the query and all the relevant formulae
in a document.
Index of terms and formulae:
To calculate
independent score, an index file (See Table 3) of terms
and formulae is constructed and this file is referred to as
indext f hereafter. For each term, a list of formulae, which
contain this term, is recorded. A formula(f ) “contains” a
term(t) denotes that the content field of one of the terms
extracted from f is exactly the same with that of t. For
each term, iff(ti ) describes the inverted formula frequency
Number of f ormulae
of ti : iff(ti ) = 1 + log 1+Number
.
of f ormulae containing ti
For each pair of term ti appears in formula fj : tlf (ti , fj )
denotes the level of ti in fj . Since there may be several
occurrences of ti in fj and their levels may be different,
tlf (ti , fj ) records all the unique levels of ti in fj . tff (ti , fj )
describes the frequency of ti occurring in fj : tff (ti , fj ) =

i

t∈Q

Wlevel (t, Q, Fi ) ∗ Wgen (t))}.

(2)

The f ormula similarity score between a formula Fi and
a query Q is the weighted sum of similarity scores of all
matched terms. For each term t generated from the query Q,
a similarity score is calculated in Equation 2, where tff (t, F )
and iff(t) are stored in the index file, indext f . Wcover (Q, F )
denotes the ratio of number of terms in Q matched by F
to the total number of terms in Q. The term level weight,

Number of ti in fj
Number of terms in fj

.
It is worth mentioning that, original terms and
generalized terms, which are extracted by the tokenizer (see
Section 3.5), are stored in the same index file. They can be
discriminated by matching the content field of terms, which

703

Wlevel , is introduced to evaluate the distance of the matched
terms on different levels:
1
Wlevel (t, Q, F ) =
. (3)
1 + min{|level(t, Q) − levelj (t, F )|}

The other part is collected from a publicly available PDF
document set proposed for formula identification [6]. It
contains 400 pages from 194 documents, which are crawled
from CiteSeerX. The dataset consists 9,482 formulae. Since
the precise boundaries of all the formulae are already
provided in this dataset, their Presentation MathML
markups are obtained based upon the given boundaries, via
adopting formula structure analysis [17] with modification
and manual correction.

j

There may be several occurrences of the term t in the
formula F and they may be at different levels of the formula
F . Therefore, different level distances may be obtained
through calculating distances between the query term level
(level(t, Q)) and each matched term level (levelj (t, F )).
In our system, a minimum level distance is taken as the
level distance between the query term t and the formula
F . In order to ensure that the exactly matched terms
would always get higher similarity score than those who
are approximately matched, the weight of generalization,
Wgen (t), is introduced as a penalty of the generalized terms.
Wgen (t) is assigned as 1 if t is an ordinary term, otherwise
Wgen (t) is set as θ, where 0 < θ < 1. In our experiment,
θ = 0.5. For instance, calculation of the independent score,
simidp , between formula, (x + y), and query, (x + y) × ab , is
illustrated in Table 5.
Table 5: Independent Score of (x + y) ×
Lq 1 Lf
1
2

Matched terms
(x + y)
(∗)

1

2

x+y

2

3

∗+∗

2

3

simidp =
1

4
8

a
b

4.2 Time & Space Efficiency
The index files are constructed offline on a MacBook Pro
with 2.8 GHz Intel Core i7, 4 GB DDR3 and 750 GB SATA
Disk. The system is implemented using Scala based on
Lucene. The time taken to construct the index files and the
sizes of the index files are evaluated with increasing amount
of indexed formulae, as shown in Table 6. It costs less than
40 minutes to generate two index files after the dataset is
inputted to our system. The total size of index is less than
1.2 GB. As the number of indexed formulae increases, the
construction time and sizes of index files increase steadily.
Table 6: Construction Time and Sizes of Index Files

and (x + y)

Number of formulae
Time (MM:SS)
Size of indext f (MB)
Size of indext d (MB)
Total size (MB)

tf * iff2 * Wlevel * Wgen
1
∗ 8.482 ∗ 1+|2−1|
∗ 1 = 8.99

1
4
1
1
∗ 2.812 ∗ 1+|2−1|
∗ 0.5 = 0.49
4
1
1
2
∗
7.71
∗
∗ 1 = 7.43
4
1+|3−2|
1
1
2∗
∗
4.73
∗
0.5 = 1.40
4
1+|3−2|

Lq & Lf denote the term level in the query and the formula.

Different from independent score, the composite score
scorecmp calculates the similarity of a query and a document
based upon all the matched terms in a document and it is
as defined in Equation 4,
X
simcmp (Q, D) = Wcover (Q, D) ∗
(tfd (t, D) ∗ idf 2 (t)∗
t∈Q

100,048
03:47
65
65
130

531,264
37:10
291
856
1,147

(4)
Table 7: Query Response Time

simcmp combines the similarity scores of all the matched
terms in the document. For each term t generated from
the query Q, the similarity score is calculated according
to the term frequency in document, tfd (t, D), and its
inverted document frequency, idf (t). Wlevel (t, Q, D) is
similar with Wlevel (t, Q, Fi ), but it chooses the shortest
term level distance from a document rather than a formula.
Wcover (Q, D) is similar with Wcover (Q, F ), but it indicates
the ratio of terms in Q, which are matched by a document
rather than a formula.

4.

10,096
00:29
7.0
6.3
13.3

Table 7 illustrates the query time with increasing amount
of indexed formulae. The minimum, maximum, median and
average query time over 100 different queries are tested upon
indexes based on increasing number of indexed formulae. It
is seen that as the size of index file increases, the average
query response time increases steadily. On average, it costs
around 500ms to respond to a query. The maximum query
time is cost by the queries containing many commonly seen
terms (e.g., x2 ), because the more number of formulae
or documents contain the queried terms, more time is
consumed to merge the document lists.

∗ (8.99 + 0.49 + 7.43 + 1.40) = 9.16

Wlevel (t, Q, D) ∗ Wgen (t)).

1,036
00:16
0.72
0.67
1.39

Number of formulae
Min (ms)
Max (ms)
Median (ms)
Average (ms)

1,036
8
147
14.0
18.3

10,096
10
431
21.5
29.8

100,048
13
532
111.5
114.6

531,264
28
1,419
488.5
514.1

4.3 Accuracy
4.3.1 Compared Algorithms
We compare the proposed method with two baseline treebased indexing mathematics retrieval systems: 1) MIaS
[15] indexes all the substructures of formulae and calculates
the similarity of each substructure considering their levels.
Because the MIaS is built upon arXiv dataset rather than
Wikipedia, we re-implement this method to compare in
this paper. 2) WikiMirs [2] is a representative tree-based
indexing system without semantic enrichment based on
Wikipedia. It indexes all substructures of the formulae in
LATEX considering the generalization of substructures.
In order to verify the effectiveness of the proposed
techniques (semantic enrichment in tree constructor,
normalization and generalization in tokenizer), comparison

EXPERIMENTAL RESULTS

4.1 Dataset
The dataset used in this paper is collected from publicly
available webpages and PDF documents.
Therefore,
comparative evaluation with further methods can be carried
out via using the same dataset. Part of the dataset
is collected from Wikipedia, whose copy can be freely
downloaded. Concretely, the 2013-07-08 dump, whose size
is 41 GB uncompressed, is used. This dataset contains
13.6 millions webpages and 521,782 mathematical formulae.

704

is also carried out when these techniques are turned off
selectively. Concretely, four systems are constructed with
four different configurations: 1) oursbase : Neither semantic
enrichment nor normalization or generalization are adopted
and this is considered as a baseline method; 2) oursgen :
Semantic enrichment and normalization of operand order
are turned off, but generalization is adopted; 3) ourssem :
Semantic enrichment and normalization of operand order
are adopted, but generalization is turned off; 4) Ours: The
proposed system with all the proposed techniques turned on.

and most of them are relevant. MIaS retrieves much more
results, but it does not rank the relevant results properly.
This is mainly why MIaS achieves higher P10 than WikiMirs,
while has a lower DCG10 than WikiMirs. It should be
mentioned that MIaS is proposed towards arXiv and the
parameters and settings are tuned for this dataset. We
consider this might be an important factor affecting MIaS’s
performance here. For WikiMirs, it is found that no result
is returned for about 40 queries and it is considered as the
main reason why WikiMirs achieves lower P and DCG.
By comparison, the proposed method achieves a
significant improvement in P and DCG. Compared with the
baseline strategy (oursbase ), both generalization strategy
(oursgen ) and semantic enrichment with normalization
strategy (ourssem ) achieves higher P10 and DCG. It is seen
that through adopting these strategies, the relevant results,
which do not exactly match the query but share similar
structures with different presentations, are retrieved back
and ranked properly. The proposed system, using all these
techniques, makes a distinct improvement in P and DCG,
compared with the other methods.

4.3.2 Query Set
In this paper, a query set containing 100 queries is utilized
for evaluation. Among this query set, 70 queries with one
relevant page for each queries are provided by [4]. 12 queries
are the queries used in the literatures [2] and [13]. The
rest is newly added and they are collected from formulae
in Wikipedia. In order to facilitate further comparison, the
query set, along with the scores for corresponding retrieved
documents given by the subjects, are publicly available at
our system’s address.

4.3.3 Evaluation Measures

Table 8: Average Precision & DCG at Top-k Results
Systems
MIaS
WikiMirs
oursbase
oursgen
ourssem
Ours

For each test query, the top-k documents retrieved by the
six different systems are evaluated. The relevances between
the retrieved documents and the queries are judged by five
postgraduates majoring in Computer Science. The query
set is divided into five independant parts randomly and
equivalently. And each part, containing 20 queries, is judged
by a subject. For each query, top-k results returned by each
system are presented to the subject in order. Each result
(document), includes the title, URL, and a representative
formula, which achieves the highest simidp score. For each
result, a subject gives a relevance score, where score ∈
{0, 1, 2, 3, 4, 5}. 0 denotes the no score has been assigned
yet, 1 indicates the result is irrelevant, and 2 ∼ 5 denotes
the relevance between the result of the query, where higher
score indicates higher relevance.
To increase the efficiency of manual measurement and
insure the same result gets the same judge in different
systems, a judging interface is implemented to reuse the
labeled results via recording a map from (Q, D) to its labeled
score. In other words, if a specific (Q, D) has been judged
in a system, the subjects do not need to judge it again when
scoring other systems. The labeled results of each system
for all the queries are released along with the query set.
Average Precision (P) and Discounted Cumulative Gain
(DCG) [3] are calculated based on the top-k retrieved
documents over all queries. For each query, a list of scores
of the top-k results is given by the subjects. The i-th
element scorei in the score list denotes the score of the i-th
retrieved document. P is calculated based on whether the
retrieved document is relevant (scorei > 1) to the query or
not (scorei = 1). P of the top-k results is calculated as,
P
documents
Pk = ki=1 Number of relevant
. DCG is calculated
k
based on the relevant score of the result according to its
position in the result list. DCG of the top-k results is defined
P
(scorei −1)
as, DCGk = ki=1 2 log (i+1)−1 .

P3
0.35
0.40
0.82
0.82
0.82
0.86

P5
0.35
0.38
0.80
0.80
0.81
0.84

P10
0.34
0.31
0.72
0.75
0.74
0.79

DCG3
1.96
5.34
11.70
12.23
12.96
14.47

DCG5
2.56
6.43
14.31
15.22
16.23
17.90

DCG10
3.75
7.95
18.10
19.57
20.54
23.27

4.3.5 Case Study
For each document, the formula with the highest
formula-query score is selected to be the representative
of this document. Table 9 shows two queries with top-5
results retrieved by different systems, ordered by document
similarity scores with the query.
P
(−1)n x2n
Take ∞
as an example, the same top-2 results
n=0
(2n)!
containing exact content of the query are found by both
WikiMirs and our system. However, the top-3 result of
our system is obviously more relevant to the query, since
it shares more common substructures with the query. It
is mainly because more delicate substructure matching and
similarity calculation is adopted
in our paper.
x
Take f (x) = x1 + 1
as an example, no result is
returned by WikiMirs because the operand order of “+”
in query is different from those in document set. Only
one result is returned by WikiMirs even if the order of
the operand “+” is the same with those in document set.
Reasonable results are returned by our system in either
cases. It is mainly because semantic enrichment
is adopted,
x
so that the substructure of x1 + 1
can be extracted,
hierarchical generalization enables equations containing such
substructure rank higher, normalization of operand order
overcome the different presentations of x1 + 1 and 1 + x1 .

5. CONCLUSIONS
To facilitate the access and search for mathematical formulae in existing information systems, this paper investigates the main challenges in constructing mathematics retrieval system for formulae in layout presentations. Meanwhile, a mathematics retrieval system focusing on such formulae is proposed, with the following three contributions:

2

4.3.4 Performance of the Top-k Results
The average P and DCG at top-k results over all queries
are illustrated in Table 8. From the experiments, we find
that WikiMirs usually retrieves a small number of results

705

Table 9: Comparison of Top-5 Results of Different Systems
Queries
P∞ (−1)n x2n
n=0

(2n)!

(substructure/fuzzy
match)

Systems
MIaS
WikiMirs

Ours
x
f (x) = x1 + 1
(generalization,
substructure match)

MIaS
WikiMirs
Ours

Top-5 results
P
1
2n; n(n − 1); 2n − 1; n; e = ∞
n=0 n!
P∞ (−1)n x2n
P∞
P∞ (−1)n x2n
; cos x
=
; (2n)!;
:=
cos x
=
n=0
n=0 kfn k
n=0
(2n)!
(2n)!
n
2n
P∞
P
(−1) x
∞
x2
x4
x6
n=0 supS |fn (x)| < ∞. cos x = 1 − 2! + 4! − 6! + · · · =
n=0
(2n)!
P∞ (−1)n x2n
P∞ (−1)n x2n
P∞ x2n P∞
n 2n .;
cos x =
; cos x =
; cosh x =
n=0
n=0
n=0 (2n)! ;
n=0 (−1) z
(2n)!
(2n)!
(2n)!
n!

a = f (x); +; +; n = 1 + D/2;
x z = a + ib

1 x
No result. f (x) = 1 + x1 is returned when searching f (x) = 1 +
.
x

x
x
x
= e; limx→∞ 1 +
f (x) = 1 + x1 ; 1 + x1 ; e = limx→∞ (1 + x1 )x ; limx→∞ 1 + x1

[6] X. Lin, L. Gao, Z. Tang, J. Baker, and V. Sorge.
Mathematical formula identification and performance
evaluation in pdf documents. Int. J. Doc. Anal.
Recogn. (IJDAR), 2013.
[7] M. Lı́ška, P. Sojka, and M. Ružicka. Similarity search
for mathematics: Masaryk university team at the
ntcir-10 math task. In Proc. of the 10th NTCIR
Conference, pages 686 – 691, 2013.
[8] X. Liu. Generating metadata for cyberlearning
resources through information retrieval and
meta-search. JASIST, 64(4):771–786, 2013.
[9] B. Miller and A. Youssef. Technical aspects of the
digital library of mathematical functions. Annals of
Mathematics and Artificial Intelligence, 2003.
[10] R. Miner and R. Munavalli. An approach to
mathematical search through query formulation and
data normalization. Towards Mechanized
Mathematical Assistants, pages 342–355, 2007.
[11] J. Mišutka and L. Galamboš. Extending full text
search engine for mathematical content. Towards
Digital Mathematics Library, pages 55–67, 2008.
[12] T. T. Nguyen, K. Chang, and S. C. Hui. A math-aware
search engine for math question answering system. In
The 21st ACM Int. Conf. on Information and
Knowledge Management, pages 724–733. ACM, 2012.
[13] T. T. Nguyen, S. C. Hui, and K. Chang. A
lattice-based approach for mathematical search using
formal concept analysis. Expert Systems with
Applications, 39(5):5820–5828, 2012.
[14] T. Schellenberg, B. Yuan, and R. Zanibbi.
Layout-based substitution tree indexing and retrieval
for mathematical expressions. In IS&T/SPIE
Electronic Imaging, volume 8297, page 82970I, 2012.
[15] P. Sojka and M. Lı́ška. Indexing and searching
mathematics in digital libraries. Intelligent Computer
Mathematics, pages 228–243, 2011.
[16] R. Zanibbi and D. Blostein. Recognition and retrieval
of mathematical expressions. Int. J. Doc. Anal.
Recogn. (IJDAR), pages 1–27, 2012.
[17] R. Zanibbi, D. Blostein, and J. R. Cordy. Recognizing
mathematical expressions using tree transformation.
IEEE Trans. on Pattern Analysis and Machine
Intelligence, 24(11):1455–1467, 2002.
[18] J. Zhao, M.-Y. Kan, and Y. L. Theng. Math
information retrieval: user requirements and prototype
implementation. In The 8th ACM/IEEE-CS joint
conf. on Digital libraries, pages 187–196. ACM, 2008.

1) This system supports searching formulae from both webpages and PDF documents with a novel query input interface, which enables users to input query formula directly
when reading PDF documents. 2) A semantic enrichment
technique is proposed to extract useful semantic information from formulae in layout presentation, resulting in better support for reasonable normalization of operand orders
and generalization of substructures. 3) Hierarchical generalization of substructures is proposed to generate index terms
to support substructure matching and fuzzy matching. 4)
The problem of scoring a document with multiple relevant
formulae is addressed, and a hybrid scoring method, considering both the most relevant formula and multiple relevant
formulae, is proposed. Experiments for self-comparison are
carried out to prove that the aforementioned techniques do
help to improve the performance of mathematics retrieval.
Moreover, comparison experiments with two representative
systems also show that the proposed system achieves better
performance.
The proposed system, dataset and query set are publicly
available for further comparison. Meanwhile, we plan
to re-evaluate and refine our system via participating in
competition of NTCIR Task Math8 , which provides a test
collection and a set of tasks for mathematics retrieval.

6.

ACKNOWLEDGMENTS

This work is supported by the National Natural Science
Foundation of China (No.61202232).

7.

REFERENCES

[1] A. Aula and M. Käki. Understanding expert search
strategies for designing user-friendly search interfaces.
In ICWI, pages 759–762, 2003.
[2] X. Hu, L. Gao, X. Lin, Z. Tang, X. Lin, and J. B.
Baker. Wikimirs: a mathematical information retrieval
system for wikipedia. In The 13th ACM/IEEE-CS
joint conf. on Digital libraries, pages 11–20, 2013.
[3] K. Järvelin and J. Kekäläinen. Ir evaluation methods
for retrieving highly relevant documents. In The 23rd
Int. ACM SIGIR Conf., pages 41–48. ACM, 2000.
[4] S. Kamali and F. W. Tompa. Retrieving documents
with mathematical content. In The 36th Int. ACM
SIGIR Conf., pages 353–362. ACM, 2013.
[5] M. Kohlhase and I. Sucan. A search engine for
mathematical formulae. In Artificial Intelligence and
Symbolic Computation, pages 241–253. Springer, 2006.
8


1 x
x

http://ntcir-math.nii.ac.jp/

706


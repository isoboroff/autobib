On Peculiarities of Positional Effects in Sponsored Search
Vyacheslav Alipov

Valery Topinsky

Ilya Trofimov

Yandex LLC
16 Leo Tolstoy St.
Moscow, Russia

Yandex LLC
16 Leo Tolstoy St.
Moscow, Russia

Yandex LLC
16 Leo Tolstoy St.
Moscow, Russia

alipov@yandex-team.ru

vtopin@yandex-team.ru

ABSTRACT

search engine’s revenue by selecting the “right” ads to show
and keep the ad-selecting mechanism fair for advertisers.
Click logs contain regularly refreshing real users’ assessments on relevance of documents and ads circulating in a
search engine system. But extracting these judgments from
logged data is not a trivial task as clicks are heavily biased
with respect to presentation order, neighboring ads, user
traits, etc., so the direct estimation of CTR may lead to
inadequate results.
One of the most studied problems is position bias. The examination hypothesis [6] suggests that the click occurs iff the
link is both relevant and examined. The cascade hypothesis
[3] assumes that user scans the results from top to bottom
making decisions whether to continue examination or quit
the search session based on the relevance of the current link.
Most of the research in positional effects falls into the field
of organic search. And the common practice is to adopt organic search click models to advertisements through modifications addressing sponsored search peculiarities such as
click sparsity and users’ negative bias [9, 2]. But there is
a reasonable doubt that users scanning through sponsored
links exercise the kind of behavior just slightly different from
that when analyzing organic search results. Mainly because
the differences between organic and sponsored results lie far
beyond lower clicks rates of ads. At first sight, the top
ads block is just an extension of the organic search results.
But there are some fundamental distinctions. It is outlined,
compact (just 3 or 4 positions at most) and well observed.
Another crucial peculiarity is that content of ad block is
homogeneous by nature: same goods, similar offers, indistinguishable prices, especially, when competition for a set of
keywords is intense. Thus users seem to analyze the whole
block and compare the offers.
The aim of this paper is to demonstrate conditions under
which the cascade-based model fails and is outperformed
even by simple examination-hypothesis-based ones which
were shown to be inferior in later works [9]. Thus, we question the practice of applying organic search click models to
ads and provide a detailed rationale for modeling much more
complicated externalities of neighboring ads. Also we reveal
the drawbacks of model assessment techniques utilized in
previous works on positional effect that may have caused
the misleading results. At Yandex we designed and conducted an experiment on a part of search engine audience
to collect test data that is really challenging for positional
click models. We demonstrate the superiority of this method
of evaluating model’s performance.

Click logs provide a unique and highly valuable source of
human judgments on ads’ relevance. However, clicks are
heavily biased by lots of factors. Two main factors that
are widely acknowledged to be the most influential ones are
neighboring ads and presentation order. The latter is referred to as positional effect. A popular practice to recover
the ads quality cleaned from positional bias is to adopt click
models based on examination or cascade hypothesis originally developed for organic search. In this paper we show
the strong evidence that this practice is far from perfection
when considering the top ads block on a search engine result
page (SERP). We show that cascade hypothesis is the most
questionable one because of important differences between
organic and sponsored search results that may encourage
users to analyze the whole ads-block before clicking. Additionally, we design a testing setup for an unbiased evaluation
of click model prediction accuracy.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

General Terms
Algorithms, Experimentation, Performance, Measurement

Keywords
Sponsored search; positional effect; click model; experiment

1.

trofim@yandex-team.ru

INTRODUCTION

The main source of income of major search engines is
sponsored search. The set of ads to be shown and their
order of presentation depend on the bid of the advertiser
for the matched keywords and the estimated click-through
rate (CTR) of the ads. Thus it is vital to perform CTR
prediction as precisely as possible in order to maximize the
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’14, July 06–11 2014, Gold Coast, QLD, Australia
Copyright 2014 ACM 978-1-4503-2257-7/14/07$15.00.
http://dx.doi.org/10.1145/2600428.2609498.

1015

2.

BACKGROUND

3.2

In this section we introduce two main positional hypotheses: examination and cascade ones.

2.1

Examination Hypothesis

P (Ei+1 = 1|Ei = 1, Ci = 0, Bi ) = I(Bi > 0)

Examination hypothesis [6] assumes that given a query q
a click on a link u at position i happens iff the link is both
relevant and examined. The model assumption is expressed
as factorizing the probability of click into two multipliers.
One depends only on a link u and a query q thus representing
relevance or quality of a document. The other depends solely
on position and can be thought of as a penalty for landing
this low in the results. Or formally:
P (C = 1|u, i, q) = P (C = 1|u, q, E = 1) ·P (E = 1|i),
{z
}
|

P (Ei+1 = 1|Ei = 1, Ci = 1, Ai ) = I(Ai > 0)
P (Ci = 1|Ei = 1, Ri ) = I(Ri > 0)

A
A
Ai = θu,q
+ bA
i + b + εi
B
B
Bi = θu,q
+ bB
i + b + εi

(1)

Ri =

Cascade Model

Under the assumption of cascade model [3] user scans the
results from top to bottom until she finds a link she was
looking for and clicks immediately abandoning the search
session. Thus cascade model is formally described by the
following set of equations:

+

bR
i

+b+

(5)

εR
i

P (E1 = 1) = 1

3.3

P (Ei+1 = 1|Ei = 0) = 0
P (Ei+1 = 1|Ei = 1, Ci ) = 1 − Ci

Both models were implemented under the Infer.NET framework [5]. The inference procedure for both models goes in
strict correspondence with the [9]:
• Prior distributions for all variables are set to N (0, 1/3).
• One pass over the training set is performed.
• For each session posterior distributions for all the variables are evaluated given clicks as observable events.
These posteriors become the new priors.

(2)

P (Ci = 1|Ei = 1) = rui ,q
where Ei , Ci are binary events that a link at the i-th position is examined and clicked respectively, rui ,q is relevance or quality of a link u that landed at position i given
query q. More recent cascade-based models basically just
remove the unrealistic restriction of one click per query session by modifying the expression for conditional probability
P (Ei+1 = 1|Ei = 1, Ci ).

4.

MODELS IN CONSIDERATION

4.1

DATASET

Training Set

We collect four-day click log data from Yandex search engine. We limit ourselves to the top ads block on the first
page of a search session. Moreover only sessions with fully
packed top ads block are considered — at Yandex full block
comprises 3 ads. Under this kind of setup the positional effects should be the most pronounced. A total of 11,701,043
sessions are collected with an average of 13.19 impressions
per ad and 7.42 impressions for ad-query pair.
A recent research in Yandex [1] showed that there are
strong positional effects in the top ads click log data, so
training a positional click model is not a pointless task.

Gaussian Linear Model (GLM)

Let’s define a simple linear model based on examination
hypothesis. The model is defined by the following equation:
P (C = 1|u, i, q) = P (θu,q + ei + b + ε > 0),

Inference

In this section we proceed on peculiarities of the data set
used.

In this section we define the click models that will be used
in the experiments.

3.1

R
θu,q

where all the summands are independent Gaussian random
variables with b-variables being the biases and ε-variables
being standard normal noise.
We chose GCM as a cascade-based model because of its
capability to fit a much wider range of user behavior allowing
all the transitions probabilities to depend on a current adquery pair. In contrast with the original paper, we do not
introduce any additional user or ad features as our goal is
testing the model assumptions on user behavior rather than
achieving maximal accuracy.

where C is a binary click event and E is a hidden binary
variable taking the value 1 when a link u at position i is
examined.

3.

(4)

where in our case continuous random variables Ai , Bi , Ri
will be modeled as:

ru,q

2.2

General Click Model (GCM)

General Click Model (GCM), described in [9], generalizes
cascade model by defining the following transition probabilities:

(3)

where θu,q , ei , b and ε are independent Gaussian random
variables corresponding to the following quantities respectively: relevance of ad u to query q; penalty for landing on
the i-th position; bias; standard normal noise.
Strictly speaking, equation (3) is not in exact correspondence with examination hypothesis (1) but fundamentally
idea is the same. The probability of click depends on two
independent variables: θu,q which represents relevance of
ad u to query q and ei which estimates how likely the user
will examine position i. It is worth noting that this model
strongly resembles the adPredictor described in [4] — a CTR
predicting click model actually implemented in Bing’s production environment.

4.2

Experiment Setup and Test Set

We collect two different test sets.
Data for the first test set is collected from the experiment conducted on a small portion of Yandex search engine
audience. During this experiment the top ads block was randomly shuffled (uniformly over all 3! permutations) before
revealing it to user. In the regular setting ads do not change
their positions that often, but in shuffled data each ad will

1016

appear on each position almost evenly. So in order to perform well on such test set a model should accurately predict
CTR for every ad on all of the positions. This experimental
click log is collected immediately after the last session from
train dataset.
As a second test set we take a regular click log from Yandex with sessions that happened right after the last session
in the training set.
Each test set comprises 1,491,357 sessions.
To illustrate the difference between two test sets we evaluate the following statistic. For each ad we measure the
dispersion of the number of times this ad appeared at each
position and average these dispersions over all ads in the
test set. Low values of this statistic demonstrate that ads
appear on all of the positions almost uniformly, while high
values show that ads tend to stick to a certain position. The
first test set has D1 and for the second test set D2 , the value
2
of D
≈ 39.8. Thus in the first test set ads are distributed
D1
among positions much more uniformly.

5.

(a)

EXPERIMENTS AND DISCUSSION

We train all the models in consideration on the same training set. Then we conduct two different experiments. The
first experiment is designed to show the flaws of the regular
test set. The aim of the second is to justify the doubts in
the cascade hypothesis in the top ads block.
We use Log-Likelihood (LL) as measure of models’ prediction accuracy. The LL of a single ad impression is evaluated
as l = c · log(p) + (1 − c) · log(1 − p), where c equals 1 if the
ad was clicked and 0 otherwise, p is predicted CTR. The LL
of test set is an average LL over all the ad impressions over
all the sessions. The improvement of LL value l1 over value
l2 is evaluated as (exp(l1 − l2 ) − 1) · 100%.

5.1

(b)
Figure 1: Log-Likelihood Improvement of different
orders of examination over the baseline “1,2,3”-order
on the regular (a) and the experimental (b) test sets.
Note the different scales of axes on figures (a) and
(b).

Experiment #1: Flaws of the Regular Test
Set

The GCM model (inherently from Cascade Model) assumes the top-to-bottom order of examination: the 1-st,
the 2-nd and then the 3-rd position. But let’s train all the
3! = 6 models considering all possible examination orders.
Evaluation on the regular test set is presented in Figure 1a. All 6 models differ in accuracy negligibly with a
bizarre “2,1,3”-order being in the lead. While evaluation on
the experimental test set, shown in Figure 1b, clearly states
that “1,2,3”-order is the most probable scenario. The explanation is simple. In the regular test set the ads appear
predominantly in the same positions as in the training set,
so the prediction task simplifies significantly as a portion of
unseen events is quite small and almost any model of examination can be fit accurately. One can consider this as a
lack of independence between train and test data. Whereas
the experimental test set puts model assumptions to a real
test. It demands from a model to deduce transition and click
probabilities from learned distribution at points previously
unobserved.

5.2

Experiment #2: Credibility of Cascade Hypothesis

We compare performance of GCM and GLM on two test
sets. In order to make our conclusions more assertive we
evaluate the relative accuracy of two models on several subsets of test sets. We leave in the test set only those sessions

1017

in which each of the three ads has the number of impressions in the training set not less than a certain threshold for
values of threshold from 0 to 100.
The LL improvement of GCM over GLM is shown in Figure 2. The improvement is negative, thus GCM is outperformed by GLM on both test sets under all values of threshold. Moreover a distinctive trend can be observed — difference between two models increases as we restrict the test
set to the ads that have a larger amount of impressions. For
ads with a significant amount of statistics a simple linear
model (like GLM) becomes quite certain about their “unbiased relevance” by averaging their performance on different
positions. With such an estimate on ad quality the straightforward positional penalty becomes good enough to slightly
improve the prediction accuracy. While GCM makes strong
assumptions on user behavior which do not seem to hold
in practice, thus producing much less accurate results even
for ads with a great number of impressions. In other words,
the bias of the model assumptions themselves makes a much
stronger impact on the learned ad’s relevance than the positional effect.
Additionally, Figure 2 shows another advantage of experimental test set over the regular one. As we already showed
in the experiment #1 even the most odd model assumptions could perform well on a not perfectly independent test
set. This result is further strengthen during the second experiment as GCM and GLM perform almost equally on the
different subsets of regular test data. Whereas experimental data reveals the flaws of the models much more explicitly. When the threshold on ads impressions increases GCM
looses to GLM with a noticeable margin. Hence the cascade

Secondly, we argue that the positional effect in the top
ads block cannot be accurately modeled by adopting the
organic search click models. We design an experimental
setup where the cascade-based model loses in accuracy to
the examination-hypothesis-based model that is considered
quite unrealistic even in organic search field. Therefore in
our future work we will focus on click models that consider
complex neighboring ads externalities and allow user to compare the offers (like in [7, 8]).

7.

[1] D. Arkhangelsky, S. Izmalkov, and D. Khakimova. On
evaluation of ctrs of different positions in sponsored
search auctions. 14th ACM Conference on Electronic
Commerce, poster, 2013.
[2] A. Ashkan and C. L. A. Clarke. Modeling browsing
behavior for click analysis in sponsored search. In
Proceedings of the 21st ACM International Conference
on Information and Knowledge Management, CIKM
’12, pages 2015–2019, New York, NY, USA, 2012. ACM.
[3] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An
experimental comparison of click position-bias models.
In Proceedings of the 2008 International Conference on
Web Search and Data Mining, WSDM ’08, pages 87–94,
New York, NY, USA, 2008. ACM.
[4] T. Graepel, J. Q. Candela, T. Borchert, and
R. Herbrich. Web-scale bayesian click-through rate
prediction for sponsored search advertising in
microsoft’s bing search engine. In Proceedings of the
27th International Conference on Machine Learning
(ICML-10), pages 13–20, 2010.
[5] T. Minka, J. Winn, J. Guiver, and D. Knowles.
Infer.NET 2.5, 2012. Microsoft Research Cambridge.
http://research.microsoft.com/infernet.
[6] M. Richardson, E. Dominowska, and R. Ragno.
Predicting clicks: Estimating the click-through rate for
new ads. In Proceedings of the 16th International
Conference on World Wide Web, WWW ’07, pages
521–530, New York, NY, USA, 2007. ACM.
[7] X. Xin, I. King, R. Agrawal, M. R. Lyu, and H. Huang.
Do ads compete or collaborate?: Designing click models
with full relationship incorporated. In Proceedings of
the 21st ACM International Conference on Information
and Knowledge Management, CIKM ’12, pages
1839–1843, New York, NY, USA, 2012. ACM.
[8] C. Xiong, T. Wang, W. Ding, Y. Shen, and T.-Y. Liu.
Relational click prediction for sponsored search. In
Proceedings of the Fifth ACM International Conference
on Web Search and Data Mining, WSDM ’12, pages
493–502, New York, NY, USA, 2012. ACM.
[9] Z. A. Zhu, W. Chen, T. Minka, C. Zhu, and Z. Chen. A
novel click model and its applications to online
advertising. In Proceedings of the Third ACM
International Conference on Web Search and Data
Mining, WSDM ’10, pages 321–330, New York, NY,
USA, 2010. ACM.

Figure 2: Log-Likelihood Improvement of GCM over
GLM
hypothesis appears to be even less realistic than examination one producing inaccurate predictions even for ads with
sound statistics.

5.3

Discussion

Let’s give a rationale for why the cascade hypothesis may
not hold in the top ads block.
Firstly, the top ads block itself is compact and emphasized
center of attention above the organic search results. With a
small number of positions in a full block it is fully observable by user instantly and without scrolling. Additionally,
sponsored results often include lots of distinctive details like:
direct links to refined sections of advertiser’s web-site; working hours; an address and a phone number; nearest subway
station; pictographs of a company’s logo; etc. All these factors motivate user to analyze the full block before clicking,
or just immediately steal user’s attention to a certain ad
even if it is not at the first position. Therefore, users often
neither examine results from top to bottom nor click before
seeing the lower ads.
Secondly, the contents of ads block are fundamentally different from the organic results. The ambiguousness of most
search queries encourages to diversify the organic search results to satisfy multiple possible user’s intents. Whereas
in sponsored search the commercial intent is often precise.
And if it is not, search engine is bound by obligation to show
only those ads that matched certain keywords in the query.
Thus the ads block is much more homogeneous than the organic search results. Especially for popular purely commercial queries where competition among advertisers is really
intense and tight. So users do not seem to scan through the
results until the link matches their intent but tend to choose
between similar offers before making a click.

6.

REFERENCES

CONCLUSIONS

There are two main results of this work. Firstly, we demonstrate that commonly used test sets for positional click models are not challenging enough and can lead to inadequate
results. We suggest a testing setup providing much more
fair and transparent evaluation results: all the ads should
appear at all the positions evenly.

1018


Opinion Spammer Detection in Web Forum
Yu-Ren Chen and Hsin-Hsi Chen
Department of Computer Science and Information Engineering, National Taiwan University
No. 1, Sec. 4, Roosevelt Rd., Taipei 10617, Taiwan
+886-2-33664888x311

chenaren@gmail.com; hhchen@ntu.edu.tw
Duplicate and near-duplicate reviews were regarded as fake
reviews. The researches [2][5][7] were based on the this dataset
for opinion spammer detection. Wang et al. [9] collected a large
amount of store reviews from resellerratings.com for their
experiments.

ABSTRACT
In this paper, a real case study on opinion spammer detection in
web forum is presented. We explore user profiles, maximum
spamicity of first posts of users, burstiness of registration of user
accounts, and frequent poster set to build a model with SVM with
RBF kernel and frequent itemset mining. The proposed model
achieves 0.6753 precision, 0.6190 recall, and 0.6460 F1 score.
The result is promising because the ratio of opinion spammers in
the test set is only 0.98%.

The evaluation methodologies are always based on human. Lim et
al. [5] proposed a rigorous human evaluation procedure to
examine a pool of ranked reviewers from different spammer
detection methods. Mukherjee et al. [6] conducted a user study,
and Mukherjee et al. [7] employed 8 expert judges for their work.
Wang et al. [9] claimed suspicious reviewers who should have
significant number of reviews satisfying three proposed
conditions. Fei et al [2] argued that human evaluation was
subjective, and proposed a complementary evaluation. They
assumed that if a reviewer was labelled as a spammer, then all
his/her reviews were considered as spam reviews. The above
work showed some degrees of annotator agreement in human
evaluation.

Categories and Subject Descriptors
H.3.3 [INFORMATION STORAGE AND RETRIEVAL]:
Information Search and Retrieval –Information filtering.

General Terms
Algorithms, Design, Experimentation, Human Factors.

Keywords

Different from the previous studies, this paper is based on a set of
internal records of opinion spams leaked from a shady marketing
campaign (see Section 2). To the best of our knowledge, it is the
first research to study the behaviors of opinion spammers in web
forum. The subtle nature of forum posts, low spam post of
spammers, different types of spammer accounts, and interaction
between forum posters are key issues.

Fake Web Review, Opinion Spammer Detection, Web Forum.

1. INTRODUCTION
Experience sharing is a common activity on the web. Users are
often willing to contribute their experiences through various
platforms. Genuine personal opinions will help users make right
decisions. In contrast, fake opinions commonly used to promote
specific targets will mislead users. Opinion spam and spammer
detection aim at identifying fake review and reviewers.

This paper is organized as follows. Section 2 describes a real case
in web forum. Section 3 shows some observations in the datasets.
Section 4 proposes an opinion spammer detection model and
discusses the experimental results under the real case study.
Section 5 concludes the remarks.

Jindal and Liu [4] addressed the importance of opinion spam
detection and proposed models to deal with this problem.
Subsequently, the researches were extended to identify individual
opinion spammers [2][5][9] and group opinion spammers [6][7].
Reviewers’ behaviors, text similarity, linguistic features, rating
patterns, relationships among reviewers, reviews and stores, and
burstiness in reviews have been explored.

2. A REAL CASE STUDY
2.1 Case Description
This paper studies a real case, Samsung probed in Taiwan over
‘fake web reviews’, reported by BBC on 16 April 2013. A covert
marketing campaign was carried out by a consulting firm that was
a subsidiary company of one of the biggest IT companies in the
world. In this campaign, hired posters were asked to promote a
certain brand and denounce its rivals on web forums. The Fair
Trade Commission (FTC) in Taiwan, investigated into the event
and announced a decision on October 31, 2013 based on the
leaked information and other documents, “the Samsung Taiwan,
OpenTide Taiwan, and Sales & Profit International Co. concealed
their identity and pretended to be regular private citizens to
market their products on the Internet by making comparisons with
and comments on the products of other enterprises.” The three
companies were imposed administrative fines of NT$10 million,
NT$3 million and NT$50,000, respectively.

Evaluation is indispensable for this task, but no “true” ground
truth data spam and non-spam are available. Jindal and Liu [4]
collected reviews for four categories of products from
amazon.com for model development and performance evaluation.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned
by others than the author(s) must be honored. Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee. Request
permissions from
Permissions@acm.org.
SIGIR '15, August 09 - 13, 2015, Santiago, Chile
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3621-5/15/08…$15.00
DOI: http://dx.doi.org/10.1145/2766462.2767766

759

have submitted posts during the first period, but not the second one
are put into 2011-user-set. Similarly, users who have submitted
posts in the second period, but not the first are assigned to 2012user-set. Now the question is in which set the users who have
submitted posts in both periods should be put. Since we will use the
opinion spam detection for first posts to assist opinion spammer
detection, this set of users should not be in the test set. In other
words, these users are assigned to 2011-user-set. Table 5 shows the
statistics of the datasets for spammer detection. The dataset is
available at http://nlg.csie.ntu.edu.tw/m01-corpus/.

2.2 Disclosed Spreadsheets
The relevant articles describing the campaign were disclosed on
Taiwansamsungleaks 1 . The leaked spreadsheets, which provide
spam posts and spammers, are considered as ground truth for this
study. Tables 1-3 show the attributes of user profiles, posts, and
threads, respectively. A thread in a web forum is composed of a
first post or replies by users. First post and reply are called posts.
Table 1. Attributes of User Profiles
Attribute
uid
reg_time
login_time
n_threads
n_eff_posts
n_posts
n_replies
karma score
p_phone

Description
id of the user
time of registration on the site
last time the user logged in
number of threads initialized by the user
number of effective posts
number of all posts
number of replies, i.e., n_posts - n_threads
karma given by other users to the threads
proportion of posts made on the smart phone

Table 5. Statistics of users in 2011-user- and 2012-user-sets
2011-user-set
2012-user-set

Description
id of the thread to which the post belong
submission time of the post
id of the poster who made the post
username of the poster
position relative to other posts in the thread
page number on which the post is
structured content in HTML

Spammers usually deliver their opinions in such a subtle way that
the portion of the spam posts do not carry any opinions about the
brands. Their purpose is to keep the discussion alive and bumping to
attract more attention to the specific topics of the thread.
There are two types of spammer accounts in the dataset: (1)
accounts of reputable posts who paid one or a few times to write
quality long post to promote the brand, and (2) throwaway accounts
shared internally among the spammers to synthesize public opinions.
Throwaway accounts are often created in mass within a short period
of time, as it takes much more effort to spread out the daunting task
of registering throwaway accounts.

Description
id of the thread
id of the forum (board) in which the thread is
title of the thread
number of pages in the thread
number of clicks (views) on this thread
submission time of the thread (=first post time)

Because making spam posts is a job rather than a leisure activity for
spammers, we observe that a higher percentage of spam posts are
submitted during work time, compared to non-spam posts.
The threads initiated by spam first post are more active since they
are written to draw attention and exposure. We measure the
activeness of a thread with total number of posts in the thread, and
find that spam threads tend to attract more replies, which can be
either spam replies or non-spam replies.

2.3 Data Partition
We partition the leaked data into the following two post sets for
training and testing, respectively, based on the submission time of
the posts:
(1) 2011-post-set: Jan 2011-Dec 2011, and
(2) 2012-post-set: Jan 2012-May 2012.
The posts in the 2012-post-set may be posted by the same user in
the 2011-post-set. To avoid the effects of writing styles of users on
the performance of opinion spam/spammer detection, we remove all
the posts by users who have posts in the 2011-post-set from the
2012-post-set. Table 4 lists the statistics of the remaining posts after
removal.

We further examine 2011-post-set, and note that some threads
contain multiple spam posts submitted by different accounts. It
indicates collusion goes on between multiple spammers. These
spammers usually express similar opinions in the same thread to
reinforce the credibility, or to bump the thread to attract more
attention to it.

4. OPINION SPAMMER DETECTION
We adopt SVM with RBF kernel from Scikit-Learn [8] after
exploring various learning algorithms. In this section, we present the
features used in opinion spammer detection. We scale each feature
to zero mean and unit variance. In the latter experiments, we
downsample the non-spammers in 2011-user-set by randomly
removing 60% of them. The remaining forms a training set. The
2012-user-set is considered as a test set.

We also assign user accounts to the 2011-user-set and 2012-user-set
according to the submission time of their posts. Users who
Table 4. Statistics of posts in 2011-post- and 2012-post-sets
2011-post-set
2012-post-set
1

#spam posts
1,883
414

#all posts
159,432
32,932

spammer ratio
1.25%
0.98%

Spammers are the posters who had submitted any spam posts in web
forum. We inspect the posts in the 2011-post-set and find that only
about 33% of the posts by spammers in the 2011-user-set are spams.
The low spam post ratio of spammers specifies that some
“spammers” actually rarely spammed.

Table 3. Attributes of Threads
Attribute
thid
fid
title
pages
clicks
time

#all users
17,216
8,603

3. SOME OBSERVATIONS

Table 2. Attributes of Posts
Attribute
thid
time
uid
uname
nfloor
pnum
content

#spammers
215
84

spam ratio
1.12%
1.26%

We first run 5-fold cross-validation multiple times on the training
set to facilitate a grid search on C and  with F1 score as the metric
to optimize. The grid to search is represented below.

http://taiwansamsungleaks.org/.

760

Table 6 summarizes the experimental results of five models, M0M4. Precision (P), Recall (R), and F-measuere (F1) are listed. M0 is
an absolute baseline with random guessing. Intuitively, its
performance is very bad due to very low spammer ratio, 0.98%. The
detail of M1-M4 will be discussed in the following sections.
Table 6. Spam detection for first post using test set
Model
M0: random baseline
M1: user profile
M2: M1+maximum spamicity
M3: M2+burstiness of reg.
M4: M3+frequent poster set

P
0.0091
0.0275
0.6102
0.6731
0.6753

R
0.4588
0.2262
0.4286
0.4167
0.6190

F1
0.0178
0.0491
0.5035
0.5147
0.6460

Figure 3. “Karma score” of spammers and non-spammers

4.2 Maximum Spamicity of First Posts
This section proposes a model to detect opinion spams from first
posts, and consider the results as an additional feature.

4.1 User Profile
The last six attributes in user profile defined in Table 1 are used. We
measure their usefulness in distinguishing the spammers from nonspammers by computing symmetric KL divergence as follows.

4.2.1 Opinion Spam Detection for First Posts

where Pspammer and Qhammer are the distributions of an attribute under
all spammers and non-spammers, respectively. Figure 1 shows the
usefulness of these features. Spammers are more productive and
reputable posters according to the number of the threads they make
(n_threads), and the “karma scores” they have.

(1) Bag of Words
We first count the occurrence of each word in training set.
Next, rare words with less than 5 occurrences are removed to
avoid overfitting. Besides, words appearing in over 30% of the
posts are regarded as stop words and also filtered. After the
vocabulary is set up, we represent each post as a weighted word
vector, where the weight of a word is its frequency in the post
normalized by the length of the post.
We apply randomized PCA [3] on the post by word matrix to
reduce the dimension. The desired number of dimension is tuned
by the average F1 score with 5-fold cross-validation on training
set. The average F1 score is the best when the bag-of-words is
reduced to 150 components. Besides the contents of posts, the
titles of threads are also informative. Thus we create another 50
bags-of-word features based on the titles, and combine these with
the content parts to yield 200 features.

We propose the following features, and employ 2011-post-set and
2012-post-set in Table 4 as training and test sets, respectively, to
detect opinion spams from first posts. This model achieves 0.6667
precision, 0.5714 recall, and 0.6154 F1 score.

Figure 2 illustrates that (1) spammers tend to initiate more threads
than non-spammers, and (2) on web forums, there are a lot of
lurkers who regularly login and read posts, but barely participate in
discussions. Figure 3 further depicts that some spammers tend to
have higher “karma scores” than non-spammers.
Table 6 shows employing features from user profile, i.e., M1,
increases F1 score compared with M0, but profile only is not
sufficient to distinguish spammers from non-spammers effectively.

(2) Content Characteristics
A set of features derived from basic characteristics of the
contents of the post is introduced in Table 7. We compute
symmetric KL divergence to find which features exhibit the most
different distributions between spams and hams, and add these 17
numerical features that characterize the contents of first posts.
(3) Submission Time
Spam posts tend to be submitted often during work time. To
make use of this observation, we add a binary feature for each
hour in a day and each day in a week, in total 24+7=31 features.
If a first post is submitted during the hour or the day a feature
corresponds to, then its value is 1; otherwise it is 0.

Figure 1. Usefulness of the features from user profies

(4) Thread Activeness
We consider number of posts in a thread started by a first
post as a feature, which measures the activeness of the thread.

4.2.2 Maximum Spamicity
A feature, max_spamicity_fps, is computed by taking the
maximum of the spamicity estimates of all first posts submitted
by a specific user. Because the definition of spammer is “whoever
makes one or more spam posts”, taking the maximum is a more
sensible choice, compared to taking the mean or the median.

Figure 2. Number of threads initialized by spammers and nonspammers

761

larger than a threshold, then we predict all users in this 3-element
poster set to be spammers.

Table 7. Description of content characteristics
Attribute
n_all
n_words
n_lines
n_hyperlinks
n_img
n_emoticon
n_quote
p_digit
p_english
p_punct
p_special
p_wspace
p_immediacy
p_ntusd_pos
p_ntusd_neg
p_emoticon_pos
p_emoticon_neg

Description
number of characters used in the post
number of words in the post
number of lines in the post
number of hyperlinks in the post
number of images added to the post
number of emoticons used in the post
number of quotations from previous posts
proportion of digits
proportion of English characters
proportion of punctuation characters
proportion of non-alphanumeric characters
proportion of white space characters
proportion of first person pronouns
proportion of positive words in NTUSD
proportion of negative words in NTUSD
proportion of positive emoticons
proportion of negative emoticons

The model integrating the mined frequent poster sets, M4 shown in
Table 6, increases recall from 0.4167 to 0.6190 without sacrificing
precision, and achieves 0.6460 F1 score. The result is promising
because the ratio of spammers in the test set is only 0.98%.

5. Conclusion
This paper investigates opinion spammer detection with a real case
study. On the basis of a decent detection model for first posts, a
quality model for spammer detection is proposed. In addition,
leveraging the collusion between spammers significantly boosts the
performance.

6. ACKNOWLEDGMENTS
This research was partially supported by National Taiwan
University under grant NTU-ERP-104R890858, and Ministry of
Science and Technology, under grant 102-2221-E-002-103-MY3.

7. REFERENCES

The model for first post spam detection in Section 4.2.1, which
achieves higher precision than recall, is a plus here. If the model
misses a spam first post of a specific spammer due to recall, it is still
possible to detect other spam first posts by the spammer. On the
contrary, if the model misidentifies a non-spam first post by a
normal user as spam, i.e., low precision and high recall, and gives it
a high spamicity estimate, then the value of max_spamicity_fps
will be high for that user, who is thus likely to be misclassified as a
spammer. Note the training set of posts does not contain any posts
by any users in test set. The data splitting method guarantees a fair
evaluation.

[1] Janez Demšar, Tomaž Curk, Aleš Erjavec, Črt Gorup, et al.
Orange: Data mining toolbox in python. Journal of Machine
Learning Research, 14:2349–2353, 2013.
[2] Geli Fei, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu
Castellanos, and Riddhiman Ghosh. Exploiting burstiness in
reviews for review spammer detection. In Proceedings of the
Seventh International AAAI Conference on Weblogs and Social
Media (ICWSM), pages 175-184, AAAI, 2013.
[3] Nathan Halko, Per-Gunnar Martinsson, and Joel A Tropp.
Finding structure with randomness: Probabilistic algorithms for
constructing approximate matrix decompositions. SIAM
review, 53(2):217–288, 2011.

Table 6 shows the performance is significantly improved by almost
50% in F1 score when the max_spamicity_fps feature is introduced
in M2. Further analysis finds that 54 out of the 84 spammers in test
set, i.e., 64.3%, have submitted a spam post which is a first post in a
thread. In principle, it is the maximum number of spammers that
could be identified with this feature.

[4] Nitin Jindal and Bing Liu. Opinion spam and analysis. In
Proceedings of the 2008 International Conference on Web
Search and Data Mining, pages 219–230. ACM, 2008.
[5] Ee-Peng Lim, Viet-An Nguyen, Nitin Jindal, Bing Liu, and
Hady Wirawan Lauw. Detecting product review spammers
using rating behaviors. In Proceedings of the 19th ACM
International Conference on Information and Knowledge
Management, pages 939–948. ACM, 2010.

4.3 Burstiness of Registration of Accounts
In Section 3, we observe most of the throwaway spammer accounts
are registered in bursts. Here, we propose a feature, burstiness_reg,
which counts the number of accounts registered 20 days within the
registration of the user account in discussion. A high
burstiness_reg indicates the user account to be discussed is in a
burst, so it is likely to be a throwaway spammer account. Table 6
shows adding this feature (i.e., M3) increases 0.0629 precision with
the penalty of 0.0119 recall.

[6] Arjun Mukherjee, Bing Liu, Junhui Wang, Natalie Glance, and
Nitin Jindal. Detecting group review spam. In Proceedings of
the 20th International Conference on World Wide Web, pages
93–94. ACM, 2011.
[7] Arjun Mukherjee, Bing Liu, and Natalie Glance. Spotting fake
reviewer groups in consumer reviews. In Proceedings of 21st
International World Wide Web Conference (WWW 2012),
pages 191-200, ACM, 2012.

4.4 Frequent Poster Set
This section models the behavior of the collusion between
spammers discussed in Section 3 with frequent itemset mining in
data mining. Applying the shopping analogy to our scenario, user id
of each post is an “item”, and every 30 posts in a thread form a
“basket”. Each frequent poster set denotes a group of users that
frequently appear together in threads. In our experiments, frequent
itemset mining is conducted with the Orange library [1].

[8] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B.
Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V.
Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M.
Brucher, M. Perrot, and E. Duchesnay. Scikitlearn: Machine
learning in Python. Journal of Machine Learning Research,
12:2825–2830, 2011.
[9] Guan Wang, Sihong Xie, Bing Liu, and Philip S Yu. Review
graph based online store review spammer detection. In
Proceedings of 2011 IEEE 11th International Conference on
Data Mining (ICDM), pages 1242–1247. IEEE, 2011.

Rather than being incorporated the cue as a feature in our model, the
mined frequent poster sets are used to examine the prediction
outputs of the model M3 further. For each 3-element frequent poster
set, we add up the spamicity prediction output by M3. If the sum is

762


Predicting User Behavior in Display Advertising via
Dynamic Collective Matrix Factorization
∗

Sheng Li

Northeastern University
Boston, MA, USA

shengli@ece.neu.edu

Jaya Kawale

Adobe Research
San Jose, CA, USA

kawale@adobe.com

ABSTRACT

yunfu@ece.neu.edu

click-through rate (CTR) has been used as a central measure for evaluating the performance of a direct response ad
campaign. An alternate strategy that has gained attention
in the recent past is to maximize the conversion rate (CVR)
instead of just ad-clicks, as many advertisers would prefer
not to pay for an ad impression unless it leads to a conversion. The conversion could either imply revenue generated
via buying a product or could mean account creation. In
both strategies it is critical to understand the user behavior
and predict the response so as to have better targeting of
the ads and as a result higher conversions.
So far, the problem of click prediction and conversion prediction has mainly been studied in isolation. Researchers
have successfully applied novel strategies for click prediction
and there has been signiﬁcant work in the area [1]. Recently
the problem of conversion prediction has been studied by [2]
to analyze the ad campaigns. However, the objectives of the
two problems are often intertwined together and there is a
need to study the two problems in conjunction with each
other. With the notable exception of [3], there is not much
work analyzing the two objectives together to understand
the user purchase behavior better. Jointly studying the two
problems can help us understand the pathway leading to
conversion and can provide answers to several questions. For
example, What ads should be shown to a particular user so
that he generates revenue? and Will a given user generate
revenue?
In this paper, we propose a novel approach called as dynamic collective matrix factorization (DCMF) to jointly examine the user click behavior and the purchase activity. The
DCMF model is a substantial extension of the collective matrix factorization model used to jointly factorize multiple
matrices [4]. Apart from considering the two matrices of
click and purchase behavior together as in a CMF model,
our model also takes into account the temporal inﬂuence of
an ad impression/click on conversion. We model the time
dependency into the matrix factorization framework to account for the decay in the inﬂuence of an ad. An eﬃcient
optimization algorithm is devised to solve the problem. Our
approach is well suited for an interactive setting where the
user preferences and behavior change over time.
Our key contributions can be summarized as follows:

Conversion prediction and click prediction are two important and intertwined problems in display advertising, but
existing approaches usually look at them in isolation. In
this paper, we aim to predict the conversion response of
users by jointly examining the past purchase behavior and
the click response behavior. Additionally, we model the temporal dynamics between the click response and purchase activity into a uniﬁed framework. In particular, a novel matrix factorization approach named dynamic collective matrix
factorization (DCMF) is proposed to address this problem.
Our model considers temporal dynamics of post-click conversions and also takes advantages of the side information
of users, advertisements, and items. Experiments on a realworld marketing dataset show that our model achieves signiﬁcant improvements over several baselines.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information
ﬁltering

Keywords
Conversion prediction; matrix factorization; temporal dynamic

1.

Yun Fu

Northeastern University
Boston, MA, USA

INTRODUCTION

With the proliferation of the Internet and online shopping
websites, digital marketing has become an eﬀective way to
reach out to consumers. Typically consumers can be inﬂuenced via targeted advertisements (ads) on the web to make
purchases. Display advertising is a popularly used medium
for targeting users and allows advertisers to place graphical ads on the publishers’ web pages. Most of the ads aim
to create an impulse leading to a sale. Traditionally, the
∗This work was completed during Sheng Li’s internship at
Adobe Research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.

DOI: http://dx.doi.org/10.1145/2766462.2767781.

• We propose a dynamic collective matrix factorization
(DCMF) approach for conversion prediction, which jointly
models the temporal relationships between click events
and purchase events in display advertising. It also incorporates the side information of users, ads and items
via regression.

875

ࢁ࢚ି૚
Vt-1
Share

Conversion
Response

ࡰ࢚ି૚

ࢁ࢚ି૚
Pt-1

Items

࡯࢚ି૚

Ads

Users
Click
Response

Ad
Feature

User
Feature

Users
Click
Response

Item
Feature

Ads

Ad
Feature

Items

Item
Feature

User
Feature

ܷ ௧ିଵ ൎ ܷ ௧ିଶ ‫ܯ‬

ࢁ
Vt

Ct

࢚

Share

Conversion
Response

ࢁ࢚

Conversion
Response

ࡰ࢚ା૚

Pt

ࡰ࢚

ܷ ௧ ൎ ܷ ௧ିଵ ‫ܯ‬

(t-1)

ilar” preferences. There has been work on applying the CF
technique to conversion prediction [8], but it models the interactions between pages and ads. In our paper, we directly
model the relationships between users and ads/items, which
enables us to predict the user behaviors. The intuition is
that “similar” users are very likely to click “similar” ads and
purchase “similar” items. Figure 1 shows our framework.
First, we want to jointly analyze the relational data, i.e.,
the click response and purchase activities of users. Inspired
by the collective matrix factorization (CMF) [4], we factorize the click response matrix (User∼Ads) and the purchase
activity matrix (User∼Item) simultaneously.
Secondly, we aim to model the temporal information,
which is critical in attributing the conversions to the ad
clicks. A key observation is that, the behavior of users
may change over time. For example, if a user has already
purchased an item in the previous week, it is unlikely that
he/she will purchase the same item again in the next week.
Therefore, we incorporate temporal information into CMF.
Thirdly, we need to ensure that the latent features of
users do not dramatically change in a short period of time,
as in reality the user preferences would evolve smoothly. To
address this concern, we leverage the latent features of the
users learned in time t − 1.
Given T pre-deﬁned time slices t ∈ {1, 2, · · · , T }, we use
C t ∈ RNu ×Na and Dt ∈ RNu ×Np to denote the click responses and purchase activities from Nu users to Na ads (or
Np items) in the time slice t, respectively. By exploiting the
temporal relationships between click response and purchase
events, we notice that the purchase events in time t + 1 are
mainly related to the click events in time t and hence our
model needs to account for that. The objective function is:

Prediction

Training

(t)

(t+1)

Timeline

Figure 1: Framework of DCMF approach.
• Our framework is based upon examining the data in
time slices to account for the decayed inﬂuence of an
ad and we use stochastic gradient descent for optimization. This makes the framework well suited for interactive settings as well as large datasets.
• We evaluate the conversion prediction performance of
our approach on real-world datasets and show that our
model performs better as compared to the several baseline methods.

2.

RELATED WORK

Response Prediction. Response prediction in digital
marketing has been widely studied in recent years. Most of
the prior work focuses on predicting the click-through-rate
(CTR) of online ads or other contents [1]. The ultimate goal
of display advertising is conversion. However, there are only
a few works that investigate the conversion prediction problem [2]. For example, Lee et al. estimated the conversion
rate by using the past performance observations along with
user, publisher and advertiser data hierarchies [2]. Unlike
the existing conversion prediction methods, our approach
takes advantage of the click response and side information
via the collective matrix factorization technique. The most
relevant method in the literature is the hierarchical multitask learning algorithm presented in [3]. It jointly models
the conversion, click and unattributed-conversion problems.
There are signiﬁcant diﬀerences between [3] and our work.
First, we make use of the explicit temporal relationship between click and purchase events, which is ignored in [3].
Second, unlike the multi-task learning model used in [3], we
develop a matrix factorization approach.
Temporal Prediction Models. The prediction model
considering temporal dynamics was ﬁrst developed for collaborative ﬁltering in [5]. The idea of using temporal dynamics has been explored in online advertising. Barajas et
al. proposed a time series approach for evaluating the eﬀectiveness of display advertising [6]. Most recently, Oentaryo
et al. designed a hierarchical importance-aware factorization machine (HIFM) for click response prediction in mobile
advertising [7]. It is able to handle the temporal ad response data. Unlike HIFM, our approach aims to tackle the
conversion prediction problem, and to model the temporal
relationships between click and purchase events.

3.
3.1

arg min

U t ,V t ,
P t ,M

f (U t , V t , P t , M ) = αW Ct  (C t − U t V tT )2F
+(1 − α)W Dt  (Dt − U t P tT )2F
+λ1 U t − U t−1 M 2F
+λ2 (U t 2F + V t 2F + P t 2F + M 2F ),

(1)
where W Ct and W Dt are boolean matrices that indicate the
training samples in C t and Dt , respectively. U t , V t and P t
are latent factors; M is a transition matrix;  denotes the
entry-wise product; α, λ1 and λ2 are trade-oﬀ parameters.
The ﬁrst two terms in (1) denote the approximation errors,
and the last four terms are regularizations used to prevent
overﬁtting. In (1), the smooth transition of user latent
factors are modeled based on the assumption:
U t ≈ U t−1 M,

(2)

t−1

is the latent features of users learned from the
where U
previous time slice t − 1. We assume that the latent features
in time t are closely related to the feature in time t−1, which
is reasonable in real applications. M is a transition matrix of
users’ behavior, which tries to capture the mappings between
users’ behavior in two successive time slices. The intuition is
that users’ intention on purchasing items should be smoothly
transited over time.

APPROACH

3.2

Modeling Side Information

So far, we have seen that the model in (1) is not aware of
side information, i.e., the features of users, ads, and items.
We can further exploit the additional information to improve the prediction performance. The side information are
also particularly useful as the data in conversion and click

Modeling Temporal Dynamics

We deal with the conversion prediction problem using the
collaborative ﬁltering (CF) technique. The fundamental intuition behind CF is that the “similar” users will have “sim-

876

∂f
where gradient is ∂M
= −λ1 U (t−1)T (U t − U t−1 M ) + λ2 M .
The above process is repeated until convergence.

prediction problems are generally sparse. For example, we
do not have any click responses or conversion responses of
some new users, which lead to the cold-start problem. In
this case, the latent features of new users estimated by (1)
are not reliable anymore. However, side information provide
useful cues from another perspective, and make it possible
to learn robust latent features in the cold-start scenario. In
this section, we incorporate the side information into (1),
and present the DCMF method.
Let X, Y and Z denote the feature matrices for users, ads
and items, respectively. We assume that the click response
and purchase activity are generated by the inner product of
latent factors, and the side information via linear regression.
Thus, the matrix approximation can be written as:

4.

EXPERIMENTS

In this section, we evaluate the performance of our approach and baselines on a marketing dataset.

4.1

Data and Settings

To evaluate the performance on conversion prediction, we
examine a subset of the marketing data from Oct. 1, 2013 ∼
Nov. 30, 2013. The dataset constitutes of behavioral characteristics of 448,158 number of users and 737 ads. Along
with the impression records, we also have click and purchase
activity information for all the users. We empirically choose
one week as the time window t in our model. To construct
C t ≈ U t V tT + Û t Y T + X V̂ tT ,
(3)
t
t tT
t T
tT
the binary response tables, we denote the click events and
D ≈ U P + Û Z + X P̂ ,
purchase events as positive responses, and the impressions
(without any following events) as negative responses. All
where Û t , V̂ t and P̂ t are regression coeﬃcients on user feathe other entries are treated as missing values. As the click
tures, ad features and item features, respectively. We treat
and purchase are rare events in reality, our data set is exthe three terms used to approximate C t (or Dt ) equally for
tremely sparse. To collect the side information, we select
simplicity. The performance can be enhanced by assigning
some features of users, ads and items, respectively. For each
diﬀerent weights for them.
user, we encode the demographic information (e.g., country,
By replacing the matrix approximations in (1) with (3),
state, domain) into a binary valued vector. The attributes
we can then rewrite the objective function as:
of ads (e.g., advertiser, ad size) and items (e.g., type, price)
αW C  (C t − U t V tT − Û t Y T − X V̂ tT )2F
arg
min
are also encoded into binary vectors, respectively. To conU t ,V t ,P t ,M,
duct fair comparisons, we set up 5 diﬀerent training/test
Û t ,V̂ t P̂ t
cases along the timeline. Each training set consists of a
+(1 − α)W D  (Dt − U t P tT − Û t Z T − X P̂ tT )2F
t
t−1
2
t 2
t 2
t 2
click events table and a purchase events table. Each test set
+λ1 U − U
M F + λ2 (U F + V F + P F
only contains a table of purchase events, as our goal is to
t 2
t 2
t 2
2
+Û F + V̂ F + P̂ F + M F ).
predict the conversions.
(4)
We compare our approach with the following baselines:
With the learned latent factors, we can predict the conPMF [9], LIBMF [10], SVDFeature [11], HBMFSI [12], and
version score of user m for item n at time t + 1 as:
CMF [4]. For PMF, LIBMF, SVDFeature and HBMFSI, we
t T
tT
only use the purchase data for training, due to the intrinsic
(5)
Score(m, n, t + 1) = utm ptT
n + ûm zn + xm p̂n ,
limitation of these methods. For CMF and our approach,
where utm and ûtm are the m-th row of U t and Û t , ptn and
we use both the click data and purchase data for training.
p̂tn are the n-th row of P t and P̂ t , respectively.
In particular, we use the click events and purchase events
at time t to predict the purchase events in time t + 1 (i.e.,
3.3 Optimization
D t+1 ). Following [3], we use the ROC curve and the area
As the stochastic gradient descent (SGD) algorithm is efunder ROC (AUC-ROC) as our evaluation metrics.
ﬁcient in practice, we utilize SGD to solve (4).
For SGD based matrix factorization methods (e.g., PMF,
First, we ﬁx M , and update other variables, U t = {ut1 , · · · , utr }, LIBMF, SVDFeature and CMF), the major parameters are
the learning rate γ and the trade-oﬀ parameter λ for reguV t = {v1t , · · · , vrt }, P t = {pt1 , · · · , ptr }, Û t = {ût1 , · · · , ûtr },
larization terms. For Bayesian method HBMFSI, we follow
V̂ t = {v̂1t , · · · , v̂rt }, and P̂ t = {p̂t1 , · · · , p̂tr }. For simplicity,
the settings in [12]. We sample a validation set from the
we use f to denote the objective in (4). After selecting a
t
t
training data, and tune these parameters empirically. The
pair of random training points Cij and Dik , we only need to
parameters γ, λ1 and λ2 are set to 0.003, 0.001 and 0.02,
update uti , vjt , ptk , ûti , v̂jt and p̂tk using:
respectively. In CMF and our approach, another important
t
t
t
t
∂
∂
∂
uti = uti − γ ∂u
parameter is α. To understand its sensitivity, we observe
t f, vj = vj − γ ∂v t f, pk = pk − γ ∂pt f,
i
j
k
(6)
the AUC-ROC of CMF and DCMF approach with various
t
t
t
t
t
t
∂
∂
∂
ûi = ûi − γ ∂ ût f, v̂j = v̂j − γ ∂ v̂t f, p̂k = p̂k − γ ∂ p̂t f,
choices of α. Figure 2(a) shows the AUC-ROC values in
i
j
k
Case-3. We can observe that our approach is not sensitive
where γ is the learning rate. The detailed gradients for each
to the values of α. We achieve better performance when α
variable are omitted here due to the space limit.
falls into the range [0.5, 0.8]. In the following experiments,
Next, we ﬁx all the other variables, and update M . By
α is set to 0.6. In addition, the dimension of latent features
ignoring all the irrelevant terms with respect to M , the obis set to 20 for each method. To initialize our approach in
jective (4) reduces to:
Case-1, we borrow the latent factors of CMF learned from
Oct. 1∼Oct. 7 as the input U t−1 .
t
t−1
2
2
f
(M
)
=
λ
U
−
U
M

+
λ
M

.
arg min
1
2
(7)
F
F
M

4.2

We can then update M using:
∂
f (M ),
M = M − γ ∂M

Results and Discussions

We evaluate the performance of each compared method
in 5 training/test splits. Figure 2(b) shows the ROC in

(8)

877

5.

0.9

In this paper, we presented a novel matrix factorization
approach DCMF for conversion prediction in display advertising. DCMF jointly examines the click events and purchase
events in an online learning fashion by leveraging the temporal information and side information. Extensive experimental results on a real-world marketing dataset demonstrate
the superiority of our approach over existing methods.

AUCíROC

0.8

0.7

0.6
CMF

0.5

Acknowledgements

DCMF
0.4

0.1

0.2

0.3

0.4

0.5

α

0.6

0.7

0.8

This research is supported in part by the NSF CNS award
1314484, ONR award N00014-12-1-1028, ONR Young Investigator Award N00014-14-1-0484, and U.S. Army Research
Oﬃce Young Investigator Award W911NF-14-1-0218.

0.9

(a)
1
0.9

True Positive Rate (TPR)

CONCLUSIONS

6.

0.8
0.7
0.6
0.5
0.4

PMF [9]
LIBMF [10]
SVDFeature [11]
HBMFSI [12]
CMF [4]
DCMF (Ours)

0.3
0.2
0.1
0
0

0.2

0.4

0.6

False Positive Rate (FPR)

0.8

1

(b)
Figure 2: (a): AUC-ROC of CMF and DCMF in Case-3
with diﬀerent α. (b): ROC curves in Case-1.

Table 1: AUC-ROC of each methods on marketing data.
Method
PMF [9]
LIBMF [10]
SVDFeature [11]
HBMFSI [12]
CMF [4]
DCMF (Ours)

Case 1
0.729
0.731
0.742
0.750
0.751
0.850

Case 2
0.718
0.719
0.729
0.737
0.746
0.851

Case 3
0.645
0.653
0.661
0.669
0.668
0.841

Case 4
0.712
0.726
0.731
0.739
0.736
0.832

REFERENCES

[1] Deepak Agarwal, Bo Long, Jonathan Traupman, Doris
Xin, and Liang Zhang. Laser: a scalable response
prediction platform for online advertising. In WSDM,
pages 173–182, 2014.
[2] Kuang chih Lee, Burkay Orten, Ali Dasdan, and
Wentong Li. Estimating conversion rate in display
advertising from past performance data. In KDD,
pages 768–776, 2012.
[3] Amr Ahmed, Abhimanyu Das, and Alexander J.
Smola. Scalable hierarchical multitask learning
algorithms for conversion optimization in display
advertising. In WSDM, pages 153–162, 2014.
[4] Ajit Paul Singh and Geoﬀrey J. Gordon. Relational
learning via collective matrix factorization. In KDD,
pages 650–658, 2008.
[5] Yehuda Koren. Collaborative ﬁltering with temporal
dynamics. In KDD, pages 447–456, 2009.
[6] Joel Barajas, Ram Akella, Marius Holtan, Jaimie
Kwon, and Brad Null. Measuring the eﬀectiveness of
display advertising: a time series approach. In WWW
(Companion Volume), pages 7–8, 2011.
[7] Richard Jayadi Oentaryo, Ee-Peng Lim, Jia-Wei Low,
David Lo, and Michael Finegold. Predicting response
in mobile advertising with hierarchical
importance-aware factorization machine. In WSDM,
pages 123–132, 2014.
[8] Aditya Krishna Menon, Krishna Prasad Chitrapura,
Sachin Garg, Deepak Agarwal, and Nagaraj Kota.
Response prediction using collaborative ﬁltering with
hierarchies and side-information. In KDD, pages
141–149, 2011.
[9] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic
matrix factorization. In NIPS, 2007.
[10] Yong Zhuang, Wei-Sheng Chin, Yu-Chin Juan, and
Chih-Jen Lin. A fast parallel sgd for matrix
factorization in shared memory systems. In RecSys,
pages 249–256, 2013.
[11] Tianqi Chen, Weinan Zhang, Qiuxia Lu, Kailong
Chen, Zhao Zheng, and Yong Yu. Svdfeature: a toolkit
for feature-based collaborative ﬁltering. Journal of
Machine Learning Research, 13:3619–3622, 2012.
[12] Sunho Park, Yong-Deok Kim, and Seungjin Choi.
Hierarchical bayesian matrix factorization with side
information. In IJCAI, 2013.

Case 5
0.714
0.723
0.732
0.741
0.737
0.837

Case-1, and Table 1 lists the AUC-ROC of all cases. Form
Figure 2 and Table 1, we make the following observations:
(1) Incorporating side information improves the prediction
results signiﬁcantly. SVDFeature and HBMFSI employ the
features of users and items, they achieve much better performance than PMF and LIBMF, which do not utilize any side
information. Similarly, our DCMF approach performs very
well by virtue of the side information. (2) Modeling click
response is helpful in predicting purchase events. CMF and
our approach take advantages of the click response information, and they outperform PMF and LIBMF in each case.
(3) Temporal dynamics is critical in conversion prediction.
Our approach obtains better results than CMF, indicating
that the latent features learned from previous time slice are
very useful. (4) Our DCMF approach achieves the best results in each case, compared to the baselines. It demonstrates that the side information and temporal information
could be complementary to each other in predicting user
behaviors such as conversion.

878


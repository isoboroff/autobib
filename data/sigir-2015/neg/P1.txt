Salton Award Lecture
People, Interacting with Information
Nicholas J. Belkin
Rutgers, The State University of New Jersey
New Brunswick, NJ, USA
belkin@rutgers.edu
science of information. Acting on my then understanding of what
a science constituted, I began the project of defining information.
Fortunately for me, I did this at University College, London, with
B.C. Brookes as my Ph.D. supervisor, and Steve Robertson my
office mate. It didn't take long for me to be disabused of a) the
idea that information could be defined; and b) that defining its
phenomena of interest was a necessary precondition to a "real"
science. Instead, perhaps under the influence of the great
pragmatist, Jeremy Bentham, founder of University College, I
turned to attempting to develop a concept of information which
would lead to being able to predict its effect on a person's state of
knowledge, which I took at that time as what IR systems should
be attempting to do.

ACM Classification
H.3.3 [Information Search and Retrieval] -- Retrieval models,
Search
General Terms
Design; Human Factors; Theory
Keywords
Interactive information retrieval; Information behavior

Abstract
Colleagues, friends, let me begin by expressing how pleased, and
humbly honored I am to be a recipient of the Gerard Salton
Award. Gerry was a great man, and to receive the award named
for him is very special. For me personally, it is especially
meaningful, given the sometime disputatious nature of our
professional interactions, and what seemed, on the surface, to be
quite different ideas about information retrieval. I say, on the
surface, because in the end, I believe that he and I both shared the
same goal for the field, although we approached it from quite
different positions. In this presentation, I will speak at some
length on that goal, and on how I think it might be best
addressed.

The confluence of all these factors resulted in my attempting to
understand what led people to engage in information seeking,
which led in turn to the Anomalous State of Knowledge (ASK)
hypothesis. Collaboration with Bob Oddy then led to a general
model of IR as a series of interactions between a person (in
particular, that person's changing ASK) and information objects,
mediated by the IR systems and its representations of the person's
ASK and of the underlying structure of the information objects
which it would propose to the person.
Thus began what I now understand as the unifying theme and
goal of my research throughout my career, understanding and
supporting people's interactions with information. The
operationalization of this goal has changed over time, beginning
with attempts to represent an information seeker's ASK, going on
to designing ASK-based IR systems, to understanding the ASK
as an aspect of a person's problematic situation (thanks to Gernot
Wersig and Alfred Schutz), to my current stance concerning the
goal of IR: supporting people in accomplishing the task or goal
which led them to engage in information seeking, by supporting
appropriate interaction with information objects. In all these
somewhat different modes, there have been two constants:
emphasis on the person (often called the "user") as the central
actor in the IR situation; and, understanding interaction as its
central process. This position, for perhaps the first 2/3 of my
career, has been in quite distinct contrast, not to say conflict, with
"mainstream" IR research, which, until quite recently, focused
almost exclusively on information object representation and
retrieval techniques, and on models of IR which included the
"user" as merely an input and feedback device, if at all, and
which had no room for interaction as a process at all.

I am humbled also by the honor of having joined the ranks of the
previous recipients of this award; the founders, leaders and
innovators in information retrieval (IR), from the earliest
beginnings of the field to today. It has been my distinct good
fortune to have known all of the previous recipients, to have
collaborated with many of them, to have argued with all of them,
to have learned from them, and, I hope, to have been able to
appropriately incorporate their insights into my own work.
Today, following the example of many of my predecessors, I'd
like to take this opportunity to, in Sue Dumais's words of 2009,
"present a personal reflection on information retrieval." This will
include an overview of my history in IR, a discussion of my
personal take on its proper goals, and on how those might be best
achieved, and saying something about the challenges that IR
theory, experiment and practice face both now, and in the future,
and how we might best address those challenges.
I came to the field of IR from a starting point in information
science; specifically, with the concern of addressing general
problems of information in society. I initially thought that the
best way to do this would be to establish a firm framework for a

In her Salton Award Lecture in 1988, Karen Spärck Jones, one of
the foremost contributors to our understanding of information
object representation, and to the development of retrieval
techniques and models, and arch experimenter, said the
following, referring to IR research at least through the 1970s:

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage, and that copies bear this notice and
the full citation on the first page. Copyrights for third-party components of this work
must be honored. For all other uses, contact the owner/author(s). Copyright is held
by the author/owner(s).
SIGIR’15, August 09-13, 2015, Santiago, Chile.
ACM 978-1-4503-3621-5/15/08.
http://dx.doi.org/10.1145/2766462.2767854

But these concerns, though worthy, had unfortunate
consequences. One was that, in spite of references to

1

entails the development of an empirically-based taxonomy of
such tasks/goals, which in turn requires the development of
methods for investigation of the behaviors and intentions of
people prior to, during, and after engagement in an IR system.
Adapting methods of information behavior research to the
specific requirements of IR system design is a likely path to such
outcomes. This, in turn, could lead to the ability to accurately
simulate whole search sessions, which might enable TREC-style
evaluation of interactive IR systems. Furthermore, evaluation
according to usefulness allows considering search sessions both
as whole entities, and as coherent sequences of different types of
interactions with information and system, each with its own
specific support techniques and usefulness-based performance
measures.

environmental parameters and so forth, it tested information
systems in an abstract, reductionist way which was not only
felt to be disagreeably arid but was judged to neglect not only
important operational matters but, more importantly, much of
the vital business of establishing the user’s need.
And, referring to her own research in relevance feedback:
More importantly, I felt that the required next step in this line
of work was to carry out real, rather than simulated, interactive
searching ...
Karen's example demonstrates that there has been, for some time,
recognition that IR research would be wise to more directly
address the user, as a significant actor in the IR system, and the
interaction of the user with the system and with the information
objects, as research foci. Why then have the terms and concepts
of users and people and interaction only so recently appeared in
any significant number in venues such as SIGIR?

The recent Dagstuhl Interactive IR and NII-Shonan Whole
Session Evaluation seminars, and the new SIGIR Conference on
Information Interaction and Retrieval (CHIIR), and its immediate
predecessors, IIiX and HCIR, are explicit demonstration of our
field's newly found commitment to accepting and addressing
these challenges. I can't help but feel that my being a recipient of
the Salton Award is further evidence of information retrieval's
acceptance of including people, interacting with information, as a
major concern, and for this I sincerely thank you all.

Clearly, the inertia associated with reluctance to give up what
seem to have been successful methods and practices has played a
significant part in this state of affairs. But more important, I
think, have been other factors, two especially. One has been the
reluctance, or inability of IR researchers to accept a broader and
more realistic goal of their enterprise; that is, to go beyond
identification of relevant, or even authoritative, information
objects, to the support of people in achievement of the goal or
task which led them to engage in information seeking. The other
is more technical, but perhaps equally important. That is, that the
theories, and research methods and techniques necessary for
addressing the issues of users and interaction in IR, and the
related evaluation methods and measures, are so very different
from what we are familiar with, and also, so very difficult to both
develop and implement.
I think that there's no question that the actual practice and
performance of IR in contemporary systems demonstrates that its
goal needs to be expanded to at least that which I propose, and
that, therefore, evaluation of performance of IR systems needs to
be radically changed. The recent emergence of a move toward
evaluation of performance of IR systems over an entire search
session is evidence of recognition of this need; the not un-related
disappearance of the TREC Session Track of the difficulty of the
enterprise. The emergence of the term, interactive information
retrieval, the amount of research conducted under that rubric, and
the lack of agreement about how to conduct, and to evaluate,
such research, are further testimony to both the significance and
the difficulty of the task.

BIO
Nicholas J. Belkin is a Distinguished Professor at the School of
Communication and Information at Rutgers University. Among
the main themes of his research are understanding human
information behavior, interactive information retrieval,
personalization of interaction with information systems, and
evaluation of information retrieval systems. Belkin is best known
for his work on human-centered Information Retrieval and the
hypothesis of Anomalous State of Knowledge (ASK). Belkin
realized that in many cases, users of search systems are unable to
precisely formulate what they need. They miss some vital
knowledge to formulate their queries. In such cases it is more
suitable to attempt to describe a user's anomalous state of
knowledge than to ask the user to specify her/his need as a
request to the system. Dr. Belkin was the chair of SIGIR in 199599, and the president of American Society (now Association) for
Information Science and Technology in 2005.

So, IR faces daunting challenges, including: understanding why
people engage in information seeking; identifying the aspects of
that condition that need to be considered in supporting them in
achieving their goals; how to design support for evolving user
goals and knowledge; how best to support people's interactions
with information objects and the other components of the IR
system with respect to different and dynamic intentions; and,
perhaps most daunting of all, how to evaluate, in ways as
rigorous and successful as IR evaluation has been to date, IR
systems which attempt to address this broader goal.
I, and others, have proposed that moving from relevance to
usefulness as the main criterion for evaluation of IR system
performance, could provide a basis for addressing many of these
challenges. For instance, evaluating an IR system's usefulness in
helping people to achieve a motivating task/goal necessarily

2


Listwise Collaborative Filtering
Shanshan Huang1∗
huangshanshansdu
@163.com
Jun Ma1
majun@sdu.edu.cn

Shuaiqiang Wang2∗
shuaiqiang.wang
@jyu.fi
Zhumin Chen1
chenzhumin@sdu.edu.cn

Tie-Yan Liu3
tie-yan.liu
@microsoft.com
Jari Veijalainen2
jari.veijalainen@jyu.fi

1

2

School of Computer Science and Technology, Shandong University, Jinan, China
Department of Computer Science and Information Systems, University of Jyväskylä, Jyväskylä, Finland
3
Microsoft Research Asia, Beijing, China

ABSTRACT

desirable products [14, 22]. As one of the most successful
recommendation techniques, collaborative filtering (CF)
avoids the necessity of collecting extensive content information about items and users by fully utilizing the useritem rating matrix to make recommendations. As a result,
CF can be easily applied to different recommender systems
without requiring additional domain knowledge [15]. In the
literature, many CF algorithms have been proposed, which
roughly fall into two categories: rating-oriented CF and
ranking-oriented CF.
Rating-oriented CF, such as user-based CF [1, 5], predicts
a user’s potential ratings on unrated items based on the
rating information from other similar users. The similarity
between two users is calculated based on their rating scores
on the set of commonly rated items. A popular similarity
measure is the Pearson correlation coefficient [5]. Since
this technique focuses on predicting each user’s rating on
an unrated item, we refer to it as pointwise CF. Please
note that pointwise CF might not be able to achieve the
ultimate goal of recommender systems, which is to present a
ranking or recommendation list to a user rather than predict
the absolute value of the ratings [25]. In fact, it has been
observed that improvements in pointwise error metrics such
as RMSE (Root Mean Squared Error) do not necessarily
lead to improved ranking effectiveness [4].
Different from rating-oriented CF, ranking-oriented CF
algorithms [18] directly generate a preference ordering of
items for each user without the intermediate step of rating
prediction. Related works include memory-based algorithms
such as EigenRank [15] and VSRank [27, 28], and modelbased algorithms such as CoFiRank [29], ListRank-MF [25]
and CCF [30]. In this paper, we focus on memory-based CF
algorithms since they have demonstrated many advantages
such as strong robustness, interpretability, and competitive
performance [6].
Existing memory-based ranking-oriented CF algorithms
[15, 27, 28] can also be referred to as pairwise rankingoriented CF, since they predict pairwise ordering of items
based on the correlation between users’ pairwise preferences
of the items. A commonly used correlation measure is the
Kendall’s τ correlation coefficient [17]. Although pairwise
ranking-oriented CF has demonstrated significant improvement over previous algorithms in terms of ranking accuracy,
it suffers from high computational complexity. Suppose
there are N items, and each user has rated n items on

Recently, ranking-oriented collaborative filtering (CF) algorithms have achieved great success in recommender systems.
They obtained state-of-the-art performances by estimating a preference ranking of items for each user rather
than estimating the absolute ratings on unrated items (as
conventional rating-oriented CF algorithms do). In this
paper, we propose a new ranking-oriented CF algorithm,
called ListCF. Following the memory-based CF framework,
ListCF directly predicts a total order of items for each
user based on similar users’ probability distributions over
permutations of the items, and thus differs from previous
ranking-oriented memory-based CF algorithms that focus
on predicting the pairwise preferences between items. One
important advantage of ListCF lies in its ability of reducing
the computational complexity of the training and prediction
procedures while achieving the same or better ranking
performances as compared to previous ranking-oriented
memory-based CF algorithms. Extensive experiments on
three benchmark datasets against several state-of-the-art
baselines demonstrate the effectiveness of our proposal.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval-Information filtering

Keywords
Recommender systems; Collaborative filtering; Rankingoriented collaborative filtering

1.

INTRODUCTION

In recent years, recommender system has become a key
technology behind e-commerce to help customers find their
∗

Indicates equal contribution.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2766462.2767693.

343

average. The average number of commonly rated items for
each pair of users is n, and the number of the neighbor
users is l. Then the time complexity of computing
 the
correlation between each pair of users is O n + n2 , and
the time complexity
of the ranking prediction procedure is

O l(N − n)2 for each user. In most cases, the majority
of the items are unrated for each user, resulting in a very
large value of N − n. As a consequence, the computations
of the pairwise ranking-oriented CF algorithms are usually
much more expensive than the pointwise rating-oriented CF
algorithms.
Beside the computational complexity, there could be
problems with the accuracy of pairwise ranking-oriented CF
algorithms too. First, Kendall’s τ correlation coefficient
ignores the ranking positions of the items, which may lead
to inaccurate similarities when discovering similar users.
Second, Kendall’s τ correlation coefficient cannot handle the
equal preferences tie, which may cause information loss in
training and prediction. Third, pairwise ranking-oriented
CF algorithms attempt to predict relative preferences between pair of items rather than the total rankings, which
may also result in accuracy loss due to rank aggregation.
To tackle the aforementioned problems with the pairwise
CF algorithms, we propose ListCF, a listwise memorybased ranking-oriented CF algorithm, which can reduce the
time complexity of both the training and prediction phases
while maintaining or even improving the prediction accuracy
as compared to conventional pairwise ranking-oriented CF
algorithms. ListCF directly predicts a ranking list of items
for the target user based on the probability distributions
over the permutations of items and thus avoids the accuracy
loss caused by the prediction and aggregation of pairwise
preferences.
In particular, ListCF utilizes the Plackett-Luce model
[17], a widely used permutation probability model in the
literature of learning to rank, to represent each user as
a probability distribution over the permutations of rated
items. In this way, both the ranking positions and equal
preferences can be well considered. In ListCF, the similarity
between two users is measured based on the Kullback–
Leibler (KL) divergence [11] between their probability distributions over the set of commonly rated items. Then for
each user, those users who have higher similarity scores
are selected as the set of neighborhood users. Given
a target user and the neighborhood users, ListCF infers
predictions by minimizing the cross entropy loss between
their probability distributions over permutations of items
with gradient descent. Extensive experiments on three
benchmark datasets in comparison with several state-of-theart algorithms demonstrate the advantages of our approach.
The rest of the paper is organized as follows. Section 2
reviews the related work. Section 3 formulates the listwise
collaborative filtering paradigm and presents the details of
our algorithm. Section 4 analyzes the relationships between
our listwise CF approach and conventional memory-based
CF approaches. Section 5 reports the experimental results
and analysis, and Section 6 concludes the paper.

2.
2.1

filtering (CF) and hybrid algorithms. Content-based algorithms make recommendations based on similarities between
the vector representing the user profile and the vectors
representing the items, where the vectors for user profile
and items are weighted explicit features [16]. CF avoids
the necessity of collecting extensive content information
about items and users by fully utilizing the user-item rating
matrix to make recommendations. Thus, CF can be easily
adopted in different recommender systems without requiring
additional domain knowledge [15]. Given the effectiveness
and convenience, many CF algorithms have been proposed,
which are either rating-oriented CF or ranking-oriented CF.
In addition, hybrid recommendation algorithms have also
been proposed to combine two or more recommendation
techniques to gain better performance [2].
In this paper, we focus on CF recommendation algorithms
and propose a listwise CF algorithm which demonstrates
advantages in recommendation efficiency and accuracy.

2.2

Rating-oriented CF

Traditional rating-oriented CF predicts the absolute value
of ratings of individual users to unrated items, thus we
refer to it as pointwise CF. Conventionally, pointwise ratingoriented CF can be either memory-based or model-based.
In memory-based rating-oriented algorithms, two representatives are user-based CF [5] and item-based CF
[14, 23], which make predictions by utilizing historical
ratings associated with similar users or similar items. The
commonly used similarity metrics are Pearson correlation
coefficient [5] and cosine similarity [1].
Model-based rating-oriented CF learns a model based on
the observed ratings to make rating predictions. Latent
factor models such as matrix factorization (MF) [9] that uses
dimensionality reduction techniques have become important
research directions in this area. A variety of adaptations
of the MF model have demonstrated promising prediction
performance, such as Probabilistic Matrix Factorization
(PMF) [19], Non-negative Matrix Factorization (NMF) [12],
and Max-Margin Matrix Factorization (MMMF) [21].

2.3

Ranking-oriented CF

Different from rating-oriented CF, ranking-oriented CF
[18] directly predicts a preference ranking of items for each
user. Similarly, ranking-oriented CF algorithms can be also
categorized into memory-based ranking-oriented CF [15, 27]
and model-based ranking-oriented CF [10, 20, 25].
EigenRank [15] is a classic memory-based ranking-oriented
CF algorithm, which measures the similarity between users
based on the correlation between their pairwise rankings
of the co-rated items and ranks items by the preferences
of similar users. VSRank [27] adopts the vector space
model in representing user pairwise preferences and makes
further improvement by considering the relative importance
of each pairwise preference. Resulting from the pairwise
preference based representations and predictions, we refer to
EigenRank and VSRank as pairwise memory-based rankingoriented CF algorithms. Although they achieve better performance in recommendation accuracy than rating-oriented
CF, they suffer from serious efficiency problem. In this
paper, we propose a listwise memory-based ranking-oriented
CF algorithm to reduce the computational complexity while
maintaining or even improving the ranking performance.

RELATED WORK
Recommender Systems

In recent years, many recommendation algorithms have
been proposed, which fall into content-based, collaborative

344

same top-k items, i.e., i1 , i2 , . . . , ik where i1 , i2 , . . . , ik ∈ I.
Formally,

A variety of model-based ranking-oriented CF algorithms
have been presented by optimizing ranking-oriented objective functions, e.g., bayesian personalized ranking (BPR)
[20], CLiMF [24], CoFiRank [29], and ListRank-MF [25].
BPR and CLiMF model the binary relevance data and
optimize binary relevance metrics, i.e., Area Under the
Curve (AUC) in BPR and Mean Reciprocal Rank (Mean)
in CLiMF, which are not suited for graded relevance data.
CoFiRank [29] minimizes a convex upper bound of the
Normalized Discounted Cumulative Gain (NDCG) [7, 8]
loss through matrix factorization while ListRank-MF [25]
integrates the learning to rank technique into the matrix
factorization model for top-N recommendation.

3.

Gk (i1 , i2 , . . . , ik ) = {π | π ∈ ΩI , πj = ij , j = 1, ..., k}.
Two top-k permutation sets of I are different if the items
in the top-k positions are different. Let GkI denote the set of
different top-k permutation sets for I. Please note that the
cardinality of Gk (i1 , i2 , . . . , ik ) is (n−k)!, and the cardinality
of GkI is n!/(n − k)!.
Example 1. Let I = {i1 , i2 , i3 }. There are totally
3! = 6 possible permutations in ΩI : hi1 , i2 , i3 i, hi1 , i3 , i2 i,
hi2 , i1 , i3 i, hi2 , i3 , i1 i, hi3 , i1 , i2 i, and hi3 , i2 , i1 i. There are
merely 3!/2! = 3 top-1 permutation sets: G1I = {G1 (i1 ), G1 (i2 ),
G1 (i3 )}, where G1 (i1 ) = {hi1 , i2 , i3 i, hi1 , i3 , i2 i}, G1 (i2 ) =
{hi2 , i1 , i3 i, hi2 , i3 , i1 i}, and G1 (i3 ) = {hi3 , i1 , i2 i, hi3 , i2 , i1 i}.

LISTWISE COLLABORATIVE FILTERING

In this section, we propose ListCF, a listwise rankingoriented collaborative filtering (CF) algorithm based on the
memory-based CF framework. Generally, memory-based CF
works in two phases [28]: The similarity calculation phase
(Phase I) calculates the similarities between pair of users,
based on which a set of most similar neighborhood users
can be discovered for each user; Then the ranking prediction
phase (Phase II) predicts the preference ordering of unrated
items for each target user by aggregating preferences of
neighborhood users for recommendation purpose.

3.1

Based on the Definition 2, the probability of the top-k
permutation P (Gk (i1 , i2 , . . . , ik )) equals to the sum of the
probabilities of permutations in which the items i1 , i2 , . . . , ik
are ranked in the top-k positions. To calculate all the probabilities of top-k permutation sets in GkI , we need consider
n!/(n − k)! top-k permutation sets, each containing (n − k)!
permutations of I. Therefore we still have to calculate
n!/(n − k)! · (n − k)! = n! probabilities of permutations in
total. In [3], an efficient way to calculate the probability of
the top-k permutation set P (Gk (i1 , i2 , . . . , ik )) is shown in
Lemma 1.

Phase I: Similarity Calculation

In ListCF, we utilize Plackett-Luce model [17], a widely
used permutation probability model, to represent each user
as a probability distribution over the permutations of rated
items. It is assumed that given a ranking function on a
set of items, any permutation on the item set is possible.
However, different permutations may have different probabilities, and more “correct” permutations where items with
larger ranking scores are ranked higher are assigned with
larger probabilities.
Let I be a set of items. A permutation of I is a bijection
from I to itself and it can be represented as an ordered
list π = hπ1 , π2 , . . . , πn i, where πi ∈ I denotes the item at
position i and πi 6= πj if i 6= j. The set of all the possible
permutations of I is denoted as ΩI .

Lemma 1. The probability of the top-k permutation set
P (Gk (i1 , i2 , . . . , ik )) equals to the probability of that the items
i1 , i2 , . . . , ik are ranked in the top-k positions respectively.
Formally,
P (Gk (i1 , i2 , . . . , ik ))
=

j=1

n
Y
i=1

φ(rπj )
Pn
, ∀j = 1, . . . , k : πj = ij
l=j φ(rπl )

(1)

where rπl is the rating score of the item which is ranked in
position l, l = 1, 2, ..., n.
Obviously, the probabilities of the top-k permutation
sets in GkI form a probability distribution, which can be
calculated much more efficiently than the probability distribution over G I . In this study, we refer to the probability
distribution over the top-k permutation sets as the top-k
probability model, which uses the top-k permutation sets
instead of the full permutations of all the items.
In recommender systems, for each pair of users u and v,
let Iu,v be the set of their commonly rated items. Then
I
Gku,v represents the set of top-k permutation sets of Iu,v .
We use Pu and Pv to denote the probability distributions
I
of u and v over Gku,v according to the top-k probability
model, which can be calculated with Equation (1) based on
their rating scores. Thus the similarity between user u and
v can be estimated as the similarity between the probability
distributions of Pu and Pv .
In this study, we use Kullback-Leibler (KL) divergence
[11] based metric for similarity calculation, since it is a
common measure of the difference between two probability
distributions in probability theory and information theory.
Given two users u and v, the KL divergence of Pu from Pv

Definition 1. (Probability of permutation). Let
φ(·) be an increasing and strictly positive function. Given
a permutation π = hπ1 , π2 , . . . , πn i and the rating scores of
the items {rπ1 , rπ2 , . . . , rπn }, the probability of π is defined
as follows:
P (π) =

k
Y

φ(r )
Pn πi
.
k=i φ(rπk )

In this paper, we use the exponential function φ(r) = er .
For a set of n items, the number of different permutations
is n!. Thus, it is too time-consuming to calculate the
probabilities of all the permutations. To cope with this
problem, an alternative solution is the top-k probability
model [3] (1 ≤ k ≤ n), which only focuses on the
permutations of items within the top-k positions.
Definition 2. (Top-k Permutation set). Given a set
of items I, the top-k permutation set Gk (i1 , i2 , . . . , ik ) of I
is a set containing all the permutations of I which share the

345

the neighborhood user v has rated, and Tu,v = Tu ∩Iv . Thus
T
Gk u,v is the set of top-k permutation sets of Tu,v . Let P̂u0
and Pv0 be the respective probability distributions of u and
T
v over Gk u,v . The cross entropy between P̂u0 and Pv0 can be
calculated as follows:
X
Pv0 (g) log2 (P̂u0 (g)).
(4)
E(P̂u0 , Pv0 ) = −

is defined as follows:
DKL (Pv kPu ) =



X

Pv (g) log2

Iu,v

Pv (g)
Pu (g)


,

g∈Gk

where Pu (g) and Pv (g) is the probability of the top-k permuI
tation set g ∈ Gku,v for u and v respectively. DKL (Pu kPv )
can be calculated in the similar way. Obviously, the KL divergence is asymmetric, i.e., DKL (Pv kPu ) 6= DKL (Pu kPv ).
In this study, we define a symmetric similarity metric based
on the KL divergence, which is shown as follows:
i
1h
(2)
s(u, v) = 1 − DKL (Pv kPu ) + DKL (Pu kPv ) .
2

Tu,v

g∈Gk

Please note that in the above equation, Pv0 is different from
Pv that is used in similarity calculation. As they are based
on different sets of items, where Pv0 is based on Tu,v while
Pv is based on the commonly
P rated items Iu,v = Iu ∩ Iv of
user u and v. Obviously g∈G Tu,v Pv0 (g) = 1 holds.
k

ListCF attempts to make predictions by minimizing the
weighted sum of the cross entropy loss between the probability distributions of the target user and his neighborhood
users over the set of the top-k permutation sets of Tu,v . For
a target user u and the set of unrated items Tu , the cross
entropy-based loss function is:
X
s(u, v) · E(P̂u0 , Pv0 )
arg min
ϕu
v∈Nu
(5)
Tu
s.t.
∀g ∈ Gk : ϕu,g ≥ 0.

The similarity metric in Equation (2) suffers from computing high similarity between users with few ratings in
common. Like in [5], this can be alleviated by multiplying
the similarity function with min{|Iu,v |/c, 1}, where c is a
threshold. When the number of commonly rated items falls
below this threshold, the similarity is scaled down.
Since DKL (Pv kPu ), DKL (Pu kPv ) ≥ 0, according to Equation (2), the similarity between each pair of users is no
greater than 1. Formally, ∀u, v ∈ U : s(u, v) ≤ 1. The
similarity between u and v reaches the maximum bound
(s(u, v) = 1) only if their probability distributions Pu and
Pv over the top-k permutation sets are the same. We also
note that s(u, v) may be negative and has no lower bound.
However, this is not an important issue in our model because
we are just interested in discovery of limited number of users
with high similarities to the target user as the neighborhood
users.

According to Equation (2) and Equation (4), the objective
function can be specified as follows:
X
F (ϕu ) =
s(u, v) · E(P̂u0 , Pv0 )
v∈Nu

=−

X
v∈Nu

3.2

P̂u (g) = P

ϕu,g
T

g 0 ∈Gk u

ϕu,g0

,

=−

X

Pv0 (g) log2 (P̂u0 (g))

Tu,v

g∈Gk

Phase II: Ranking Prediction

For a target user u, let Nu be the set of neighborhood
users and Tu = {t1 , t2 , . . . , tp } be the set of items to be
predicted. The ultimate goal of ranking-oriented CF is to
predict a preference ranking of items in Tu for u.
Let P̂u be the probability distribution over the set of topk permutation sets GkTu to be predicted for u. In order to
guarantee that the sum of the probabilities in P̂u is equal to
1, for each top-k permutation set ∀g ∈ GkTu , the probability
P̂u (g) is denoted as follows:

X

s(u, v)

X

s(u, v)

v∈Nu

Tu,v

g∈Gk







Pv0 (g) log2 





ϕu,g

X

ϕu,g0 
Tu,v

g 0 ∈Gk


=

X

X

s(u, v)

v∈Nu







Pv0 (g) log2 

X





ϕu,g0  − log2 (ϕu,g ) .

Tu,v

Tu,v

g 0 ∈Gk

g∈Gk

(6)
We optimize Equation (6) with the gradient descent
method. The derivative of F with respect to ϕu,g is:

(3)

∂F
∂ϕu,g


where {ϕu,g |∀g ∈ GkTu } are unknown variables to be
P
predicted for user u and g∈G Tu P̂u (g) = 1 holds.
k
In this study, following the same assumption of memorybased CF, we make predictions based on a set of neighborhood users with similar ranking preferences to the target
user. If users have similar ranking preferences in the past,
they are most likely to have similar ranking preferences
in the future, which means that P̂u should be as close as
possible to the probability distributions of the neighborhood
users over their sets of top-k permutation sets.
We use the cross entropy loss function to make predictions, as it is widely-used for optimizing similarity/distance
between probability distributions in machine learning, and it
has been successfully used in the text mining [3], multimedia
retrieval [13], and pattern recognition [26] fields.
Given a target user u with a set of unrated items Tu and
a neighborhood user v ∈ Nu , let Iv be the set of items that

X

s(u, v)


X 

=

v∈Nu  ln 2 ·

Pv0 (g)

Tu,v
g∈Gk

X

ϕu,g0



X



−



s(u, v)Pv0 (g)

v∈Nu

ln 2 · ϕu,g
(7)

Tu,v
g 0 ∈Gk

X
=

X
v∈Nu

ln 2 ·

s(u, v)
X

−
ϕu,g0

s(u, v)Pv0 (g)

v∈Nu

ln 2 · ϕu,g

.

Tu,v

g 0 ∈Gk

Given a learning rate η, the update formula of the gradient
descent method is:
∂F
.
(8)
ϕu,g ← ϕu,g − η
∂ϕu,g

346

Algorithm 1: The ListCF Algorithm
Input: An item set I, a user set U , and a rating matrix
R ∈ RM ×N . A set of rated items Iu ⊆ I by
each user u ∈ U . The maximal number of
iterations maxIteration and error threshold .
Output: A ranking τ̂u of items for each user u ∈ U .
1 for u ∈ U do
2
for v ∈ U and u 6= v do
3
Pu , Pv ← TopKProDist(Iu , Iv , R)
/* Eq.1 */
4
sim(u, v) ← Similarity(Pu , Pv )
/* Eq.2 */
5
end
6
Nu ← SelectNeighbors({sim(u, v)}v∈U/u )
7 end
8 for u ∈ U do
9
t=1
10
repeat
11
ε=0
12
Initialize(ϕ0u )
13
for g ∈ GkTu do
14
ϕtu,g ← Update(Nu , sim, R)
/* Eq.8 */
qP
2
15
ε+ =
(ϕtu,g − ϕt−1
)
u,g
16
end
17
t←t+1
18
until t > maxIteration or ε < ;
19
for t ∈ Tu do
20
P (t) ← Aggregation({ϕu,g }g∈G Tu )

model, lines 19-21 aggregate the probabilities of the topk permutation sets to obtain the probabilities of the top1 permutation sets, that are the probabilities of each item
t ∈ Tu ranked in the first position.
In the proposed ListCF model, we use the top-k (k ≥
1) probability model [3] in the similarity calculation and
ranking prediction phases. ListCF with different values of
k may achieve different recommendation performances. On
one hand, generally the accuracy will be higher when a larger
k value is used. On the other hand, the computational
complexity of similarity calculation and ranking prediction
procedures will be exponentially increased. In particular, for
a user u associated with n items, the number of permutation
sets in the top-k probability model is n!/(n − k)!, and
specially this number is merely n when k = 1. Thus the time
complexity of ListCF based on the top-k (k > 1) probability
model is (n − 1)!/(n − k)! times higher than that of ListCF
based on the top-1 probability model.

21
end
22
τ̂u ← Ordering({P (t)}t∈Tu )
23 end

For illustration purpose, we randomly selected 1000 users
from the MovieLens-1M dataset and conducted experiments
to compare the ranking accuracy as well as the runtime
of the similarity calculation and ranking prediction phases
(Phase I and II respectively) of ListCF when k = 1, 2 and
3. The size of neighborhood users was set to be 50, and 50
unrated items were predicted for each user in Phase II. The
results are reported in Table 1.
From the table we can see that, when k > 1 in ListCF,
the improvement in recommendation accuracy is very subtle,
but the degeneration of efficiency is extremely significant.
For example, ListCF with k = 3 achieves about 0.02
improvement in NDCG@5 over ListCF with k = 1, but
it takes 433 and 488 times longer in Phase (I) and Phase
(II) respectively. Obviously, the loss outweighs the gain.
Thus we set k = 1 when compare ListCF with other
recommendation algorithms in the experimental section.

Table 1: Accuracy and efficiency comparison of
ListCF with different k.
k=1
k=2
k=3
Accuracy (NDCG@5) 0.7866 0.7953 0.8052
Runtime of Phase I
8s
71s
3463s
Runtime of Phase II
1.5s
20.2s
731.7s

k

After updating ϕu,g , we can easily get the probabilities
P̂u (g) according to Equation (3), which meets the constraint
P
of g∈G Tu P̂u (g) = 1.
k
In order to obtain an ultimate ranking of Tu for each user
u, the probabilities of the top-k permutation sets need to be
aggregated. One intuitive way is to get the probabilities
of the top-1 permutation sets and rank the items in Tu
according to the descending order of the corresponding
probabilities. The probability of the top-1 permutation set
P (G1Tu (tj )) actually equals to the sum of the probabilities
of the top-k (k > 1) permutation sets with the item tj ∈ Tu
ranked in the top-1 position. Here gives an example.
Example 2. Suppose user u has items I = {i1 , i2 , i3 } to
be recommended. We have probability distribution {0.2, 0.3,
0.1, 0.1, 0.1, 0.2} over the set of top-2 permutation sets
G2I = {G2 (i1 , i2 ), G2 (i1 , i3 ), G2 (i2 , i1 ), G2 (i2 , i3 ), G2 (i3 , i1 ),
G2 (i3 , i2 )}. We can obtain the probabilities of that each item
is ranked in the top-1 position: P (G1 (i1 )) = 0.2 + 0.3 =
0.5, P (G1 (i2 )) = 0.1 + 0.1 = 0.2, and P (G1 (i3 )) = 0.1 +
0.2 = 0.3. Since P (G1 (i1 )) > P (G1 (i3 )) > P (G1 (i2 )), the
recommendation list is ordered as hi1 , i3 , i2 i.

3.3

4.

4.1

COLLABORATIVE FILTERING: LISTWISE VS. POINTWISE AND PAIRWISE
Relationship

Although ListCF, as a listwise memory-based CF algorithm, is completely different from pointwise and pairwise
memory-based CF algorithms in similarity calculation and
ranking prediction, these three categories of algorithms
inherently share similar prediction strategy.

Pseudocode and Discussion

The pseudocode of the ListCF algorithm is shown in
Algorithm 1, where lines 1-7 calculate the similarities
between users and discover the neighbor users for each target
user, and lines 8-23 predict the ranking of items to make
recommendations. When k > 1 in the top-k probability

Theorem 1. ListCF predicts the probability of a top-k
permutation set as the weighted average of the neighbors’
probabilities of the corresponding top-k permutation sets, if

347

∀v ∈ Nu : Tu,v ≡ Tu holds. Formally, for ∀g ∈ GkTu ,
X
s(u, v)Pv0 (g)
P̂u (g) =

v∈Nu

simply make predictions with a weighted average formula as
pointwise and pairwise CF do. However, with the constraint
T
of ∀v ∈ Nu : Tu,v ≡ Tu , Gk u,v = GkTu , the probabilities P̂u (g)
Tu
0
and Pv (g) (∀g ∈ Gk ) in the ranking prediction formula are
invariable, which is the same as those in pointwise CF and
pairwise CF. In this case, we can obtain the same result
shown in Theorem 1.

.

X

s(u, v)

v∈Nu
T

Proof. If ∀v ∈ Nu : Tu,v ≡ Tu , then ∀v ∈ Nu : Gk u,v ≡
For the optimization problem in Equation (5), set the
derivative of F (Equation 7) to be 0:
GTk u .

X
s(u, v)
X

X
ln 2 ·

v∈Nu

−

4.2

s(u, v)Pv0 (g)

v∈Nu

ln 2 · ϕu,g

ϕu,g0

Tu,v
g 0 ∈Gk

X
=

X

s(u, v)

v∈Nu

−

X

ln 2 ·

s(u, v)Pv0 (g)

v∈Nu

= 0.

ln 2 · ϕu,g

ϕu,g0

T

g 0 ∈Gk u

Thus
X

X

s(u, v)

v∈Nu

X

=

s(u, v)Pv0 (g)

v∈Nu

ϕu,g

ϕu,g0

,

T

g 0 ∈Gk u

and
X

s(u, v)Pv0 (g)

v∈Nu

X
v∈Nu

=
s(u, v)

Advantages of ListCF

In comparison with conventional pairwise ranking-oriented
CF, listwise CF demonstrates many advantages in efficiency
(when k = 1) and accuracy on account of the listwise
representation.
On the efficiency side, let M and N be the number of
users and items. Suppose each user has rated n items on
average, and the number of commonly rated items for each
pair of users is n. In the similarity calculation
 phase, the
time complexity of ListCF is O M 2 (n + n) . Recall that

the complexity of pairwise CF is O M 2 (n + n2 ) , which
is (n + n2 )/(n + n) times higher than that of ListCF.
Suppose each user has l neighbor users on average, and
each prediction process maximally performs d iterations for
gradient descent optimization. In the ranking prediction
phase, the time complexity of ListCF is O (M (N − n)ld),
where N − n is the number of items to recommend. Recall

that the complexity of pairwise CF is O M (N − n)2 l ,
which is (N − n)/d times higher than that of ListCF, and
d  N − n in our experiments. Since d is a constant, the
ratio of the complexity of pairwise CF to that of ListCF
increases linearly with the growth of the number of items to
be predicted in the ranking prediction phase.
On the accuracy side, firstly, permutation probability
based similarity metric considers the ranking position information of items, which can discover more accurate neighbor
users with similar preferences.
Secondly, permutation
probability based representation can easily handle the the
case of equal preferences on items, i.e., assigns equal
probability to the permutations in which the top items have
equal ranking scores. Thirdly, ListCF attempts to make
top-n recommendation by optimizing listwise loss function,
which is more natural and accurate. The following example
demonstrates the accuracy loss of the Kendall’s τ correlation
coefficient because of not considering the ranking position
information of items.

ϕu,g
X
= P̂u (g).
ϕu,g0
T

g 0 ∈Gk u

Theorem 1 presents the prediction formula of ListCF in
a special case when all the neighbor users have rated the
items in test set Tu of user u, i.e., ∀v ∈ Nu : Tu,v ≡
Tu holds. In this case, for ∀g ∈ GkTu , the probability
P̂u (g) can be predicted as the weighted average of the
neighbors’ corresponding probabilities, which is the same
as the pairwise preference prediction formula in pairwise
memory-based CF [15, 27, 28] as well as the rating prediction
formula in the pointwise memory-based CF after performing
the normalization of the ratings, i.e., the average rating of
the user u has been deducted from each rating ru,i of u,
(N )
formally ru,i = ru,i − ru .
Now we explain why we cannot obtain such a result
without the constraint of ∀v ∈ Nu : Tu,v ≡ Tu in ListCF
while we can with the constraint. In pointwise CF and
pairwise CF, the ratings and the pairwise preferences of
users are constant. However, in listwise CF, the probability
distributions of each pair of users u and v in the ranking
prediction phase vary with respect to the set of items Tu,v :
(1) Given a target user u, for any two different neighborhood
Tu,v
Tu,v
users v1 and v2 , since Tu,v1 6= Tu,v2 and Gk 1 6= Gk 2 ,
the length of the probability distribution P̂u of user u
could change and the values in P̂u could be different; (2)
Given two different target users u1 and u2 who have a
same neighborhood user v, the probability distribution of
Pv0 for user v could also be different. Thus we cannot

Example 3. Suppose there are three users U = {u1 , u2 , u3 }
and three items I = {i1 , i2 , i3 }, where u1 assigned ratings
of {5, 3, 4} to items, u2 assigned {5, 4, 3}, and u3 assigned
{4, 3, 5}.
In pointwise CF, the similarity (Pearson correlation coefficient) between u1 and u2 and the similarity between u1
and u3 are ρ(u1 , u2 ) = ρ(u1 , u3 ) = 0.5.
In pairwise CF, the similarity (Kendall’s τ correlation
coefficient) between u1 and u2 and the similarity between
u1 and u3 are τ (u1 , u2 ) = τ (u1 , u3 ) = 0.333.
In ListCF, according to Equation (1), the top-1 probability
distributions of users u1 , u2 and u3 are Pu1 = (0.665, 0.090,
0.245), Pu2 = (0.665, 0.245, 0.090), and Pu3 = (0.245, 0.090,
0.665). According to Equation (2), s(u1 , u2 ) = 0.776 and
s(u1 , u3 ) = 0.395, and thus s(u1 , u2 ) > s(u1 , u3 ).
Since recommender systems aim to recommend the items
that users may be most interested in, we should emphasize

348

the items with highest scores in the similarity calculation
and ranking prediction phases, and thus u2 is more similar to
u1 than u3 in Example 3. Obviously, ListCF can successfully
recognize it while pointwise CF and pairwise CF cannot.

5.

share the same memory-based CF framework with ListCF.
Since CofiRank1 and ListRank-MF2 are two model-based
CF algorithms and the implementation of them is based on
the publicly available software packages written in different
program languages from us, we did not include them in this
section.
We conducted experiments to compare their runtime
of the similarity calculation phase and ranking prediction
phase on the datasets. Due to the huge size of the Netflix
data, we selected users from Netflix who had rated no more
than 50 items to form an extremely sparse dataset containing
about 100,000 users. As analyzed in Section 4.2, when the
number of items each user has rated increases the difference
between EigenRank and ListCF would be more distinct,
and we omit the result here. Experiments were run on a
computer with 4 core 2 GHz CPU and 64 GB RAM.

EXPERIMENTS

5.1
5.1.1

Experimental Settings
Datasets

Table 2: Statistics on the three datasets.
Movielens-1M EachMovie
Netflix
#users
6,040
36,656
429,584
#items
3,952
1,623
17,770
#ratings
1,000,209
2,580,222
99,884,940
#ratings/user
165.6
70.4
232.5
#ratings/item
253.1
1589.8
5621.0
sparsity
93.7%
95.7%
98.7%

1000
PointCF

ListCF

EigenRank

800
600
400

We conducted a series of experiments on three real-world
rating datasets: Movielens-1M, EachMovie, and Netflix. All
of these datasets are commonly used benchmark datasets
in evaluating recommendation performance. The ratings
in Movielens-1M and Netflix are on a scale from 1 to 5,
while the EachMovie rating scale is from 1 to 6. In order
to guarantee that there are adequate number of ratings per
user for training and testing, we removed those users who
have rated less than 20 items from these datasets. Several
statistics on the resulting datasets are presented in Table 2,
where the sparsity levels in the last row are calculated as
follows [23]:
Sparsity = 1 −

5.1.2

200
0

EachMovie (min)

Netflix (h)

Figure 1: Runtime comparison of the similarity
calculation phase.
Figure 1 demonstrates the respective runtime of the similarity calculation phase of PointCF, ListCF and EigenRank
on three datasets. Note that the units of the runtime are
Second (s), Minute (min) and Hour (h) for the datasets of
Movielens-1M, EachMovie and Netflix respectively. From
Figure 1, we can observe that in the similarity calculation
phase:

#rating scores
.
#users × #items

• The runtime of ListCF is comparable with PointCF,
where ListCF is merely around 1.2 times higher than
PointCF. The slight increase of the runtime of ListCF
mainly results from an extra step of computing the
top-1 probability distributions for each pair of users.

Comparison Algorithms

In our experiments, we mainly compared the performance
of ListCF with three memory-based CF algorithms of
PointCF[1], EigenRank [15] and VSRank [27, 28], a classic
pointwise rating-oriented algorithm and two state-of-theart pairwise ranking-oriented algorithms respectively. In
particular, PointCF uses the Pearson correlation coefficient
to calculate the similarity between users, and ranks the
items according to the predicted ratings for each user. In
EigenRank and VSRank, the greedy aggregation method
is used to aggregate the predicted pairwise preferences of
items into total ranks. In the memory-based CF algorithms,
the number of neighborhood users was set to be 100 in
Movielens-1M and EachMovie, and 300 in Netflix. Since
ListCF is also a memory-based CF algorithm, a direct
comparison of them will provide valuable and irreplaceable
insights.
Besides, we also chose CoFiRank [29] and ListRank-MF
[25], two state-of-the-art model-based ranking-oriented CF
algorithms for comparison to further demonstrate the promising performance of ListCF. Like [29], the dimensionality
of latent features was set be to 10.

5.2

Movielens (s)

• The runtime of ListCF is much lower than that of
EigenRank, saving almost 40% time. This observation is consistent with our theoretical analysis in
Section 4.2, which is that in the similarity calculation
phase, the computational cost of pairwise CF is (n +
n2 )/(n + n) higher than that of ListCF, where n is the
average number of items rated by users, and n is the
average number of co-rated items by each pair of users.
Figure 2 shows the runtime comparison of the ranking
prediction phase of the three CF algorithms, where the
horizontal axis in these four sub-figures is the number of
items to be predicted for each user. The vertical axis in
Figure 2(a), 2(b) and 2(c) is the runtime of the algorithms,
and the vertical axis in Figure 2(d) is the runtime ratio of
EigenRank to ListCF. From the figures we can see that,
in the ranking prediction phase ListCF demonstrates significant improvement in prediction efficiency in comparison
with EigenRank.

Efficiency Comparison

1

In order to evaluate the efficiency of our model, we chose
PointCF and EigenRank as our comparison partners, as they

2

349

http://www.CoFiRank.org/
http://mmc.tudelft.nl/users/yue-shi

60
40
20
0
0 10

50
100
150
#items to be predicted

200

(a) Runtime on Movielens

400
300

Runtime (minutes)

80

7000
PointCF
ListCF
EigenRank

200
100
0

0 10

50
100
150
#items to be predicted

5000
4000
3000
2000
1000
0

200

(b) Runtime on EachMovie

25

PointCF
ListCF
EigenRank

6000

Ratio of EigenRank/ListCF

500
PointCF
ListCF
EigenRank

Runtime (minutes)

Runtime (minutes)

100

0 10

50
100
150
#items to be predicted

15
10
5

200

(c) Runtime on Netflix

Movielens−1M
EachMovie
Netflix

20

50

100
150
#items to be predicted

200

(d) Runtime improvement

Figure 2: Runtime comparison of the ranking prediction phase.
• From Figure 2(a), 2(b) and 2(c) we can see that
the runtime of both ListCF and PointCF is linearly
increased with the growth of the number of items to be
predicted, while the increase of EigenRank (the pairwise CF) is quadratic. This observation is consistent
with our theoretical analysis in Section 4.2 that, in
the ranking prediction phase, the computational costs
of ListCF and pairwise
CF are O (M (N − n)ld) and

O M (N − n)2 l respectively, where M is the number
of users, and N − n is the number of items to be
predicted. l is the size of the neighbor set, and d is the
maximal number of iterations in the gradient descent
based optimization method.

Cumulative Gain (NDCG) [7, 8] as the evaluation metric,
which is the most popular accuracy metric in information
retrieval for evaluating ranking of retrieved documents with
multi-level relevance scores.
In the context of collaborative filtering, item ratings
assigned by users can naturally serve as relevance judgments.
The NDCG metric is evaluated over some number of the top
items on the ranked item list. Let U be the set of users and
rup be the rating score assigned by user u to the item at the
pth position of the ranked list. The NDCG value at the
nth position with respect to the given user u is defined as
follows:
p
n
X
2ru − 1
,
N DCGu @n = Zu
log(1 + p)
p=1

• From Figure 2(d) we can see that the runtime ratio
of EigenRank to ListCF increases linearly with the
growth of the number of items to be predicted in the
ranking prediction phase. This observation is consistent with our analyzed result (N − n)/d in Section 4.2,
where N −n is the number of items to be predicted, and
d is a constant, i.e., the maximal number of iterations
in the gradient descent optimization method. The
gradients of the curves are slightly different because
some iterative optimization processes could converge
before reaching the maximal number of iterations d.

where Zu is a normalization factor calculated so that the
NDCG value of the optimal ranking is 1. N DCG@n takes
the mean of the N DCGu @n over the set of users U , which
is defined as follows:
N DCG@n =

where |U | is the cardinality of the set of users.

5.3.2
0.85

Rank accuracy

0.8

PointCF
EigenRank
VSRank

0.75
0.7

0.6

Prediction Accuracy Comparison

0.8

CofiRank
ListRank−MF
ListCF

0.75

PointCF
EigenRank
VSRank

CofiRank
ListRank−MF
ListCF

0.7

0.65

0.65

NDCG@1

NDCG@3
NDCG@5
Recommendation position

(a) Movielens-1M

To demonstrate the recommendation accuracy of our
model, we compare ListCF with all of the state-of-the-art
recommendation algorithms mentioned in Section 5.1.2 on
three datasets of Movielens-1M, EachMovie and Netflix. For
each dataset, we randomly select each user’s 10 rated items
and their corresponding ratings to form test set, and the
remaining ratings are used to form train set.

5.3.1

Performance on Movielens-1M and EachMovie

Rank accuracy

• The runtime of ListCF is significantly reduced as
compared to EigenRank even when no more than 200
items are predicted. For example, for the EachMovie
dataset, ListCF takes 20min to predict the total
rankings of 200 items for 36656 users, while the
runtime of EigenRank is 423min, which is 21 times
longer. The results on Movielens-1M and Netflix are
19 times and 16 times longer respectively.

5.3

|U |
1 X
N DCGu @n,
|U | u=1

0.6

NDCG@1

NDCG@3
NDCG@5
Recommendation position

(b) EachMovie

Figure 3: Ranking performance comparison on
Movielens-1M and EachMovie.
Figure 3 shows the performance comparison results in
terms of NDCG@1, 3 and 5 on the Movielens-1M and
EachMovie datasets. From the figure we can observe that:

Evaluation Metric

• Ranking-oriented CF algorithms generally achieve more
accurate top recommendations than the rating-oriented
CF algorithm (PointCF) under most conditions except
NDCG@3 and 5 on Movielens-1M.

For rating-based CF algorithms, the standard evaluation
criteria are the Mean Absolute Error (MAE) and the Root
Mean Square Error (RMSE). Both criteria measure the
error between true ratings and predicted ratings. Since
our study focuses on improving item rankings instead of
rating prediction, we employ the Normalized Discounted

• ListCF outperforms all of the comparison partners,
including the pairwise ranking-oriented CF algorithms

350

Table 3: Ranking performance comparison on Netflix with different user groups. The percentages are the
improvements of ListCF over the corresponding approaches.
User group
Metric
PointCF EigenRank VSRank CoFiRank ListRank-MF ListCF
0.6581
0.6600
0.6590
0.6824
0.6929
0.7004
NDCG@1
6.42%
6.12%
6.28%
2.56%
1.08%
0.6866
0.6791
0.6723
0.7106
0.7218
0.7174
20-50
NDCG@3
4.49%
5.64%
6.71%
0.96%
-0.61%
0.7233
0.7144
0.7126
0.7322
0.7570
0.7502
NDCG@5
3.40%
4.69%
4.95%
1.72%
-0.90%
0.6693
0.6898
0.6883
0.6990
0.7233
0.7372
NDCG@1
10.14%
6.87%
7.10%
5.46%
1.92%
0.7057
0.7085
0.7117
0.7153
0.7359
0.7563
50-100
NDCG@3
7.17%
6.75%
6.27%
5.73%
2.77%
0.7445
0.7364
0.7406
0.7591
0.7679
0.7817
NDCG@5
5.00%
6.15%
5.55%
2.98%
1.80%
0.6765
0.6900
0.7014
0.6954
0.7357
0.7666
NDCG@1
13.32%
11.10%
9.30%
10.24%
4.20%
0.7093
0.7174
0.7228
0.7235
0.7494
0.7739
100-200
NDCG@3
9.11%
7.88%
7.07%
6.97%
3.27%
0.7491
0.7565
0.7641
0.7755
0.7794
0.7987
NDCG@5
6.62%
5.58%
4.53%
2.99%
2.48%

and also listwise model-based CF algorithms. The improvement is more distinct on EachMovie dataset. For
example, ListCF achieves improvements of 9.25% over
EigenRank and 5.9% over ListRank-MF on EachMovie
in terms of NDCG@5.

algorithm ListCF achieves 0.7666 in NDCG@1 on
group “100-200” while 0.7004 on group “20-50”, and the
numbers of the model-based algorithm ListRank-MF
are 0.7357 on group “100-200” while 0.6929 on group
“20-50”.

• In comparison with all the other algorithms, the
improvements of ListCF are more significant in terms
of NDCG at higher positions. For example, for
Movielens-1M, ListCF improves 19.88%, 14.97%, and
13.41% in terms of NDCG@1, 3 and 5 in comparison with PointCF, and these numbers are 16.29%,
15.51%, and 13.93% respectively in comparison with
EigenRank. For EachMovie, we can get similar trends.
This is because ListCF considers the ranking position
issue in the similarity calculation phase, which is
demonstrated in Example 3 in Section 4.2.

5.3.3

• Our ListCF can significantly outperform other memorybased algorithms, both pointwise (PointCF) and pairwise CF (EigenRank and VSRank), in all evaluation
metrics of NDCG@1, 3 and 5. In addition, similar to
the results on Movielens-1M and EachMovie, rankingoriented algorithms, both pairwise and listwise CF,
achieve more accurate predictions than rating-oriented
CF (PointCF).
• ListCF can outperform the model-based ranking-oriented
algorithms under most conditions except NDCG@3
and NDCG@5 on group “20-50” of ListRank-MF. The
reason might be that ListCF, as a memory-based
algorithm, cannot find useful neighborhood users and
make accurate predictions if the dataset is too sparse
because of that the commonly rated items between
users are too rare. However, even on this dataset with
the sparsity of 99.87%, ListCF can also achieve the
best performance in NDCG@1, with improvements of
2.56% and 1.08% over CoFiRank and ListRank-MF
respectively.

Performance on Netflix

In previous experiments, we show that ListCF can generate superior performance in top-n recommendation on
Movielens-1M and EachMovie datasets compared with other
recommendation algorithms. In order to compare our model
with the other algorithms thoroughly, distinct from previous
validations focusing on comparing global quality of recommendations over all users, here we are particularly interested
in testing the performance of respective algorithms in regard
to different groups of users. We first select user groups based
on the number of observed ratings in the training set. We
use group “20-50”, “50-100” and “100-200” as experimental
subjects, and each user group contains about 90 thousand
users. User group “20-50” denotes users who have rated more
than 20 and less than 50 items in the training set. User
groups represent different datasets with different sparsities.
The sparsity of user group “20-50” is 99.87%, and it is the
sparsest dataset among three datasets.
The detailed experimental results are reported in Table 3.
From the table we can see that:

• As a whole, the improvements of ListCF are more
distinct on denser datasets in comparison with other
algorithms. For example, on the densest dataset
(group “100-200”), the improvements of ListCF are
13.32%, 9.11% and 6.62% in terms of NDCG@1, 3
and 5 respectively compared with PointCF, while on
the sparsest dataset (group “20-50”), these numbers
become 6.42%, 4.49% and 3.40%. The reason is
similar to the previous observation, which is that the
number of co-rated items between users are larger
on a denser dataset, and thus ListCF can find more
accurate neighborhood users to make predictions.

• All of the recommendation algorithms perform worse
on sparser datasets. For example, our memory-based

351

• Similar to the experimental results on Movielens-1M
and Eachmovie, the improvements of ListCF over
other algorithms are more significant in terms of
NDCG at higher positions as a whole. We can
see that the improvements of ListCF are increased
with decrease of positions (n) in NDCG@n. For
example, for the group “100-200”, ListCF improves
13.32%, 9.11% and 6.62% over PointCF in terms of
NDCG@1, 3 and 5 respectively, and similar results can
be obtained as compared with other algorithms on all
of the three groups. This is because the permutation
probability model in ListCF consider the ranking
position issue in the similarity calculation phase, which
is demonstrated in Example 3 in Section 4.2.

6.

[8] K. Järvelin and J. Kekäläinen. Cumulated gain-based
evaluation of ir techniques. ACM Trans. Inform. Syst.,
20(4):422–446, 2002.
[9] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization
techniques for recommender systems. Computer,
42(8):30–37, 2009.
[10] Y. Koren and J. Sill. Ordrec: an ordinal model for
predicting personalized item rating distributions. In
RecSys, pages 117–124, 2011.
[11] S. Kullback. Information Theory and Statistics. Courier
Dover Publications, 1997.
[12] D. D. Lee and H. S. Seung. Algorithms for non-negative
matrix factorization. In NIPS, pages 556–562, 2001.
[13] X. Li, E. Gavves, C. G. Snoek, M. Worring, and A. W.
Smeulders. Personalizing automated image annotation
using cross-entropy. In MM, pages 233–242, 2011.
[14] G. Linden, B. Smith, and J. York. Amazon. com
recommendations: Item-to-item collaborative filtering.
IEEE Internet Comput., 7(1):76–80, 2003.
[15] N. N. Liu and Q. Yang. Eigenrank: A ranking-oriented
approach to collaborative filtering. In SIGIR, pages 83–90,
2008.
[16] P. Lops, M. de Gemmis, and G. Semeraro. Content-based
recommender systems: State of the art and trends. In
F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, editors,
Recommender Systems Handbook, pages 73–105. Springer
US, 2011.
[17] J. I. Marden. Analyzing and modeling rank data. CRC
Press, 1996.
[18] S. M. McNee, J. Riedl, and J. A. Konstan. Being accurate
is not enough: How accuracy metrics have hurt
recommender systems. In CHI, pages 1097–1101, 2006.
[19] A. Mnih and R. Salakhutdinov. Probabilistic matrix
factorization. In NIPS, pages 1257–1264, 2007.
[20] S. Rendle, C. Freudenthaler, Z. Gantner, and
L. Schmidt-Thieme. Bpr: Bayesian personalized ranking
from implicit feedback. In UAI, pages 452–461, 2009.
[21] J. D. Rennie and N. Srebro. Fast maximum margin matrix
factorization for collaborative prediction. In ICML, pages
713–719, 2005.
[22] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Analysis
of recommendation algorithms for e-commerce. In EC,
pages 158–167, 2000.
[23] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl.
Item-based collaborative filtering recommendation
algorithms. In WWW, pages 285–295. ACM, 2001.
[24] Y. Shi, A. Karatzoglou, L. Baltrunas, M. Larson, N. Oliver,
and A. Hanjalic. Climf: learning to maximize reciprocal
rank with collaborative less-is-more filtering. In RecSys,
pages 139–146, 2012.
[25] Y. Shi, M. Larson, and A. Hanjalic. List-wise learning to
rank with matrix factorization for collaborative filtering. In
RecSys, pages 269–272, 2010.
[26] Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. DeepFace:
Closing the gap to human-level performance in face
verification. In CVPR, pages 1701–1708, 2013.
[27] S. Wang, J. Sun, B. J. Gao, and J. Ma. Adapting vector
space model to ranking-based collaborative filtering. In
CIKM, pages 1487–1491, 2012.
[28] S. Wang, J. Sun, B. J. Gao, and J. Ma. VSRank: A novel
framework for ranking-based collaborative filtering. ACM
Trans. Intell. Syst. Technol., 5(3):No.51, 2014.
[29] M. Weimer, A. Karatzoglou, Q. V. Le, and A. Smola.
Maximum margin matrix factorization for collaborative
ranking. In NIPS, pages 1329–1336, 2007.
[30] S.-H. Yang, B. Long, A. J. Smola, H. Zha, and Z. Zheng.
Collaborative competitive filtering: Learning recommender
using context of user choice. In SIGIR, pages 295–304,
2011.

CONCLUSION

In this paper, we propose ListCF, a listwise rankingoriented model for collaborative filtering. ListCF measures the user-user similarity based on the Kullback-Leibler
divergence between users’ probability distributions over
permutations of commonly rated items. It predicts item
rankings for each user by minimizing the cross entropy loss
between the target user and his neighbors with weighted
similarities. Experimental results on three benchmark
datasets show that ListCF demonstrates many advantages
in recommendation efficiency and ranking accuracy. In
addition, we prove that ListCF shares similar prediction
strategy with pointwise and pairwise memory-based CF
under certain constraints.
In the future, we plan to explore other possible listwise
loss functions in ListCF. In addition, it is also interesting
to investigate model-based listwise CF algorithms based on
the top-k probability representations.

7.

ACKNOWLEDGMENTS

This work was supported by the Natural Science Foundation of China (61272240, 61103151, 71402083, 71171122),
Humanity and Social Science Foundation of Ministry of Education of China (12YJC630211), the Natural Science foundation of Shandong province (ZR2012FM037, BS2012DX012),
Academy of Finland (268078), the Doctoral Fund of Ministry of Education of China (20110131110028).

8.

REFERENCES

[1] J. S. Breese, D. Heckerman, and C. Kadie. Empirical
analysis of predictive algorithms for collaborative filtering.
In UAI, pages 43–52, 1998.
[2] R. Burke. Hybrid recommender systems: Survey and
experiments. User Model. User-Adap. Inter., 12:331–370,
2002.
[3] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning
to rank: From pairwise approach to listwise approach. In
ICML, pages 129–136, 2007.
[4] P. Cremonesi, Y. Koren, and R. Turrin. Performance of
recommender algorithms on top-n recommendation tasks.
In RecSys, pages 39–46, 2010.
[5] J. Herlocker, J. A. Konstan, and J. Riedl. An empirical
analysis of design choices in neighborhood-based
collaborative filtering algorithms. Inform. Retr.,
5(4):287–310, 2002.
[6] T. Hofmann. Latent semantic models for collaborative
filtering. ACM Trans. Inform. Syst., 22(1):89–115, 2004.
[7] K. Järvelin and J. Kekäläinen. IR evaluation methods for
retrieving highly relevant documents. In SIGIR, pages
41–48, 2000.

352


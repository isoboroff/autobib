StarSum: A Simple Star Graph for Multi-document
Summarization
Mohammed Al-Dhelaan
Department of Computer Science
King Saud University
Riyadh, Saudi Arabia

mdhelaan@ksu.edu.sa
ABSTRACT

phts
1

Graph-based approaches for multi-document summarization
have been widely used to extract top sentences for a summary. Traditionally, the documents’ cluster is modeled as a
graph of the cluster’s sentences only which might limit the
ability of recognizing topically discriminative sentences in regard to other clusters. In this paper, we propose StarSum a
star bipartite graph which models sentences and their topic
signature phrases. The approach ensures sentence similarity
and content importance from the graph structure. We extract sentences in an approach that guarantees diversity and
coverage which are crucial for multi-document summarization. Regardless of the simplicity of the approach in ranking, a DUC experiment shows the effectiveness of StarSum
compared to different baselines.

S

phts
3

phts
4

Figure 1: StarSum example: S represents a sentence
and phts represents topic signature phrase(bigram)

Moreover, when constructing the graph edges, all words are
used to determine the sentences similarity which might overestimate the importance of longer sentences. Therefore, we
propose an approach that addresses such limitations while
maintaining simplicity.
In this paper, we propose a new graph-based summarizer
that combines topic signature phrases with sentences in a
star bipartite graph, called StarSum. Sentences are modeled as central nodes while their topic signature phrases are
modeled around the sentences. This way we can rank sentences not only based on their relations to other sentences
but also to how many topic signature phrases do they cover.
For example, assume a sentence Si has a relation to three
other sentences. It is not clear if the traditional homogeneous graphs differentiate between whether Si shares a small
or large set of words with all three sentences regardless of the
edge weight. Imagine for instance that Si shares {w1 , ..., w4 }
with all three sentences, which means an edge weight of 4
between all sentences with Si . Now, if Si shares different
sets of words with all three sentences each of which is of 4
words, it would mean that the sentence cover more information and would probably be more suitable for a summary
regardless of the edge weights. It is clear that if the sentence
shares more words, then it should be ranked higher than a
sentence with fewer important words.
By explicitly representing words in the graph, we overcome the aforementioned problem. Moreover, by only considering topic signatures we have a less condensed graph
which makes clustering the graph to components easier and
ensures diversity. We show that by using a simple degree
centrality of sentences with their topic signature phrases and
neighboring sentences we can easily ensure coverages. The
experimental work shows the effectiveness of our approach
regardless of its simplicity compared to eigenvector centrality measures.

Categories and Subject Descriptors
I.2.7 [ARTIFICIAL INTELLIGENCE]: Natural Language Processing—Text analysis

Keywords
Text summarization; Text graphs; Multi-document summarization; Topic signatures

1.

phts
2

INTRODUCTION

Multi-document text summarization is the process of automatically producing a concise summary version representing a group of related documents. Graph-based text summarization algorithms have been widely used for multi-document
summarization where sentences are modeled as vertices and
their similarities or content overlap are modeled as edges.
After constructing the graph, an eigenvector centrality measure, as in PageRank[2], is used to rank the vertices. Notable algorithms as in TextRank[12] and LexRank[5] have
shown tremendous success in text summarization. However,
it is not clear if they capture important characteristics for
multi-document summarization as in coverage and diversity.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2766462.2767790 .

715

2.

PROPOSED APPROACH

The proposed approach StarSum combines topic signatures bigrams with sentences in a star graph for multi-document
summarization. By using topical bigrams, we ensure the selection of sentences that are topical in respect to different
clusters of documents. We start by describing the extraction
of topic signatures; then we explain the proposed StarSum
graph-based approach.

2.1

Topic Signatures

Topic signatures[9] are unigrams, or bigrams in our case,
that describe the topics of a giving document compared to
a background corpus. These descriptive bigrams are found
by using the log-likelihood ratios log λ of two different hypotheses. We have the input document cluster as DI , and
the background corpus as DB which is all the other clusters. To calculate the log-likelihood ratio of a given bigram
log λ(ph) 3 ph = wi−1 wi , we form two different hypotheses.
The first one is H1 which assumes to have the same probability of occurrence of ph in both DI and DB giving us
P (ph|DI ) = P (ph|DB ) , and is considered the null hypothesis. The second hypothesis, H2 , which assumes that ph has
higher probability of occurrence in the input DI compared to
DB giving us P (ph|DI ) > P (ph|DB ) which indicates that
ph is descriptive. The log-likelihood ratio is calculated as
1)
where L is calculated by using the binolog λ = log L(H
L(H2 )
mial distribution from the Bernoulli trials of sequences of
bigrams.
To find topic signature bigrams, we use −2 log λ to test the
statistical significance of their occurrences, which is asymptotically approximated to the χ2 distribution. We classify bigrams to be descriptive if their R(ph) = 1 iff(−2 log λ(ph) >
10.83), 0 which is equal to confidence level of 0.001. All the
significant bigrams are stored for each input cluster sepats
ts
rately as DI = {phts
1 , ..., phn |R(ph ) = 1}.

2.2

ply decompose the graph G to different graph components
G = {G1 , ..., Gn } that loosely represent different topics of
the document cluster. We greedily choose the top ranked
sentence from each graph component Gi starting with the
largest component in number of vertices to the smallest.
Therefore, we have a diversified list of sentences that cover
the main topics of the document cluster. Next, we explain
the ranking approach for sentences and how we measure the
saliency scores for them.
Our saliency scores of sentences are measured in a way
to ensure coverage of the topic within a given graph component Gi . The rank of sentences in a graph component
is measured by the degree centrality of the sentence vertices, which chooses the sentence that covers the topic well.
However, instead of only using the degree centrality, which
is the number of topic signature bigrams in the sentence,
we use both the first-order degree which is the number of
phrases, and the second-order which are the number of other
sentences that share topic signature phrases. Let us define
N (v, d) to be the neighborhood set of vertices for vertex v of
order d. For example, N (v, 1) is only the set of adjacent vertices to v. Therefore, the rank of the sentences is measured
as:
R(v) =

|N (v, 2)| − 1
length(v)

(1)

Where |N (v, 2)| is the total number of vertices in the neighborhood set which contains topic signature phrases and sentences that share these phrases with sentence v, we subtract
one since we do not want to count v, and length(v) is the
total number of bigrams in sentence v for penalizing long
sentences. The final summary is then constructed as:
[
Summary =
arg max R(v)
(2)
Gi

StarSum: Combining Topic Signatures with
Sentences

After explaining the topic signature extraction, we move
on to describe our proposed approach StarSum, which models sentences with their topic signature bigrams in a bipartite graph. By modeling the relations between sentences
and their topical phrases in a graph, we ensure that saliency
scores of sentences depend on the topicality of their phrases
as well as their connectivity to other sentences. Our approach is designed to cover two main properties of summaries in a multi-document settings: diversity and coverage. First, we describe our approach to ensure diversity of
main topics. Second, we describe our ranking approach that
ensures coverage.
Before we describe our approach to ensure diversity in
summaries, let us define the StarSum graph. Let G(V1 ∪
V2 , E) be a bipartite star graph where V1 ∪ V2 is a set of finite vertices, and E is a set of finite edges connecting V1 and
V2 . The set of sentences is denoted as V1 = {S1 , ..., Sn }, and
ts
the set of topic signature bigrams as V2 = {phts
1 , ..., phn }.
We are interested on ranking V1 only. To have a diversified ranking of sentences, traditional approaches use clustering algorithms which might be computationally intensive
for well connected graphs. However, since we only model
sentences with their topic signatures as opposed to all words
or phrases, the graph G is loosely connected. We can sim-

v∈Gi

We keep picking top sentences from each graph component, starting from the largest, until we reach the summary
length. If we cover all the graph components but have not
reached the summary length, we start over in a round robin
fashion.
The intuition behind the StarSum approach is that assessing sentences’ appropriateness for summaries should not
only be about sentence similarity, as in number of common
words or cosine similarity. Instead, it should be about both
containing topical phrases and sharing them with other sentences. Therefore, modeling the topic signature phrases in
the graph is important to ensure rewarding sentences that
are more topically informative. Additionally, despite its simplicity, StarSum is an effective approach for guaranteeing
diversity and coverage compared to other eigenvector approaches that uses a random walk.

3.

EXPERIMENT

To evaluate how our proposed approach compares to other
baselines, we use Task 2 of the Document Understanding
Conference dataset (DUC 2001) which is designated for multidocument summarization. The DUC is an English news
benchmark for text summarization. The dataset is clustered to 30 news topics where each cluster contains roughly
10 documents1 . Each cluster has 3 different human written summaries that are considered as the golden summaries
1

716

we used the 30 topics in the test set only

Table 1: Multi-document Summarization Results over DUC 2001
Log Likelihood
TextRank + MMR
LexRank + MMR
Hypergraph + MMR
StarSum

ROUGE-1
0.47433
0.47545
0.51071
0.51612
0.52337

ROUGE-2
0.31205
0.31768
0.35801
0.37431
0.39148

ROUGE-3
0.26083
0.26979
0.31120
0.32444
0.34649

ROUGE-L
0.45782
0.45569
0.49046
0.50291
0.51193

topic signatures in the hyperedge weights so the surfer
in the random walk will prefer sentences that contain
more topic signatures.

to compare against all multi-document summarization algorithms2 . All the baseline algorithms are set to produce
a 100 word summary, which will be compared against the
100 word summary of the gold set. The topic signatures
are calculated by assigning DI to the current cluster, and
the DB to the other 29 clusters. For the preprocessing, we
remove punctuations, lowercase all characters, and stem the
text with Porter stemmer.
We use the well-known recall metric ROUGE [10] for evaluating the automated summaries. The metric measures the
overlap between the generated summaries and the human
summaries. We use 5 different options for ROUGE which
depends on the size of the textual unit. ROUGE-1 is the
unigram measure which shows the most agreement with human judges[10]. Additionally, we use the bigram measure
ROUGE-2, the trigram measure ROUGE-3, ROUGE-4, and
ROUGE-L for the longest common subsequence of words.
We use a number of different baselines to test our StarSum approach validity through ROUGE[10]. The baselines
are common graph-based approaches that generally use an
eigenvector centrality algorithms for ranking vertices and
extracting the top sentences. The baselines are chosen to
directly examine whether our simple approach for ensuring
coverage and diversity is effective. The baselines used for
comparison are described as follows:

• StarSum (unigram) This baseline is built as a star
graph between sentences and unigram topic signatures
to validate the use of bigram in the proposed approach.
The experimental results in Table 1 shows that regardless
of StarSum’s simplicity, it still outperforms computationally intensive approaches. Additionally, it slightly outperforms a state-of-the-art approach that uses random walks
with topic signatures on a hypergraph. The improvement
over baselines is noticed in all different options of ROUGE
which shows the validity of the approach. Moreover, the usage of topic signature bigrams has outperformed using unigrams topic signatures in the StarSum approach in Table 2.
This shows that informative bigrams are more important in
highlighting salient sentences compared to unigrams in the
StarSum algorithm.
To understand why StarSum works well despite its simple algorithmic design, we show how the intuition behind it
is slightly different than eigenvector centrality approaches.
StarSum is tailored toward two goals: coverage and diversity, where the random walk approaches focus on the prestige
of vertices. It is not clear if prestige ensures either diversity
or coverage. Additionally, modeling the relation between
topic signature bigrams and sentences ensures that we prefer sentences that both contain many topical bigrams and
share many connections with other sentences.
The efficiency of the StarSum ranking comes from the
fact that it is simply a degree centrality approach. To get
the rank of sentence v, the algorithm only needs to traverse
the local neighborhood of that sentence. This means that for
a single node v, the running time will be O(|Vn |+|En |) which
is linear in v’s local neighborhood n. In algorithms that use
PageRank, the ranking of a node is dependent on the entire
graph structure and number of iterations until convergence.
Additionally, our approach avoids doing any sentence pair
similarity calculation as in most of the baseline approaches
which is of quadratic time.

• Log Likelihood Similar to[4], topic signatures of words
are calculated to rank the sentences. Each sentence is
ranked by the density of topic signature unigrams over
the length of the sentence.
• TextRank+MMR This is well-known approach that
builds a graph of sentences based on the overlap of
words [12]. Specifically, edge weights are defined as the
number of common words between the two sentences
divided by the sentences’ length. Sentences are then
ranked by using a weighted PageRank[2] approach. To
compare such approach to StarSum which uses diversity, we combine TextRank with a Maximal Marginal
Relevance (MMR)[3]in a similar approach to[17]. The
MMR is a simple reranker for ensuring diversity of top
sentences.
• LexRank+MMR LexRank[5] builds a graph of sentences where the edge weight is the cosine similarity
of the two sentences being greater than 0.1. Then
we compute the rank of vertices by using a weighted
PageRank approach. After ranking the vertices, we use
an MMR approach to ensure diversity in the summary.

4.

RELATED WORK

Summarizing a cluster of documents through graphs has
been extensively researched. The most notable work is TextRank[12] and LexRank[5]. In TextRank[12], the edge weights
are defined using the words overlap normalized by the length
of the two sentences. A weighted PageRank is then used to
rank the sentences. Similarly in LexRank[5], a PageRank
approach is used to rank vertices but the edge weights are
based on cosine similarity between the two sentences. To ensure diversity, some enhanced approaches cluster the graph
first as in C-LexRank[13], or enhance the random walk process as in DivRank[11].

• Hypergraph+MMR This is a state-of-the-art algorithm that models sentences as hyperedges in a hypergraph and words as vertices[1]. It also uses unigram
2

The total is actually 29 clusters. Given that the organizers
made a mistake in cluster d31’s summaries, it was excluded
from our experiment

717

Table 2: Comparision between bigram StarSum and unigram StarSum
StarSum (unigram)
StarSum (bigram)

ROUGE-1
0.46915
0.52337

ROUGE-2
0.37690
0.39148

Other approaches model both sentences and words in a
bipartite graph fashion and approach the task as mutual reinforcement between keywords and sentences[14, 16]. However, they are different approaches than StarSum since we
are using the log likelihood to identify important phrases a
priori to enhance sentence selection. Some new approaches
have relied on the log likelihood of word association in sentences[7] which shows their importance in summarization.
Additionally, Yih et al. [15] proposed an approach to find
sentences that maximize the coverage of informative words.
They recognized informative words by frequency and position of words. Similarly, Gillick and Favre[6] proposed to use
Integer Linear Programming to find sentences that cover important bigrams based on their document frequency. Both
approach do not use discriminative weighting approach as
in topic signature. A recent survey on text summarization
comparing baselines with state-of-the-art approaches can be
found in[8].

5.

[4]

[5]

[6]
[7]

[8]

CONCLUSION & FUTURE WORK

In this work, we proposed a simple, yet effective, star
graph that combines topic signature bigrams and sentences.
We ensure diversity by decomposing the StarSum graph
into different components and picking top sentences from
each different component, and we ensure coverage by ranking sentences through their degree connection to other topic
phrases and sentences. The experiment showed the effectiveness of our approach by outperforming all other baselines.
The results highlighted the shortcoming of using an eigenvector approach on graphs which ranks sentences based on
their prestige as opposed to diversity and coverage. Moreover, the simplicity of the StarSum should be appealing to
systems that needs to scale to large collection of documents
as in the modern Information Retrieval systems.
In the future, we plan to experiment with more datasets
and different summary length. Additionally, we will test our
approach in related summarization tasks as query-focused
summarization. Also, we will experiment with different setup
for calculating the topic signature statistics and examine
whether it changes the accuracy of summarization. For example, studying the effect of changing the statistical significance level for finding topic signatures. Moreover, we plan to
test using a larger background dataset for finding topic signature phrases. Additionally, testing the use of trigrams, in
addition to bigrams, and whether they improve the quality
of the summaries is in our future plans.

6.

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]

REFERENCES

[17]

[1] A. Bellaachia and M. Al-Dhelaan. Multi-document
hyperedge-based ranking for text summarization. In
CIKM, pages 1919–1922, 2014.
[2] S. Brin and L. Page. The anatomy of a large-scale
hypertextual web search engine. In WWW, pages
107–117, 1998.
[3] J. Carbonell and J. Goldstein. The use of mmr,
diversity-based reranking for reordering documents

718

ROUGE-3
0.33750
0.34649

ROUGE-L
0.45944
0.51193

and producing summaries. In SIGIR, pages 335–336,
1998.
J. M. Conroy, J. D. Schlesinger, and D. P. O’Leary.
Topic-focused multi-document summarization using
an approximate oracle score. In COLING-ACL, pages
152–159, 2006.
G. Erkan and D. R. Radev. Lexrank: graph-based
lexical centrality as salience in summarization. Journal
of Artificial Intelligence Research, 22(1):457–479, Dec.
2004.
D. Gillick and B. Favre. A scalable global model for
summarization. In ILP, pages 10–18, 2009.
O. Gross, A. Doucet, and H. Toivonen. Document
summarization based on word associations. In SIGIR,
pages 1023–1026, 2014.
K. Hong, J. Conroy, B. Favre, A. Kulesza, H. Lin, and
A. Nenkova. A repository of state of the art and
competitive baseline summaries for generic news
summarization. In LREC, pages 1608–1616,
Reykjavik, Iceland, May 2014.
C.-Y. Lin and E. Hovy. The automated acquisition of
topic signatures for text summarization. In COLING,
pages 495–501, 2000.
C.-Y. Lin and E. Hovy. Automatic evaluation of
summaries using n-gram co-occurrence statistics. In
NAACL, pages 71–78, 2003.
Q. Mei, J. Guo, and D. Radev. Divrank: The
interplay of prestige and diversity in information
networks. In KDD, pages 1009–1018. ACM, 2010.
R. Mihalcea and P. Tarau. Textrank: Bringing order
into texts. In D. Lin and D. Wu, editors, EMNLP,
pages 404–411, Barcelona, Spain, July 2004.
V. Qazvinian and D. R. Radev. Scientific paper
summarization using citation summary networks. In
Coling 2008, pages 689–696, Manchester, UK, August
2008.
X. Wan, J. Yang, and J. Xiao. Towards an iterative
reinforcement approach for simultaneous document
summarization and keyword extraction. In ACL, pages
552–559, Prague, Czech Republic, 2007.
W.-t. Yih, J. Goodman, L. Vanderwende, and
H. Suzuki. Multi-document summarization by
maximizing informative content-words. In IJCAI,
pages 1776–1782, 2007.
H. Zha. Generic summarization and keyphrase
extraction using mutual reinforcement principle and
sentence clustering. In SIGIR, pages 113–120, 2002.
B. Zhang, H. Li, Y. Liu, L. Ji, W. Xi, W. Fan,
Z. Chen, and W.-Y. Ma. Improving web search results
using affinity graph. In SIGIR, pages 504–511, 2005.


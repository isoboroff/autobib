LBMCH: Learning Bridging Mapping for Cross-modal
Hashing
Yang Wang†‡ , Xuemin Lin† , Lin Wu] , Wenjie Zhang† and Qing Zhang‡†
†

]

The University of New South Wales, Kensington, Sydney, Australia
Australian Centre for Visual Technologies, The University of Adelaide, SA, Australia
‡
Australian E-Health Research Centre, Brisbane, Australia

{wangy,lxue,zhangw}@cse.unsw.edu.au, lin.wu@adelaide.edu.au, qing.zhang@csiro.au
ABSTRACT

ous hashing methods over single-modal data, which is described within only one feature space.

Hashing has gained considerable attention on large-scale similarity search, due to its enjoyable efficiency and low storage
cost. In this paper, we study the problem of learning hash
functions in the context of multi-modal data for cross-modal
similarity search. Notwithstanding the progress achieved by
existing methods, they essentially learn only one common
hamming space, where data objects from all modalities are
mapped to conduct similarity search. However, such method
is unable to well characterize the flexible and discriminative
local (neighborhood) structure in all modalities simultaneously, hindering them to achieve better performance.
Bearing such stand-out limitation, we propose to learn
heterogeneous hamming spaces with each preserving the local structure of data objects from an individual modality.
Then, a novel method to learning bridging mapping for
cross-modal hashing, named LBMCH, is proposed to characterize the cross-modal semantic correspondence by seamlessly connecting these distinct hamming spaces. Meanwhile, the local structure of each data object in a modality
is preserved by constructing an anchor based representation,
enabling LBMCH to characterize a linear complexity w.r.t
the size of training set. The efficacy of LBMCH is experimentally validated against real-world cross-modal datasets.

Figure 1: (a) Conventional methods learn the hashing functions to map all modalities into one common
hamming space (b) Our proposed technique learns
individual hamming space to well preserve the local
structure for each modality.
With the rapid growth of information technology, significant efforts are shifted to learning hashing functions from
single-modal hashing to Cross-modal hashing, which is more
widely seen in real-life application over multiple data sources
as multi-modalities [9, 10, 8, 11, 12, 7], while characterize
the same semantics, with each individual data source corresponding to one modality, where a query from one modal is
issued to search semantically relevant results from another
modal [14]. Typical example is image search via a text query
to return the images characterizing the similar semantics as
text query. There have been a lot of approaches, where
the basic idea of learning cross-modal hashing functions is
relying on canonical correlation analysis (CCA) [4]. Specifically, [5] extended conventional spectral hashing [13] from
single modality to multi-modal data, and learnt a common
hamming space in which the local structure of all modalities
can be well preserved. Motivated by anchor graph hashing [6], Zhu et al. [16] proposed a linear cross-modal hashing method against anchor based representation regarding
each modality. To effectively preserve local structure, [15]
proposed a novel parametric method to learn an individual
projection matrix for each data object.
Despite the progress achieved by these approaches, one
fundamental limitation is that they learn only one common
hamming space, which is unable to simultaneously characterize the flexible and discriminative local structure of each
individual modal, or even ignore the local structure preservation, hindering them to achieve better performance.
Bearing the limitation above, we propose a novel technique aimed at Learning Bridging Mapping for Cross-modal
Hashing, named LBMCH, to learn an individual hamming

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

Keywords
Hashing; Multi-modal Data; Bridging Mapping

1.

INTRODUCTION

Hashing is dramatically efficient for approximate nearest
neighbor search while enjoying the low storage cost of loading low dimensional hash codes. It, hence, inspired numerPermission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2766462.2767825.

999

the pth modal to search semantically relevant result within
the hamming space from q th modal.

space adaptive to local structure of each modal, while automatically learn a bridging mapping to preserve cross-modal
semantic correspondence by seamlessly connecting distinct
hamming spaces.
Our proposed method is orthogonal to recent state-of-thearts with featured contributions summarized below

2.2

We rewrite two hashing projection matrices Wp and Wq
m
m
to be Wp = [wp1 , · · ·, wp p ]T and Wq = [wq1 , · · ·, wq q ]T , where
each column of Wp and Wq generates one bit of hash code for
the pth and q th modal. Then we attempt to learn a bridging mapping matrix, M, to map the hash codes from mp dimensional hamming space to mq -dimensional hamming
space or vice versa, by utilizing the cross-modal semantic
correlation as provided by training data objects. That is, the
cross-modal semantically related data objects should have
similar hash codes after mapping. Besides, we expect the
bridging mapping matrix to have a good generalization capacity simultaneously. Then we propose to minimize the
following objective function
!2
mq
mp
Npq
X
X (pq) X
l T (p)
h T (q)
Sij
Mhl (wp ) ρi − (wq ) ρj
+ λ||M||2F ,

• We adaptively learn distinct hamming spaces to characterize discriminative local structure for each modal.
The bridging mapping is automatically learned to characterize the cross-modal semantic correlation by connecting these hamming spaces.
• We formulate the problem of learning bridging mapping for cross-modal hashing, and propose a novel twostage optimization technique to achieve the goal, featured with a sub-linear time complexity with respect
to the size of training samples.
• Extensive experiments are conducted over real-world
datasets, which demonstrate the superiority of LBMCH
over state-of-the-art methods.

i,j

2.

In this section, we focus on two modalities, which can be
easily extended to multiple modalities.

(q)

Problem Definition

2.3

j∈{p,q}
mq
µ X (pq) X
S
+
2 i,j ij
Npq

(q)

(q)

h=1

+

(1)

which can be defined as the largest distance to all its
(q)

(q)

−

(q)
(wqh )T ρj

(3)

l=1

λ
||M||2F
2

where µ and λ are trade-off parameters, mp and mq denote
the hash code length for the pth and q th modal. Imp and
Imq represent the identity matrix with the size of mp × mp
and mq × mq . Unlike existing methods that narrowly consider only one hamming space, we account for a generalized
case adaptive to different modalities, while bridged by mapping M. Next, we will discuss the optimization solution to
Eq. (3).

(q)

zij , σ is the bandwidth parameter controlling the decay rate
(q)

!2
(p)
Mhl (wpl )T ρi

Wq Z (q) (Z (q) )T WqT = Nq Imq ,

(q)

of

mp
X

s.t. Wp Z (p) (Z (p) )T WpT = Np Imp

where pij represents the refined representation based on
(q)
zij ,

Overall Objective Function

Given the pth and q th modality, we propose to learn Wp ,Wq ,
and M by minimizing the objective function below.
X
F (Wp , Wq , M) =
T r(Wj Z (j) L(j) (Z (j) )T WjT )

as zij . We make this fit Gaussian distribution, formulated
as
pij =

l=1

similar to xj , it is 0 otherwise. The regularization term
||M||2F is leveraged into Eq. (2) to achieve the good generalization power.
Now we are ready to propose the overall objective function
to learn hash functions Wp and Wq , for both modalities and
the bridging mapping M, simultaneously.

Assume Nq is the number of training data in the q th
modal, denoted as X (q) ∈ RNq ×dq , where dq is the dimen(q)
sions for q th modal. xi is the ith training data object from
th
the q modal. Npq is the number of observed semantic correspondence between training data objects in the pth and
q th modalities. Without relying on semantic labels of training data, we study a more practical case with training data
unlabeled. Unless otherwise specified, given any matrix A,
Aij represents the entry at the ith row and j th column of
(q)
A. Given xi , we map it to k-dimensional representation
(q)
zi , with its j th dimension encoding the Euclidean distance
(q)
(q)
between xi and the j th anchor, aj (j = 1, . . . , k), denoted

(q)
exp(−zij /σ)
,
Pk
(q)
l=1 exp(−zil /σ)

h=1

(2)
where Mhl is the lth entry of the hth row of M. S pq encodes
the semantic correlation between training data objects from
(p)
pq
two modalities. Sij
= 1 indicates that xi is semantically

LEARNING BRIDGING MAPPING FOR
CROSS-MODAL HASHING

2.1

Learning Bridging Mapping to Preserve
Cross-modal Semantic Correlation

(q)

k anchors. We further represent xi as ρi = [pij , · · ·, pik ].
We only keep the value for the s nearest anchors (s  k)
with others being 0, then we can normalize s positive values
(q)
to refine the representation. Collecting all ρi (i = 1, ···, Nq )
to be the columns of Z (q) , we have Z (q) ∈ Rk×Nq .
Instead of learning only one common hamming space,
LBMCH is to learn hashing functions characterized by Wp
and Wq for the pth and q th modalities, which can map training data objects into distinct hamming spaces with mp and
mq dimensions i.e., code length, respectively, such that mp
and mq may be different. A bridging mapping matrix i.e.,
M ∈ Rmp ×mq , is learnt to map the hash code of query from

2.4

Two-Stage Sequential Optimization Strategy

Minimizing Eq. (3) is not jointly convex to Wp , Wq and
M. Hence, we turn to propose a gradient descent method
[2] to minimize Eq. (3), seeking the local optimization for
each variable while fixing others.

1000

Assume we have learned the previous h − 1 bits, and we
are ready to learn the hth bit by calculating the derivative
with respect to wqh , then we have
Npq
(q)

Eh wqh + µ

=µ

X

(pq)

Sij

i,j

mp
X

(q)

(p)

(q)

Mhl ρj (ρi )T wpl + λq Kh wqh ,

(7)

l=1

(q)

(q)

(q)

(q)

(q)

(q)

(q)

(q)

• Eh = Zh Lh (Zh )T , Lh = Dh − Sh and Sh =
(q)
(q)
(Zh )T (Zh ).
(q)

• Zh = Z (q) −

Ph−1
k=1

(q)

(q)

(q)

wqk (wqk )T Z (q) and Kh = Zh (Zh )T .
(q)

(q)

The variables above are updated due to Zh , and Zh =
P
k
k T (q)
is formed by removing the projecZ (q) − h−1
k=1 wq (wq ) Z
(q)
tions of Z on the subspace spanned by wqk (k = 1, ··, h−1),
to encourage bits de-correlation. To learn the optimum wqh
w.r.t. the hth bit of hash code, we have

mp

(4)

Npq

l=1

−

(q)

where

Why learn all bits from q th modal and Mhl at the
second stage? To answer this question, we first derive the
∂F
, formulated as
gradient descent for Mhl by calculating ∂M
hl

(q)
(wqh )T ρj )

(pq) (q)

Sij ρj (ρj )T wqh

i,j

• Sequentially learn each bit of hash code for the q th
modal, and each entry Mhl in M based on all the mp
hash bits from the pth modal learned in the first stage

Npq

X

Npq

• Sequentially learn each hash bit for the pth modal.

X (pq) l T (p) X
∂F
(p)
Sij (wp ) ρi (
=µ
Mhl (wpl )T ρi
∂Mhl
i,j

Sequentially learning each bit from the qth modal
and M

2.4.2

Motivation. Unlike conventional methods [15] by conducting one-to-one bit of hash code learning fashion (e.g.,
learning only the pth bit for two modalities at each iteration)
alternatively for two modalities regarding one common hamming space, we consider a more generalized case of learning
heterogeneous hamming spaces via many-to-many bit relationship, characterized by bridging mapping M, which is
more practical yet challenging. As we observed, the second
term in Eq. (3) indicates that one bit of hash code from the
pth modal is related to all bits from the q th modal, and vice
versa. Hence, without loss of generality, we first initialize all
mq bits from q th by using spectral hashing [13], while initializing all Mhl to be 1. Particularly, we conduct a sequential
optimization strategy, which comprises of two stages below.

wqh

+ λMhl .

=

(q)
(Eh

+µ

X

Sij ρj (ρj )T − λq Kh )−1 Hp ,
(pq) (q)

(q)

(q)

(8)

i,j

Then we update Mhl by one step gradient descent. Remark∂F
ably, ∂M
relies on all hash bits from the pth modal and
hl

PN
(pq) Pmp
(q) (p) T l
where Hp = µ i,jpq Sij
l=1 Mhl ρj (ρi ) wp . Meanwhile, we learn Mhl via one step gradient descent by Eq. (4)
based on wql and all mp hash bits from the pth modal.

(q)

the hth hash bit from the q th modal, implied by (wqh )T ρj .
Thus, we can learn each entry Mhl upon the hth bit i.e.,
wqh from the q th modal, and all mp bits of hash code at the
second stage.

2.4.1

3.

Sequentially learning each bit from the pth modal

Assume we have learned the previous l − 1 bits, then we
can learn the lth bit by calculating the derivative with respect to wpl , that is,
X

(pq)

Sij

i,j
Npq

=µ

X

m
X

(p)

(p)

Mhl ρi (ρi )T wpl

h=1
mq

(pq)

Sij

i,j

X

(p)

(p)

(q)

ρi (ρj )T wqh + λp Kl wpl ,

(5)

h=1

where
(p)

(p)

(p)

(p)

(p)

(p)

(p)

• El = Zl Ll (Zl )T ∈ Rk×k , Ll = Dl − Sl
(p)
(p)
(p)
and Sl = (Zl )T (Zl ).
P
(p)
(p)
(p)
(p)
k
k T (p)
• Zl = Z (p) − l−1
and Kl = Zl (Zl )T .
k=1 wp (wp ) Z
Remarkably, all the above variables are updated and deterP
(p)
(p)
k
k T (p)
mined by Zl , and Zl = Z (p) − l−1
is
k=1 wp (wp ) Z
(p)
formed by removing the projections of Z
on the subspace
spanned by wpk (k = 1, ··, l − 1), thus to encourage bits decorrelation. To learn the optimum wpl w.r.t. the lth bit of
hash code, we have
Npq
mq
X
(p)
(pq) X
(p) (p) T
(p) −1
l
wp = (E
+µ
S
Mhl ρ
(ρ
) − λp K
)
Hq ,
ij
i
i
l
l
i,j
h=1

where Hq = µ

PNpq
i,j

(pq)
Sij

The time complexity of learning each bit e.g., wpl , from the
p modal of running Eq. (6) comes from the inverse computation, which costs O(k3 ). The same cost holds for learning
each bit e.g., wqh , from q th modality by the inverse computation from running Eq. (8). The cost for updating Mhl is
O(mp Npq k) by implementing Eq. (4). Therefore, the total
complexity is O((mp + mq )k3 + mp mq kNpq + kNp + kNq ) =
O(max{kNp , kNq , (mp +mq )k3 , mp mq Npq k}), where k is the
number of anchors. As k  Np and k  Nq , while mp and
mq are the length of hash codes for pth and q th modalities,
such that mp  k and mq  k.
Therefore, we expect m2j(j=p,q) < min{Np , Nq , Npq } and
2
k < min{Np , Nq , Npq }, which leads to mp mq k < k3 <
min{kNp , kNpq , kNq } < max{kNp , kNq }. Having k as a
constant, the time complexity can be rewritten as
O(max{Np , Nq }), which is linear to the number of training
samples on both modalities.
th

q

Npq
(p)

El wpl + µ

COMPLEXITY ANALYSIS AND DISCUSSIONS

4.

EXPERIMENTS

We use Wiki 1 and NUS-WIDE 2 for cross-modal hashing with two tasks: retrieving relevant texts by using images
as queries and retrieving images by using texts as queries.
The Wiki dataset consists of 2,866 Wikipedia documents,
each of which contains one text-image pair. All documents

(6)

1

Pmq

(p) (q) T h
h=1 ρi (ρj ) wq .

2

1001

http://www.svcl.ucsd.edu/projects/crossmodal/
http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm

are labeled by one of 10 semantic categories. Each image is
represented by a 128-dimensional bag-of-visual SIFT feature
vector and each text is encoded by a 10-dimensional feature
vector generated by Latent Dirichlet Allocation (LDA) [1].
Following [16], 2173 documents are partitioned as training
pairs and remaining 693 documents form query set.
The NUS-WIDE database contains 269,648 labeled images crawled from Flickr, and is manually annotated with 81
categories. We prune it via selecting 186,577 image-tag pairs
that belong to the ten largest concepts. The images are represented by 500-dimensional bag-of-visual words (BoVW)
and the tags are represented by 1000-dimensional tag occurrence feature vectors. We randomly select 300 × 300 =
90, 000 image-tag pairs to be training pairs, with remaining
to be query set for two tasks. Besides the training and query
set, we also conduct out-of-sample experiments by randomly
selecting the 2000 images from the remaining to be query set
to search tag modal.
Following [16], we set 300 and 600 anchors i.e., k = 300
and k = 600 in Eq. (1), for both modalities on Wiki and
NUS-WIDE datasets. Among k centroids, we set s = 3
nearest anchors to encode the local structure of each data
object for both modalities. We set λ = 0.01 in Eq. (3).

4.1

we can see the advantage of LBMCH by flexibly learning
the bridging mapping for various hamming spaces instead
of only one common space characterized by other methods.
Time complexity against training size. We evaluate the time complexity with varied training size on two
databases, and report the results in Fig.3. It can be seen
that the time cost of our method grows linearly with increasing training samples, which demonstrates the efficiency
of LBMCH.

(a)

Figure 3: Time complexity against training size over
two databases.

Competitors

We consider three state-of-the-art competitors: (1) CrossModal Similarity-Sensitive Hashing (CMSSH) [3] tackles
cross-modal hashing by using Adaboost to sequentially construct hash function for each modality whilst only considering cross-modal similarity in one common hamming space
without preserving local structures. (2) Cross-View Hashing
(CVH) [5] extends spectral hashing to cross-modal hashing
via CCA (Canonical Correlation Analysis) in one common
hamming space. (3) Linear Cross-Modal Hashing (LCMH)
[16] propose a cross-modal hashing using different anchor
graphs, while preserving both intra-and-inter modal similarity in one common hamming space.

4.2

(b)

5.

CONCLUSIONS

In this paper, we propose a novel technique by learning
distinct hamming space so as to well preserve the flexible
and discriminative local structure of each modality. Based
on that, a bridging mapping is learned to seamlessly connect these individual hamming spaces for cross-modal hashing. Extensive experimental results over real-world datasets
demonstrate the effectiveness and efficiency of our method.
Acknowledgements. Xuemin Lin is supported by
NSFC61232006, ARC DP120104168, ARC DP140103578,
and ARC DP150102728. Wenjie Zhang is supported by ARC
DP150103071 and ARC DP150102728.

Performance Comparison
6.

(a) 32 bits

(b) 64 bits

(c) 32 bits

(d) 64 bits

REFERENCES

[1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. In
NIPS, 2001.
[2] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University
Press, 2004.
[3] M. Bronstein, A. Bronstein, F. Michel, and N. Paragios. Data fusion
through cross-modality metric learning using similarity-sensitive hashing.
In CVPR, 2010.
[4] H. Hotelling. Relations between two sets of variables. Biometrika,
28(3/4):321–377, 1936.
[5] S. Kumar and R. Udupa. Learning hash functions for cross-view similarity
search. In IJCAI, 2011.
[6] W. Liu, J. Wang, S. Kumar, and S. Chang. Hashing with graphs. In ICML,
2011.
[7] Y. Wang, M. A. Cheema, X. Lin, and Q. Zhang. Multi-manifold ranking:
Using multiple features for better image retrieval. In PAKDD, 2013.
[8] Y. Wang, X. Lin, L. Wu, Q. Zhang, and W. Zhang. Shifting
multi-hypergraphs via collaborative probabilistic voting. Knowledge and
Information Systems, DOI 10.1007/s10115-015-0833-8.
[9] Y. Wang, X. Lin, L. Wu, W. Zhang, and Q. Zhang. Exploiting correlation
consensus: Towards subspace clustering for multi-modal data. In ACM
Multimedia, 2014.
[10] Y. Wang, X. Lin, and Q. Zhang. Towards metric fusion on multi-view data:
a cross-view based graph random walk approach. In ACM CIKM, 2013.
[11] Y. Wang, X. Lin, Q. Zhang, and L. Wu. Shifting hypergraphs by
probabilistic voting. In PAKDD, 2014.
[12] Y. Wang, J. Pei, X. Lin, Q. Zhang, and W. Zhang. An iterative fusion
approach to graph-based semi-supervised learning from multiple views. In
PAKDD, 2014.
[13] Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In NIPS, 2008.
[14] L. Wu, Y. Wang, and J. Shepherd. Efficient image and tag co-ranking: a
bregman divergence optimization method. In ACM Multimedia, 2013.
[15] D. Zhai, H. Chang, Y. Zhen, X. Liu, X. Chen, and W. Gao. Parametric
local multimodal hashing for cross-view similarity search. In IJCAI, 2013.
[16] X. Zhu, Z. Huang, H. T. Shen, and X. Zhao. Linear cross-modal hashing
for efficient multimedia search. In ACM Multimedia, 2013.

Figure 2:

Precision-recall curve on Wiki dataset
((a),(b)) and NUS-WIDE dataset ((c),(d)) over searching text modality via image query and searching image
modality via text query.

Results on NUS-WIDE Dataset. We show the result
of two tasks on NUS-WIDE in Fig.2 (c)-(d). Obviously,

1002


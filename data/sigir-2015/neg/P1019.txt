When Personalization Meets Conformity: Collective
Similarity based Multi-Domain Recommendation
Xi Zhang1 , Jian Cheng1 , Shuang Qiu1 , Zhenfeng Zhu2 , Hanqing Lu1
1

National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences
2
Institute of information Science, Beijing Jiaotong University

{xi.zhang, jcheng, shuang.qiu, luhq}@nlpr.ia.ac.cn, zhfzhu@bjtu.edu.cn
ABSTRACT

ilarity. Namely, users with common interests in the past
would behave much more similarly on items in the future.
Traditionally, CF approaches regard mining distinct types
of user behavior as a task within a single domain. Nevertheless, in many real applications, multiple behaviors ranging
from reading books, favoring music, to watching videos can
reﬂect the characteristics of users together, and thus training a group of predictors in a uniﬁed manner would enhance
accuracy for all the domains.
To cope with multi-domain recommendation, a straightforward scheme is to extend the CF algorithms into a multitask learning problem solved by propagating similarities among domains [4, 2]. However, somewhat surprisingly, the
context of multi-domain often introduces conformity 1 to online user behaviors, which cannot be ignored. In particular,
the public are inclined to conform to the choices or beliefs of domain authorities [6]. For example, comments from
well-known movie critics would be likely to aﬀect the trend
of box oﬃces while reading lists of celebrated writers would
probably receive admiration. That is to say, compared with
ordinary users, opinions of these domain elites are more representative and thus have considerable inﬂuence on recommendation results. Unfortunately, this eﬀect has not been
fully exploited in existing multi-domain approaches.
The key problem becomes how to detect the domain authorities and integrate the conformity eﬀect into recommendation. To simplify this problem, we concern that the elites
are users whose past behaviors can largely reﬂect the public tastes. In fact, if a user has signiﬁcant similar behaviors
to a large number of other users, she/he is probably the
elite user who can represent others. To this end, a domainspeciﬁc user similarity matrix based on observed behaviors
is built to embody conformity. On the other hand, since
users’ intrinsic preferences over domains are also decisive,
a domain-shared user similarity matrix is utilized to proﬁle
users globally. Therefore, a collective similarity combining
the eﬀect of conformity with the original personalization is
established.
In this paper, we propose a Collective Structured Sparse
Representation(CSSR) method to optimize the collective similarity for a top-N multi-domain recommendation task. The
CSSR is on the basis of the adaptive k-Nearest-Neighbor
framework. To learn ranked item lists under each domain
for users, a least square regression loss of feedback representation is employed. To encode personalization and confor-

Existing recommender systems place emphasis on personalization to achieve promising accuracy. However, in the
context of multiple domain, users are likely to seek the same
behaviors as domain authorities. This conformity eﬀect provides a wealth of prior knowledge when it comes to multidomain recommendation, but has not been fully exploited.
In particular, users whose behaviors are signiﬁcant similar
with the public tastes can be viewed as domain authorities. To detect these users meanwhile embed conformity
into recommendation, a domain-speciﬁc similarity matrix is
intuitively employed. Therefore, a collective similarity is obtained to leverage the conformity with personalization. In
this paper, we establish a Collective Structure Sparse Representation(CSSR) method for multi-domain recommendation. Based on adaptive k-Nearest-Neighbor framework, we
impose the lasso and group lasso penalties as well as least
square loss to jointly optimize the collective similarity. Experimental results on real-world data conﬁrm the eﬀectiveness of the proposed method.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information
Filtering

Keywords
Multiple Domains; Recommendation; Conformity

1. INTRODUCTION
The fast growth of Web 2.0 technologies facilitates and
encourages various online user behaviors, meanwhile brings
tremendous information to the public. Personalized recommendation, as critical methods to push the right information
to the right users, have attracted large amounts of research
in both industry and academia. Among these methods, Collaborative Filtering(CF) has superior performance than other methods via an underlying assumption about entity simPermission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
⃝
DOI: http://dx.doi.org/10.1145/2766462.2767810.

1

The general conformity is a social phenomenon of matching
attitudes, beliefs, and behaviors to group norm. Here we
narrow the concept to achieving same behaviors as elites.

1019

Domain-Shared
Similarity

mity, regularization with lasso and group lasso are adopted.
Also, we show how to use the Alternating Direction Method
of Multipliers(ADMM) [1] to eﬃciently optimize the parameters. Experiments show that our method consistently
achieves more accurate results than other state-of-the-arts.

Least Squares Regression Loss

+

´

»

2. THE PROPOSED APPROACH

Feedbacks Matrices

Suppose that there are a set of users U = {u1 , · · · , un } and
D types of domains. Let the matrix Xd ∈ Rmd ×n record the
interactions between the overall user set and item set Vd for
the d-th domain, where d = 1, · · · , D and md is the size of
the item set. Then if a user has any behavior on item, the
element entry of Xd could be 1 or a positive value, otherwise
the entry is set as 0. Note that implicit feedback such as
clicks, purchases and posts are easier to obtain than rating
records in real-world scenarios. Thus we assume that the
multiple feedback matrices are binary.
For a multiple domain recommendation, given a series of
user-item feedback matrices {X1 , · · · , XD }, our goal is to
recommend a personalized ranking list of the potential enjoyed items under each domain for users.
Here we introduce a general similarity based framework
for recommendation without multi-domain. Normally, preference scores are estimated by a function of f (X, Θ), where
X is the feedback matrix and Θ is the model parameter.
The adaptive k-Nearest-Neighbor(kNN) method, which is
very popular for collaborative ﬁltering, has been shown its
simpleness but eﬀectiveness in top-N recommendation [3].
We establish our model based on the adaptive kNN technique in this paper. Consider a user based kNN problem,
the parameter Θ is set as matrix W ∈ Rn×n , and the prediction function f (·) could be presented as an aggregation of
the feedback values of k nearest neighbors. Mathematically, x
bij = xTi wj , where x
bij is the predicted scores, xi ∈ Rn
denotes the feedback indicator of item vi , and wj ∈ Rn denotes a similarity coeﬃcients of user uj . The parameter W
can be regarded as the similarity between user pairs, which
can be optimized by the following problem
W

Xd

Xd

2.1 Notation and Background

f = arg min L(W) + Ω(W)
W

Lasso
Regularization

V

Group Lasso
Regularization

Vd

Wd
Collective Similarity

Domain-Specific
Similarity

Figure 1: Illustration of the CSSR Model
representative elite users and others tend to be signiﬁcant.
Hence, we propose a collective similarity as
Wd = V + Vd

(2)

where d = 1, · · · , D. Parameter matrix V ∈ Rn×n indicates the personalized neighbors with intrinsic similar interest across domains, which is a domain-shared component.
Parameter matrix Vd ∈ Rn×n embodies the representative
of elite neighbors in the domain, which is a domain-speciﬁc
component.
Next, we seek to explore the conformity by regularizing
the structure of the parameter set {V1 , · · · , VD } with group
lasso. On the one hand, the domain-speciﬁc elite users can
largely represent other users, which results in more dense for
the corresponding rows in Vd . On the other hand, the fact
that elite users are always the minority leads to the sparsity
in columns. Hence, the above structure serves to deﬁne a
group lasso regularization term
Ωglas (Vd ) = βd ∥Vd ∥2,1 =

n
∑

βd ∥vdi ∥2

(3)

i=1

where ∥vdi ∥2 is the ℓ2 -norm for each row of Vd . ℓ2,1 -norm
encourages the row sparsity with jointly selecting the signiﬁcant rows as elite users. βd encodes the contributions of
group lasso for each domain. Without loss of generality, we
assume ∀d, βd = β.
Furthermore, users’ personalized neighbors are also sparse
in the overall user set. A lasso constraint is utilized to ﬁlter
out noised coeﬃcients in V, which is

(1)

where L is a loss function usually deﬁned as least squares
or logistic regression, and Ω is a regularization penalty to
enforce parameter with speciﬁc structures. Ridge, lasso, or
elastic net regularization has been used in previous methods.

Ωlas (V) = λ∥V∥1 =

n ∑
n
∑

λ|vij |

(4)

i=1 j=1

With above discussion, the collective similarity can be incorporated into a loss function with a least square loss as
L(Wd ) = 12 ∥Xd − Xd Wd ∥2F . Following the general framework in Eq. (1), we propose a CSSR model for adaptive kNN
problem in multiple domains as

2.2 Collective Similarity
Now we consider the problem of multi-domain recommendation. As the user set is common across domains, the user
based similarity is exploited. The interpretation behind the
idea is simple. That is, to learn a set of nearest neighbors who are suﬃciently similar with the user in terms of
multiple behaviors over domains. In other words, a user’s
interests can be represented by the set of her/his neighbors.
The usual approach assumes that all users are ordinary with
the comparative ability of representation and thus the personalized neighbors are mined for each users independently. Nevertheless, conformity always occurs in the context of
multi-domain. Under a speciﬁc domain, elite users’ favorites
are more acceptable to the public during recommendation.
This indicates that the similarity coeﬃcients between these

min
Θ

D
∑

αd (L(Wd ) + Ωglas (Vd )) + Ωlas (V)

d=1

s.t.Wd = V + Vd , Wd ≥ 0, diag(Wd ) = 0
∀d,

(5)

d = 1, · · · , D

The parameter set Θ is written as {Wd , Vd , V} for succinct. And αd balances the eﬀect of diﬀerent domain. In
addition, the non-negative constraint is used on similarity
for a more interpretable consideration, while diag(Wd ) = 0
ensures that the trivial solution of identity matrix is avoided. From the uniﬁed objective function, information of feed-

1020

where i is the row index of parameter matrices. Let zid =
wdi − vi + uid . This problem can be solved by a proximal
operator of group lasso to each row vector as

back matrices can be transferred among domains by V and
distinctions can be captured by Vd . The entire model is
depicted in Figure 1.

2.3 Optimization

vdi = Sglas, β (zid ) =

Although non-smooth terms are introduced, our approach
maintains convexity of the objective function. We propose
to apply the ADMM [1] to split the original problem into
several subproblems which can be handled in alternating
directions.
To solve the problem in Eq. (5), we ﬁrst obtain the augmented Lagrangian as
min

D
∑

Θ,Yd

ρ



∥zid ∥2 − β
ρ
∥zid ∥2

if ∥zid ∥2 ≤
zid ,

β
ρ

otherwise.

(12)

Update for V. Optimizing the second term ∑
with respect
D
1
to V in Eq.(7c) equals to optimizing ρ2 ∥V − D
d=1 (Wd −
2
Vd + Ud )∥F which can be substituted into Eq.(7c). Then
we have the element-wise optimal solution as
[
[V]ij = Slas, λ

(
)
αd L(Wd ) + I+ (Wd ) + Ωglas (Vd ) + Ωlas (V)

ρ

] 
D
∑
1

(Wd − Vd + Ud ) 
D d=1

(13)

ij

d=1

+

D (
∑

tr(YdT (Wd − V − Vd )) +

d=1

where Slas,ε (·) is the soft-thresholding operator

)
ρ
∥Wd − V − Vd ∥2F
2
(6)



x − ε,
Slas,ε (x) = x + ε,

0,

where Yd is Lagrangian multiplier of the d-th domain, I+ (·)
is the indicator function for the non-negative constraint, and
ρ > 0 is a penalty parameter. For the given domain d,
optimizing {Wd , Vd , Yd } are independent with optimizing
the set of variables in other domains, thus ADMM proceeds
by solving following problems alternately until convergence
ρ
∥Wd − V − Vd + Ud ∥2F
2
ρ
min αd Ωglas (Vd ) + ∥Wd − V − Vd + Ud ∥2F
Vd
2
min αd L(Wd ) +

min Ωlas (V) +
V

3.

(7c)

d=1

Ud = Ud + W d − V − Vd

(7d)

where Ud = ρ1 Yd leads to a scaled form. Then we provide closed-form solutions of the subproblems for Eq.(7a),
Eq.(7b) and Eq.(7c) as below.
Update for Wd . We ﬁrst rewrite the problem into an
unconstrained problem as
min αd L(Wd ) +
Wd

For personalized item recommendation, we analyze performance of the model by comparing the top suggestions to the
true behaviors taken by a user. We adopt two widely used
evaluation metrics in top-N recommendation: MAP(Mean
Average Precision), NDCG(Normalized Discounted Cumulative Gain) with the setting N = 5. Higher values on the
metrics imply better recommendation results.
We compare the proposed CSSR with several popular
baseline methods: PopRank, NCDCF U, NCDCF I [5], mrBPR [2], mrSLIM. Here we extend SLIM [3] to mrSLIM by
constructing a feedback matrix that takes all items in three
domains as rows. For a comprehensive comparison, performances of CSSRsh and CSSRsp are shown. They merely
consider the domain-shared or domain-speciﬁc similarity in
Eq. (2), and utilize lasso constrains.
In our experiments, we randomly pick 80% observed feedbacks for each user to form the training set in each domain
and the rest of 20% is test set. The random sampling is
repeated 10 times and the average performance are reported. We set the weights combination of domains in CSSR as

Since Eq.(7a) is smooth, the solution can be found by taking
its derivative and set it to be zero
)
T
XT
d Xd + ρI Wd + ρ(Ud − V − Vd ) − Xd Xd − Φd = 0 (9)

Using the Karush-Kuhn-Tucker complementary condition
for the nonnegativity of Wd , [Φd ]ij [Wd ]ij = 0, we get
[Wd ]ij = [Wd ]ij

[

−
XT
d Xd + ρ(Ud − V − Vd )

]
ij

+
(XT
d Xd + ρI)Wd + ρ(Ud − V − Vd )

]
ij

(10)

To guarantee the nonnegativity, we decompose matrices with
any signs as A = A+ − A− , where A+
ij = (|Aij | + Aij )/2
and A−
ij = (|Aij | − Aij )/2.
Update for Vd . For each row of Vd , the optimization
problem in Eq.(7b) comes to
min β∥vdi ∥2 +
i
vd

ρ i
∥v − (wdi − vi + uid )∥22
2 d

Experiment Settings

Table 1: Description of Douban Dataset
Domain #Items %Sparsity #Ratings per User
Book
14,155
99.85
22
Music
99.75
38
15,492
Movie
7,845
98.87
88

ρ
∥Wd − V − Vd + Ud ∥2F − tr(ΦT
d Wd ) (8)
2

v
u
u
t[

(14)

To empirically study the eﬀectiveness of our method, we
perform experiments on a multi-domain dataset crawled from
the publicly available site Douban2 . It is a famous Web2.0
website containing rating behavior of users, scaled from 1
to 5 stars, on books, music and movies. As we face with a
top-N recommendation task, we use the implicit feedback
instead of rating scores. For a suﬃcient evaluation of each
user, we ﬁltering out users with less than 10 feedbacks on
the three domains and obtained a dataset of 5, 916 users.
The detailed description is presented in Table 1.

(7b)

D
ρ∑
∥Wd − V − Vd + Ud ∥2F
2

if x > ε
if x < −ε
otherwise.

EXPERIMENTS

3.1

(7a)

Wd ≥0

(


0,

(11)

2

1021

http://www.douban.com

Table 2: Prediction performance(mean ± std.) of three variants of CSSR and PopRank, NCDCF U, NCDCF I, mrSLIM, mrBPR on three domains of Douban dataset. Results in bold indicate the best ones.

5
0.01

N/A
100
50
0.1
1e-3

Book
MAP
NDCG
0.1370±0.0039
0.0619±0.0014
0.1826±0.0033
0.0813±0.0013
0.1864±0.0029
0.0835±0.0011
0.2014±0.0035
0.0906±0.0013
0.2333±0.0035
0.1071±0.0019

0.5

0.01
0.01
0.01

0.2217±0.0023
0.2348±0.0041
0.2746±0.0032

Methods

Params

PopRank
NCDCF U
NCDCF I
mrSLIM
mrBPR
CSSRsh
CSSRsp
CSSR

0.1013±0.0010
0.1070±0.0019
0.1241±0.0013

Music
MAP
NDCG
0.1879±0.0029
0.0922±0.0014
0.2647±0.0035
0.1325±0.0015
0.2668±0.0016
0.1341±0.0007
0.2861±0.0028
0.1453±0.0022
0.3180±0.0037
0.1554±0.0021

Movie
MAP
NDCG
0.3784±0.0031
0.2249±0.0017
0.4982±0.0038
0.3159±0.0024
0.5049±0.0047
0.3230±0.0027
0.5115±0.0040
0.3241±0.0023
0.5206±0.0039
0.3377±0.0025

0.2949±0.0028
0.3020±0.0046
0.3345±0.0037

0.4952±0.0055
0.5052±0.0029
0.5341±0.0030

0.1453±0.0011
0.1539±0.0022
0.1703±0.0014

0.3106±0.0026
0.3241±0.0020
0.3471±0.0015

0.54

s show that they obtain improvement on Book and Music
domains but fail to outperform previous methods in Movie
domain. Integrating diﬀerent aspect of the two variants, our
method yields the best performance in multiple domains.
Finally, to understand the inﬂuence of regularization terms,
we analyze the performance variations with respect to λ and
β. As illustrated in Fig.2, by ﬁxing α, the performance ﬁrst
increases when β gets larger. This veriﬁes our conformity
assumption that some users are representative and could be
detected by enforcing a group lasso structure. But overwhelmingly large β would cause information loss in domains
and result in the accuracy declining. By ﬁxing β, we can
see that the α is less sensitive. Another interesting observation is when β is improperly large(β = 10), decreasing
α can upgrade results to some extent. This indicates some
missing information of domain-speciﬁc component could be
compensated by domain-shared component.

0.28

0.53

0.34
0.26

0.52

0.33

0.51

0.22

0.16

0.31

0.5
0.49

0.3

0.2

0.18

MAP

0.32

MAP

MAP

0.24

0.48
b=0.05
b=0.1
b=0.5
b=1
b=10
1e-3

0.29
0.28

0.01

0.1

1

10

0.27

b=0.05
b=0.1
b=0.5
b=1
b=10
1e-3

0.47
0.46

0.01

0.1

1

10

0.45

b=0.05
b=0.1
b=0.5
b=1
b=10
1e-3

0.01

0.1

l

l

l

Book

Music

Movie

1

10

Figure 2: Performance variation of CSSR with respect to β and λ on three domains.
{α1 = 0.2, α2 = 0.3, α3 = 0.5} based on the MAP performance on the test set. The impact of group lasso parameter
β and lasso parameter λ will be further studied.

3.2 Results and Analysis
Experimental results of above baselines and three variants
of the proposed CSSR are shown in Table 2. The optimal parameters we obtained for CSSR are β = 0.5, λ = 0.01. From
Table 2 we observed that, our full model CSSR consistently outperforms all the other baselines. Speciﬁcally, for the
reason that PopRank is not a personalized algorithm and
only recommends items based on their popularity, all other
baselines can beat it. This proves the importance of personalization in recommender systems. By comparing the results
along with three domains, we discover that recommending
movies is a relatively easier task as all the approaches except
PopRank perform well on this domain. Thereby, transferring knowledge from movie domain would beneﬁt the other two tasks. Lacking of a properly designed mechanism
for multi-task learning, NCDCF U and NCDCF I (with the
number of nearest neighbors k = 100 and k = 50) cannot
achieve satisfying results in book and music domains. We
implement mrSLIM by setting the weights of elastic net as
β = 5 and λ = 0.1 to ﬁnd an optimal performance. With the
learned item similarity matrix, mrSLIM behaves better than
its simple version NCDCF I. Moveover, CSSR surpasses the
state-of-the-art ranking method mrBPR with the learning
rate as 0.01 and the weights of ℓ2 -norm as 1e − 3. mrBPR
focuses on studying the domain consistency to model a sharing component, but ignores the heterogeneous part which
might be diﬀerent in domains, in particular, conformity.
To evaluate the eﬀectiveness of collective similarity, we
compare the three variants of CSSR. CSSRsh and CSSRsp
encode consistency and heterogeneous among domains under
the adaptive kNN settings, separately. However, the result-

4.

CONCLUSIONS

In this paper, we propose a novel CSSR method for multidomain recommendation, which integrates personalization
with conformity eﬀect to construct a collective similarity
parameter. By applying the least square loss, ranking scores
can be predicted by the optimized neighbors. To model the
diﬀerent kind of neighbors, lasso and group lasso constraints
are used. Experiments on multi-domain dataset show our
method outperforms baselines for top-N recommendation.

5.

REFERENCES

[1] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein.
Distributed optimization and statistical learning via the
alternating direction method of multipliers. Found. Trends
Mach. Learn., 2011.
[2] A. Krohn-Grimberghe, L. Drumond, C. Freudenthaler, and
L. Schmidt-Thieme. Multi-relational matrix factorization
using bayesian personalized ranking for social network data.
In WSDM, 2012.
[3] X. Ning and G. Karypis. SLIM: Sparse linear models for
top-n recommender systems. In ICDM, 2011.
[4] A. P. Singh and G. J. Gordon. Relational learning via
collective matrix factorization. In KDD, 2008.
[5] T. Yuan, J. Cheng, X. Zhang, S. Qiu, and H. Lu.
Recommendation by mining multiple user behaviors with
group sparsity. In AAAI, 2014.
[6] X. Zhang, J. Cheng, T. Yuan, B. Niu, and H. Lu. Toprec:
domain-speciﬁc recommendation through community topic
mining in social network. 2013.

1022


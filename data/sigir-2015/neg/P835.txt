About the ‘Compromised Information Need’ and Optimal
Interaction as Quality Measure for Search Interfaces
Eduard Hoenkamp
Queensland University of Technology (QUT), Brisbane, Australia
Radboud University, Nijmegen, the Netherlands

hoenkamp@acm.org
“We have become the tool of our tools”
— Henry David Thoreau

ABSTRACT
Taylor’s concept of levels of information need [16] has been
cited in over a hundred IR publications since his work was
first published. It concerns the phases a searcher goes through,
starting with the feeling that information seems missing, to
expressing a query to the system that hopefully will provide
that information. As every year more IR publications reference Taylor’s work, but none of these so much as attempt
to formalize the concept they use, it is doubtful that the
term is always used with the same connotation. Hence we
propose a formal definition of levels of information need, as
especially in IR with its formal underpinnings, there is no
excuse to leave frequently used terms undefined.
We cast Taylor’s informally defined levels of information
need — and the transitions between them — as an evolving
dynamical system subsuming two subsystems: the searcher
and the search engine. This moves the focus from optimizing the search engine to optimizing the search interface. We
define the quality of an interface by how much users need
to compromise in order to fill their information need. We
show how a theoretical optimum can be calculated that assumes the least compromise from the user. This optimum
can be used to establish a base-line for measuring how much
a search interface deviates from the ideal, given actual search
behavior, and by the same token offers a measure of comparison among competing interfaces.

1.

INTRODUCTION

Over the years, much work in information retrieval (IR)
has focused on improving effectiveness and efficiency of search
algorithms, notably encouraged by the TREC program and
nourished by the SIGIR conferences. Early in the history of
IR, however, several researchers emphasized that the function of IR systems is first and foremost, to quote Belkin
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’15, August 09 - 13, 2015, Santiago, Chile.
c 2015 ACM. ISBN 978-1-4503-3621-5/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2766462.2767800.

835

[3] “...to help people solve problems, rather than directly to
solve problems posed to them” (p. 42). This led to experiments aimed at helping searchers formulate their questions,
such as suggesting suitable keywords [4], prompting them
to be more talkative [14], or comparing the effects of written versus spoken queries [8]. The general finding is that if
searchers could express their information need more in the
way they would talk to a fellow-human, and in particular in
everyday language, then this would benefit both the search
results and the user satisfaction [12]. IR researchers recognized that the searcher’s struggle to formulate a query has an
obvious analog in a person browsing a library with only an
approximate idea of the information needed. However, the
librarian can assist a searcher with considerable more verve
than we can expect from today’s search interfaces. And thus
the librarian as shining role model for future search interfaces explains the growing IR interest in the process of query
formation. The latter process has been exemplary described
in Taylor’s [16] “The process of asking questions” which can
be summarized with a direct quote from his abstract:
Four levels of question formation may be isolated and
analyzed: the actual, but unexpressed, need for information; the conscious within-brain description of the
need; the formal statement of the question; and the
question as presented to the information system (p. 391).
In his article the word ‘information’ in information retrieval
denotes tangible things such as books, reports, and drawings, rather than information per se. In the case of IR we
can take the images on a computer screen as perfect proxies
for those books, reports etc. (printed on paper if necessary).
And the analogy goes further. One could argue that in recents years IR has reached a phase of diminishing returns
[11], as more and more effort is needed to achieve only a
slight improvement in search performance. So further improvement can only be expected from improving the query,
moving the onus from search engine back to the searcher.
This is the point of Belkin’s remark in the beginning of
this section. That, in other words, means that IR should
not be about getting the right answer, but about asking
the right question. In the library context this is where the
librarian steps in. This lead Taylor to write a follow-up article on question-negotiation for librarians [17]. In practice,
though, IR researchers are still trying to push this part into
the search engine, as we are about to see. Yet, it would be
careless to write off Taylor’s work as old hat, since bibliometric analysis shows [7] that the number of references to
his approach increases each year, with IR notably occupying
most of those references.

2.

‘INFORMATION NEED’ AND ‘INTENT’

• Finally, if humans can not infer the intent from a
fellow-human’s query, how much hope is there that a
search engine can achieve this feat?

In Information Retrieval (IR) the term information need
is ubiquitous, important, and intuitively clear. Surprisingly,
attempts to formally define the notion are all but nonexistent [10]. Publications that tried a philosophical or sociological approach toward a definition got stuck in their attempts
to cover everything that the term might connote. The last
decade, following Broder’s work [6] a movement is afoot to
study the related notion of ‘intent’ instead. The suggestion is that if a search engine could infer the intent of the
searcher, it would be better equipped to provide an optimal
answer. There are, however, several issues with studying
‘intent’ in isolation:

The last point is bad news for search algorithms, obviously.
The tension is located in the transition from Taylor’s third
level to his fourth level. That is, from the formalized need
which is the searcher’s expression of the information need
that he hopes the system will answer, to the compromised
need, which is the question asked in a way that the he thinks
the system can answer (i.e. in a compromise to the system).
This to us seems the main issue with the intent studies: they
attempt to distill the third level from the fourth level. We
are aware of many proposals to relax the compromise demanded from the user, such as making the interface more
like a conversation between two humans [1, 12]. But in light
of [18] it would be moot to try to push the envelope of studies of questionable validity. Instead, and at the same time
to obviate the issues with defining ‘intent,’ we undertake a
formalization of Taylor’s levels of information need and we
shift attention from ranking the search engine to ranking the
interface. For this reason we need to dedicate a substantial
part of this paper to the informal rendering.

• Early publications that studied ‘intent’ per se, sometimes lead to philosophical essays about all that could
be understood by the term, but not applicable, formalizable, or amenable to empirical investigation.
• Conversely, pressed for an operational definition, as in
patent applications, usually just one aspect of intent
is selected and worked out (e.g. [15]).
• In dozens of experimental studies where intent was assessed on the basis of queries, the results were reliable
but not valid [18].

3.

The latter has serious consequences for the study of intent
as a road to improve search, as we will see in a moment.

2.1

QUERY AND SEARCH RESULT
AS MEASUREMENTS

Taylor’s informal definitions are rather verbose, so we extract the parts that are essential for our formalization. To
formalize the different levels, we found the terminology from
quantum mechanics (QM) most convenient. Hopefully this
will not deter the reader, as the terminology fits like a glove,
as we will see. (So keep in mind that we do not want to describe a physical system let alone a Schrödinger equation.)
At the first level (the visceral need ) we find:

Reliability v. validity in appraising intent

About a century ago, it was common to assess a person’s
intelligence by measuring size and form of the skull. These
measurements were extremely reliable: Someone who measured a second time would get the same answer, and someone else making the same measurement would get about the
same answer as well. Yet, as Binet [5] showed at the time,
these measurements had little to do with the ‘intelligence’ it
was supposed to measure. Binet then introduced what became known as the Stanford-Binet test, which until today
is considered a valid measurement, i.e. one that actually
measures what it is supposed to measure (intelligence). Applying this distinction to the IR studies, it turns out that
in the dozens of publications, the assessors of the query intent were different from the searcher who formulated the
query. So, as with the studies of intelligence: even if the
measurements were reliable, were they actually measuring
the searcher’s intent? To answer this question we carried
out a careful meta-study of intent assessment: We recorded
the interaction with a search engine from the participant’s
formulation of a query, the subsequent interaction with the
search interface, and ending with the instruction to formulate the original intent. Afterwards the query and the interaction were presented to external assessors who were to
guess the intent. What we found was a substantial discrepancy between the two [18]. That is, the measurements we
found in the dozens of publications we studied, even if they
were reliable, are not necessarily valid. It follows that:

...the conscious and unconscious need for information
not existing in the remembered experience of the investigator [...] It may be only a vague sort of dissatisfaction
[...] which would bring from the ideal system exactly
what the inquirer needed, if he could state his need (p.
392).
Belkin [3] refers to this level as the anomalous state of knowledge. The correlate of the first level is the observable in QM,
a superposition of states, in this case of mental states. The
searcher is sitting and waiting for a query to come to the
fore, no definite (mental) state exists at that time. After
the searcher becomes aware of this, the first attempt at consciously describing what is missing arrives. This is what
Taylor calls the second level (the conscious need ):
the conscious mental description of an ill-defined area of
indecision [...] He qualifies his area of doubt by various
oral and physical means.
This is the correlate of a measurement in quantum mechanics. Next comes the third level (the conscious need ) at which
the searcher forms:
...a rational and unambiguous description of his doubts.
This question is what we like to believe the information
system answers. It may not be, however, and probably
is not, the question asked of the system.

• The word ‘intent’ may have different meanings in different publications,
• A score of publications may have studied something
other than the searcher’s intent, and therefore their
advice about dealing with intent becomes dubious,

This unambiguous description is the outcome of a measurement. In QM terminology: through the measurement the

836

observable collapses into a query Q. The searcher could
have come up with another query, assuming it is not a deterministic event but a probability distribution over queries
p(Q). Finally level four (the compromised need ):

that during that time the operators do not commute,
and so ‘joint probability’ has no meaning),
The first two cases are easy, so onwards with the last one:
two systems, Q and R, that have some interaction. In
the case of classical mechanics (commuting operators) we
could consider a joint probability p(Q, R), from which the
marginal distributions can be computed. But the converse
is not true: for a pair of marginals, many joint probabilities
could give rise to these marginals. So suppose one samples
distributions from the searcher and the search engine, Is
there a joint distribution given the marginals that deserves
a special place? The next section will point out that special
place.

The question is recast in anticipation of what the inquirer thinks he will get out of the system.
The searcher has made a compromise here, instead of his
original query (the measurement) he expresses a query that
he thinks the search engine is able to answer. In today’s
search technology, instead of using everyday language as he
would do to another human, he uses the well-known terse
query of two to three keywords. Only now the interaction
with the search engine begins. We consider the state of the
search engine as a second observable. Presumably there is a
deterministic process underlying the search engine. But the
links in it are updated, deleted, or created, in a way that for
all intents and purposes is as opaque to us as the superposition of mental states that gave rise to a query. The first
measurement, the query Q, is presented to the search engine,
resulting in a set of documents R, which is a second measurement (a measurement of the search engine), governed
by distribution p(R). We are now ready to describe how the
back and forth of the measurements can be described as the
dynamics of the information need.

4.

5.

THE OPTIMAL SEARCH INTERFACE

The foregoing may remind the reader of approaches to
compute the cost of searching, such as Azzopardi’s using
economic principles [2]. These can be used to explore optimal search strategies given a search interface. Here we
explore the opposite however, optimality of interfaces given
search behavior. It addresses the compromised information
need: given a choice of interfaces, which one requires the
fewest compromises? The less searchers have to compromise
to the technology, the less interaction they need to amend
their query (in level 3) when the technology gets in the way.
Suppose we can avail ourselves to a joint probability interaction between searcher and search engine, such as click
traces or interactions accumulated from a number of users.
A joint probability distribution can then be derived by sampling queries and search engine results. How can we, given
the joint probabilities decide which one required the least interaction? Interestingly, this problem can be formally solved
as we will do in a moment. For the reader not familiar with
the mathematics in the next paragraph: what we derive is a
formal criterion for the optimality of search interfaces, based
on the interaction they demand from the user. More compromise requires more interaction to fulfill the information
need. Therefore, we propose to measure the quality of the
search interfaces by the amount of interaction they demand.
We are going to use a technique proposed by Jaynes [13]
for statistical mechanics. Let us choose the distribution closest to the independent case (1) above [9]. As there is no
weaker interaction than no interaction at all, this assumes
the weakest interaction among the candidate distributions.
In other words, we are looking for a distribution that is the
most difficult to distinguish from the independent case (by
the best test). So by definition of K-L divergence KL(·||·),
we need the joint probability with the smallest divergence
from the independent case. That is, we are looking for a
p(x, y) that minimizes

THE DYNAMICS OF AN INFORMATION
NEED

We continue to denote the query and search results as the
measurements Q and R with probability distributions p(Q)
and p(R). So far we could have abstained from the QM
terminology, as we have only used other names for undefined terms, e.g. by calling the visceral level an observable
and the query a measurement. If we were not going to use
the terms, this would only be window dressing. But we are
going to exploit the QM model by looking at the observables as (Hermitian) operators. And more importantly as
operators that do not commute. For this four page short
paper there is not enough space to work out the constraints
of how exactly the interaction between searcher and search
engine could proceed. For example, there can be no way in
which the searcher with just a feeling of missing information
would cause the search engine to behave in a particular way.
So what we will do is borrow from the insight of quantum
systems and ask the reader to bear with us in the formal
treatment. We may or may not presume an interaction between the two observables (the searcher and the search engine). And here is were we are going to use not just the QM
terminology but the QM model. In that model we have to
distinguish three cases:
1. Q and R belong to one system but they do not interact. That happens for example at the time when the
searcher formulates the query, before sending it to the
search engine. At that time, Q and R are independent processes, so their joint probability distribution
is simply p(Q, R) = p(Q) × p(R),

KL(Q||R) =

XX
Q

R

log p(x, y)

p(x, y)
p(x) · p(y)

constrained by what we know about p(Q) and p(R), such as
their moments
P and,
P since they are probabilities, also the condition that Q R p(x, y) = 1. This is a variational problem that can be solved using Langrange multipliers, yielding
−F (λ1 ,λ2 ,λ3 ,...)
the general form: p(Q, R) = e G(λ1 ,λ2 ,λ3 ,...) where the λi
are the Langrange multipliers to be found for the F and G.
For example if we would know
P the means ofPthe query and
search engine observables Q x · p(x) and P y · p(y), we

2. They belong to two different systems.
3. They belong to one system but they do interact. This
is a time of the back and forth between searcher and
search engine, and there is obviously no way to measure one component independent of the other. (Note

837

would have:
∇KL(Q||R) =

X

λ1 ∇x · p(x) +

Q

X

[2] L. Azzopardi. The economics in interactive
information retrieval. In Proceedings of SIGIR-11,
pages 15–24, New York, NY, USA, 2011. ACM.
[3] N. J. Belkin. Anomalous states of knowledge as a basis
for information retrieval. The Canadian Journal of
Information Science, 5:133–143, 1980.
[4] N. J. Belkin, P. Marchetti, and C. Cool. BRAQUE:
Design of an interface to support user interaction in
information retrieval. Information Processing and
Management, 29(3):325–344, 1993.
[5] A. Binet. The mind and the brain. London: Kegan
Paul, Trench, Trübner, 1907.
[6] A. Broder. A taxonomy of web search. SIGIR
FORUM, 36(2):3–10, 2002.
[7] Y.-W. Chang. The influence of taylors paper,
question-negotiation and information-seeking in
libraries. Information Processing and Management,
49(5):983 – 994, 2013.
[8] F. Crestani and H. Du. Written versus spoken queries:
A qualitative and quantitative comparative analysis.
JASIST, 57(7):881–890, 2006.
[9] S. Guiasu. Joint probability distribution of composite
quantum systems. International Journal of Theoretical
Physics, 26(1):11–20, 1987.
[10] E. Hoenkamp. On the notion of “an Information
Need”. In L. Azzopardi, G. Kazai, S. Robertson,
S. Ruger, M. Shokouhi, D. Song, and E. Yilmaz,
editors, Second International Conference on the
Theory of Information Retrieval, ICTIR 2009, pages
354–357, 2009.
[11] E. Hoenkamp. Taming the terabytes: a
human-centered approach to surviving the
information-deluge. In J. Strother, J. Ulijn, and
Z. Fazal, editors, Information Overload : A Challenge
to Professional Engineers and Technical
Communicators, IEEE PCS professional engineering
communication series, pages 147–170. John Wiley &
Sons, Ltd, Hoboken, New Jersey, November 2012.
[12] E. Hoenkamp and P. Bruza. How everyday language
can and will boost effective information retrieval.
JASIST doi: 10.1002/asi.23279.
[13] E. T. Jaynes. Information theory and statistical
mechanics. Phys. Rev., 106:620–630, May 1957.
[14] D. Kelly, V. D. Dollu, and X. Fu. The loquacious user:
a document-independent source of terms for query
expansion. In R. A. Baeza-Yates, N. Ziviani,
G. Marchionini, A. Moffat, and J. Tait, editors,
SIGIR, pages 457–464. ACM, 2005.
[15] F. Radlinski, M. Szummer, and N. Craswell. US
Patent No. 20110289063. Washington, DC: U.S.
Patent and Trademark Office., 2011.
[16] R. S. Taylor. The process of asking questions.
American Documentation, 13(4):391 – 396, 1962.
[17] R. S. Taylor. Question-negotiation and information
seeking in libraries. College and Research Libraries,
29(3):178–194, 1968.
[18] S. Verberne, M. van der Heijden, M. Hinne,
M. Sappelli, S. Koldijk, E. Hoenkamp, and W. Kraaij.
Reliability and validity of query intent assessments.
JASIST, 64(11):2224–2237, 2013.

λ1 ∇y · p(y)

R

with ∇ to abbreviate ∇x,y,λ1 , and analogous expressions
with λ2 if the variances were known (and λi ’s for each additional constraint).
This model is ready for experiments to see how viable
the technique is. This is imminent future work. Compare
the design of it to TREC experiments where different search
engines can be evaluated using a standardized corpus and
topics, and precision and recall as metrics. In this vein
we think of using one search engine and possibly similar
standardized information needs to experiment with different search interfaces. This allows marginals over the queries
to be computed and these can be compared to the marginals
found by the proposed minimal interaction marginal. The
interface nearest this minimum would then be counted as
the best interface.
Of course this will be no sinecure, as no experimental work
is. But the important message of this paper is: we now
have a formal way to rank search interfaces, just as for years
there has been wide consensus about how to rank search
algorithms.

6.

CONCLUSION AND FUTURE WORK

We showed how to formalize Taylor’s levels of information as a quantum system. It contains two interacting subsystems, with query and search results as measurements of
searcher and search engine. Presuming a quantum character, their statistical properties can be used to compute a
parsimonious candidate for the minimal interaction needed
to fulfill an information need during interaction.
Useful for future work are the manually constructed relevance data from the IR experiments of yesteryear. For example, the classical Cranfield paradigm provides correlations
between query and relevant documents, ρ(Q, R), that can be
added as Lagrange constraint. The results will then serve
as the base-line to compare the performance for different
search interfaces, ranked according to their K-L divergence
with the base-line.
Such work will tell if this is indeed a viable way to compare
interfaces. But even if we are not immediately successful in
applying this advice to IR, perhaps our operational definition of quality as optimal interaction may lead the way to
investigate the necessity of evaluating search interfaces, in
line with of Taylor’s advice [16] that summarizes this goal:
These areas of ignorance require discussion, experimentation, and analysis, not only for better design, but also
to make the information system an effective and continuous element in the research process. The approach
to such a Utopia will come only when we recognize that
the inquirer is an integral part of the information system
and not a stranger knocking at the door for directions
(p. 396).

7.

REFERENCES

[1] J. Allan, W. B. Croft, A. Moffat, and M. Sanderson.
Frontiers, challenges, and opportunities for
information retrieval. SIGIR Forum, 46(1):2–32, June
2012.

838


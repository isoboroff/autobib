VenueMusic: A Venue-Aware Music Recommender System
Zhiyong Cheng

Jialie Shen

School of Information Systems
Singapore Management University
Singapore, 178902

School of Information Systems
Singapore Management University
Singapore, 178902

zy.cheng.2011@smu.edu.sg

jlshen@smu.edu.sg

ABSTRACT
Users’ music preferences can be greatly influenced by their
location and environment nearby. In this demonstration,
we present an intelligent music recommender system, called
VenueMusic, to automatically identify suitable music for
various popular venues in our daily lives. VenueMusic enjoys
a set of nice features: i) music concept sequence generation
scheme and Location-aware Topic Model (LTM) are proposed to map the characteristics of venues and music into a
latent semantic space, where suitability of music for a venue
can be directly measured, ii) a smart interface enabling user
to smoothly interact with VenueMusic, and iii) high quality
music playlist. The demonstration will show several interesting use-cases of VenueMusic, and illustrate its superiority
on recommending music based on where user presents.

Concept-labeled
Music Collection

Concept
Sequence
Generation

Music Concept
Detection

Venue Topic
Distributions

Mobile Device

Venue Relevance
Matching

Train

Venue Topics

Playlist

Loc ation-Aware
Topic Model

Song Topics
Song Topic
Distributions

Music Dataset

VenueMusic Server

Figure 1: System architecture.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Query formulation, Search process; H.5.5 [Sound and Music Computing]: Systems

Keywords
Music Recommendation, Context-Aware, Topic Model

1.

Venue-labeled
Music Collection

INTRODUCTION

Mobile devices have increasingly become significant mediums for enjoying music anywhere and anytime. It is well
known that users’ music preferences can be greatly influenced by where they are and surrounding environment. Therefore, how to leverage venue related information is a key issue towards effective location based music recommendation.
Different venues usually have different atmosphere and ambience. Accordingly, different music contents are suitable
for different venues in general. For example, energetic music is popular in gym, while love songs fit a romantic restaurant well. Recent physiological study [3] shows that human
judges the suitability of a music for a place based on various

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the Owner/Author(s). Copyright is held by the
owner/author(s).
SIGIR’15, August 09-13, 2015, Santiago, Chile.
ACM 978-1-4503-3621-5/15/08.
DOI: http://dx.doi.org/10.1145/2766462.2767869.

1029

music semantics (e.g., genre and mood). However, it is very
difficult to apply low level acoustic features to explicitly describe those semantics due to the well-known “semantic gap”.
Besides, the acoustic contents of music belonging to same or
similar concepts could be highly diverse [4]. In the demonstration, we present an intelligent music recommender system, called VenueMusic, to automatically identify suitable
music for various popular venues in our daily lives [2]. Towards this goal, a novel topic model called Location-aware
Topic Model (LTM) is proposed to measure the suitability
of music for venues in a latent semantic space. Besides,
music concept sequence generation scheme is developed to
represent each track as a set of music concepts. The demonstration also focuses on a few interesting use-cases, and illustrates the superiority of VenueMusic on recommendation
accuracy and robustness at various venues.

2.

SYSTEM OVERVIEW

VenueMusic’s architecture comprises two major components: (1) Music Concept Sequence Generation (MCSG)
and (2) Location-aware Topic Model (LTM). Main functionality of MCSG is to detect music concepts (e.g., instrument, genre, and mood ) to represent audio contents of
the music tracks. Figure 1 illustrates the detail architecture
of VenueMusic. Specifically, when receiving a music track,
VenueMusic partitions it into multiple short segments, from
which different concepts (i.e., genres and moods) are extracted based on their audio contents using automatic concept detectors (trained based on concept-labeled data). To
improve the quality of the detected concepts for a segment,
concepts with low detected probabilities or causing rare concept co-occurrence patterns are removed via Infrequent Concept Pattern Filtering (ICPF). For a track, its music concept

3.2

sequence is the concatenation of the concepts of all segments.
Serving as the second component, LTM extracts the latent
topics from location-labeled music tracks and uses them to
represent the characteristics of the location and the music
content with the probabilistic distributions of the mined topics. When the new tracks (unlabeled-tracks) are available,
we fit them into the model by fixing the topics and obtain their topic distributions. Through characterizing the
location and music tracks by probability distributions of the
same topics, the suitability score of a music track m for a
venue v is estimated using Kullback-Leibler (KL) distance
as,
KL(v||m) =

X

v(i)ln(

i

3.

v(i)
)
m(i)

In order to validate the effectiveness and robustness of the
system, a user study was conducted using large scale test
collection including 10,000 songs. In the test, the system
was applied to recommend suitable music tracks to eight
common venues (as shown in Table 1) and compared with
several competitors. Due to the space limitations, the results
of three competitors are presented:
• Audio-Based Content Filtering (ABCF) - this method
recommends music based on the audio content. Each
venue is represented by several representative audio
feature vectors, which are generated from the labeled
tracks using K-means method.

(1)

• Concept-Based Content Filtering (CBCF) - in this
method, tracks and venues are described using generated concept histograms.

DEMONSTRATION

In the demonstration, we show a few nice features of the
VenueMusic including good usability, effectiveness and robustness.

3.1

Effectiveness and Robustness

• Concept-based LTM (CLTM) - comparing to VenueMusic, this method does not use ICPF in the concept
generation process.

Good Usability

Totally 29 music concepts (5 moods, 12 genres and 12 instruments) are used in the experiments. 7 human subjects
are recruited to evaluate the recommendation results of each
method. The evaluation procedure is the same to the user
study in [1]. Table 1 presents the mean P@20 of all subjects over the eight venues. The comparisons with ABCF
and CBCF demonstrate the superiority of using semantic
topic representations for venues and music; and the comparison with CLTM verify the usefulness of using ICPF in
the generation of music concept sequences for music tracks.
VenueMusic outperforms the competitors across the eight
venues significantly and consistently, which demonstrates its
effectiveness and robustness on location-aware music recommendation.

VenueMusic has a simple but effective interface alongside
with intelligent recommendation engine at backend. The
design of the interface is to facilitate the easy use of the
system, and the intelligent backend enables flexible recommendation to satisfy different music needs and personal preferences. The demo will focus on several nice characteristics
of VenueMusic’s user interface.
• Simplicity: To simplify the process of finding suitable music tracks in different venues, VenueMusic only
needs users to select the venue where they are currently present, then a suitable playlist for the venue
will be presented to the users. Meanwhile, the songs
having a good matching to different venues are periodically generated and updated based on users’ listening
records.

Table 1: Precision@20 comparison over different venues.

• Flexibility: Users might have different preferences for
the songs listened in a venue according to their activities or other factors (e.g., mood and event). To better
satisfy their needs, in addition to the selection of venue
type, the system also allows users to input several keywords to describe their specific music needs. Based on
the input keywords (query), songs are recommended
based on their relevances to the query and suitability
to the given venue type.

4.

Venue

ABCF

CBCF

CLTM

VenueMusic

Bar
Bedroom
Gym
Library
Office
Restaurant
Mall
Bus/Train

0.95
0.25
0.40
0.35
0.40
0.30
0.15
0.20

0.85
0.45
0.45
0.60
0.45
0.20
0.35
0.50

0.95
0.55
0.55
0.60
0.45
0.30
0.30
0.45

0.95
0.65
0.65
0.65
0.50
0.30
0.45
0.55

ACKNOWLEDGEMENTS

This research is supported by Singapore Ministry of Education under Academic Research Fund Tier-2 (MOE Ref:
MOE2013-T2-2-156) and the Microsoft Research Grant (FY14RES-OPP-048).

• Adaptivity: Although users share common interest
on the features of music they prefer in a certain venue,
different users typically favor different songs due to
their unique personalities and tastes. To providing
better personal service, VenueMusic is adapted for personalization with the use of personal listening records,
such as played and skipped times of different songs,
and other listening contexts (e.g., time). The listening history is recorded automatically and implicitly
with the permission of users. Besides, users can also
construct their own profiles by creating a personal account and providing additional information for better
personal service, such as demographic information and
favorite songs.

5.

REFERENCES

[1] Z. Cheng and J. Shen. Just-for-me: An adaptive
personalization system for location-aware social music
recommendation. In ACM ICMR, 2014.
[2] Z. Cheng and J. Shen. On effective location-aware music
recommendation. Submitted to ACM TOIS, 2015.
[3] S. Hallam, I. Cross, and M. Thaut. Oxford Handbook of
Music Psychology. Oxford University Press, 2009.
[4] J. Shen, H. Pang, M. Wang, and S. Yan. Modeling concept
dynamics for large scale music search. In ACM SIGIR, 2012.

1030


Exploiting User and Business Attributes for Personalized
Business Recommendation
Kai Lu, Yi Zhang, Lanbo Zhang

Shuxin Wang

School of Engineering
University of California, Santa Cruz

Institute of Computing Technology
Chinese Academy of Sciences

{kailu, yiz, lanbo}@soe.ucsc.edu

wangshuxin@ict.ac.cn

ABSTRACT

categories: neighborhood models and matrix factorization
(MF) models [1]. Neighborhood models capture the similarities between the neighbors of users (or items). However,
this approach performs poorly when the data is sparse. MF
maps users and items into comparable latent factors and can
handle the data sparsity problem better.
There are two major problems which aﬀect the performances of recommendation models: data sparsity and the
cold-start (i.e. new user or new item ) problem. In business recommendation, these two problems are more severe.
As business transactions are usually completed oﬄine, user
ratings are extremely sparse, e.g., each user has very few
ratings. For example, 50% of the users have only 1 rating
in the training data released in RecSys13 Yelp business recommendation challenge. Traditional MF models often fail
for two reasons: 1) existing user and business latent factor
vectors over ﬁt as each user/business has too few ratings in
the training data; 2) predictions for new users or new businesses are very unreliable and introduces much uncertainty
into the latent space.
To overcome the weakness of MF, we propose an Integrated Bias and Factorization Modeling approach (IBFM) which
can mitigate both problems. IBFM overcomes the data sparsity and cold-start problem simultaneously in a framework
through three major components. First, IBFM incorporates
multiple user and business features into an integrated framework, which can mitigate the data sparsity, and enable the
model to learn hidden representations of users and items
more reliably with augmented information. Second, IBFM
utilizes a sampling strategy to generate the new uers’ (businesses’) latent factor vectors. Instead of random sampling,
IBFM considers user and business attributes, and uses the
trained latent vectors of a new user/business’s nearest existing users/businesses to generate their latent vector. Third,
IBFM also incorporates user’s potential interests in businesses they are not aware of before.

Data sparsity and cold-start are two major problems in personalized recommendation. They are especially severe in
business recommendation, because business transactions are
usually completed oﬄine and customers generally do not
provide ratings after a transaction. Due to these two problems, matrix factorization (MF) models, which are shown to
be eﬀective in many recommendation tasks, are likely to fail
on business recommendation tasks, especially for new users and new items. In this paper, we propose an Integrated
Bias and Factorization Model (IBFM), which exploits user and business attributes. The user attributes include demographic information, vote information, point-of-interests;
the business attributes include check-in information, locations, business names, categories, etc. To handle the coldstart problem, we employ a sampling strategy to generate
the latent factor vectors for new users and new businesses
based on similar users/businesses. Our methods are evaluated on the data set used in the RecSys 2013 Yelp business
rating prediction challenge. Experimental results show that
our proposed methods signiﬁcantly outperform several existing state-of-the-art methods. In particular, the single model
IBFM performs the best in this challenge on both public and
private leaderboards.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information
Filtering

Keywords
Collaborative Filtering; Data Sparsity; Cold-start; Context
Information; Matrix Factorization

1. INTRODUCTION
Collaborative Filtering (CF) based recommender systems
provide an eﬀective way to solve the information overload
problem. In general, CF approaches can be divided into two

2.

RELATED WORK

Variations of MF models are becoming very popular for
their good performances on standard rating prediction tasks
such as Netﬂix challenge. An SVD model with alternating
least square optimization was proposed in [5]. Stochastic
gradient descent based approaches for basic MF and Regular SVD were discussed [7]. SVD ++ [4] and Factorization
Machine [8] which use Bayesian inference and MCMC sampling are now two of the state-of-the-art models in rating
prediction tasks. However, these methods do not work well
in the cold-start scenarios.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SIGIR’15, August 09 - 13, 2015, Santiago, Chile.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3621-5/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2766462.2767806.

891

To solve the cold-start problems, many methods have been
tried. [11, 2, 10] asked new users for several interviews to
capture their preferences, and deployed latent factor models
to provide recommendations for new users. [9] and [3] utilized content information to solve the new item recommendation problem, while their methods require a long training
time and are not suitable for new users.
Compared with the methods mentioned above, our approaches can mitigate the data sparsity and cold-start problem for both new user and new business together. They are
also more eﬃcient and scalable to large data.

Checkin: For the check-in information, we think that
a business’s rating bias is related to the businesses whose
check-in patterns are close to it. Thus the business rating
bias can be represented as follows:
∑
j∈C(i) bj · csim(i ∥ j)
(2)
ci = ∑
j∈C(i) csim(i ∥ j)
where C(i) are the businesses with check-in patterns similar
to i. We measure csim(i ∥ j) using KL-divergence:
KL(pi ∥ pj ) =

k=0

3. PROPOSED APPROACH
To solve the data sparsity and cold-start problems simultaneously, we propose an integrated single model, which we
call Integrated Bias and Matrix Factorization Model, to incorporate user and business’s various attributes together.
The model contains three major components: user bias (i.e.
preferences) model, business bias (i.e. preferences) model
and latent factor space. We introduce each part step by
step in the following sub sections.

csim(i ∥ j) = 1 −

To illustrate our idea, let’s start with a baseline rating
bias model proposed by [4], which is represented as: r̂ui =
µ + bu + bi . Where µ is the global average rating value, bu
is user’s rating bias and bi is business’s rating bias.

3.1.1 User Attributes
We argue that a user’s bias is related to his demographic
information, his point-of-interests, and other users’ voting
information (e.g., funny, useful, cool) for his ratings. First,
users who have the same gender might have similar rating
tendency. Gender bias can be seen as the shared component
for all the ratings by users with the same gender. Second, we
assume if users have similar vote patterns, they share similar
rating bias. Thus we can employ the user’s vote information
to infer his bias. Third, a user’s rating bias is also related
to his point-of-interests. Therefore we try to model user’s
bias/preference as follows:

j∈G(i)
∑

bj ·gsim(i,j)

j∈G(i)

pi (k)
pj (k)

KL(pi ∥ pj )
max{KL(pi ∥ px ) : x ∈ X}

gsim(i,j)

is other closest businesses’ bias aﬀect for

i’s bias. We use longitude and latitude to measure the similarities between two businesses:
gsim(i, j) = 1 −

(1)

In this equation, gender(u) = {0, 1}, vote(u) = {0, 1, 2}.
i.e., based on all the votes u gets, we choose the largest number as his vote classiﬁer (i.e. funny, useful, cool). bu,lct(i)
represents u’s point-of-interests and bu,lct(i) = αu,lct(i) ·ωu,lct(i) .
We represent the business’s location using its zip code, thus
lct(i) is the location (i.e. zip code) of business i. αu,lct(i)
is user u’s bias for location of business i (i.e. zip code) and
ωu,lct(i) is the location weights, which is calculated as follows:
ωu,lct(i) =

pi (k) log

where pi and pj denote business i and j’s check-in distributions in diﬀerent hours of weekdays, P is the vector length,
and X denotes all businesses with check-in information.
Location: Based on a business’s location information, we
propose a location bias model that incorporates the business’s zip code, street, city, longitude and latitude. The
model is:
∑
j∈G(i) bj · gsim(i, j)
li = bzip code(i) + bstreet(i) + bcity(i) + ∑
j∈G(i) gsim(i, j)
(3)
In the location bias, zip code(i), street(i) and city(i) are
business i’s zip code, street and city information respectively.
G(i) are the nearest businesses in terms of geolocation.
∑

3.1 User and Business Bias Model

b′u = bu + bgender(u) + bvote(u) + bu,lct(i)

P
∑

log(1 + Ru,lct(i) )
1 + log(1 + Ru )

distance(i, j)
max{distance(i, l) : l ∈ L}

In this equation, distance(i, j) is calculated by the longitude
and latitude of i and j, L denotes all the businesses with
location information.
Name and Category: Two types of business content
information are considered: name and category taxonomy.
A speciﬁc company may have multiple stores in diﬀerent
places; e.g., in Yelp review data, there are over 30 diﬀerent “CVS pharmacy” stores in Arizona. Assuming businesses with the same name are similar, we introduce a name
based bias to capture the similarities between stores of similar names. There are over 2,000 diﬀerent categories in the
Yelp business data set, among which 25 are ﬁrst level categories. We use the ﬁrst level category which each business
is classiﬁed into. We also consider that the business’s bias is
related to other businesses’ bias in the same category. Thus
the content bias model is:
∑
∑
1
1
ti = bu,rtc(i) +bcg(i) +
bj +
bj
|N ame(i)|
|CG(i)|
j∈N ame(i)

Where Ru is u’s total ratings, Ru,lct(i) is u’s rating number
of the businesses whose zip code is lct(i).

j∈CG(i)

(4)
where CG(i) contains all the businesses in the same category as business i. N ame(i) are the set of businesses with
the same name as business i. bu,rtc(i) is user u’s bias for
business i’s root category (i.e. rtc(i)).

3.1.2 Business Attributes
On the business side, we can also collect various features.
These features can be categorized into three categories: checkin information, location information and content information.

892

3.1.3 Unified Bias Model
By integrating all the aspects of business features mentioned in Equation (2), (3) and (4), we get the business’s
new rating bias b′i = bi + ci + li + ti .
Integrating user and business attributes together, we get
the full bias model as follows:
′
rui
= µ + b′u + b′i

(5)
Figure 1: The ratings’ distribution in the test data

3.2 Integrated Bias and Factorization Model
In the basic MF model, a user is modeled by a hidden
vector pu and a business is modeled by a hidden vector qi .
The prediction is calculated as the inner product of the two
user and business latent factor vectors: r̂ui = pTu qi .
After integrating the full bias model (Equation (5) ), we
get the ﬁnal Integrated Bias and Factorization Model (IBFM)
as follows:
(
∑
1
′
r̂ui = rui
+ qiT pu + |N (u)|− 2
yj +
|C(u)|

−1
2

∑
j∈C(u)

j∈N (u)

cj + |G(u)|

−1
2

∑

)

rating data, business check-in data, user proﬁle data and
business proﬁle data. There are 60,692 users and 15,040
businesses in the ratings, and the training data contains
230,000 ratings and test data has 36,404 ratings. The objective is to predict user-business ratings on the test data.
This data set has several unique characteristics. First of
all, rating density is only 0.03%, which means the data sparsity issue is much more serious than that of the Yahoo!
Music rating data set (0.4%) released in KDD-Cup 2011 and
Netﬂix movie rating data set(1.1%). Second, about 49.65%
users have only 1 rating in the training data, 16.15% users have 2 ratings, and only 8.23% users have more than 10
ratings. In addition, the cold-start problem is more serious
as well. The rating distribution of the test data is shown in
Figure 1. We can see only 35.36% ratings are warm ratings.
In the test data set, about 52.6% users are new users and
about 25.75% businesses are new businesses without training data. Therefore, all the problems mentioned above cause
huge diﬃculty to make accurate rating predictions.
Meanwhile, there is rich information in user proﬁles, business proﬁles and business check-in data. For users, their
names and other users’ vote distributions for their ratings
are given. Each user gender is inferred based on a male/female
name dictionary. For each business, its name, category, address, city, longitude and latitude are available. The checkin data contains each business’s check-in times in diﬀerent
time periods.
We use several state-of-the-art rating prediction models as
our baselines, including SVD with alternating least-square
optimization (ALS-SVD) [5], basic MF [7], RSVD [7], rating bias [4], SVD ++ [4] and Factorization Machine (FM)
model [8]. To learn the factorization models, we randomly generate a validation data based on the cold-start rating
distributions of the test data from the original Yelp competition training data, so that the validation data’s cold-start
rating distributions are close to that of the test data. There
are 32,020 ratings in the validation data, where 37.85% ratings are warm ratings, 37.20% ratings are new users and old
businesses, 20.55% ratings are new users and new businesses, and 4.5% ratings are existing users and new businesses.
In addition, there are 53.50% new users and 16.03% new
businesses. The remaining data are used for training.
Without lose of generality, we set k to 100 in our experiments. The latent factor dimensions of all factorization models are set as 50. To learn the model parameters
(b∗ , yi , ci , gi , pu , qi ), we minimize the mean square error of
the predicted ratings on the training data using a stochastic
gradient descent method and the validation data is used for
early stopping to avoid over ﬁtting. To tune the relevant
hyper-parameters, i.e., learning rate and regularization, we
use Nelder-Mead simplex search algorithm [6] with the initial learning rate as 0.001 and regularization value as 0.01.

(6)

gj

j∈G(u)

where N (u) represents the set of all businesses user u has
rated. C(u) and G(u) are the business sets user u is interested in and has not rated. yj , cj and gj are parameters to be
estimated and they are used to capture the user’s implicit
feedback. C(u) is calculated based on the category information associated with the businesses u has rated. G(u) is
calculated based on the zip code associated with the businesses u has rated. The businesses in C(u) and G(u) are
sorted by their popularity, and only the top 20 businesses
are considered.
New users/businesses: Each unrated user-business pair
falls into one of the following scenarios: existing user and existing business, existing user and new business, new user and
existing business, new user and new business. New users and
new businesses pairs do not have related training data, thus
their latent vectors are unknown, which introduces huge uncertainty in the prediction stage. To reduce uncertainty, we
use user and business features to compensate the disadvantages of traditional MF models as follows:
1) New user u: we use u’s gender to ﬁnd the top-k most
popular existing users with the same gender. Then we ﬁt a
Gaussian distribution to the hidden representation of those
users, and sample from this distribution to generate u’s latent vector pu .
2) New business i: Based on i’s location information, content information and check-in information, we ﬁnd the top-k
closest existing businesses using the similarity measure described in 3.1. Then we ﬁt a Gaussian distribution to the
hidden representation of those businesses, and sample from
this distribution to generate pu .

4. EXPERIMENT
To test the performance of the proposed methods, we carried out extensive experiments on the Yelp business review
data. RMSE is used to evaluate the models’ performance.

4.1 Datasets and Experimental Settings
The Yelp business data set is a publicly available benchmark data set shared on Kaggle 1 . The data set includes
1

http://www.kaggle.com/c/yelp-recsys-2013

893

utilizes user’s demographic information, votes and point-ofinterests, business check-in information, content information, and location information seamlessly. Second, it uses
sampling method to generate latent factor vectors for new
users and new businesses, which enables IBFM to make reasonable predictions in cold-start scenarios. Our experimental results show that IBFM can signiﬁcantly outperform the
traditional state-of-the-art models on benchmark business
rating prediction tasks. In addition, our single model IBFM
performs the best on both the public and private leaderboard
of RecSys 2013 Yelp business challenge, which demonstrate
it can eﬀectively take advantages of user and businesses attributes and the superiority of factorization model.

Table 1: Performance (RMSE) of relevant models
Validation Public LB Private LB
Method
ALS-SVD
1.27046
1.31063
1.31572
BasicMF
1.26489
1.30671
1.31370
RSVD
1.21214
1.25138
1.25543
SVD++
1.19324
1.24473
1.24971
FM
1.19298
1.24311
1.24870
RatingBias
1.19404
1.24291
1.24912
UserFeature
1.19107
1.23837
1.24012
CheckinFeature 1.19221
1.2401
1.24419
ContentFeature 1.18076
1.22701
1.23010
LocationFeature 1.17518
1.22424
1.22282
UniﬁedBiasModel 1.14003
1.19171
1.19780
IBFM *
1.12691
1.17858
1.18389

6.

ACKNOWLEDGMENTS

This work was funded by National Science Foundation
ICES-1101741 and IIS-0953908. Any opinions, ﬁndings, conclusions or recommendations expressed in this paper are the
authors, and do not necessarily reﬂect those of the sponsors.

4.2 Experimental Results
The ratings of the test data are unknown, and they are
randomly divided into two parts in the yelp competition.
20% ratings are used in the public leaderboard evaluation
and the left 80% ratings are used in the private leaderboard
evaluation. The results can be known through submitting
the results in Kaggle.
The experimental results of all models are shown in Table
1. We have the following ﬁndings:
1) Both of the BasicMF and ALS-SVD perform poorly
on this data set. RSVD, which incorporates user and business rating bias, greatly improve prediction accuracy compared with MF and ALS-SVD. RatingBias model performs
much better than RSVD, and has a similar performance as
SVD++ and FM. The reason is that when users have too
few ratings on the training data, the user and business latent
vectors have big variance. In addition, the cold-start ratings
in the test data make user and business latent vectors very
unreliable for predictions.
2) By incorporating user’s attributes (gender, vote information and point-of-interests), business’s features (check-in,
name and category and location information), all the models (UserFeature, CheckinFeature, ContentFeature and LocationFeature) signiﬁcantly improve the recommendation performance. Among all the four features, the location feature
is most eﬀective. This makes sense, because locations play
an important role in business recommendations. By combining user and business attributes together, the UniﬁedBiasModel further improves performance signiﬁcantly. This
demonstrates that the user and businesses features are complementary, and using appropriate feature learning methods can eﬀectively mitigate the data sparsity and cold-start
problem.
3) Furthermore, after adding the sampling method for
generating new user and new business latent vectors based
on user and business attributes, IBFM shows the best performance on all three data sets. Compared with the state-ofthe-art models (SVD++ and FM) on prediction problems,
IBMF increases the prediction accuracy by 5.15%. It shows
that our sampling method can eﬀectively generate reasonable initial hidden representations for new users and new
businesses.

7.

REFERENCES

[1] G. Adomavicius and A. Tuzhilin. Toward the next
generation of recommender systems: A survey of the
state-of-the-art and possible extensions. IEEE Trans.
on Knowl. and Data Eng., 17(6):734–749, June 2005.
[2] N. Golbandi, Y. Koren, and R. Lempel. Adaptive
bootstrapping of recommender systems using decision
trees. In Proceedings of the Fourth ACM International
Conference on Web Search and Data Mining, 2011.
[3] A. Gunawardana and C. Meek. Tied boltzmann
machines for cold start recommendations. In
Proceedings of the 2008 ACM Conference on
Recommender Systems, 2008.
[4] Y. Koren. Factorization meets the neighborhood: a
multifaceted collaborative ﬁltering model. In
Proceedings of the 14th ACM SIGKDD Conference,
2008.
[5] Y. Koren, R. Bell, and C. Volinsky. Matrix
factorization techniques for recommender systems.
Computer, 42(8):30–37, 2009.
[6] J. A. Nelder and R. Mead. A simplex method for
function minimization. Computer journal,
7(4):308–313, 1965.
[7] A. Paterek. Improving regularized singular value
decomposition for collaborative ﬁltering. In
Proceedings of KDD cup and workshop, volume 2007,
pages 5–8, 2007.
[8] S. Rendle. Factorization machines with libFM. ACM
Trans. Intell. Syst. Tech., 3(3):57:1–57:22, May 2012.
[9] L. Zhang and Y. Zhang. Discriminative factored prior
models for personalized content-based
recommendation. In Proceedings of the 19th ACM
CIKM Conference, CIKM ’10, 2010.
[10] L. Zhang and Y. Zhang. Interactive retrieval based on
faceted feedback. In Proceedings of the 33rd
International ACM SIGIR Conference, SIGIR’10,
2010.
[11] K. Zhou, S.-H. Yang, and H. Zha. Functional matrix
factorizations for cold-start recommendation. In
Proceedings of the 34th International ACM SIGIR
Conference, 2011.

5. CONCLUSION
In this paper, we propose an integrated bias and factorization model (IBFM) which has two advantages. First, it

894


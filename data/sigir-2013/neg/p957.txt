Ranking-Oriented Nearest-Neighbor Based Method for
Automatic Image Annotation
Chaoran Cui1
Jun Ma1
Tao Lian1
bruincui@gmail.com
majun@sdu.edu.cn
liantao1988@gmail.com
1,2
Zhaochun Ren3
Xiaofang Wang
z.ren@uva.nl
ise_wangxf@ujn.edu.cn
1

School of Computer Science and Technology, Shandong University, Jinan, China
School of Information Science and Engineering, University of Jinan, Jinan, China
Intelligent Systems Lab Amsterdam, University of Amsterdam, Amsterdam, The Netherlands
2

3

ABSTRACT

searching images with a textual query, which can be achieved
by ﬁrst annotating images manually, and then searching over
the annotations using the query. However, manual image annotation is a laborious and time-consuming process. Therefore, many eﬀorts have been devoted to the research on automatic image annotation.
The goal of automatic image annotation is to assign a
few relevant keywords to an image that can reﬂect its visual
content. Recently, the nearest-neighbor based scheme [4]
has become increasingly attractive because of its superior
performance and straightforward framework. It is on the
assumption that visually similar images are more likely to
share common keywords. Given a new image, the nearestneighbor based scheme ﬁrst ﬁnds a set of its most similar
neighbors from labeled images, and then propagates the keywords associated with the neighbors to it.
In spite of the simplicity of the nearest-neighbor based
annotation framework, there are some critical issues that
remain to be addressed. One important aspect of the framework is how to perform the process of the nearest neighbor
search eﬀectively. Many studies [4, 5, 6] focused on designing a suitable visual distance metric between images, which
is then used to rank all labeled images according to their distance to the new image. Typically, the work aimed to weight
and combine the distances from diﬀerent dimensions in visual feature space. Despite the encouraging results achieved,
we argue that higher accuracy in distance prediction does
not necessarily lead to better ordering of labeled images,
which is the ultimate goal of our problem. For example, let
u and v denote two labeled images whose true distances to
the new image are 4 and 5 respectively. Suppose a method
has predicted the distance to be 5 for u and 4 for v. Although
it is a desirable result in terms of prediction error, it fails in
ensuring the correct ordering of u and v. In light of this, it
is necessary to shift our attention from approximating the
absolute distance between images to directly predicting the
relative ordering of labeled images.
In this paper, we propose a ranking-oriented neighbor
search mechanism, which uses the learning to rank [3] techniques to directly produce the ordering of all labeled images
for a new image, without going through the intermediate
step of distance prediction. Unlike regular learning to rank
methods, our proposed ranking algorithm exploits the implicit preference information hidden in the training images.
In addition, since only the k nearest neighbors are generally

Automatic image annotation plays a critical role in keywordbased image retrieval systems. Recently, the nearest-neighbor
based scheme has been proposed and achieved good performance for image annotation. Given a new image, the scheme
is to ﬁrst ﬁnd its most similar neighbors from labeled images,
and then propagate the keywords associated with the neighbors to it. Many studies focused on designing a suitable distance metric between images so that all labeled images can
be ranked by their distance to the given image. However,
higher accuracy in distance prediction does not necessarily
lead to better ordering of labeled images. In this paper, we
propose a ranking-oriented neighbor search mechanism to
rank labeled images directly without going through the intermediate step of distance prediction. In particular, a new
learning to rank algorithm is developed, which exploits the
implicit preference information of labeled images and underlines the accuracy of the top-ranked results. Experiments on
two benchmark datasets demonstrate the eﬀectiveness of our
approach for image annotation.

Categories and Subject Descriptors
H.3.1 [Information Storage and Retrieval]: Content
Analysis and Indexing

Keywords
image annotation; nearest-neighbor based scheme; learning
to rank

1.

INTRODUCTION

In recent decades, the number of digital images has been
growing rapidly and there is an increasingly urgent demand
for eﬀective image retrieval techniques. Users often prefer
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

957

is estimated in a manner similar to F1 measure:

considered in the nearest-neighbor based scheme, we enforce
the ranking model to focus more on the correctness of the results in top-k positions. A boosting algorithm [1] is utilized
to solve the resulting optimization problem in our approach.

2.

CON (y, ŷ) =

2pr
p+r

p=

y T ŷ
ŷ T ŷ

r=

y T ŷ
.
yT y

(1)

With this deﬁnition, for a labeled image x(i) , we deﬁne
Ri = {ri1 . . . rii−1 , rii+1 . . . rin } to be the relevance degrees
of the other corresponding labeled images, i.e., T \x(i) =
{x(1) . . . x(i−1) , x(i+1) . . . x(n) }, where rij = CON (y (i) , y (j) ).
Then, let πi denote the total ranking of T \x(i) with respect
to x(i) , which can be derived in descending order of Ri , and
πi (xj ) stands for the position of image xj ∈ T \x(i) .
Although πi seems a natural way of representing the preference information associated with x(i) , the variations in
the importance of partial orderings with diﬀerent ranking
positions cannot be easily reﬂected in such a form of linear
ordering. To allow encoding this kind of information, in this
paper, we construct the preference information in the form of
ordered pairs of images, and also assign each pair a weight to
represent the importance of its being satisﬁed. In particular,
a set of p ordered pairs Wi = {w(xjm i xqm ) | m = 1, . . . , p}
is further randomly picked up from πi , where xj i xq denotes a ordered pair indicating that the labeled image xj is
ranked before xq in πi , and w(xj i xq ) is its corresponding
importance weight. To determine the value of w(xj i xq ),
we ﬁrst deﬁne πi as a new ranking of T \x(i) , which exchanges the positions of xj and xq in πi . Then we calculate
the NDCG@k metric of πi :

RANKING-ORIENTED NEIGHBOR
SEARCH MECHANISM

In this section, we introduce our ranking-oriented neighbor search mechanism in details. For the ease of explanation,
we ﬁrst give some notations.
Let X be an image collection, and all keywords appearing
in the collection are W = {w1 , w2 , . . . , wc }, where c is the
total number of unique keywords. In image annotation task,
we are given n labeled training images, T = {x(i) ∈ X | i =
1, . . . n}, each of which is associated with a c-dimensional
(i)
label vector y (i) ∈ {0, 1}c , where yj = 1 if x(i) is labeled
(i)

by the jth keyword wj and yj = 0 otherwise. Given a
query image q ∈ X , our goal is to ﬁnd a ranking function
H : X × T → R such that H(q, x(i) ) represents the relevance
of the labeled image x(i) with respect to q, and x(i) is ranked
before x(j) if H(q, x(i) ) > H(q, x(j) ).
To resolve the above challenge, we seek to exploit the
learning to rank (hereinafter referred to as LTR for short)
techniques to learn the optimal ranking function H from the
training data. Although LTR has been extensively studied
[3], it is not straightforward to directly apply regular LTR
techniques to our problem for the following two reasons.
First, unlike standard LTR tasks where some preference information (in the forms of pairwise or listwise constraints)
is often explicitly given to supervise the learning process, in
our problem, preference information is only implicitly available in the training set. Moreover, generally we only consider the k nearest neighbors for a new image to prohibit
the potential noisy keywords introduced by those distant
neighbors. Therefore, in our ranking problem, the correct
ordering of the top-k results is crucial, and the mistakes in
low ranks may not deteriorate the ﬁnal performance. It is
necessary to redesign the training procedure to ensure the
top-k results are as accurate as possible.
Based on the above analysis, to facilitate our ranking task,
in the following, we ﬁrst generate the implicit preference
information hidden in the training data. With the preference
information, we further present a new LTR algorithm that
underlines the accuracy of the top-k results.

N DCGπi @k =

k
1  2rl − 1
,
Nk l=1 log2 (1 + l)

(2)

where rl denotes the relevance degree of the image with position l in πi , and Nk is a normalization factor chosen so that
the NDCG@k of the original ranking πi is 1. Furthermore,
the exact form of w(xj i xq ) is given as

1 − N DCGπi @k πi (xj ) ≤ k
.
(3)
w(xj i xq ) =
η
otherwise
In the above, if xj or xq involves the top-k instances in πi ,
we take the drops of πi in terms of NDCG@k as the value
of w(xj i xq ). Intuitively, as NDCG includes a position
discount factor in its deﬁnition, incorrectly ordering higher
ranks of πi can lead to greater losses in terms of NDCG@k.
As a result, a large weight will be assigned to the ordered
pair at high positions. On the contrary, if both xj and xq appear behind the kth position in πi , there is no eﬀect on the
value of NDCG@k when their positions exchange. Therefore, we set w(xj i xq ) to be η, which is a small constant.
Finally, we repeat the above process for each labeled image and give the ultimate set of preference information as
P = ∪n
i=1 Wi , which will be used as input training data for
the following LTR algorithm.

2.1 Generation of Preference Information
As no explicit preference information is given for our problem, the ﬁrst step before LTR is to derive some preference
information from the training data. Speciﬁcally, we separately submit each labeled image as a query and look for the
information that could indicate the relative ordering among
the other labeled images with respect to it.
It is notable that the intuition behind the nearest-neighbor
based methods is that similar images should share more
common keywords. This means that given an image, its
close neighbors may have a higher keyword agreement with
it compared to those distant neighbors. In accordance with
this principle, we consider measuring the relative distance
between labeled images by the consistency of their keywords.
Given two label vectors y and ŷ, their consistency CON (y, ŷ)

2.2 Top-k Focused Ranking Algorithm
With the derived preference information set P, we now
present the formulation of the proposed top-k focused LTR
algorithm. The basic idea is that the optimal ranking function H should be consistent with the preference information
in P as much as possible. To this end, we deﬁne the ranking
error of H with respect to P as follows:

err =
Wijq I(Hiq ≥ Hij ) .
(4)
xj i xq ∈P

958

Here, we introduce Wijq = w(xj i xq ) and Hij = H(x(i) , xj )
for the simplicity of description. I(·) is an indicator function
that outputs 1 if the input boolean variable is true and zero
otherwise. In fact, err measures the weighted number of the
preference pairs misordered by H. As described in Section
2.1, the preference pairs at high positions have relatively
larger weights, thus the incorrect orders of these pairs will
result in more severe ranking errors; whereas the pairs only
involving the instances behind the kth positions have been
assigned small weights, and misordering them may aﬀect
little on the error. As a result, through minimizing err, we
can ﬁnd the optimal ranking function H that gives priority
to ensuring the correctness of the top-k results.
However, the ranking error deﬁned in (4) is a non-smooth
function as the indicator function I(·) is non-smooth. It
is well known that directly optimizing a non-smooth function is computationally infeasible. To address the problem,
we follow the idea of AdaBoost algorithm by replacing the
indicator function I(x ≥ y) with an exponential function
exp(x − y). The resulting new ranking error is:
err
 =



Wijq exp(Hiq − Hij ) .

Algorithm 1 Rankboost algorithm for minimizing err

Input: P, F and T
Output: H
1: Initialize a distribution D over all preference pairs in P:

W
(1)
Dijq = Zijq
where Z0 =
Wijq
0
x j i x q

2: for t = 1, . . . , T do
3:
Create a weak ranker ht : Rr × Rr → R from F
1+r
)
4:
Compute αt = 12 ln( 1−r

(t)
where r =
Dijq (ht (x(i) , xj ) − ht (x(i) , xq ))
x j i x q

5:

Update

(t+1)
Dijq

where Zt =

(t)

=


Dijq exp(ht (x(i) ,xq )−ht (x(i) ,xj ))
(t)

x j i x q

6: end for
7: return H(q, x) =

Zt

Dijq exp(ht (x(i) , xq ) − ht (x(i) , xj ))

T

t=1

αt ht (q, x)

function H through their weighted combination, and αt is
the corresponding contribution of ht (line 7).
After ﬁnding the optimal ranking function H, given a new
image q, we employ H to produce the total ranking of all
labeled images with respect to q, and take the top-k results
as its k nearest neighbors, which is denoted by NH (q) =
{N N1 , . . . , N Nk }.

(5)

xj i xq ∈P

Since it always holds that exp(x − y) ≥ I(x ≥ y), by minimizing the new error err,
 we eﬀectively reduce the original
ranking error err. Besides, another advantage of using err
 is
from the theoretical property of AdaBoost, i.e., minimizing
the exponential loss can not only reduce the training errors
but also increase the margins of the training samples, and
the enlarged margins are the key to ensure a low generalization error for test instances.
In our study, we utilize the RankBoost [1] algorithm to
learn the optimal ranking function H by minimizing err.
 To
guarantee the correct execution of the algorithm, we need
to give a group of ranking features F = {f1 , . . . , fg }, where
each ranking feature fi deﬁnes a linear ordering of the images to be ranked. To this purpose, we calculate the distance of all ranked images to the query image in the space
of a certain visual feature, and a ranking feature is generated in ascending order of the distance. It should be noted
that the ranking features are only related to the ordering of
the ranked images rather than the actual numerical values
of their distance. Algorithm 1 shows the details of the RankBoost algorithm. The algorithm operates for T iterations.
For each successive iteration t = 1, 2, . . . , T , it maintains a
weight distribution D(t) over the preference pairs in P, and
(t)
denotes Dijq as the weight on the pair xj i xq . Initially, the
weights are set according to the importance of preference
pairs (line 1). At iteration t, a weak ranker ht is created
from F based on the current weight distribution D(t) (line
3). We use the same generation process of weak ranker as
described in [1]. Then the algorithm chooses a weight coeﬃcient αt for ht by measuring its ranking accuracy on all
preference pairs (line 4). Intuitively, a greater coeﬃcient is
given to the more accurate weak ranker. Meanwhile, the
weight distribution D(t) is updated according to the performance of ht (line 5). The preference pairs misordered by
ht have their weights increased, whereas the weights are decreased for those pairs that are ordered correctly. Therefore,
the weak ranker in the next iteration ht+1 will concentrate
more on the “hard” pairs for ht . Once all the weak rankers
have been created, the algorithm outputs the ﬁnal ranking

3. IMAGE ANNOTATION WITH DERIVED
NEIGHBORS
With the set of neighbor images NH (q), the next step is
to evaluate the keyword relevance and propagate a certain
number of the most relevant keywords to the new image q. In
most previous work, researchers determined the relevance of
a keyword by the majority or weighted voting of the nearest
neighbors. However, there is no theoretical guarantee that
the keywords selected by this manner are always the suitable
annotations for q. In [2], Li et al. demonstrated that the
diﬀerence between the keyword frequency in local neighbor
set and that in entire image collection is a good keyword
relevance indicator. Therefore, in our study, we adopt the
similar method to compute the relevance of the keyword w
with respect to q:
rel(w, q) = kfNH (q) (w) − kfprior (w) ,

(6)

where kfNH (q) (w) is the number of labeled images containing w in NH (q), and kfprior (w) denotes the total frequency
of w in the entire training collection.

4. EXPERIMENTS
4.1 Experiment Settings
We conduct experiments on two benchmark datasets: Corel
5K and IAPR TC 12. The two datasets have been widely
used in previous studies so we can directly compare the experiment results. Each image on both datasets is represented with the same visual features as described in [4].
On Corel 5K and IAPR TC12, all comparative methods
are required to annotate each image with 5 most relevant
keywords. The quality of predicted annotations is assessed
by retrieving test images using the keywords in annotation

959

Table 1: Performance comparison in terms of
P %, R% and N + between our method and previous
published work.
Corel 5K
P% R% N+
MSC
JEC
LASSO
GS
NW-RNN
RNN
Figure 1: Eﬀect of the variation of k on Corel 5K.

Nw
Np

Recall(w) =

Nw
,
Nr

32
32
29
33
32
34

136
139
127
146
149
149

—
28
28
32
28
33

—
29
29
29
30
31

—
250
246
252
259
255

neighbor search mechanism. In addition, RNN outperforms
all the distance-oriented approaches listed in diﬀerent evaluation measures. The performance increase over the best
distance-oriented method (GS) still achieves 1% , 1% and
3 in terms of P , R and N +. On IAPR TC12, RNN is
superior to other approaches as well. These improvements
suggest that the annotation results provided by our method
is preferable.

vocabulary. For a keyword w, its precision and recall is
computed as follows:
P recision(w) =

25
27
24
30
29
31

IAPR TC12
P% R% N+

(7)

where Nw denotes the number of images correctly annotated
with w, Np denotes the number of images predicted to have
w, and Nr is the number of images annotated with w in
ground-truth. The average precision (P ) and recall (R) are
computed over all keywords as two evaluation measures. In
addition, we also consider another measure to assess the
coverage of correctly annotated keywords, i.e., the number
of keywords with non-zero recall (N +).
In our approach, the number of neighbors considered in
the nearest-neighbor based scheme, k, is a parameter to be
determined. In the experiments, the optimal value of k is
found via an exhaustive search with a 5-fold cross-validation
on training set. Figure 1 presents the performance comparisons by varying k from 30 to 400 on Corel 5K. We can see
that the best results can be achieved when k = 200, and
a very small or large value of k degrades the performance.
This is reasonable because a small number of neighbors cannot provide suﬃcient information to reﬂect the characteristics of a new image, while too many neighbors may introduce
some information irrelevant to that image. On IAPR TC12,
similar variation trend of performance can be observed as k
changes, and the optimal value of k is around 500. Therefore, we set k = 200 for Corel 5K and k = 500 for IAPR
TC12 in our later experiments.

5. CONCLUSIONS
In this paper, we have introduced a novel image annotation method, which adapts the conventional nearest-neighbor
based approaches with a ranking-oriented neighbor search
mechanism. A new learning to rank algorithm is developed to directly produce the ordering of all labeled images. It leverages the implicit preference information of
training data and underlines the accuracy of the top-ranked
results. Experiments have demonstrated the eﬀectiveness of
our method for image annotation. For future study, we plan
to examine the scalability of our method and experiment on
large-scale web image datasets.

6. ACKNOWLEDGMENTS
This work is supported by the Natural Science Foundation of China (61272240,60970047,61103151), the Doctoral
Fund of Ministry of Education of China (20110131110028)
and the Natural Science Foundation of Shandong Province
(ZR2012FM037).

7. REFERENCES

4.2 Experiment Results

[1] Y. Freund, R. Iyer, R. Schapire, and Y. Singer. An
eﬃcient boosting algorithm for combining preferences.
The Journal of Machine Learning Research, 4:933–969,
2003.
[2] X. Li, C. Snoek, and M. Worring. Learning social tag
relevance by neighbor voting. Multimedia, IEEE
Transactions on, 11(7):1310–1322, 2009.
[3] T.-Y. Liu. Learning to rank for information retrieval.
Found. Trends Inf. Retr., 3(3):225–331, 2009.
[4] A. Makadia, V. Pavlovic, and S. Kumar. A new baseline
for image annotation. In ECCV, pages 316–329, 2008.
[5] C. Wang, S. Yan, L. Zhang, and H.-J. Zhang.
Multi-label sparse coding for automatic image
annotation. In CVPR, pages 1643–1650, 2009.
[6] S. Zhang, J. Huang, Y. Huang, Y. Yu, H. Li, and
D. Metaxas. Automatic image annotation using group
sparsity. In CVPR, pages 3312–3319, 2010.

To investigate the eﬃcacy of our ranking-oriented nearestneighbor based method for image annotation, which is denoted by RNN, we compare it with some previous distanceoriented methods, i.e., MSC [5], JEC [4], LASSO [4] and
GS [6]. Besides, we design a modiﬁed version of our original method, NW-RNN, which adopts a similar ranking algorithm to RNN but without considering the procedure of
preference pair weighting in equation (3). Instead, NWRNN assigns equal weight to all preference pairs. As a result, it is diﬃcult for NW-RNN to ensure the correctness of
the top-ranked results suﬃciently. Table 1 shows the annotation results of diﬀerent approaches.
As clearly observed in the table, on Corel 5K, NW-RNN
gains comparable performance with RNN in N +, but loses
a lot a in terms of P and R respectively. Such results underlines the importance of focusing more on the correctness of
the top-ranked results for the success of our ranking-oriented

960


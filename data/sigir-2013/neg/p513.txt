Personalized Time-Aware Tweets Summarization
Zhaochun Ren

Shangsong Liang

ISLA, University of Amsterdam
Amsterdam, The Netherlands

ISLA, University of Amsterdam
Amsterdam, The Netherlands

z.ren@uva.nl

s.liang@uva.nl

Edgar Meij

Maarten de Rijke

Yahoo! Research
Barcelona, Spain

ISLA, University of Amsterdam
Amsterdam, The Netherlands

derijke@uva.nl

emeij@yahoo-inc.com
ABSTRACT

One task that is aimed at addressing this dual problem is tweets
summarization [6]: to extract a group of representative tweets from
a set of tweets. The task is similar to tweet recommendation, but
tweets summarization pays more attention to the quality of selected
results, including notions such as representativeness and diversity.
So far, tweets summarization methods are typically query and userindependent. How to adapt tweets summarization to a specific user
is still a topic of ongoing research [4, 5, 7, 22, 31, 36]. Current
methods, whether personalized or not, also neglect to explicitly
model the temporal nature of the microblogging environment; timeawareness is a key feature of Twitter in general and tweets summarization in particular.
We put forward a model for personalized, time-aware tweets
summarization (TaTS). We investigate three key aspects of tweets
summarization: (a) novelty, preventing near-duplicate tweets to
be included, (b) coverage, so as to be representative to candidate
tweets, (c) diversity, covering as many aspects as possible. When
working with Twitter data, several methodological challenges arise.
In order to perform effective tweets summarization, we require a
notion of a user’s interest. Most Twitter users, however, mostly
consume information without producing a lot of information. That
is, they rarely post tweets of their own [22]. Hence, in order to infer a user’s interest in a robust manner, we need to use other signals
than just the user’s tweets. To address the issue, we incorporate
intuitions from the field of collaborative filtering and base our estimation of a person’s interest on those of their friends on Twitter,
following [5]. We assume that for each user there exist one or more
“social circles,” in which three or more users follow each other and
form cliques. We find that people are usually connected to specific
communities and assume that each user’s behavior on Twitter is affected by: (a) a user’s private taste, (b) a collaborative effect from
social circles, and (c) a bursty component, reflecting current events.
Clearly, a user’s interest can change over time. Topic modeling
has proven effective for topic detection and user behavior modeling
on Twitter [8, 25, 32]. As a dynamic extension of the author-topic
model [26], our proposed Tweet Propagation Model (TPM) aims to
track both a user’s interests and any topic drift arising with the passing of time. Based on “social circles", TPM derives the user’s interest from a dirichlet mixture over interests of someone who share
“social circles.” It does so by inferring distributions over topics and
interests that change over time. Following existing topic modeling
approaches for Twitter [8, 37], we extend TPM and classify the topics as (a) personal topics, (b) common topics, or (c) bursty topics.
Gibbs Expectation Maximization (EM) sampling [29] is used to
infer the posterior probabilities and to estimate the value of hyperparameters in our topic models. After inferring the probabilities of

We focus on the problem of selecting meaningful tweets given a
user’s interests; the dynamic nature of user interests, the sheer volume, and the sparseness of individual messages make this an challenging problem. Specifically, we consider the task of time-aware
tweets summarization, based on a user’s history and collaborative
social influences from “social circles.” We propose a time-aware
user behavior model, the Tweet Propagation Model (TPM), in which
we infer dynamic probabilistic distributions over interests and topics. We then explicitly consider novelty, coverage, and diversity
to arrive at an iterative optimization algorithm for selecting tweets.
Experimental results validate the effectiveness of our personalized
time-aware tweets summarization method based on TPM.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information filtering

Keywords
Twitter, tweets summarization, data enrichment, topic modeling

1.

INTRODUCTION

Twitter has amassed over half a billion users in 2012, who produce (“tweet”) over 300 million tweets per day.1 Twitter users
can subscribe to updates from other users by following them, essentially forming a unidirectional friend relationship. Moreover,
tweets can be “retweeted,” basically copying a tweet posted by another user to one’s own timeline. From an information retrieval
point of view, the sheer volume of users and tweets presents interesting challenges. On the one hand, interesting, relevant, or meaningful tweets can easily be missed due to a large number of followed users. On the other hand, users may miss interesting tweets
when none of the users they follow retweet an interesting piece of
information.
1
http://blog.twitter.com/2012/03/
twitter-turns-six.html.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

513

each tweet, we employ an iterative algorithm to optimize the tweet
selection procedure, considering coverage, novelty, and diversity.
Our contributions in this paper are as follows. (1) We propose
the task of personalized time-aware tweets summarization, selecting personalized meaningful tweets from a collection of tweets.
(2) We leverage a user’s “collaborative influence” in order to derive
the user’s interests. (3) We introduce a tweet propagation model
to address the potential drift in a user’s interests as well as topics
over time. (4) We employ a tweet selection algorithm that jointly
optimizes for coverage, diversity, and novelty.
The rest of this paper is organized as follows. We introduce related work in Section 2. Our problem formulation is detailed in
Section 3. Our strategy for tweet summary generation, is described
in Section 4. Section 5 details our experimental setup and Section 6
presents and discusses the experimental results and Section 7 concludes the paper.

2.

RELATED WORK

Our approach builds on earlier work in tweets summarization,
tweet recommendation and topic modeling.

2.1

Tweets Summarization

Several publications have focused on tweets summarization: the
task of selecting a list of meaningful tweets that are most representative for some topic. Most work in the literature concerns tweets
as basic constituents to compose a summary. Some authors bring
feature-based or graph-based summarization technologies to bear
on this task [6, 27], while other methods use a term-frequency
based method [28] or a strategy based on mutual reinforcement between users’ influence and qualifications of tweets [9]. Recently,
time-aware summarization has been studied by several authors, often in the form of timeline generation on Twitter. Chakrabarti and
Punera [4] separate topic related tweets into various periods as an
event evolution map, and generate an update-summarization result.
Yan et al. [33] propose an evolutionary timeline summarization
strategy based on dynamic programming. Evolutionary summarization approaches segment post streams into event chains and
select tweets from various chains to generate a tweet summary;
Nichols et al. [21] propose an effective method to separate timelines using Twitter. To the best of our knowledge, existing work on
tweets summarization focuses on the extraction of representative
tweets for specific topics, without considering personalization.
Other work integrates the task of selecting tweets with other web
documents: Yang et al. [35] use mutual reinforcement to train both
the selection of related web documents and tweets via a single
graph factor model. Zhao et al. [37] extract representative keywords from tweets based on a topic model. Tweet ranking has also
attracted attention: Weng et al. [31] proposed a graph-based ranking strategy for ranking tweets based on the author-topic model.

2.2

Symbol

Table 1: Glossary.
Description

K
U
V
T
Dt
Dt
u
Cu,t
Du,t
Du,t
Fu,t
Cu,t
dt
w
zt
cu,t
θu,t
ϑt
φt
Z
β, α, σ, r
N
λu,c,t

number of topics
number of users
the size of the vocabulary
number of time periods
candidate tweets at time t
number of candidate tweets at time t, i.e., |Dt |
user u on Twitter, u ∈ U
social circle for user u at t
tweets posted by u at time t
number of tweets posted by u at time t, i.e., |Du,t |
number of friends of u at time t
number of social circles around u at time t
tweet published at time t, dt ∈ Dt
token/word present in some tweet, w ∈ W
latent topic at t time, zt ∈ Zt
social circle around u at time t, cu,t ∈ Cu,t
distribution of u’s interests over topics at time t
distribution of topics within a tweet at time t
distribution of words over topics at time t
classification of individual topics in θ or ϑ
hyper-parameters in TPM
maximum number of tweets returned
weight of social circle c for user u at t

propose a method to recommend “novel" tweets to users by following users’ interests and using the tweet content. However, many of
these methods ignore the dynamic nature of the problem; with the
change of time, user interests may also change.

2.3

Topic Models

Topic models [2, 12] are employed to reduce the high dimensionality of terms appearing in text into low-dimensional, “latent”
topics. Ever since Hofmann [12] presented probabilistic latent semantic indexing (pLSI), many extensions have been proposed. In
latent Dirichlet allocation (LDA, [2]) each document is generated
by choosing a distribution over topics and then each word in the
document is chosen from a selected topic. To handle users’ connections with particular documents and topics, the author-topic model
has been proposed [26]. However, for data with topic evolution the
underlying “bag of words” representation may be insufficient. To
analyze topic evolution, other models have been proposed, such as
the Dynamic Topic Model [1], Dynamic Mixture Models [30] and
the Topic Tracking Model [13]. Topic models have not yet been
considered very frequently in the setting of Twitter. Twitter-LDA
is an interesting exception; it classifies latent topics into “background" topic and “personal" topics [37], while an extension of
Twitter-LDA has been proved to be effective in burst detection [8].

Collaborative Tweet Recommendations

Our work is different from the related work mentioned above in
the following important ways: (1) our work focuses on personalized and time-aware tweets summarization and (2) we propose
a tweet propagation model by jointly modeling time-aware propagation and collaborative filtering from “social circles,” which is
different from existing topic models.

In recent years, collaborative filtering on Twitter has attracted
increased attention. Yang et al. [34] address recommendation and
link prediction tasks based on a joint-propagation model, FTP, between social friendship and interests. Ye et al. [36] propose a generative model to describe users’ behavior, given influences from
social communities, for recommendation [18, 19]. To track social influence of users in a social network, Xu et al. [32] propose
a graphical mixture model to describe user’s behavior in posting
tweets and analyze the original topic domain for a specific proposed
tweet. Chen et al. [5] propose a collaborative filtering method to
generate personalized recommendations in Twitter through a collaborative ranking precedure. Similarly, Pennacchiotti et al. [22]

3.

PROBLEM FORMULATION

Before introducing our method for time-aware tweets summarization, we introduce our notation and key concepts. Table 1 lists
the notation we use. Given two users ui and uj on Twitter, there are
two main reasons for ui and uj to follow each other: either because

514

Friend

Friend

user B

user A

Friend

Friend

user D

u ,t 1

user C

 u ,t
D u ,t

Cu ,t 1
Friend

Friend

C1,t 1

user E

C2,t 1

…

C x ,t 1

…

CC ,t 1

N d ,t

Fu,t 1

u ,t1
1

C

u ,t 1
2

…

u ,t 1
x

…

u

F ,t 1



Dt

t

t
t

N d ',t

et
w

 tB

z

rt

qt
z

w

C

 tu

tu1

Figure 1: Example of social circles on Twitter: there are two
social circles (indicated using the ‘c’) among the five users in
this graph, where each pair of vertices in each social circle is
connected through the “friend” relationship.

 tco m

tcom
1


B
t 1

 tB

…

Figure 2: Graphical representation of TPM.

they have similar interests or they have some relationship outside
Twitter [32]. If two users ui and uj follow each other, we define
them to be friends on Twitter. Given this definition, we define a
social circle around a user u to be a set of friends of u such that
every pair of users in this set is in the friend relation. See Figure 1
for a schematic representation.
Similar to the author-topic model [26], we assume that each
Twitter user’s interests are represented by a multinomial distribution θu,t , which may, however, change over time. That is, the timeaware interests of user u are represented as a multinomial distribution θu,t over topics, where each topic is represented as a probabilistic distribution over words [2]. Formally, we have θu,t =
{θu,t,z1 , · · · , θu,t,zK }, where θu,t,zi , denotes the distribution of
topic zi for user u at time t.
We further assume that each tweet can be represented as a probabilistic distribution over topics. To cater for the phenomenon of
user interests changing over time, we assume that topic distributions are dynamic and may differ between time periods. Given
a user u, we split the topic set Zt at time t into three classes:
Zt = Ztu ∪ Ztcom ∪ ZtB : there exist “private” topics Ztu that solely
depend on the user, there are common topics Ztcom that are influenced by friends from shared social circles, and there are topics
from event-related, bursty sources, ZtB . The latter type of topic
will typically transfer from initially being observed at time t into
Z com at some later time t0 .
The dynamic interests of user u at time t, reflected by θu,t ,
evolve in different ways depending on the class that a topic zt ∈ Zt
belongs to. For each user, θu,t is affected by the following three
classes.

time-aware tweets summarization is defined similar to time-aware
tweets summarization, but in this case the tweets selected for inclusion in RTt need to be relevant based on u’s interests θu at time
t.

4.

METHOD

In this section, we detail our tweets summarization method, including the required methods for joint user-tweets topic modeling,
inference and parameter estimation. As input, our method has probabilistic distributions from topic modeling. The output is the timeaware tweets summary, i.e., a selection of tweets (per period) satisfying the user’s interest.

4.1

Topic Modeling: Tweets Propagation

We start by proposing the tweets propagation model (TPM) to
jointly track dynamic user’s interests and topics. The interests of
a user u are assumed to be reflected by a multinomial distribution
θu,t over topics. We assume that the distribution of topics φt over
words follows a dynamic propagation process with changes over
time. Figure 2 provides a graphical overview of TPM.
In the graphical structure of TPM, we see a number of ingredients. Among the variables related to user u in the graph, z, θ and
γ are random variables and w is the observed variable. In the candidate tweets part, ϑ, z and σ are random variables; Du,t and Dt
indicate the number of variables in the model. As usual, directed
arrows in a graphical model indicate the dependency between two
variables; the variables cu,t−1 depend on variables {θui ,t−1 |ui ∈
Cu,t−1 }. The variables φcom
and φut depend on variables {φcom
t
t−1 ,
u
φB
}
and
φ
,
respectively.
t−1
t−1
Now, let us give a more detailed technical account of our model.
Around user u, there exist multiple social circles. For each social
circle cu,t in time period t, there is a random parameter λcu,t indicating the importance of cu,t to u at t. User u’s interests θu,t are
composed of three parts: the personal aspect,
topic
 com theu common
B
aspect and the bursty aspect, i.e., θu,t = θu,t
, θu,t , θu,t
, where
the common topics are not only influenced by the user’s social circles, but also by his own previous interests. Therefore, we use a
com
Dirichlet distribution to derive the probability of θu,t
over xcom
u,t
as:

u
(a) If zt ∈ Ztu is a “private" topic, then θu,t,z
only depends on
u
θu,t−1,z at time t − 1.
(b) If zt ∈ Ztcom then the topic is dependent on friends in the
com
user’s social circle(s). θu,t,z
is computed from the collabt
com
orative effect θui ,t−1 at time t − 1 from the social circles
{ui |ui ∈ Cu,t−1 }.
(c) If zt ∈ ZtB is a “burst” topic, θuBi ,z,t is generated according
to a distribution of “burst" words in ui ’s tweets at time t.

Typically, traditional summarization does not cover the evolution
of a specific event. Given a split of a user’s history into time periods, the task of time-aware tweets summarization is to select the
most representative tweets for each time period, covering the whole
event evolution on a timeline. More precisely, given a set of tweets
D, a set of time periods T , and a maximum number of tweets per
period, N , time-aware tweets summarization aims to extract multiple sets of tweets RTt (1 ≤ t ≤ T ) from D, where for each time
period t, RTt = {dt,x1 , dt,x2 , . . . , dt,xN } is a set of representative tweets that summarize the period. Furthermore, personalized

com+B
xcom
u,t = αu,t θu,t−1 + (1 − αu,t )

X

λci θccom+B
i ,t−1

(1)

ci ∈Cu,t−1
com+B
com
B
where θu,t−1
refers to the set {θu,t−1
, θu,t−1
} at period t − 1,
which reflects user u’s interests for common
and
burst
topics at time
 com
B
t − 1, and θccom+B
refers
to
the
set
θ
,
θ
at period
c
,t−1
c
,t−1
,t−1
i
i
i
com+B
t − 1. The hyperparameter αu,t indicates the weight of θu,t−1

515

4.2

1. For each topic z, z ∈ Ztcom ∪ ZtB ∪ Ztu :

Inference and Parameter Estimation

Sampling-based methods for LDA rarely include methods for
optimizing hyper-parameters. In the TPM model, since αu,t and
fl
βz,t
indicate the weight of the results for period t − 1 for computations for period t, it is necessary to find an optimized process
fl
for hyper-parameters αu,t and βz,t
during our posterior inference.
Therefore, unlike many previous dynamic topic models, to infer
weighted priors we use a Gibbs EM algorithm [29] to handle the
approximate posterior inference step. For user u at time interval t,
we first jointly sample topic zi and parameter qi from the ith word
in tweet d (d ∈ Du,t ) over other variables. So for u’s tweets we
obtain:

B
• Draw φB
t ∼ Dir(βt ) ;


B
• Draw φcom
∼ Dir(βtcom φcom
t
t−1 , φ t−1 );
• Draw φut ∼ Dir(βtu φut−1 )
2. For each candidate tweet dt ∈ Dt :
• Draw ϑt ∼ Dir(αt , αtB ); rt ∼ Dir(γt );
• For each word w in dt
– Draw q ∈ M ulti(r); zw ∼ M ulti(ϑt );
∗ if q = 0: Draw w ∼ M ulti(φcom
z,t );
∗ if q = 1: Draw w ∼ M ulti(φuz,t );
∗ if q = 2: Draw w ∼ M ulti(φB
t );

p(ei = l, zi = z|W, e−i , Z−i , xu,t , σ, βtu ) ∝
f

3. For user u, u ∈ U :

z 0 ∈Z fl


B
• Draw θu,t ∼ Dir( xuu,t , xcom
u,t , αt );

(nu,t
d,z,0 −i +

·

nu,t
d,−i + 3σ

(2)

f

l
nu,t
d,z,−i + xu,z,t

P

nu,t
d,l,−i + σ

fl
xu,z
0 ,t )

·

l
nu,t
w,z,−i + βt

P
w0 ∈Nu,t

nu,t
w0 ,z,−i +

f
Nu,t βt l

,

where l indicates the possible values of variable e for the ith word
in tweet p, and the fl indicate the corresponding kind of topics
when ei = l. For private and common topics in u, i.e., l = 0, 1, in
Equation 2, nu,t
d,l,−i indicates the number of times that words in d
are assigned to label l except for the ith word, whereas nu,t
d,−i indiu,t
cates the sum of nu,t
for
all
values
of
l.
Furthermore,
n
d,l,−i
d,z,−i is
the number of times that tweet d is assigned to topic z excluding the
ith word in d, whereas nu,t
w,z,−i indicates the number of times that
word w is assigned by topic z excluding the ith word. According to
Figure 3, if ei = 2, we are dealing with a “bursty" topic, so the vocabulary only refers to the set of “bursty" keywords in {Du,t , Dt },
B
then xB
u,t in Eq. 2 equals to αt .
For the process of sampling candidate tweets from Dt , we have
a similar procedure, as follows:

• Draw πt ∼ Dir(σt );
• For each word w ∈ du,t , where du,t ∈ Du,t :
– Draw e ∼ M ulti(π); zw,t ∼ M ulti(θu,t )
∗ if e = 0: Draw w ∼ M ulti(φcom
z,t );
∗ if e = 1: Draw w ∼ M ulti(φuz,t );
∗ if e = 2: Draw w ∼ M ulti(φB
t );
Figure 3: Generative process for the TPM model.
com+B
in Equation 1 that we use to calculate θu,t
. Here, the value of
P
com+B
1
θci ,t−1 is equal to C
θui ,t−1 , where ui ∈ Cu,t−1 .
| u,t |
u
For private topical aspects θu,t
, we use a Dirichlet distribution
u
u
over xt = θu,t−1 that is derived from values in period t − 1. For
bursty topics in period t , we only focus on those “burst" words that
have a high term frequency within period t. Similar to [32], we define a keyword to be “bursty" if its frequency nw,t at time t is above
B
a threshold value. We derive θu,t
from a Dirichlet distribution over
B
the hyperparameter αt .
For a tweet in Dt that is posted during time period t, a probabilistic distribution ϑt over topics Zt = Ztu ∪ Ztcom ∪ ZtB is derived
from a Dirichlet distribution over the hyperparameter αt .
For each word w in tweet dt , dt ∈ {Du,t , Dt } proposed during period t, we assign a specific topic z from u’s interests θu,t
or distribution ϑt for candidate documents. For topic aspects z
(z ∈ Ztcom ∪ ZtB ∪ Ztu ), we introduce three kinds of multinomial
com
distribution φcom
, φut and φB
,
t
t to reflect the probability over Z
Z B and Z u , respectively. Based on [13, 30], we assume that the
common and personal topic propagations follow a Dirichlet distribution over the value from the previous interval’s distributions, with
a weighted prior βt = {βtcom , βtu }: for common topics z ∈ Ztcom ,
B
we use the Dirichlet distribution to infer from φcom
t−1 , φt−1 ; for
u
u
u
private topics z ∈ Zt , φt is derived from φt−1 .
This concludes the technical account of the graphical model depicted in Figure 2. After computing the models for period t for
all users in U, we update the edge weights for the social circles
(λu,ci ,t ), using related users’ interests θ and current social circles.
Inference for our topic modeling process will then move on to period t + 1. The generative process for the TPM model at time
interval t, 0 < t < T , is described in Figure 3.

p(qi = l, zi = z|W, d−i , Z−i , αt , γ, βtu ) ∝
f

z 0 ∈Z fl

(3)

f

ntd,z,−i + αt l
P

ntd,l,−i + γ
·
ntd,−i + 3γ

f

ntd,z,0 −i + Z fl αt l

·

ntw,z,−i + βt l
f

P
w0 ∈Nt

l
nu,t
w0 ,z,−i + Nu,t βt

.

Meanwhile, every time after sampling for p(ei = l, zi = z) and
fl
p(qi = l, zi = z), we optimize α
bu,t and βbz,t,t−1
by maximizing
the likelihood posterior distribution
p(W |Φt−1 , xu,t−1 , αB , βt , σ, γ),
so we get
P
α
bu,t = α
bu,t ·

P

(θu,t−1,z −

z∈Ztcom

λθci ,t−1 )Au,z,t

ci ∈Cu,t−1

Ψ(ncom
u,t + αu,t ) − Ψ(αu,t )

(4)

and
P
f

f

l
l
β̂z,t
= β̂z,t
·



fl
fl
w,z
w,z
φt−1,w
Ψ(nw,z,t
+ yt,t−1
) − Ψ(yt,t−1
)

w∈Nt
f

l
Ψ(nz,t
+ βz,t ) − Ψ(βz,t )

where Ψ(x) is defined by Ψ(x) =
Ψ(ncom
u,z,t

+

∂ log Γ(x)
,
∂x

xcom
u,z,t )

−

(5)

Au,z,t refers to

Ψ(xcom
u,z,t ),

w,z
and yt,t−1
is defined as βtcom φcom+B
.
t−1
Algorithm 1 summarizes the Gibbs EM sampling inference based
on the equations that we have just derived. During the Gibbs EM

516

[:
We calculate the saliency of ci after normalizing SIM into SIM
X
d ci ,t , θcj ,t |θu,t ) · λu,ci ,t + (1 − µ) (8)
λu,ci ,t = µ
sim(θ
|Cu,t |

Algorithm 1: Gibbs EM Sampling Process during period t
Input: βt , β B , αB , αt , Xu,t , Φft−1 , dt , U, Dt and R
f
Output: β̂t l ,b
αt ,he, zi and hq, zi
Initialize βt , β B , αB , αt ; Topic assignment for all words
for u ∈ U do
r = 0;
for r<R do
E-Step:
for d = 1 to Du,t do
for i = 1 to Nd do
Draw hei , zi i from Eq. 2
u,t
u,t
Update nu,t
e,0,i , ne,z,i and nw,z,i
end
end
for d = 1 to Dt do
for i = 1 to Nd do
Draw hqi , zi i from Eq. 3
Update ntq,l,i , ntd,z,i and ntw,z,i ;
end
end
M-Step:
fl
fl
fl
Calculate θu,t
, φw,t
, ϑd,t
, and λu,ci from Eq. 6, 8;
(r)

i6=j

4.3

Time-Aware Summarization

After Gibbs EM sampling, for each candidate tweet dt at time
t, we have two parametric distributions ϑt and φt that reflect the
topic-tweet distribution and the word-topic distribution, respectively.
I.e., P (zt |dt ) = θzt ,dt and P (w|zt ) = φz,t,w . For user u at time
t, we now derive the distribution of interests over topics θu,t , i.e.,
P (zt |u, t).
Given the distribution θu,t , one intuitive way to get the most
meaningful tweets is to extract the most similar tweets with θu,t
from among a candidate set Dt . However, a high-degree relevance
in latent topic distributions cannot be taken as the only criterion in
our tweet selection. Thus after extracting a set of relevant tweets
Rt from Dt , there are three key requirements for an ideal summary [16] that we need to consider in generating a tweet summary:
novelty, the coverage and the diversity.
Novelty calculates the semantic divergence between the currently
selected set RTu,t and the results in previous time periods RTt0 .
Our intention is to make the current results as different as possible
from previous results as much as possible. Therefore, we have:
X
LN (RTt |RTt0 ) =
minp0 ∈RTt0 (div(ϑp , ϑp0 |θu,t )) (9)

f ,(r)

l
Maximize α
bu,t and β̂z,t
from Eq. 4, 5;
r = r + 1 and go to E-Step;

end

p∈RT

end

where the divergence div(ϑp , ϑp0 |θu,t ) between ϑp and ϑp0 are
calculated based on Equation 7.
Furthermore, a tweet summary should contain important aspects
from all related tweets and minimize the information loss with the
set of all candidate tweets. Thus, given θu,z,t , the coverage between RT and Dt is calculated as follows:

sampling process, we estimate the parameters of user u’s interests
e=l
θu,z,t
, the probability of topics over candidate tweets ϑq=l
d,z,t , topic
fl
distributions over words φw,z,t
and {πd,l,t , rd,l,t } as follows:
f

l
θu,z,t

=

P

f

=

n
+ αz,t
P d,z,t
nd,z0 ,t + αz0 ,t

=

rd,l,t

=
=

div(ϑd,z ,ϑd0 ,z |θu,z,t )

(10)

ϑd,z
ϑd,z
− ϑd0 ,z ln
θu,z,t
θu,z,t

(11)

Diversity calculates the information divergence among all tweets
within the current candidate result set. Ideally, the tweet summary
results have the largest possible difference in topic distributions
with each other. The equation is as follows:
X
Y
LD (RT ) =
maxz div(φw,z,t , φw0 ,z,t |
ϑd,z ) (12)

(6)

z∈Z fl

πd,l,t

P
d0 ∈Dt

div(ϑd,z , ϑd0 ,z |θu,z,t ) = ϑd,z ln

f

l
nw,z,t + βw,t
P
fl
nw,z,t + βw,t

−minz

e

where the divergence div(ϑd,z , ϑd0 ,z |θu,z,t ) is calculated as follows:

z∈Z fl
fl
φw,z,t

X
d∈RT

fl
+ xu,z,t
fl
nu,t
z 0 + xu,z 0 ,t

nu,t
z
z∈Z fl

l
ϑd,z,t

LC (RT |Dt ) =

nu,t
d,l + σ
nu,t
d + 3σ

w,w0 ∈RT

ntd,l + γ
ntd + 3γ

d∈Dt

Q
where we compute the divergence div(φw,z,t , φw0 ,z,t | d∈Dt ϑd,z )
in the same way as Equation 11.
The exact process for generating RTu,t given user u is shown
in Algorithm 2. Illuminated by a previous work [33], an iterative
optimization algorithm is used to select the set RTu,t . During each
iteration n, we extract tweet dx such that dx ∈ Rt ∩ dx ∈
/ RTu,t to
(n)
substitute dy ∈ RT u,t when the saliency gain S((RTu,t −)∪dx )−
S(RT u,t ) gets a maximum value. The algorithm will converge
when S(RT u,t ) reaches its maximum value.

To compute the weight λcu,t , we use a Markov random walk
strategy, which calculates saliency of a social circle based on “voting” from others. Since each social circle can be considered as a
set of users, an interest distribution θccom+B
for each social ciri ,t−1
P
cle ci can be computed as u0 ∈ci θucom+B
.
Thus we compute
0 ,t−1
com+B
u,t
a θu,t
-based similarity matrix SIM
among different social
circles, where each item SIM u,t
i,j is computed based on the divergence between two items:
X
θc ,z
θc ,z
div(θci , θcj |θu ) =
θci ,z ln i − θcj ,z ln i
(7)
θ
θu,z
u,z
z∈Z

5.

EXPERIMENTAL SETUP

For our experiments we employ a Twitter dataset that includes
both social relations and tweets: we crawl tweets via the Twitter

517

6

x 10

Algorithm 2: Iterative Process for RTu,t Generation.
Input : Dt , RTu,t0 , θu,t , φt , N ;
Output: RTu,t ;

3.5

Calculate Kullback-Leibler divergence KL(ϑd,t , θu,t );
Rank and extract relevant tweets to Rt by e−KL(ϑd,t ,θu,t ) ;
Initialize: Extract N tweets from Rt to RT u,t ;
repeat
Extract Xt = {dx ∈ Rt ∩ dx ∈
/ RTu,t };
for dx ∈ Xt , ∀dy ∈ RT u,t do
Calculate SRT u,t = F (LC · LN · LD );
Calculate
∆Sdx ,dy = S((RTu,t − dy ) ∪ dx ) − S(RT u,t );
end
D
E
D
E
Get dˆx , dˆy that dˆx , dˆy = arg maxdx ,dy ∆Sdx ,dy ;

2.5

1.5

400

0.5
100

500
Number of Tweets

900

1000
3000
Number of Friends

5000

(a)
(b)
Figure 4: Histograms of the number of users and tweets in our
dataset: the left (a) indicates the number of tweets per user
in our dataset where the y-axis denotes the number of tweets;
while the right (b) indicates the number of tweets per user
with its number of friends in Twitter, where y-axis indicates
the number of tweets the user wrote and the x-axis indicates
the number of friends.

RTu,t = (RTu,t − dˆy ) ∪ dˆx ;
until ∀∆Sdx ,dy < ε;
return RT u,t .

lar to [10], to each Wikipedia article to ranking sentences, using the
tweet dt as the query. This calculates the score of each sentence via
“votes” from other sentences in a document. Figure 5 shows 4 example tweets and the appended sentences. Here, the left text box
in each item is a tweet and on the right we show the identified sentences from the linked Wikipedia articles.

streaming API,2 which contains a random sample of around 10%
of all items posted on Twitter. Timestamps in our dataset are from
November 1, 2009 to December 31, 2010; the 2009 part contains
47,373,408 tweets and 562,361 users, while the numbers for 2010
are 295,145,421 and 5,828,356, respectively. Figure 4(a) shows the
statistics of the number of tweets per user in our dataset, where we
can find that most users (75.2%) in our dataset wrote fewer than
100 tweets. For crawling the social relations, we use the dataset
from [15], which includes social relations for all users on Twitter
until July 2009. In our experiments, we use only those tweets and
users that appear in both datasets. In our experiments we assume
social relations among users to remain the same over the entire time
period.
Since it is impossible to evaluate the effectiveness if a user posted
nothing on Twitter, sparse postings obstruct our experimental evaluation. We therefore only consider users who posted a sufficient
number of tweets for our evaluation: we collect users who post
over 100 tweets in our dataset. This results in a subset containing
32,659 users. Thereafter we use social relations to build the social
circles around those users. Figure 4(b) shows the number of tweets
of these users (y-axis) versus the number of friends on the x-axis.
We further remove non-English tweets through automatic language
identification [3]. We remove stop words and apply Porter stemming [23].

5.1

Number of Tweets

User Numbers

800

5.2

Experimental Setup

Following existing topic models [11], we set pre-defined values
for the hyperparameters αt and βt in our graphical model: for the
weighted parameter αu,t and βt , we set 50/Ktu to αu,t and 0.5 to
βt respectively. And we set 50/KtB to αB and 0.5 to β B respectively. For the hyperparameters γ and σ in TPM, as defined in [14],
we set σu = γcom = 0.5 and γu = σcom = 0.3. For burst topics
we set γB = σB = 0.2 in our experiments. The initial value of
λu,ci ,t−1 for each social circle of u is set to 1/Cu,t , the parameter
µ is set as 0.85; and ε in Algorithm 2 is set to 0.0001. For the number of topics in our topic modeling process, the default values for
Z0u and Z0com in our experiments are set to 100, respectively. To
optimize the number of topics, we compare performance in various
values and discuss it latter.
Statistical significance of observed differences between two comparisons is tested using a two-tailed paired t-test. In our experiments, statistical significance is denoted using N for significant differences for α = 0.01, or M for α = 0.05.

Data Enrichment

5.3

Since each tweet is only up to 140 characters long, the amount of
textual evidence to work with is very limited. To remedy this, we
employ a state-of-the-art method for linking tweets to Wikipedia
articles [20]. In particular, we employ the so-called CMNS method
that uses the prior probability that Wikipedia article c is the target
of a link with anchor text q within Wikipedia:

Evaluation Metrics

where Lq,c denotes the set of all links with anchor text q and target
c.
After we have obtained three Wikipedia articles with the highest CMNS score, we extract the most central sentences from these
Wikipedia articles and append them to the tweet. In particular, we
apply a query-sensitive graph-based summarization method, simi-

Evaluating the effectiveness of time-aware tweets summarization is a challenging task, especially in the absence of explicit user
feedback. One possible solution is to use evidence from users themselves: we use a user’s retweeted post(s) at time t + 1 as the ground
truth to evaluate performance of comparisons at time t.
We measure the quality of summaries by counting overlapping
textual units between the generated results and the ground truth results. In our experiments, we adopt the ROUGE evaluation metrics
[17], a widely-used recall-oriented metric in the task of document
summarization that evaluates the overlap between a gold standard
and candidate selections.3 In our experiments, ROUGE-1 (unigram
based method), ROUGE-2 (bigram based method) and ROUGE-W
(weighted longest common sequence) are used as evaluation metrics.

2

3

CMNS (c, q) = P

|Lq,c |
,
|Lq,c0 |

(13)

c0

https://dev.twitter.com/docs/streaming-apis.

518

Version 1.5.5 is used in this paper.

0.5

Waiting for
Charlie
Sheen to
say the
Bush
administrati
on was
behind the
attack on
his wife.

She appeared on the dramatic
series The West Wing for four
years (2002–2006) in the
recurring role of presidential
secretary Deborah Fiderer.
Nominated—Screen Actors
Guild Award for Outstanding
Performance by an Ensemble
in a Drama Series (2003, 2005)
Sheen has since become a
prominent advocate of the 9/11
Truth movement.
He was characterized by the
press as believing the 9/11
Commission was a whitewash
and that the administration of
former President George W.
Bush may have been
responsible for the attacks.
After the terrorist attacks on
September 11, 2001, Bush
declared a global War on
Terrorism and, in October
2001, ordered an invasion of
Afghanistan to overthrow the
Taliban, destroy Al-Qaeda, and
to capture Osama bin Laden.
On December 25, 2009, Sheen
was arrested for assaulting his
wife, Brooke Mueller in Aspen,
Colorado.

Tyranny
Disguised
As Health
Care
Reform &
How To
Truly
Reform
Health
Insurance:

Hyundai
Enhances
Assurance
for 2010:
This
compliment
ary service
is termed
Hyundai
Assurance

Health care reform in the
United States
President Obama gave a
speech at a rally in
Pennsylvania explaining the
necessity of health insurance
reform and calling on Congress
to hold a final up or down vote
on reform

ROUGE−1

whenever i
see lily
tomlin, i
call her
debbie
fiderer

She is Executive Assistant to
the President, and is portrayed
by noted actor and comedienne
Lily Tomlin.

The law includes health-related
provisions that take effect over
several years, including
expanding Medicaid eligibility
for people making up to 133%
of the federal poverty level
(FPL)

0.4

0.35

On January 6, Hyundai
reported sales of December
2008 fell to 24,037, from
46,487 in previous year and
sales for the year dropped
14%, a day after the company
launched 'Hyundai Assurance'
in order to spark sales amid
tough economic conditions.

1 day

3 days

5 days
7 days
Granularities of Time

11 days

14 days

Figure 6: Performance of TPM-ALL with various granularities
of time periods.
static topic models, results at time t, 1 ≤ t ≤ T are calculated after
re-modeling for all past data before period t.
To evaluate the effectiveness of results to personalized aspect,
we introduce several other sentence extraction procedures from the
area of document summarization (without personalization) as baselines: LexRank and Centroid are two widely-used unsupervised
document summarization methods, where LexRank [26] is a graphbased method for ranking tweet as “votes” from other tweets, and
Centroid [24] applies the MEAD summarization method that uses
statistical and structural features in tweets selection.

In 2010, a Consumer Reports
reliability survey ranked
Hyundai (including Kia) as the
fourth-best automaker.
U.S. Hydrogen Highway Paved
With Public-Private Research
Funds

Figure 5: Four examples for entity linking and ranking corresponding to four individual tweets, where the textbox on left
side indicates the original tweet while the textbox on the right
side shows the extracted related sentences. A mixture of the
tweet and extracted wiki sentences will replace the original
tweet in our experiments.

5.4

0.45

5.5

Granularities and Number of Topics

To test the optimal granularity of time intervals, we examine
ROUGE-1 performance of TPM-ALL with different values for granularities, shown in Figure 6. The performance of TPM-ALL in
terms of ROUGE-1 peaks when the granularity is set to 7 days.
With fewer than 7 days, performance keeps increasing because
adding more days reduces sparseness; but after 7 days, due to the
increase in irrelevant and noisy tweets, the ROUGE-1 score decrease. Thus, we set the granularity to 7 days in the remainder of
our experiments.

Baseline Comparisons

Given the TPM modeling introduced in Section 4.1, our contribution is twofold: (1) we introduce collaborative influence to user’s
interests detection; (2) we adopt time-aware propagation to infer
topics. To evaluate the influence of social circles and time-aware
topics, besides our overall TPM-based strategy, we also evaluate
the performance of the model that only includes (1) the collaborative influence or only the (2) time-aware propagation, respectively.
We write TPM-ALL for the overall process as described in Section 4.1, which includes both the social influence modeling and
time-aware topic and interests tracking. We write TPM-SOC for
the model that only considers users’ social influence (so excluding
time-aware topic propagation and it doesn’t consider if some topic
is private or not). We write TPM-TOP for the model that uses a
user’s own tweets (without social circles but considering topic and
interests propagation with the time).
To evaluate our proposed method in more detail, in our experiments the baselines not only include widely-used topic models,
but also recent user behavior models on Twitter. For those topic
models, we use the Author-Topic Model (AT) [26] and the TwitterLDA [37] as baselines for topic models: (AT) focuses on various
users’ interests in one static corpus. Since each tweet only has one
author, AT’s process on Twitter coincides with the LDA modeling
process on all tweets written by a specific user. As an extension
of the author-topic model, Twitter-LDA (TLDA) classifies topics
into private topics and background topic by introducing one binomial distribution. For comparison, we use one more state-of-the-art
use behavior model, UBM [32]; here, a user’s interest is tracked by
a mixture graphical model that considers background knowledge,
social interests and the user’s own interest. The final baseline that
we consider is TF-IDF, which uses TF-IDF to re-calculate SRT u,t
in Algorithm 2. Finally, we also use SUM-TF, a baseline used in
[4] that extract tweets by ranking tf scores, and Random, which
extracts tweets randomly in each period.
For the baseline topic models, we use a similar tweet selection
method as in Algorithm 2 to select tweets in each time interval. For

Author Topic model
TPM−SOC model

Perplexity

8000
6000
4000
0

100

200
300
Number of Topics

400

Figure 7: Perplexity performance with different number of topics in Author topic model and TPM-SOC model;
Optimizing the number of topics is a problem shared between all
topic modeling approaches. Similar to previous work [2, 11, 32],
we introduce the perplexity of a held-out test set to evaluate the
performance of our topic models. The perplexity, usually used in
language modeling, focuses on the inverse of the geometric mean
per-word likelihood, which is calculated as follows:
 P P

log p(w)
t∈T w∈Dt

P
(14)
P erplexity(W ) = exp −
dt
t∈T

where p(w) indicates p(w) = p(w|z)p(z). Thus, a lower perplexity score indicates a better generalization performance [2]. Figure 7
shows the results of perplexity values for the author-topic model

519

of tweets selected per period (40 or 60). We separate users into
3 classes by counting their tweets: (1) less than 400 tweets; (2) between 400 to 800; and (3) more than 800 tweets. As shown in
Figure 10(a) and (c) that focusing on ROUGE-1, the difference between TPM-ALL and TPM-TOP is bigger for users with up to 400
tweets than for those with more than 400. This can be explained by
the fact that the collaborative filtering used in TPM-ALL becomes
more effective when there is a bigger data sparseness issue to overcome. In terms of ROUGE-2, similar results can be found in Figure
10(b) and (d).

and the TPM-SOC model with differing numbers of topics on our
held-out test set. After the number of topics becomes larger than
300, the perplexity of both approaches starts to flatten out. We
find that TPM-SOC outperforms the author-topic model with better generalization performance. For TPM-ALL and TPM-TOP we
set the number of “private" topics and “common" topics to 150,
separately.

6.

RESULTS AND DISCUSSION

In this section we provide an answer to the following research
questions. (1) How does the TPM-based TaTS strategy perform on
time-aware tweets summarization (§6.1)? (2) How does the TPMbased TaTS strategy perform on social-aware tweets summarization? (§6.2)? And (3) what is the overall performance for TPM on
the task of personalized TaTS (§6.3)?

6.1

6.3

Time-Aware Comparisons

To illustrate the performance at different time periods, the evaluation results of the TPM-ALL, TPM-TOP, UBM and AT strategies at different time periods are shown in Figure 8, in terms of
ROUGE-1, ROUGE-2 and ROUGE-W, respectively. We select 10
contiguous weeks from November 1, 2009 onwards as the test period and separate it into 10 periods.
In Figure 8 we observe that the AT model obtains the worst
performance, while both TPM-ALL and TPM-TOP outperform all
other strategies in terms of ROUGE metrics at all time intervals.
This demonstrates the advantage of TPM-based strategies in timeaware comparisons. In Figure 8, we observe a “cold-start” phenomenon, which results from the sparseness of the context in the
first time period. In that condition, TPM-ALL and TPM-TOP are
nearly equivalent to the UBM and AT since there are neither social
circles nor burst topics during the first time period. After that, the
performance of the TPM based methods keeps increasing over time
until it achieves a stable performance after t = 3. We find that TPM
based strategies are sensitive to time-aware topic drifting. Meanwhile, we find that TPM-ALL performs better than TPM-TOP in
Figure 8. TPM-ALL detects user’s interests using social circles
whereas TPM-TOP ignores them.

6.2

Overall Performance

Table 2 shows the average performance of our TPM-based strategies and baselines, in terms of ROUGE-1, ROUGE-2 and ROUGEW, based on all candidate tweets in all time periods. We find that
our method outperforms the baselines in every case. Except for our
TPM-based strategies, UBM get the best performance than others.
Since summarization baselines are not sensitive to users’ interests,
thus we find that Centroid, Lex-R (short for LexRank), and SUMTF do not perform well. Among the topic models, we found that
the AT-based method yields almost the worst performance. This
can be explained by the fact that the topic modeling procedure in
AT does not capture topic drift and users’ social circles.
We evaluated the performance of the various approaches in terms
of the three ROUGE metrics for a varying number of tweets selected per period, i.e., N = 40 and N = 60. As shown in Table
2, TPM-ALL performs better than all baselines on all metrics. For
N = 40, TPM-ALL achieves an increase of 10.6%, 11.6% and
8.9% over UBM in terms of ROUGE-1, ROUGE-2, and ROUGEW respectively. For N = 60, TPM-ALL gives an increase of
11.2%, 11.2% and 10.1% over UBM. For the dynamic version
without social influence, TPM-TOP outperforms all other baselines
also, which indicates the effectiveness of detecting dynamic topics.
We further compare TPM-TOP with UBM: for N = 40, TPMTOP offers relative performance improvements of 4.1%, 6.25% and
4.8%, respectively, for the ROUGE-1, ROUGE-2 and ROUGE-W
metrics, while the relative improvements are 7.8%, 6.7% and 7.3%
on the same metrics for N = 60. We find that TPM-ALL outperforms the UBM baselines with a statistical significance difference at level α < 0.01 in terms of all ROUGE metrics, whereas
TPM-TOP and TPM-SOC outperforms UBM with a statistical significance difference at level α < 0.05.

Social-Aware Comparisons

To evaluate the influence of social circles in our proposed strategy, we investigate the performance under various numbers of social circles. From our dataset, we extract users with different numbers of social circles and compare the performance of our methods
on these data sets in terms of ROUGE. In Figure 9 we plot the values of ROUGE-1, ROUGE-2 and ROUGE-W in (a) to (c), respectively. For each figure, we compare our strategies that do consider
social circles, TPM-ALL and TPM-SOC, against the TPM-TOP
and UBM methods under varying number of social circles.
We observe from Figure 9(a) that the performance in terms of
ROUGE-1 changes with the number of social circles, and the value
increases and achieves a maximal value between 3 and 5 social
circles. After that, the value decreases rapidly; redundant and irrelevant “relations” seem to enter the picture. Another plausible
explanation concerns the difference of user characteristics in various social circles. Since the UBM and TPM-TOP models do not
consider the social influence, their ROUGE values keep constant
for different numbers of social circles. We observe a similar behavior in Figure 9(b) and 9(c) in terms of ROUGE-2 and ROUGE-W.
To evaluate the effect of collaborative filtering in TPM for various classes of users, especially for “passive” users on Twitter who
rarely write a tweet, we compare the performance of different users
in terms of ROUGE metrics with varying values of the number

7.

CONCLUSION AND FUTURE WORK

We have considered the task of personalized time-aware tweets
summarization, based on user history and influences from “social
circles.” To handle the dynamic nature of topics and user interests
along with the relative sparseness of individual messages, we have
proposed a time-aware user behavior model. Based on probabilistic
distributions from our proposed topic model, the tweets propagation model, we have introduced an iterative optimization algorithm
to select tweets subject to three key criteria: novelty, coverage and
diversity. In our experiments we have verified the effectiveness of
our proposed method, showing significant improvements over various state-of-the-art baselines.
As to future work, we aim to employ a user-study to enhance the
accuracy of interest detection, e.g., via an online evaluation. Another future direction is to take more information and features into
account for our task: our current experiments ignore, e.g., URLs
appearing in tweets which could enhance our entity linking setup. It
will also be interesting to consider other features for modeling, such
as geographic or profile information. Finally, our current model is
evaluated based on fixed time intervals, which might not accurately

520

TPM−ALL
TPM−TOP
UBM
AT

0.5

TPM−ALL
TPM−TOP
UBM
AT

0.17

ROUGE−2

0.4

ROUGE−W

0.15

0.45
ROUGE−1

TPM−ALL
TPM−TOP
UBM
AT

0.13

0.15

0.11
0.35

0.09
0.3

0.13
1

2

3

4

5
6
Timeline

7

(a) ROUGE-1

8

10

1

2

3

4

5
6
Timeline

7

8

9

10

1

2

3

(b) ROUGE-2
Figure 8: Time-aware performance in terms of ROUGE metrics.
TPM−ALL
TPM−SOC
TPM−TOP
UBM

0.42

4

5
6
Timeline

7

8

9

10

(c) ROUGE-W

TPM−ALL
TPM−SOC
TPM−TOP
UBM

0.14

ROUGE−2

0.46
ROUGE−1

9

0.13

0.12

0.11

0.38
0

2

4
6
Number of Circles

8

10

0

2

4
6
Number of Circles

8

10

(a) ROUGE-1
(b) ROUGE-2
(c) ROUGE-W
Figure 9: ROUGE-1 and ROUGE-2 performance with increasing numbers of social circles.
TPM−TOP
TPM−ALL

TPM−TOP
TPM−ALL

0.15

ROUGE−1

ROUGE−2

ROUGE−1

0.5

0.45

0.13

0.4

400<x<=800
Number of Users’ Tweets

x>800

0.16

0.5

x<=400

400<x<=800
Number of Users’ Tweets

x<=400

x>800

0.15

0.14

0.44

0.11

x<=400

TPM−TOP
TPM−ALL

0.56

ROUGE−2

TPM−TOP
TPM−ALL

400<x<=800
Number of Users’ Tweets

x>800

x<=400

400<x<=800
Number of Users’ Tweets

x>800

(a) ROUGE-1, N=40
(b) ROUGE-2, N=40
(c) ROUGE-1, N=60
(d) ROUGE-2, N=60
Figure 10: Performance for different kinds of users: users in our dataset are classified by their number of tweets.
reflect bursty topics on Twitter. Therefore, a novel graphical model
that includes dynamic time bins instead of the fixed time granularities, will be another direction for future research.

(KNAW), and the Netherlands eScience Center under project number 027.012.105.

Acknowledgements. This research was supported by the European
Community’s Seventh Framework Programme (FP7/2007-2013) under grant agreements nr 258191 (PROMISE Network of Excellence) and 288024 (LiMoSINe project), the Netherlands Organisation for Scientific Research (NWO) under project nrs 640.004.802,
727.011.005, 612.001.116, HOR-11-10, the Center for Creation,
Content and Technology (CCCT), the BILAND project funded by
the CLARIN-nl program, the Dutch national program COMMIT,
the ESF Research Network Program ELIAS, the Elite Network
Shifts project funded by the Royal Dutch Academy of Sciences

8.

REFERENCES

[1] D. Blei and J. Lafferty. Dynamic topic models. In ICML
2006, pages 113–120, 2006.
[2] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation.
Journal of machine Learning research, 3:993–1022, 2003.
[3] S. Carter, W. Weerkamp, and M. Tsagkias. Microblog
language identification: overcoming the limitations of short,
unedited and idiomatic text. Language Resources and
Evaluation, 2012.

521

Table 2: Overall ROUGE Performance for All Comparisons
TPM-TOP TPM-SOC UBM TLDA
AT
TF-IDF Centroid

Metrics

TPM-ALL

ROUGE-1
ROUGE-2
ROUGE-W

0.428 N
0.125 N
0.159 N

0.403 N
0.119 M
0.153 N

0.395 N
0.387 0.374 0.355
0.341
0.116 M
0.114 0.112 0.102
0.095
0.149 M
0.146 0.142 0.144
0.137
Cut-off of N = 60 tweets per period

ROUGE-1
ROUGE-2
ROUGE-W

0.513 N
0.149 N
0.197 N

0.497 N
0.142 M
0.191 N

0.482 N
0.139 M
0.189 N

Lex-R

SUM-TF

Random

0.302
0.081
0.118

0.291
0.077
0.115

0.274
0.079
0.105

0.252
0.037
0.076

0.362
0.097
0.131

0.369
0.102
0.135

0.329
0.095
0.119

0.281
0.041
0.081

Cut-off of N = 40 tweets per period

0.461
0.134
0.178

0.457
0.127
0.176

[4] D. Chakrabarti and K. Punera. Event summarization using
tweets. In ICWSM 2011, pages 66–73, 2011.
[5] K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and Y. Yu.
Collaborative personalized tweet recommendation. In SIGIR
2012, 2012.
[6] B. Connor, M. Krieger, and D. Ahn. Tweetmotif:
Exploratory search and topic summarization for twitter.
ICWSM 2010, pages 2–3, 2010.
[7] G. De Francisci Morales, A. Gionis, and C. Lucchese. From
chatter to headlines: harnessing the real-time web for
personalized news recommendation. In WSDM 2012, 2012.
[8] Q. Diao, J. Jiang, F. Zhu, and E. Lim. Finding bursty topics
from microblogs. In ACL 2012, 2012.
[9] Y. Duan, Z. Chen, F. Wei, M. Zhou, and H. Shum. Twitter
topic summarization by ranking tweets using social influence
and content quality. In COLING 2012, pages 763–779, 2012.
[10] G. Erkan and D. Radev. Lexrank: Graph-based lexical
centrality as salience in text summarization. JAIR, 22:
457–479, 2004.
[11] T. Griffiths and M. Steyvers. Finding scientific topics.
National Academy of Sciences, 101:5228–5235, 2004.
[12] T. Hofmann. Probabilistic latent semantic indexing. In
SIGIR 1999, pages 50–57, 1999.
[13] T. Iwata, S. Watanabe, T. Yamada, and N. Ueda. Topic
tracking model for analyzing consumer purchase behavior.
In IJCAI 2009, volume 9, pages 1427–1432, 2009.
[14] O. Jin, N. Liu, K. Zhao, Y. Yu, and Q. Yang. Transferring
topical knowledge from auxiliary long texts for short text
clustering. In CIKM 2011, 2011.
[15] H. Kwak, C. Lee, H. Park, and S. Moon. What is twitter, a
social network or a news media? In WWW 2010, pages
591–600, 2010.
[16] L. Li, K. Zhou, G. Xue, H. Zha, and Y. Yu. Enhancing
diversity, coverage and balance for summarization through
structure learning. In WWW 2009, 2009.
[17] C. Lin. Rouge: A package for automatic evaluation of
summaries. In ACL 2004, pages 74–81, 2004.
[18] H. Ma, I. King, and M. Lyu. Learning to recommend with
social trust ensemble. In SIGIR 2009, pages 203–210, 2009.
[19] H. Ma, D. Zhou, C. Liu, M. Lyu, and I. King. Recommender
systems with social regularization. In WSDM 2011, pages
287–296, 2011.
[20] E. Meij, W. Weerkamp, and M. de Rijke. Adding semantics
to microblog posts. In WSDM 2012, pages 563–572, 2012.
[21] J. Nichols, J. Mahmud, and C. Drews. Summarizing sporting
events using twitter. In IUI 2012, pages 189–198, 2012.
[22] M. Pennacchiotti, F. Silvestri, H. Vahabi, and R. Venturini.
Making your interests follow you on twitter. In CIKM 2012,
2012.

0.423
0.122
0.166

0.411
0.116
0.161

[23] M. Porter. An algorithm for suffix stripping. Program:
electronic library and information systems, 1980.
[24] D. Radev, H. Jing, M. Styś, and D. Tam. Centroid-based
summarization of multiple documents. Information
Processing & Management, 2004.
[25] D. Ramage, S. Dumais, and D. Liebling. Characterizing
microblogs with topic models. In ICWSM 2010, pages
130–137, 2010.
[26] M. Rosen-Zvi, T. Griffiths, M. Steyvers, and P. Smyth. The
author-topic model for authors and documents. In UAI 2004,
pages 487–494, 2004.
[27] B. Sharifi, M. Hutton, and J. Kalita. Summarizing
microblogs automatically. In NAACL 2010, 2010.
[28] H. Takamura, H. Yokono, and M. Okumura. Summarizing a
document stream. Advances in Information Retrieval, pages
177–188, 2011.
[29] H. Wallach. Topic modeling: beyond bag-of-words. In ICML
2006, pages 977–984, 2006.
[30] X. Wei, J. Sun, and X. Wang. Dynamic mixture models for
multiple time series. In IJCAI 2007, pages 2909–2914, 2007.
[31] J. Weng, E. Lim, J. Jiang, and Q. He. Twitterrank: finding
topic-sensitive influential twitterers. In WSDM 2010, pages
261–270, 2010.
[32] Z. Xu, Y. Zhang, Y. Wu, and Q. Yang. Modeling user posting
behavior on social media. In SIGIR 2012, pages 545–554,
2012.
[33] R. Yan, X. Wan, J. Otterbacher, L. Kong, X. Li, and
Y. Zhang. Evolutionary timeline summarization: a balanced
optimization framework via iterative substitution. In SIGIR
2011, pages 745–754, 2011.
[34] S. Yang, B. Long, A. Smola, N. Sadagopan, Z. Zheng, and
H. Zha. Like like alike: joint friendship and interest
propagation in social networks. In WWW 2011, pages
537–546, 2011.
[35] Z. Yang, K. Cai, J. Tang, L. Zhang, Z. Su, and J. Li. Social
context summarization. In SIGIR 2011, 2011.
[36] M. Ye, X. Liu, and W. Lee. Exploring social influence for
recommendation: a generative model approach. In SIGIR
2012, 2012.
[37] X. Zhao, J. Jiang, J. He, Y. Song, P. Achananuparp, E. LIM,
and X. Li. Topical keyphrase extraction from twitter. In ACL
2011, 2011.

522


Modeling the Uniqueness of the User Preferences for
Recommendation Systems
Haggai Roitman, Yosi Mass, Iris Eiron

David Carmel∗

IBM Research Haifa
Haifa 31905, Israel

Yahoo! Research
Haifa 31905, Israel

{haggai,yosimass,irise}@il.ibm.com

david.carmel@ymail.com

ABSTRACT
In this paper we propose a novel framework for modeling
the uniqueness of the user preferences for recommendation
systems. User uniqueness is determined by learning to what
extent the user’s item preferences deviate from those of an
“average user” in the system. Based on this framework, we
suggest three diﬀerent recommendation strategies that trade
between uniqueness and conformity. Using two real item
datasets, we demonstrate the eﬀectiveness of our uniqueness
based recommendation framework.
Categories and Subject Descriptors: H.3.3 [Information Search
and Retrieval] Information Filtering
General Terms: Algorithms, Experimentation
Keywords: Recommender Systems, User uniqueness, Popularity

tures “encoded” in user rating data can be derived. Based
on derived user preferences, we further show how the user’s
global uniqueness level can be estimated. The second strategy, termed POP (for popularity), assumes that the user has
no unique preferences, i.e., she actually “toes the line”, and
therefore, recommends poplar items that are likely to satisfy
the preferences of an average user of the system.
Finally, recognizing that every user preferences may actually lie in between the two extremes, we further propose
a hybrid recommendation strategy, termed POPERS, which
utilizes the user’s uniqueness level to trade between the two
pure strategies. As a proof of concept, using two real item
datasets, we evaluate the eﬀectiveness of the various recommendation strategies and demonstrate the important role
that user uniqueness may play for recommender systems.

1. INTRODUCTION
2. RELATED WORK

In recent years, recommender systems have gained immense popularity for information ﬁltering and personalization purposes. Existing recommendation methods can be
roughly classiﬁed into three main types: collaborative ﬁltering (CF), content-based (CB), and hybrids of the two [1].
While remarkable research has been done and many instantiations of various CB and CF methods have been proposed,
much less eﬀort has been made to take into consideration the
uniqueness of the user preferences for recommendation.
In this work we propose a novel framework for modeling the uniqueness of the user preferences for recommendation systems. User uniqueness is determined by learning to
what extent the user’s item preferences deviate from those
of an “average user” in the system. Using this framework,
we study three alternative recommendation strategies that
are based on dual user uniqueness assumptions.
The ﬁrst strategy, termed PERS (for personalization), recommends items that satisfy the user unique preferences. For
that, we extend the user model we previously suggested
in [7] and show how user preferences for various item fea∗

We now shortly review several related works. A survey on
state-of-the-art recommendation methods is available at [1].
This work is based on an earlier work we did in the domain
of user proﬁling [7]. In [7], user content preferences were
implicitly estimated from web browsing logs by utilizing the
collection of users of the system (termed user community
in [7]) as an auxiliary reference. Though, while the basic
model in [7] considers only textual data, this work considers
both diverse item features and explicit user rating data. In
addition, [7] neither focused on user uniqueness modeling
nor its usage for recommender systems.
In this work we combine a recommendation method based
on user’s proﬁle with a recommendation method based on
item popularity. Several previous works have studied the usage of popular items for recommendation, and more specifically, its combination with more traditional recommendation methods [6, 2, 3, 4]. Recommendation of popular items
has been studied in the context of the cold-start problem of
recommender systems [4]. Ahn [2] has studied various popularity characteristics for recommendation and demonstrated
that recommendation of popular items can be superior to
other methods (for example, to CF) under data sparsity and
cold-starting situations. Clema and Cano [3] have further
shown that collaborative ﬁltering methods are more prone
to popularity bias. Rashid et al. [6] has combined CF with
popularity by biasing CF recommendations towards popular items. Our work complements these works by further
demonstrating how user uniqueness can be estimated and
utilized to automatically trade between personalization and
popularity based recommendations.

This work was done while the author worked in IBM

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

777

3. FRAMEWORK

Hence, for a given user u ∈ U , the marginal contribution
of each feature value f.v to the divergence of the user preferences from that of the average user of U derives its ﬁnal
weight:

3.1 Preliminaries
Let I denote a collection of items and F a set of n features. Let Vf be the vocabulary of feature f ∈ F , i.e., an
ordered set of all possible feature values. For example, a
movie may have the features title, director, actors, genre,
and Vgenre = {comedy, drama, romance}. We further denote
by f.v a speciﬁc
feature value in Vf (e.g., genre.comedy).


be a binary vector over
Let if = if.v1 , if.v2 , . . . , if.v

u
u
wf.v
 Pf.v
log

|Vf |



3.3

(1)

f|

u
wf.v
is a real number that corresponds to the relative importance of feature value f.v for user u. For simplicity, in
this work, we assume that all features are equally important
to all users of the system.
Finally, the scalar β u ∈ [0, 1] models the uniqueness level
of user u within her community U . The lower the value of
β u , the higher the uniqueness of u.

In this work, we derive a given user u’s preferences from
u’s ratings to various items in I. Let riu be the rating given
by user u ∈ U to item i ∈ I. Furthermore, for a given item
i ∈ I, let Ui be the set of users who rated item i.
Given a feature f ∈ F , let If.v denote the subset of items
such that if.v = 1. We now derive Pf , the probability distribution of the community’s preferences over the feature
vocabulary Vf , by:
Pf.v  

i∈If.v
f.v  ∈Vf

log





log

i∈If.v 

riu


u∈Ui

riu



(2)

u
Similarly, for a given user u, we deﬁne If.v
to be the set
of items in If.v rated by u. The probability distribution of
u’s preferences over the feature vocabulary Vf , Pfu , is then
estimated by:


u
Pf.v
 (1 − λ) 

u
i∈If.v

f.v  ∈Vf



riu

i∈I u 
f.v

riu

+ λPf.v

(3)

3.4

where λ = 0.01 is a (ﬁxed) smoothing coeﬃcient parameter1 .
Finally, user preferences over feature values in Vf are derived according to their marginal contribution to the KullbackLeibler (KL) divergence [5] between the two distributions:
DKL (Pfu Pf ) =


f.v∈Vf

u
Pf.v
log

u
Pf.v

Pf.v

u |≤
# f.v | f.v ∈ Vf ∧ |wf.v

|Vf |

(6)

The conﬁdence level parameter, , is determined by  
θ · σfu , where θ is a free parameter for the entire user community and σfu denotes the standard deviation of Ffu (w). A
large θ value would imply that we relax the criterion for conformity within the user community, while a smaller θ value
would imply that we require higher conﬁdence interval for
a user’s conformity pattern. It is further important to note
that, while θ is set based on the entire user community, the
uniqueness threshold for each user is actually personalized
and based on the properties of her private Ffu (w) preference
distribution. Hence, the uniqueness level is personally set
for each user.
Finally,
 the global uniqueness level of the user is set by
β u = n1 f ∈F βfu , which models the average uniqueness level
of user u over the feature set F . Next we describe how a
recommendation strategy can trade between recommending
popular items to items that “satisfy” the user proﬁle, based
on the user uniqueness level.



u∈Ui

Learning the user uniqueness level

βfu =

3.2 Learning the user preferences



(5)

Using the last observation from Section 3.2 we now shortly
describe how the user’s uniqueness level (or non-conformity)
can be estimated using the same framework.
For a given feature f ∈ F , let Ffu (w) denote the probability density function of the user preferences over the feature
value weights. The user level of uniqueness, therefore, may
be estimated by measuring the conﬁdence interval around
zero of the user preferences density function. Formally, let
βfu denote the probability that user u is a conformist up to
 +
some conﬁdence level  ≥ 0, given by βfu = − Ffu (w)dw
which can be estimated as follows:



u
u
u
wf.v
, wf.v
, . . . , wf.v
1
2
|V

Pf.v

u
Consequentially, if wf.v
> 0, it immediately implies that
u
Pf.v
> Pf.v which can be interpreted as “user u prefers feature value f.v more than an average user ”. Similarly, if
u
u
wf.v
< 0, it follows that Pf.v
< Pf.v , hence this feature
value is less preferred by the user in relation to an average
u
user. The special case of wf.v
= 0 implies that both the user
and the average user exhibit similar preferential pattern for
this feature value.

the feature vocabulary; i.e., if.v = 1 if item i has the feature
value f.v ∈ Vf , else, if.v = 0. Each item i is represented by
the list of its feature vectors, i = (if1 , . . . ,ifn ).
Let U be a set of users of the system (also termed user
community hereinafter). A user u ∈ U is modeled by a
user proﬁle deﬁned by the pair pu = W u , β u . W u =
(w
 fu1 , . . . , w
 fun ) is a list of weight vectors, where w
 fu models
u’s intra-feature preferences over the feature’s vocabulary
Vf ,
w
 fu =

u
Pf.v

(4)

Item recommendation

Built on top of our new user modeling framework, we
now describe three diﬀerent item recommendation strategies. The ﬁrst one personalizes recommended items based
on the user proﬁle. The second recommends popular items
to the user. The third one utilizes the uniqueness level of
the user to trade between the two basic strategies.

Personalized Item Scoring. Our ﬁrst item recommendation strategy, termed PERS, aims at providing personalized
recommendations to the user based on her preferences by
scoring the items as follows:

1

u
We smooth Pf.v
with the community’s preferences distribution due
to the limited amount of training data for many of the users.

778

 fu
1  if · w
scorePERS (i, u) =
n f ∈F if 

Ziegler et al. [8] in a 4-week crawl during 2004 from the
BookCrossing community5 . It contains about 1 million anonymous ratings of 271,379 books made by 278,858 users. Ratings in this dataset were made on a 10-star scale, with 10
stars being the highest rating. Ziegler et al. provide for
each book several features such as the book’s title, author
and publisher. Google Books6 API was further used to enrich the books metadata with two more features: categories
and keywords.

(7)

According to Equation 7, positive feature values in the
user’s intra-preferences vector contribute to the item score,
while those with a negative value reduce its score. We further linearly normalize scorePERS (i, u) over all items in I into
the range of [0, 1], where the lowest scored item is assigned
with 0 score and the highest with 1. The top scored items
are recommended.

4.2

Popularity Item Scoring. Our second item recommendation strategy, termed POP, recommends items that would
probably satisfy the preferences of an average user of U . A
straight forward strategy is to recommend the most popular
items to the user. In this work we recommend popular items
to user u, derived from the ratings of her K nearest neighbors (KNN). The K nearest neighbors are determined based
on their rating similarity to u’s ratings (e.g., using Pearson
Correlation [1]).
Let Uku denote the top-k most similar users in U to user
u; the popularity score for each item i ∈ I is calculated by
the relative rating volume given by the community Uku to
that item, measured as follows:


scorePOP (i, u) = 

i ∈I

u
u ∈Ui ∩Uk



riu



u
u ∈Ui ∩Uk



riu

(8)

Combined Item Scoring. Our ﬁnal item recommendation
strategy, termed POPERS, is a hybrid strategy which utilizes
the user uniqueness level to trade between the two basic
strategies. The hybrid item score of POPERS strategy for
user u is then given by:
scorePOPERS (i, u) = β u scorePOP (i, u) + (1 − β u )scorePERS (i, u) (9)

The lower the uniqueness level of the user (the higher the
user conformity), the higher the eﬀect of POP on the ﬁnal
score of the item and vice versa. Therefore, unique users
will be recommended by items that satisfy their preferences,
while conformist users will be recommended mostly by popular items.

4.

Setup & Evaluation

The three diﬀerent item recommendation strategies were
evaluated on each dataset. As a baseline, the TASTE open
source package7 was used to compare the three recommenders
with several state-of-the-art collaborative ﬁltering (CF) methods and with an SVD-based matrix-factorization (MF) method.
We shall use the label “CF” and “MF” to refer to TASTE’s best
performing CF method and the MF-based method, respectively. The various recommenders (ours and TASTE’s) were
implemented in Java SDK 6, and were run on a dual core
Windows XP machine with 4GB RAM.
The popularity based recommenders (i.e., POP and POPERS) and the CF and MF methods were experimented with
various sizes of Uku , the subset of the u’s nearest neighbors,
varying k over the values {20, 50, 100, 200, 500, |U |}.
Additionally, the POPERS recommender depends on the
global parameter θ for deriving personalized β u values for
each user. The θ parameter was tuned for each dataset using a random sample of 100 users from U with at least 50
ratings; the values obtained were θ = 1.0 and θ = 0.5 for
the movies and the books datasets respectively.
The various recommenders were evaluated on each dataset
using 30 user subsets, each contains 100 users with at least
50 ratings that were randomly drawn from U . For each recommended user, we took out the user’s top-20 rated items
(while further using the item ids for breaking possible rating ties) and used them for testing, while the remaining
user’s rated items were used for training. The various recommenders were evaluated based on their ability to identify
the testing items (rank them higher) out of all items in I
that were not used for training.
Recommendation quality was measured using nDCG@20
which measures the ranks of the testing items at the top-20
recommended results, while considering their rating score as
a relevance level. Items recommended by CF and MF methods
were ranked according to their predicted user ratings. In
the followings, we report on the average performance of all
recommenders over the 30 user datasets.

EXPERIMENTS

4.1 Data Sets
We evaluated our item recommendation strategies using
two real-world datasets, namely: MovieLens and BookCrossing. We now shortly describe each dataset.
MovieLens is a movie rating dataset2 from GroupLens
Research. This dataset contains about 1 million anonymous
ratings of approximately 3,900 movies made by 6,040 users
during 2000. Ratings in this dataset were made on a 5star scale, with 5 stars being the highest rating. The set of
movie features in this dataset is limited to genre, title and
release year. Each movie’s metadata was enhanced with additional features (list of actors, director, writer, screenplay,
and world certiﬁcate) obtained from the movie’s record in
IMDB3 .
BookCrossing is a book rating dataset4 , collected by

The results of our evaluation are depicted in Figure 1. The
ﬁrst observation we make is that the relative performance
of the various recommenders among the two datasets signiﬁcantly diﬀers. We mainly attribute this diﬀerence to the
fact that the BookCrossing dataset is much sparser than the
MovieLens dataset.
As we can observe, for both datasets, popularity based
recommendation (i.e., POP) dominates personalized recommendation based on the user’s proﬁle (i.e., PERS), CF (supporting [2]) and MF. Next, we observe that overall, for both

2

5

3

6

4.3

http://www.movielens.org
http://www.imdb.com/
4
http://www.informatik.uni-freiburg.de/~cziegler/BX/

Results

http://www.bookcrossing.com/
http://books.google.com/
7
http://mahout.apache.org/taste.html

779

(a) MovieLens

(b) BookCrossing

Figure 1: Evaluation results of the various recommenders for the two datasets
This also demonstrates the eﬀectiveness of our model for
learning user uniqueness for recommendation.

5.

SUMMARY

In this work we have shown how the user’s unique preferences over item features can be estimated and used for
recommendation. Using an experimental evaluation with
two real datasets we have studied various recommendation
strategies and demonstrated the eﬀectiveness of a recommendation strategy that trades between personalization and
popularity according to the user’s uniqueness level.
For future work, we wish to explore more usages of user
uniqueness with other recommendation strategies (e.g., CF
methods) and further extend our basic model to consider
the possibility of diversity in item feature signiﬁcance among
users.

Figure 2: Comparing the user uniqueness distributions in the MovieLens and BookCrossing datasets

6. REFERENCES

datasets and all conﬁgurations, the POPERS recommender
signiﬁcantly outperformed the other alternatives up to 4%
(p-value<10−10 ) and 13% (p-value<10−10 ) improvement over
the second best recommender, using the best conﬁguration
for the movies (k = 50) and the books datasets (k = 100),
respectively. Recall that POPERS utilizes the user uniqueness
level for “optimal” trading between POP and PERS strategies.
An important observation that we make is that PERS relative performance, compared to the other strategies, is signiﬁcantly higher for BookCrossing. This diﬀerence can be
explained by analyzing the distribution of user uniqueness
level within the two datasets.
Figure 2 provides a box-plot comparison between the user
uniqueness distributions in the two datasets. As we can observe, user uniqueness level varies among users with a median value of 0.213 (IQR = 0.0489) and 0.444 (IQR = 0.08)
for the movies and books datasets, respectively. Therefore,
the relative better performance of PERS for the books dataset
can be directly explained by the higher user uniqueness level
among recommended users in that dataset. This diﬀerentiation is exploited by the POPERS strategy which (relatively)
utilizes more personalization for users in the books dataset.

[1] Gediminas Adomavicius and Alexander Tuzhilin. Toward the
next generation of recommender systems: A survey of the
state-of-the-art and possible extensions. IEEE Trans. on
Knowl. and Data Eng., 17:734–749, June 2005.
[2] Hyung Ahn. Utilizing popularity characteristics for product
recommendation. Int. J. Electron. Commerce, 11:59–80,
December 2006.
[3] Òscar Celma and Pedro Cano. From hits to niches?: or how
popular artists can bias music recommendation and discovery. In
KDD Workshops, NETFLIX ’08, pages 5:1–5:8, New York, NY,
USA, 2008. ACM.
[4] Nadav Golbandi, Yehuda Koren, and Ronny Lempel. On
bootstrapping recommender systems. In Proceedings of
CIKM’10.
[5] Solomon Kullback and Richard A. Leibler. On information and
suﬃciency. The Annals of Mathematical Statistics, 22(1):79–86,
1951.
[6] Al Mamunur Rashid, Istvan Albert, Dan Cosley, Shyong K.
Lam, Sean M. McNee, Joseph A. Konstan, and John Riedl.
Getting to know you: learning new user preferences in
recommender systems. In IUI’02.
[7] Michal Shmueli-Scheuer, Haggai Roitman, David Carmel, Yosi
Mass, and David Konopnicki. Extracting user proﬁles from large
scale data. In MDAC ’10.
[8] Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, and
Georg Lausen. Improving recommendation lists through topic
diversiﬁcation. In WWW 2005, pages 22–32, 2005.

780


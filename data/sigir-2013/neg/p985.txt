Commodity Query by Snapping
Hao Huang†

Yunjun Gao‡
†

†

Kevin Chiew§

Lu Chen‡

School of Computing, National University of Singapore, Singapore
‡
College of Computer Science, Zhejiang University, China
§
School of Engineering, Tan Tao University, Vietnam

huanghao@comp.nus.edu.sg, ‡ {gaoyj, hqm, chenl}@zju.edu.cn, § kevin.chiew@ttu.edu.vn

ABSTRACT

the keywords to describe the product by themselves, and input these keywords on their Internet-linked mobile devices,
followed by checking each search result if it contains review
information as expected. Such a process is not so easy since
the choosing of keywords affects the search results. Instead,
it would be more efficient and effective for users to snap a
photo of the product, and let the system automatically generate the keywords as inputs to an existing search engine.
The idea of query by snapping is not new. It was introduced
in 2006 when camera became a part of a mobile phone.
In recent years, several APPs and APIs running on mobile
devices have been developed for query by snapping, such as
barcode scanners, image matching-based solutions [5], and
Google Goggles which combines image matching and OCR.
Nevertheless, these approaches still have a few minor flaws
in effectiveness or convenience when they are used to query
commodities. For example, (1) it is not convenient for a
user to take and turn a commodity to scan its barcode when
the commodity is not at hand or the user is in a hurry;
(2) commodities sharing similar appearances, such as series products, significantly affect the image matching results;
and (3) the results of image matching and OCR are directly
returned by Google Goggles without a further analysis to
determine the exact names of the objective commodities.
In this paper, we focus on a simple yet effective mechanism for commodity query by snapping. It enables users to
retrieve relevant and useful product information, such as the
exact name, brand information, recommended retail price,
reviews, and similar alternatives, by just snapping a photo
of a commodity and submitting it to our system. We propose a framework which addresses the following three issues:
(1) first, extracting the information printed on the surface of
an objective commodity; (2) second, deducing the brand information which will help users locate the commodity more
accurately; and (3) third, generating the final keywords that
exactly describe the commodity for the retrieval of the related product information from the Internet.

Commodity information such as prices and public reviews is
always the concern of consumers. Helping them conveniently
acquire these information as an instant reference is often of
practical significance for their purchase activities. Nowadays, Web 2.0, linked data clouds, and the pervasiveness of
smart hand held devices have created opportunities for this
demand, i.e., users could just snap a photo of any commodity
that is of interest at anytime and anywhere, and retrieve the
relevant information via their Internet-linked mobile devices.
Nonetheless, compared with the traditional keyword-based
information retrieval, extracting the hidden information related to the commodities in photos is a much more complicated and challenging task, involving techniques such as
pattern recognition, knowledge base construction, semantic
comprehension, and statistic deduction. In this paper, we
propose a framework to address this issue by leveraging on
various techniques, and evaluate the effectiveness and efficiency of this framework with experiments on a prototype.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

Keywords
Information retrieval; commodity; snapping

1.

Qinming He‡

INTRODUCTION

Query by keywords is one of the most important and
prevalent mechanisms for information retrieval. Nonetheless, this mechanism is still far from perfect or convenient
sometimes. Take the following scenario as an example. When
users stumble across a “new” product in a supermarket, they
usually would like to refer to others’ reviews and comments
on the product, or to know whether there is a lower price or
any better alternatives. With the traditional information retrieval procedure, users have to visually extract and organize

2.

FRAMEWORK OVERVIEW

The framework contains two parts, i.e., (1) the off-line
part in which a knowledge base is constructed based on m
product names Nj (j = 1, . . . , m) crawled from e-commerce
web sites, such as Amazon and eBay; and (2) the on-line part
consisting of three phases, i.e., keyword extraction, brand
deduction, and information retrieval.
In the off-line knowledge base, the product names are
split into a set W of standard word items wi ∈ W , i =
1, . . . , n, and the three matrices below are constructed by

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

985

to recognize the characters printed on its package. Thanks
to the advanced OCR techniques (e.g., Tesseract-OCR), the
character recognition can handle characters from multiple
languages and with poly-fonts. Nonetheless, due to the various design styles of product package, such as flourish letters,
and different inter-word and inter-character spaces, OCR is
often unable to recognize every word on the commodity accurately. Partial OCR results are useless string fragments
corresponding to errors in the recognition. To address this
problem, we employ the set W of standard word items to
emend the OCR results, and filter out the useless standardized word items based on the word symbiosis matrix S.

statistics, namely (1) the word symbiosis matrix S where
the value of each element Sik (i, k ∈ {1, . . . , n}) denotes the
co-occurrence probability Pr(wk | wi ) that word wk appears
in the product names containing word wi ; (2) the productword matrix P of which each element Pji (j ∈ {1, . . . , m},
i ∈ {1, . . . , n}) represents the occurrence times of word wi
in product name Nj ; and (3) the brand-product matrix B
of which each element Btj (t ∈ {1, . . . , b}, j ∈ {1, . . . , m})
indicates whether or not the commodity with product name
Nj belongs to the tth brand with 1 for yes and 0 for no.
Using the knowledge base, the on-line part carries out a
query by snapping through the following three phases.
• Keyword Extraction. On a commodity, there are usually
both useful information (e.g., product name, brand) and
trivial information (e.g., net weight, user guide). Thus this
phase aims to extract the informative keywords that describe
the commodity in the specified photo appropriately.
• Brand Deduction. To retrieve the product information
of a correct commodity for users, it is important to identify the commodity accurately. Although the extracted keywords may express the most important information of the
commodity, sometimes they are not clear enough to find
out the exact commodity, especially when there is no brand
information contained in the keywords. For example, keywords “facial”, “foam”, and “cucumber” have delivered the
main information for a commodity named dove facial foam
of cucumber scent though, they are still ambiguous for the
commodity identification without the brand “dove”1 . Motivated by this, we deduce the brand of the commodity to
complement extracted keywords for the sake of clarity. Instead of using existing techniques such as image matchingbased Logo recognition [1], we infer the brand information
based on the extracted keywords, the product-word matrix
P and the brand-product matrix B, avoiding the extensive
cost of building a large-scale brand Logo database.
• Information Retrieval. In a traditional information acquisition mechanism, users provide an exact description of a
commodity as the query keywords to obtain a better search
results. In our framework, this query keywords can be generated automatically using extracted keywords and the deduced brand with the help of Google. With our query keywords which exactly describe an objective commodity, the
desired commodity information can be accurately retrieved
from the e-commerce and product-review websites.

3.

3.2

Similarity(s, wi ) = 1 −

Ed(s, wi )
max{Length(s), Length(wi )}

where Ed(s, wi ) is the edit distance (a.k.a. Levenshtein distance, which is commonly used to evaluate the similarity between strings [3]) between s and wi , Length(s) & Length(wi )
As Ed(s, wi ) ∈
are the string lengths of s and wi respectively.

0, max{Length(s), Length(wi )} , Similarity(s, wi ) ∈ [0, 1].
Since a few string fragments are meaningless symbols (e.g.,
“?”, “||”, “–”) corresponding to errors and noises in OCR,
we make use of the following heuristic, i.e., for each string
fragment s, if Similarity(s, wi ) is less than a threshold Ts
(Ts = 0.5 in this paper) for any wi , then the current s is
discarded without mapping it to any standard word item.

3.3

Filtering

Although standardization cleans up OCR results, it may
occasionally bring with several word items that are not printed
on the commodity. For example, the word “men” may be
transformed from a meaningless string fragment “ren”. In
order to improve the accuracy of the commodity identification, these unexpected word items should be removed.
Inspired by collaborative filtering [4] which predicts the
interests of a user by collecting preferences from many users,
we predict the unexpected word items according to the cooccurrence probability of each two standard word items, i.e.,
the elements of the word symbiosis matrix S. The detailed
steps for the filtering process are as follows.
Step 1. If ∀wk , Sik = 0, then filter out this standardized
word item wi .
Step 2. For each remaining wi with maxk Sik < 1, if
P
k Sik
P
< Tp
k I(Sik > 0)

KEYWORD EXTRACTION

There is plenteous information on a commodity’s package,
such as the product name, brand, producer, net weight, and
so on. Hence, it plays a key role in the commodity identification to extract the most useful keywords from the package.
To this end, we introduce a three-step approach, i.e., (1)
running OCR on the photo of a commodity to obtain what
are printed on its package, (2) standardizing the OCR results to a subset of the standard word items, and (3) filtering
the standardized word items to remove the noise words that
are not regular collocations of the other words.

3.1

Standardization

For each string fragment s in OCR results, we map it to
a standard word item wi ∈ W (i ∈ {1, . . . , n}) with the
maximal similarity to s. Here, the similarity is defined as

where I(·) is the indicator function, and Tp a threshold (Tp =
0.2 in this paper), then filter out this wi .
By filtering out the unexpected words, we can obtain a
set of word items with much more cohesiveness in collocation. These filtered word items are returned as the extracted
keywords for the objective commodity.

Optical Character Recognition

To utilize the existing information of a commodity in a
specified photo for the subsequent steps, first of all, we have

4.

BRAND DEDUCTION

Product brand is important for commodity identification
due to its uniqueness. However, sometimes there is no brand
information in the extracted keywords, especially in the cases

1

According to the search results on Google using keywords
“facial foam cucumber” and “dove facial foam cucumber”.

986

that the commodity brands are images or in art fonts that
are very difficult to be recognized by OCR. Instead of using Logo recognition, we deduce a product brand with the
extracted keywords, avoiding to hassle with constructing a
large-scale Logo database.
In fact, even if extracted keywords may not contain product brands explicitly, their collocations can also imply brand
information. For example, keywords “pro-x” and “professional” imply that the commodity is very likely one of the
pro-x series products of Olay. Thus, we can deduce the product brand by two steps, i.e., (1) finding out the most relevant
commodities of the extracted keywords, and (2) checking
which brand owns these relevant commodities.

4.1

Figure 1: Example of the generated final keywords
Step 1. Combine the brand with the extracted keywords
as the search terms k = {k1 , . . . , kp }, where ki (1 6 i 6 p) is
the ith word in the search terms, and input them to Google.
Step 2. Extract a set t = {t1 , . . . , tq } of the titles of the
top search results listed on the first search result page, in
which tj (1 6 j 6 q) represents the jth title.
Step 3. Rank each title tj according to its consistency
C(tj ) with the search terms k, where C(tj ) denotes the total
number of matched word items and approximately matched
collocations in tj and k, and can be calculated as
Xp
Xp−1
C(tj ) =
I(ki ∈ tj ) +
I(ki ∈ tj , ki+1 ∈ tj ).

Finding Relevant Commodities

In our knowledge base, there are n standard word items
wi (i = 1, . . . , n) extracted from the product names Nj
(j = 1, . . . , m) of m commodities. For each wi , the productword matrix P has recorded its occurrence times Pji in each
product name Nj . Let Yi be the occurrence times of wi in
the extracted keywords, we can evaluate each commodity’s
relevance αj (j ∈ {1, . . . , m}) to the extracted keywords by
solving the following minimization problem.
!2
n
m
m
X
X
X
α = arg min
Yi −
αj Pji
, s.t.
αj2 6 1
α

i=1

j=1

i=1

Step 4. Select the title with the maximal consistency with
the search terms k as the final keywords.
Fig. 1 illustrates an example of the final keywords generated by our framework for a commodity photo, together
with the search results of these final keywords on Google,
where the first one corresponds to the correct commodity.
By using the generated final keywords as the query terms,
we can retrieve the related product information, such as recommended retail price, reviews, and alternatives, from the
e-commerce and product-review web sites.

j=1

where α = {α1 , . . . , αm }.
The reasons behind are as follows.
P To minimize the squares
bias between Yi (i = 1, . . . , n) and m
j=1 αj Pji (j = 1, . . . , m),
(1) if Pji is close to Yi > 0, i.e., word wi appears in both
the extracted keywords and the jth commodity’s name with
about the same occurrence times, then the jth commodity
should have a higher relevance αj to the extracted keywords;
(2) otherwise, αj will be close to zero since the extracted
keywords include only a few standard word items such that
most of Yi are equal to 0. Therefore, by solving the minimization problem with ridge regression [2], the relevance α
between the extracted keywords and the commodities in the
knowledge base will be revealed.

4.2

6.

EXPERIMENTAL EVALUATION

We have implemented a prototype with Java for the proposed framework. With the prototype, we verify the effectiveness and efficiency of our framework from the two aspects
below, i.e., (1) the performance study in terms of accuracy
of commodity identification, and (2) the efficiency study in
terms of runtime, after we present the experimental setup.

Deducing Brand

As the brand-product matrix B has recorded the affiliation between brands and commodities, we can combine it
with the relevance α to deduce the brand of the commodity
in the photo. Let βt (t ∈ {1, . . . , b}) be the probability of
that the tth brand is the true one, then the probability of
each brand can be estimated as
Pm
j=1 αj Btj
.
βt = P b P m
k=1
j=1 αj Bkj

6.1

Experimental Setup

The prototype focuses on query personal care commodities by snapping. It constructs a knowledge base with 830
standard word items, which are extracted from the product names of 600 personal care commodities crawled from
Amazon.com. All these products come from 201 brands.
We adopt 100 photos of personal care commodities as the
testing set. These photos differ from sizes, image-capturing
conditions, illuminations, pros and cons of the commodities,
etc. Furthermore, for the sake of fairness, about half of the
testing commodities are outside the knowledge base.
The prototype runs on a laptop PC (2GB RAM, Intel Core
2 Due CPU 1.80GHz) under a 54.0Mbps wireless network.

By summing up the relevance between the extracted keywords and the relevant commodities belonging to the tth
brand, each probability βt denotes the relevance between
the commodity in the photo and the tth brand. The brand
with the maximal probability is returned as the target one.

5.

i=1

INFORMATION RETRIEVAL

6.2

Based on the extracted keywords and the deduced brand,
we generate the final keywords that describe the objective
commodity much more exactly with the help of Google. The
generation can be performed as follows.

Accuracy Study

We study the accuracy performance of our prototype in
terms of (1) the accuracy of commodity identification (name
accuracy for short), and (2) the brand accuracy. We also
report the performance of Google Goggles, which is based

987

1

1

0.9

0.9

0.6

12
Runtime

Name(Prototype)

0.5

Brand(Prototype)

0.4

Name(Goggles)
Brand(Goggles)

0.3
0.2
100

200
300
400
500
600
Number m of Product Names in Knowledge Base

(a)

Name(Ts)

0.6

Brand(Ts)
Name(Tp)

0.5

Brand(Tp)
0.4

6

0.3

4

0.2

2

0.1

Name(Goggles)
Brand(Goggles)

0.3
0.2
0.1

Communication Time

0.4
pdf

0.6

0.7

Computation Time

Communication Time

8
Seconds

0.7

OCR Time

0.5

Computation Time

0.8
Accuracy

Accuracy

0.8

Runtime

OCR Time

10

0.2

0.3

0.4
0.5
0.6
Value of Threshold

0.7

0

0.8

(b)

20

40
60
Individual Photos

80

100

0

0

2

(c)

4

6
Seconds

8

10

12

(d)

Figure 2: Performance of the prototype. (a) Accuracy vs. knowledge base sizes. (b) Accuracy vs. thresholds
Ts & Tp . (c) Runtime on each tested photo. (d) Runtime distribution

on both OCR and image matching, just for a reference. The
detailed performance metrics are as follows.
• Our prototype. (1) For the name accuracy, the first
search result on Google using the generated final keywords
should correspond to the true commodity; and (2) for the
brand accuracy, the brand information within the final keywords should be unique and exactly the true brand.
• Google Goggles. (1) The metric for its name accuracy is
relaxed to either the first search result on Google using the
OCR results as the search terms or the returned similar image corresponding to the true commodity; and (2) its brand
accuracy can be checked by its Logo recognition result.
The accuracy study consists of two parts, i.e., (1) the effect
of the size of knowledge base, in which we randomly select
m (m = 100, 200, . . . , 600) product names from the original
600 product names to construct knowlege base with different
sizes, and record the accuracy performance of the prototype.
Without loss of generality, we report its average performance
of 20 times of run for each m; and (2) the effect of the two
parameters in our framework, i.e., the thresholds Ts (see
Section 3.2) and Tp (see Section 3.3).
Fig. 2(a) illustrates the accuracy performance of the prototype using knowledge bases with various sizes, from which
we can observe that the name and brand accuracy increase
with the growth of the size of knowledge base. The reasons behind are as follows. (1) With fewer product names
in the knowledge base, the number of the standard word
items is smaller, increasing the risk that the OCR results
cannot be mapped to the correct standard word items, and
thus affecting the performance of the subsequent processes.
(2) Contrarily, if there are abundant standard word items
collected from many real product names, these word items
can cover most words, even those in a “new” product name
not included in the knowledge base, which better reflects
the word collocations in reality, leading to more reasonable
extracted keywords and deduced brand.
Fig. 2(b) depicts the accuracy performance of the prototype using different thresholds Ts and Tp , from which we
can observe that the name and brand accuracy vary slightly
with the change of these two parameters. In other words,
the prototype is relatively robust to the parameters.

6.3

three parts, namely (1) the time for OCR; (2) the computation time for the standardization and filtering processes,
the brand deduction, and the computation of local matching
degree during the product information acquisition via web,
and (3) the time consumed on Internet communication, the
OCR, computation, and communication times and their distribution are also depicted in the figures respectively.
We can observe that (1) the average runtime of the prototype is about 4.5 seconds, comparable to approximately
5 seconds required by Google Goggles running on the same
wireless network; and (2) the computation and communication times change slightly in each execution, resulting in
that the runtime mostly depends on the time for OCR.

7.

CONCLUSION

In this paper, we have proposed a simple yet effective
framework for commodity query by snapping, which enables
users to obtain relevant commodity information via their
smart mobile devices by just taking a snapshot of an objective commodity and submitting it to our system. Experiments on a prototype have verified the effectiveness and
efficiency of the proposed framework.

8.

ACKNOWLEDGMENTS

This work was partly supported by the National Key Technologies R&D Program (Grant No.: 20128AH94F01), NSFC
61003049, the Fundamental Research Funds for the Central
Universities (Grant No.: 2012QNA5018, 2013QNA5020), and
the Key Project of ZJU Excellent Young Teacher Fund.

9.

REFERENCES

[1] J. Chen, L. Wang, and D. Chen. Logo Recognition:
Theory and Practice. CRC press, Boca Raton, 2011.
[2] T. Hastie, R. Tibshirani, and J. Friedman. The
elements of statistical learning: data mining, inference,
and prediction, 2nd ed. Springer, Heidelberg, 2009.
[3] Y. Li and B. Liu. A normalized levenshtein distance
metric. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 29(6):1091–1095, 2007.
[4] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl.
Item-based collaborative filtering recommendation
algorithms. In WWW’01, pages 285–295, 2001.
[5] S.S. Tsai, D. Chen, V. Chandrasekhar, G. Takacs, N.M.
Cheung, R. Vedantham, R. Grzeszczuk, and B. Girod.
Mobile product recognition. In MM’10, pages
1587–1590, 2010.

Efficiency Study

In this experiment, we investigate the efficiency performance of our prototype in terms of runtime by illustrating the runtime for processing each photo in the testing
set, and the runtime distribution in Figs. 2(c) and 2(d),
respectively. Furthermore, since each runtime consists of

988


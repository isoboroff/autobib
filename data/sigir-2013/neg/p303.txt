Opportunity Models for E-commerce Recommendation:
Right Product, Right Time
Jian Wang, Yi Zhang

School of Engineering
University of California, Santa Cruz
Santa Cruz, CA 95060 USA

{jwang30, yiz}@soe.ucsc.edu
ABSTRACT

Categories and Subject Descriptors

Most of existing e-commerce recommender systems aim to
recommend the right product to a user, based on whether
the user is likely to purchase or like a product. On the other
hand, the eÔ¨Äectiveness of recommendations also depends on
the time of the recommendation. Let us take a user who
just purchased a laptop as an example. She may purchase a
replacement battery in 2 years (assuming that the laptop‚Äôs
original battery often fails to work around that time) and
purchase a new laptop in another 2 years. In this case, it is
not a good idea to recommend a new laptop or a replacement
battery right after the user purchased the new laptop. It
could hurt the user‚Äôs satisfaction of the recommender system
if she receives a potentially right product recommendation
at the wrong time. We argue that a system should not only
recommend the most relevant item, but also recommend at
the right time.
This paper studies the new problem: how to recommend
the right product at the right time? We adapt the proportional hazards modeling approach in survival analysis to the
recommendation research Ô¨Åeld and propose a new opportunity model to explicitly incorporate time in an e-commerce
recommender system. The new model estimates the joint
probability of a user making a follow-up purchase of a particular product at a particular time. This joint purchase
probability can be leveraged by recommender systems in
various scenarios, including the zero-query pull-based recommendation scenario (e.g. recommendation on an e-commerce
web site) and a proactive push-based promotion scenario
(e.g. email or text message based marketing). We evaluate
the opportunity modeling approach with multiple metrics.
Experimental results on a data collected by a real-world
e-commerce website(shop.com) show that it can predict a
user‚Äôs follow-up purchase behavior at a particular time with
descent accuracy. In addition, the opportunity model significantly improves the conversion rate in pull-based systems
and the user satisfaction/utility in push-based systems.

H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

General Terms
Algorithms, Design, Experimentation

Keywords
Recommender System; Opportunity Model; E-commerce

1. INTRODUCTION
As online shopping becomes popular, e-commerce recommendation is an increasingly important business tool for promoting sales. Researchers and industry practitioners are
looking for all possible approaches to improve the recommendation performance. Even a minor improvement could
lead to a big business return.
Traditional recommender systems focus on Ô¨Ånding the
right item to recommend. Major approaches include contentbased methods, collaborative Ô¨Åltering methods and hybrid
methods. For example, if a user viewed or purchased some
camera(s) in the website, the system recommends more similar items (e.g. similar cameras) to the user. Recent research [19] proposed that recommender systems should recommend items that maximize the users‚Äô marginal utility,
instead of only items that a user likes. As the marginal utility of a camera decreases immediately after a user purchased
a camera, a system‚Äôs follow-up recommendation should include camera accessories instead of similar cameras.
On the other hand, the user satisfaction/utility depends
on both the relevance and the time of the recommendation.
While an irrelevant recommendation results in a negative
utility, the opportunity cost of recommending a relevant
item at the wrong time could also be high, as we wasted
the space while giving the user a negative impression. This
is especially a problem for email or message based recommendations, as it wastes a user‚Äôs time and eÔ¨Äort to receive
product recommendation emails/messages that are full of
products she does not need to purchase at the time. In the
long term, the user may have negative impression about the
company, unsubscribe from the marketing email list, label
the emails as spams, or uninstall the message application.
To address these issues, recommender systems need to answer the following question: when is the right time for the
system to make recommendations of the right product(s)?
For example, after a user purchased a camera, whether and

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR‚Äô13, July 28‚ÄìAugust 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

303

when should the system recommend related accessories including camera lenses, batteries, digital photo frames, etc.?
Multiple heuristic approaches [18, 24] have been proposed
to tackle this problem. In this paper, we propose a theoretical model to learn the probability of a user making a followup purchase at a particular time. The model is inspired
by the hazards model in survival analysis in statistics. The
purchase time would be inÔ¨Çuenced by multiple factors, such
as the user‚Äôs characteristics, the user‚Äôs purchase history, the
product promotion information, the global environment and
so on. Thus we propose to leverage the proportional hazards modeling approach which incorporates related factors
as covariates(i.e., features). We further extend the model
with the hierarchical Bayesian framework to handle the data
sparsity issue. The new model is denoted as the Opportunity
Model in this paper. It predicts the joint purchase probability, i.e., the probability of a user purchasing a product at
a particular time. It helps to promote a right item at the
right time which further enhances the user satisfaction. Experimental results are performed with a dataset from a realworld e-commerce website. Detailed analysis shows that the
opportunity model could help to signiÔ¨Åcantly improve the
conversion rate and the user satisfaction.
The major contribution of this paper includes:
‚Ä¢ We propose a new research problem in recommender
systems: When is the right time to make recommendation of the right product in the e-commerce domain?
‚Ä¢ To solve this problem, we propose a principled approach, (i.e. theopportunity model), to predict the
joint probability of purchasing a product and the time
of the event. We extend the proportional hazards
model in statistics with the hierarchical Bayesian framework as part of the solution, and derive detailed inference steps based on the variational Bayesian algorithm.
‚Ä¢ We leverage the joint probability in both the zeroquery pull-based recommendation scenario and the proactive push-based email/message promotion scenario 1 .
In particular, the probability enables a proactive recommendation agent to decide whether to send recommendations of certain items to a user at a particular
time based on a solid utility optimization framework.
Experimental results show that the opportunity modeling approach signiÔ¨Åcantly improve the user satisfaction and the conversion rate of the system.

2. RELATED WORK
To provide recommendations to a user, recommendation
systems usually predict a user‚Äôs ratings for each item or
probability of purchasing, then rank all items in the descending order. There are two major recommendation approaches: content-based Ô¨Åltering and collaborative Ô¨Åltering.
Content-based Ô¨Åltering [12]assumes that descriptive features
of an item indicate a user‚Äôs preferences. Thus a recommender system estimates the score of each item based on
descriptive features of other items the user likes or dislikes.
Usually, the system recommends items that are similar to
what the user liked before. On the other hand, collaborative Ô¨Åltering [7, 18, 13, 5] assumes that users with similar

tastes on some items may also have similar preferences on
other items. Thus the main idea is to use the behavior history from other like-minded users to provide the current user
with good recommendations. Research on collaborative Ô¨Åltering algorithms reached a peak due to the 1 million dollar
NetÔ¨Çix movie recommendation competition. Factorizationbased collaborative Ô¨Åltering approaches [3, 9, 19, 17], such
as the regularized Singular Value Decomposition, performed
well on this competition. A common characteristic of these
models is the introduction of user latent factors and/or item
latent factors to solve the data sparsity issue. In the Ô¨Åeld of
recommender systems, the eÔ¨Äect of time [10, 18, 24] has received some research attention recently. One focus is about
the drift of the user‚Äôs preference over time [10, 23, 15]. Koren [10] revamped two popular collaborative Ô¨Åltering methods by modeling the time drifting factor of user preferences.
Rendel et al. [15] proposed a factorized personalized model
that subsumes both a common Markov chain and the normal
matrix factorization model.
Recommendation in the e-commerce domain is a topic
that has been studied in the IR community [8, 20]. Several
methods have been tried in this domain, including neighborhoodbased method, graph models [6], MDP-based methods [16],
multi attribute utility theory based methods [11] and so on.
In general, most of these existing methods, directly or indirectly, only estimate whether a user would like an item or
purchase an item. Some recent work studied modeling the
time interval between purchase orders in the e-commerce
domain [18, 24]. Wang et al. [18] discovered diÔ¨Äerent postpurchase behavior in diÔ¨Äerent time windows after purchasing. Zhao et al. [24] used the purchasing time interval to improve the temporal diversity of recommendations [15]. The
time interval and the corresponding purchase probability
is modeled inside the framework of a utility-based recommender system [19]. The hybrid system takes the time interval into consideration when ranking all candidate items.
Compared to the prior work about time, our work explicitly
models the joint probability of purchasing the product at the
time based on a solid theoretical foundation. We explicitly
model the conditional probability as a white box by leveraging Weibull distribution with various covariates to estimate
the time-based probabilistic density. These covariates enable
us to capture various time-dependent patterns such as local
changes, cyclic behavior, seasonable pattern, general trend
of follow-up purchase behaviors, which are not captured by
the prior work. Besides, the joint probability of product and
time enables us to improve the recommendation accuracy.

3. OPPORTUNITY MODEL IN E-COMMERCE
To recommend the right product at the right time, we
exam each candidate product for each user at a particular
decision time. We propose to build an opportunity model
to estimate the probability of a user purchasing the product at a particular time interval (i.e. (y, y + Œît]). That is
the joint probability P (p product, T ‚àà (y, y + Œît]), where
T is the purchasing time. Let P (p product) represent the
probability of the user purchasing the product, and P (T ‚àà
(y, y + Œît]|p product) represent the conditional probability
of the user purchasing the product at a particular time period conditioned on that the user will purchase the product.

1

In the pull-based scenario, a user comes to the website and
views some recommendation. In the push-based scenario, a
system sends promotion emails or messages to the user.

304

Based on the chain rule, we have the joint probability:
P (p product, T ‚àà (y, y + Œît])
= P (T ‚àà (y, y + Œît]|p product)P (p product)

  
 

(1)

We propose to adapt hazards models in survival analysis to
estimate P (T ‚àà (y, y + Œît]|p product), and adapt existing
recommendation algorithms to estimate P (p product).

3.1

 

Hazards Model in Survival Analysis

   

Survival analysis is a heavily studied topic in statistics,
which is named as duration modeling in economics or reliability analysis in engineering. One major part of survival
analysis is to estimate the time of an event, such as when a
machine fails to work or when a patient fails to survive. In
the e-commerce domain, we can view the task of conditional
opportunity model as predicting the time of the follow-up
purchase event of the product. Follow-up purchases may include repurchases that happen regularly or new purchases
that are triggered by the previous purchase. Given the similar nature of survival analysis and our e-task, we propose
to use the hazards model in survival analysis to estimate
p(y|p product) in this paper.
Let us review basic hazards models in survival analysis.
Let p(y) denote the density function of the time distribution
of an event. Let y be a value of time and T be a random
variable representing the event time. The cumulative distribution function is denoted as P (y) = P r(T ‚â§ y) and survival function is denoted as S(y) = P r(T > y) = 1 ‚àí P (y).
p(y)
The hazards function is h(y) = S(y)
. It indicates the instantaneous potential per unit time for the event to occur
at time y given that the event has not occurred up to time
y.
The survival analysis further extends the model with covariates. Covariates are features that would aÔ¨Äect the survival time. For example, if a product is on promotion, it
might shorten the time before a user waits to purchase it.
The covariates could include diÔ¨Äerent types of features, including time independent variables (user age, gender, household income, product brand etc.), time dependent internal
variables (time since last purchase of the same product, recent user search queries or clicks etc.) and time dependent
external variables (global economy, seasonal index, day of
the week, etc.). There are two common approaches to incorporate covariates x(a vector of features) in a hazards
model. The Ô¨Årst approach is the Cox proportional hazards
model [14]. It assumes that covariates are multiplicatively
related to the hazards. The second approach is the Accelerated life model [22]. It assumes that covariates are multiplicatively related to the survival time. Research in statistics
discovered that the Weibull distribution satisÔ¨Åes assumptions in both directions. The density function of the basic
Weibull distribution is shown in Equation 2 [21].
p(y) =Œ≥Œ∏y Œ≥‚àí1 exp{‚àíŒ∏y Œ≥ }

 



 




Figure 1: Illustration of the relationship of variables.
The user Ô¨Årst makes a series of product purchases
before timestamp tm . Then the user makes a purchase of item jm in category m at timestamp tm . This
follow-up purchase in category m is the ith observation in category m. Suppose that the purchase of jm
is triggered by item js at timestamp ts . Purchase
time ym,i = tm ‚àí ts is the time gap between tm and ts .
An observation i is associated with two major variables: 1) purchase time ym,i and 2) covariates xm,i
(which is not shown in the Ô¨Ågure).
where exp{Œ≤ T x} represents the new scale parameter Œ∏ . This
density function represents the basic proportional hazards
model that models the event time with associated covariates. The corresponding hazards function is simply h(y) =
Œ≥Œ∏ y Œ≥‚àí1 .

3.2 Notations
Here we describe notations in the e-commerce domain in
this paper. The relationship between diÔ¨Äerent variables is
shown in Figure 1.
‚Ä¢ u = 1, 2, ..., U : the index of users.
‚Ä¢ m = 1, 2, ..., M : the index of item categories. In the ecommerce domain, it is the category of the product,
such as Apparel & Accessories|Swimwear, Baby|Car
Seats, Sports and Fitness|Football, etc.
‚Ä¢ jm = 1m , 2m , ..., Jm : the index of items in category m.
In this paper, an item is a product.
‚Ä¢ tm : the purchase timestamp of item jm .
‚Ä¢ Œît: the window size of the purchase time in consideration (such as 3 days or 1 hour)

(2)

where Œ≥ is sometimes called the shape parameter and held
Ô¨Åxed. If Œ≥ = 1, the Weibull model reduces to the exponential
model and the hazard is constant. If Œ≥ > 1, the hazard increases as time increases. If Œ≥ < 1, the hazard decreases over
time. Œ∏ is the scale parameter and can be re-parameterized
based on a regression parameter Œ≤ and covariates x as follows:
p(y) =Œ≥exp{Œ≤ T x}y Œ≥‚àí1 exp{‚àíexp{Œ≤ T x}y Œ≥ }

 



‚Ä¢ D: The observed data of all follow-up purchases from
all users. Each category m has Nm follow-up purchase
observation from all users. Each follow-up purchase
observation i = 1, ..., Nm in category m is associated
with the purchase time ym,i and covariates xm,i .
‚Ä¢ ym,i : the purchase time of the ith observation in category m. ym,i = tm ‚àí ts is the time distance between

(3)

305

the user‚Äôs purchase timestamp tm of item jm and the
user‚Äôs purchase timestamp ts of the triggering item js .
‚Ä¢ xm,i : the k-dimensional vector of covariates associated
with the ith observation in category m. Covariates
could be associated with user u who makes the purchase, the user‚Äôs purchase history j1 , ..., jm‚àí1 , the purchase item jm , the global environment, etc.
‚Ä¢ P (p product = yes): the probability of a user purchasing the product. The probability is calculated for each
user-product pair.
‚Ä¢ Opportunity model : density function/model to predict
the joint purchase probability p(y, p product), i.e., the
probability of a user purchasing of the product at the
particular time.

data
category

‚Ä¢ Conditional opportunity model : density function/model
to predict the conditional time probability p(y|p product),
i.e., the probability of a user purchasing the product at
the particular time, given that the user will purchase
the product.

3.3

Conditional Opportunity Model

In this paper we propose to adapt the Cox proportional
hazards model to the e-commerce domain and use it to estimate P (T ‚àà (y, y + Œît]|p product). To do that, we learn the
conditional opportunity model p(y|p product), which is the
density function/model of the purchasing time. We can either learn one model per product or one model per product
category. Without loss of generality, we describe the model
by assuming one model per category in this paper.
In the real world, a small number of categories are often purchased while most categories have few purchases. To
solve the data sparsity issue, we follow a common practice
and extend the conditional opportunity model with a hierarchical Bayesian framework as illustrated in Figure 2. This
framework helps the category with few observations by borrowing information from other categories through a common
prior for parameters of all proportional hazards models.
For each category m, Œ≤m is sampled from a Gaussian distribution: Œ≤m ‚àº N (ŒºŒ≤ , Œ£Œ≤ ) and Œ≥m is sampled from the
Gamma distribution: Œ≥m ‚àº Gamma(aŒ≥ , bŒ≥ ). We denote
œÜ = (ŒºŒ≤ , Œ£Œ≤ , aŒ≥ , bŒ≥ ). For each ith observation in category
m with its observed covariates xm,i , its purchase time ym,i
is sampled from the conditional opportunity model
p(ym,i |Œ≤m , Œ≥m )
=

3.4

L(œÜ) = ln p(D|œÜ) =

m=1

p(ym |œÜ) =

M



ln

p(Œ∏m , ym |œÜ)dŒ∏m

m=1

3.4.1 E-Step


p(Œ∏m , ym |œÜ)dŒ∏m

ln p(ym |œÜ) =

We can simplify the problem by introducing an auxiliary
distribution q(Œ∏m ) for each hidden variable Œ∏m [1]. In the
variational approach, we constrain q(Œ∏m ) to be a particular tractable form for computational eÔ¨Éciency. In particular, we assume that q(Œ≤m ) = N (ŒºŒ≤m , Œ£Œ≤m ) and q(Œ≥m ) =
Gamma(aŒ≥m , bŒ≥m ). The process to infer parameters is to
iterate between the following E-step and M-step until convergence.

Consider that data D consists of a series of observations from
all categories. Purchase times in the observations are generated by using a set of hidden variables Œ∏ = {Œ∏1 , Œ∏2 ..., Œ∏M }
(Œ∏m = {Œ≤m , Œ≥m }). The likelihood can be written as a function of œÜ = (ŒºŒ≤ , Œ£Œ≤ , aŒ≥ , bŒ≥ ). We use ym to represent {ym,1 ,
..., ym,i , ..., ym,Nm }, i.e., observation times in category m.
p(D|œÜ) =

M

m=1

(4)

M


Parameter Inference with Variational
Bayesian

There is no closed-form solution for the estimation of
the model parameters. We follow the variational Bayesian
method[1] for constrained (approximate) optimization to derive an iterative process to Ô¨Ånd the approximate solution.
Maximizing the likelihood in Equation 5 is equivalent to
maximizing the log likelihood L(œÜ).

T
Œ≥m ‚àí1
T
Œ≥m
Œ≥m exp{Œ≤m
xm,i }ym,i
exp{‚àíexp{Œ≤m
xm,i }ym,i
}

M


Figure 2: Illustration of dependencies of variables
in the hierarchical conditional opportunity model.
It shows the ith observation of category m. ym,i is
the purchase time which is dependent on the conditional opportunity model Œ∏m = {Œ≤m , Œ≥m } of category
m, as wells the observed covariates xm,i of this purchase. Each category m has its own parameters of
the conditional opportunity model Œ≤m , Œ≥m . Models of
each category share information through the prior,
œÜ = (ŒºŒ≤ , Œ£Œ≤ , aŒ≥ , bŒ≥ ).

In the E-step, we infer the posterior distributions over
hidden variables Œ∏m given the current parameter setting œÜ.
There is no closed-form solution. Instead, we Ô¨Ånd a tractable
approximation of the posterior distribution of Œ∏m given œÜ
(i.e, q(Œ∏m ) that maximizes L(œÜ)).

(5)

m=1

306



M


L(œÜ) =

ln

q(Œ∏m )

m=1
M 


We can combine the above derivations with Equation 8,
then Ô¨Ånd q(Œ∏m ) using the conjugate gradient descent method.

p(Œ∏m , ym |œÜ)
dŒ∏m
q(Œ∏m )

3.4.2 M-Step

In the M-step, the goal is to maximize F (q(Œ∏1 ), ..., q(Œ∏M ), œÜ)
in Equation 6 with respect to œÜ given all Œ∏m . It is same as
m=1
to maximize the following quantity:
M 
M 


q(Œ∏m )
M 

dŒ∏m
=
q(Œ∏m ) ln p(ym |œÜ)dŒ∏m ‚àí
q(Œ∏m ) ln
(t+1)
p(Œ∏
|y
,
œÜ)
œÜ
q(Œ∏m ) ln p(ym |œÜ)dŒ∏m
‚Üê
arg
max
(10)
m
m
m=1
m=1
‚â•

q(Œ∏m ) ln

p(Œ∏m , ym |œÜ)
dŒ∏m
q(Œ∏m )

œÜ

‚â°F (q(Œ∏1 ), ..., q(Œ∏M ), œÜ)

The optimal œÜ at this step can be estimated with the following closed form:

To maximize L(œÜ), it is the same as minimize the following
equation to Ô¨Ånd each distribution q(Œ∏m ):

q(Œ∏m )
q(Œ∏m ) ln
q(Œ∏m )(t) = arg min
dŒ∏m (7)
q(Œ∏m )
p(Œ∏m |ym , œÜ)
Given that p(Œ∏m |ym , œÜ) =

p(ym |Œ∏m )p(Œ∏m |œÜ)
,
p(ym |œÜ)

M

ŒºŒ≤ m
M
M
T
m [Œ£Œ≤m + (ŒºŒ≤m ‚àí ŒºŒ≤ )(ŒºŒ≤m ‚àí ŒºŒ≤ ) ]
Œ£Œ≤ =
M
M
‚àí1
m Œ®(aŒ≥m ) ‚àí ln(bŒ≥m )
)
aŒ≥ = Œ® (ln bŒ≥ +
M
M aŒ≥
b Œ≥ =  M aŒ≥
m
ŒºŒ≤ =

we have:



q(Œ∏m ) = arg min KL[q(Œ∏m )||p(Œ∏m |œÜ)] ‚àí

q(Œ∏m ) ln p(ym |Œ∏m )dŒ∏m

q(Œ∏m )

(8)

where Œ®

3.5

KL[q(Œ∏m )||p(Œ∏m |œÜ)] = KL[q(Œ≤m )||p(Œ≤m |œÜ)] + KL[q(Œ≥m )||p(Œ≥m |œÜ)]
KL[q(Œ≤m )||p(Œ≤m |œÜ)]
1
T ‚àí1
= [tr(Œ£‚àí1
Œ≤ Œ£Œ≤m ) + (ŒºŒ≤ ‚àí ŒºŒ≤m ) Œ£Œ≤ (ŒºŒ≤ ‚àí ŒºŒ≤m )
2
det Œ£Œ≤m
) ‚àí k]
‚àí ln(
det Œ£Œ≤

The KL-divergence between two gamma distributions is
KL[q(Œ≥m )||p(Œ≥m |œÜ)]
= (aŒ≥m ‚àí aŒ≥ )Œ®(aŒ≥m ) ‚àí log Œì(aŒ≥m ) + log Œì(aŒ≥ )

(11)
P (T ‚â§ y)

N
m


(9)

T
xi }]}
‚âà 1 ‚àí exp{EŒ≤m ,Œ≥m [‚àíy Œ≥m exp{Œ≤m



T
xi }]}
= 1 ‚àí exp{EŒ≥m [‚àíy Œ≥m ]EŒ≤m [exp{Œ≤m

q(Œ≤m )q(Œ≥m )ln p(ym,i |Œ≤m , Œ≥m )dŒ≤m dŒ≥m

a

= 1 ‚àí exp{‚àí

[E(ln Œ≥m ) + E(Œ≤m )T xm,i + (E(Œ≥m ) ‚àí 1) ln ym,i

Œ≥m
T
‚àí E(exp(Œ≤m
xm,i ))E(ym,i
)]

The expectations in the above equation are
E(ln Œ≥m ) =Œ®(aŒ≥m ) ‚àí ln(bŒ≥m )

1
1 + e‚àíf T x
where x is a vector of features that are associated with the
purchasing, which includes the score/output of the existing
recommender system(such as SVD), as well as other features
that might help to predict the user‚Äôs purchase probability. f
is a vector of coeÔ¨Écients that can be learnt by maximizing
the likelihood of the training data.
P (p product = yes) =

E(Œ≤m ) =ŒºŒ≤m
aŒ≥
E(Œ≥m ) = m
bŒ≥m
1
xm,i T Œ£Œ≤m xm,i }
2

a

Œ≥m
E(ym,i
)=

(bŒ≥m

(bŒ≥m

Œ≥m
bŒ≥m
1 T
exp{ŒºT
Œ≤m xi + xi Œ£Œ≤m xi }}
‚àí ln y)aŒ≥m
2

The approximation is used because there is no closed-form
solution of the integration for calculating the expectation.
To estimate P (p product = yes), i.e., the probability of
the user purchasing the product, we can use any existing
recommender systems through the logistic regression model:

i=1

T
E(exp(Œ≤m
xm,i )) =exp{ŒºT
Œ≤m xm,i +

(12)

T
= 1 ‚àí EŒ≤m ,Œ≥m [exp{‚àíy Œ≥m exp{Œ≤m
xi }}]

i=1

=

P (T ‚â§ y + Œît) ‚àí P (T ‚â§ y)
1 ‚àí P (T ‚â§ y)

where:

i=1

=

Joint Purchase Probability

=

where Œ®(‚àó) is the digamma function.
The second part in Equation 8 is to maximize the data
likelihood of ym = {ym,1 , ..., ym,i , ..., ym,Nm } with the current Œ∏m = {Œ≤m , Œ≥m }.

N
m


(‚àó) is the inverse digamma function.

P (y < T ‚â§ y + Œît|T > y, p product = yes)

bŒ≥ ‚àí bŒ≥m
bŒ≥m

q(Œ∏m ) ln p(ym,i |Œ∏m )dŒ∏m

‚àí1

At a time y, we can decide whether to recommendation a
particular product in category m to a particular user or not
based on the following estimation: whether a user is likely to
purchase the product in the near future (i.e. between time
y and time y + Œît), given that the user has not purchased
the product since a triggering time point. To do so, we
need to estimate P (p product = yes, T ‚àà (y, y + Œît]) =
P (p product = yes)P (y < T ‚â§ y + Œît|T > y, p product =
yes), where

The KL-divergence between two Gaussian distributions is

+ aŒ≥ (log bŒ≥m ‚àí log bŒ≥ ) + aŒ≥m

m

m bŒ≥m

The Ô¨Årst part in Equation 8 is the KL-divergence between
the posterior distribution q(Œ∏m ) and the prior distribution
p(Œ∏m |œÜ).

N
m


m=1

(6)

Œ≥m
bŒ≥m
‚àí ln ym,i )aŒ≥m

307

3.6

Implementation Details

4.1

The purchase time ym is determined by the purchase timestamp of product jm and that of the triggering product js .
The triggering product is not necessarily the product in
the most recent purchase. There are multiple heuristic approaches to Ô¨Ånd the triggering item js in the user‚Äôs purchase history. Here we leverage the transition probability
P (js , jm ) in Equation 13.
P (ja , jb ) = 

# (ja , jb ) + Œª
# (ja , ‚àó) + J ¬∑ Œª

4.1.1

Evaluation of Conditional Opportunity
Model
Metrics

It is a relatively new research topic to predict the purchase
time and evaluate the performance of such model. We introduce the following two metrics to evaluate the performance
of the conditional opportunity model.
The Ô¨Årst metric is the perplexity of the model. It is motivated by the perplexity metric used to evaluate language
models and speech recognition [2]. The perplexity measures
how well a model predicts the testing data. It is deÔ¨Åned as
follows:
 M N
 M 1
m
 
m=1 Nm
1
perplexity =
P (T ‚àà (y, y + Œît]|p product)
m=1 i=1

(13)

of follow-up purchases of jb
where # (ja , jb ) is the number

that happened after ja .
# (ja , ‚àó) is the number of followup purchases after ja . J is the number of products and Œª is
the smoothing factor, which is set as 0.1.
We Ô¨Årst rank all items {j1 , ..., js , ..., jm‚àí1 } that happened
less than kt days before jm and have P (js , jm ) > T hrestran .
Then we use the top one as the triggering item. Other approaches can be explored in the future work. Although other
purchases {j1 , ..., js‚àí1 , js+1 , ..., jm‚àí1 } in the user history are
not treated as the triggering item, they are incorporated into
the opportunity model as covariates xm,i .
In this paper, we use the following covariates for each
purchase of product jm made by user u at timestamp tm :
whether user u purchased any product in category m in time
bin tb1 , ..., tbk ; how many times the user u purchased any
product in category m in time bin tb1 , ..., tbk ; whether the
user purchased the product jm in time bin tb1 , ..., tbk ; how
many times the user u purchased the product jm in time bin
tb1 , ..., tbk ; which season tm is in, whether tm is in the holiday
season, etc. Time bins tb1 , ..., tbk are set as one day, one
week, one month, two months, three months, six months,
one year, etc. We choose these covariates to show the eÔ¨Äect
of incorporating covariates in the conditional opportunity
model. These covariates capture the change of the time
distribution with the user‚Äôs purchase history, the seasonal
change, the cyclic pattern, etc. All covariates are normalized
in the scale of [0, 1].

(14)
=2

‚àí

M

m=1

Nm

1

i=1 M
m=1 Nm

log2 P (T ‚àà(y,y+Œît]|p product)

where P (T ‚àà (y, y+Œît]|p product) is deÔ¨Åned in Equation 11,
and i is the index for a testing data point. A better model
tend to give a higher data likelihood to the actual followup purchase time in the testing data, thus they have lower
perplexity, which means they are less surprised by the testing data.
The second metric focuses on the diÔ¨Äerence between the
estimated time ym,i and the actual time yÃÇm,i . After a model
predicts the distribution p(ym,i |p purchase) of the purchase
time, we use the median of the distribution as the estimated purchase time yÃÇm,i . The median of the distribu1
‚àí 1
tion is exp(Œ≤m xm,i ) rm (ln 2) rm . The error across all testing data can then be used to analyze and compare. The
smaller the error, the better the model. Here we use three
types of errors: mean absolute error(MAE), mean squared
error(MSE) and mean absolute percentage error(MAPE =
M Nm |yÃÇm,i ‚àíym,i |
M 1
).
i=1
m=1
ym,i
N
m=1

4.1.2

4. EVALUATION METHODOLOGY

m

Conditional Opportunity Models to Compare

In our experiments, we compare the following four conditional opportunity models.

As we are studying a new problem of recommending the
right product at the right time, there is no standard evaluation methodology. We design various experiments to evaluate the performance of the opportunity model. Major research questions that we aim to answer are:

Uniform assigns a uniform distribution to all time. p(ym,i
|p purchase) = Tunif1 orm where Tunif orm is the maximum time in consideration. We set Tunif orm = 500,
i.e., 500 days, arbitrarily in this paper.

Predictability of the conditional opportunity model
How accurate is the conditional time probability that is
predicted by the conditional opportunity model? How
accurate is the predicted purchase time, compared to
the actual purchase time? Are covariates useful?

O-One is a conditional opportunity model that Ô¨Åts a single set of parameters with no covariates (i.e., a basic Weibull distribution) to the purchase data. All
follow-up purchases in diÔ¨Äerent category m use the
same model.

Predictability of the opportunity model Is the joint purchase probability a good signal of making recommendations? Does it generate a better ranking in traditional zero-query pull-based recommendation systems?
Can it help to improve the user satisfaction/utility in
proactive push-based recommendation systems?

O-Dest is a hierarchical conditional opportunity model that
Ô¨Åts one Weibull distribution per product category, with
no covariates.
O-DestCov further incorporates covariates into O-Dest. In
this case, the probability density function changes for
each user and product as values of the associated covariates change over time.
All models smooth the conditional probability estimation
P (T ‚àà (y, y + Œît]|p product) = max(P (minThres, T ‚àà (y,

308

To achieve a better utility, the system with a Ô¨Åltering
component should send emails only if the expected utility
of adding the product is higher than zero (i.e. the joint
probability is higher than the threshold). The recommendation threshold is automatically determined by the following
P ‚àíuT N
equation [4]: uF P ‚àíuuTF N
.
+uF N ‚àíuT P
We don‚Äôt have a real push-based email promotion system
for a user study. Instead, we create an evaluation dataset
with the purchase data from a pull-based e-commerce website. The goal is to evaluate each model‚Äôs predictability of
discovering the ‚Äúreal opportunity‚Äù and avoiding the ‚Äúfake opportunity‚Äù in the email marketing. For each purchase at time
t in the testing dataset, we let each model consider two opportunities: sending a recommendation email the weekend
right before t and sending an email on some other random
weekend before t. Since existing models can not tell whether
to send an email or not, they always send an email with top
K recommendations for each opportunity. The opportunity
model with a Ô¨Åltering component will add a product to the
email if the expected utility of adding the product is higher
than zero. If no product is added to the email, the opportunity model would skip this opportunity and do not send an
email. Recommendations in the email are compared with
actual products that the user purchases in the week after
the email is sent. Assume that there are G opportunities
to send recommendation emails in the testing period. The
average utility/user satisfaction utility can be calculated as

Table 1: The utility set of the recommender system. There are four types of utilities, depending
on whether the system recommends the item to the
user and whether the user purchases the item.
accept:Y
accept:N

show:Y
uT P
uF P

show:N
uF N
uT N

y + Œît]|p product)) to avoid having a probability that is
too low (such as when there is no triggering item before the
purchase). minThres is set as 0.001. Œît in Equation 11 is set
as 7 (i.e., 7 days) for all models during the prediction step.
The threshold for the transition probability to consider the
an item js as the triggering item is set as 0.01.

4.2
4.2.1

Evaluation of Opportunity Model
Metrics

Here we evaluate the predictability of the opportunity
model with the joint purchase probability in two scenarios.
1) [Zero-query pull-based scenario] assumes the user
comes to the site to look for products to purchase without
issuing any search query. In this scenario, the goal is to discover products that the user would purchase and recommend
them to the user proactively. The system ranks all products
by their joint purchase probability and recommends top K
products to the user.
The evaluation metric in this scenario is the conversion
rate which reÔ¨Çects whether a user receives at least one good
recommendation. Each testing time corresponds to the time
when a user comes to the site and makes purchases. Let
Spurchased contain all unique products in the order. Let
Cpurchased contain all unique categories in the order. Let
SK,recommended contain top K unique product recommendations. Let CK,recommended top K unique category recommendations. CRproduct is the conversion rate at the product
level and CRcategory is the conversion rate at the category
level. SigniÔ¨Åcance level of 0.05 with the paired two-tailed
t-test is used to compare two models.

CRproduct @K =

CRcategory @K =

1
0

Spurchased ‚à© SK,recommended = ‚àÖ
otherwise

1
0

Cpurchased ‚à© CK,recommended = ‚àÖ
otherwise

G

following: utility =

4.2.2



.

Recommendation Models to Compare

TopPop recommends most popular products to the user.
SVD is a widely-used recommendation algorithm with a
decent performance on the well-known NetÔ¨Çix competition. It is the basis of several recommendation algorithms based on latent factors.
SVD.util is the state-of-art recommendation algorithm in
the e-commerce domain without time consideration.
It modiÔ¨Åes SVD with the marginal net utility framework [19].
Regression.Model is an alternative new approach to predict the probability of a user purchasing a product
at a particular time using a logistic regression model,
with various important time-dependent features. This
model contains features such as the SVD score of the
product, whether the product/category has been purchased t days ago, how many time the product/category
has been purchased t days ago, etc.
Conditional.Opportunity.Model recommends products
based on P (T ‚àà (y, y + Œît]), which is estimated by
the hierarchical conditional opportunity model with
covariates.

(uT P Ishow,accept + uF P Ishow,accept
¬Ø
+ uF N Ishow,accept
+ uT N Ishow,
)
¬Ø
¬Ø accept
¬Ø

utilityg
G

We choose the following recommendation models to compare:

2) [Push-based email promotion scenario] assumes
that recommender systems send email/message proactively
to a user regularly regardless of whether the user comes to
the site or not.
The evaluation metric in this scenario is the average utility/user satisfaction. The utility for each type of recommendations is shown in Table 1. The utilityg for each email of
recommendations is calculated by Equation 15.
utilityg =

g=1

(15)

Opportunity.Model recommends products based on the
joint probability of a user making a purchase of a product in the near future(P (p product, T ‚àà (y, y + Œît])).

I‚àó is the indicator function where I‚àó = 1 if ‚àó is true. Unlike
traditional metrics such as conversion rate@K, the utility
metric considers both the positive eÔ¨Äect for good recommendations and the negative eÔ¨Äect for bad recommendations.
The higher the utility, the better the model.

Opportunity.Model.Filtering adds a Ô¨Åltering component
to Opportunity.M odel. In the push-based email scenario, it adds a product to the promotion email only

309

0.010

if the expected utility of adding the product is higher
than zero.

prob of time

0.002
0.000
0

100

200

300

400

500

days

Figure 3: Density plot of the purchase time between
diÔ¨Äerent follow-up purchases from Baby|Feeding

Table 2: Perplexity of diÔ¨Äerent conditional opportunity models in 10-fold cross validation.
Data
All purchases
repurchases
new purchases

Uniform
46.95
58.99
44.25

O-One
23.75
16.68
26.04

O-Dest
22.45
14.80
25.01

O-DestCov
18.95
9.75
22.48

portunity models, O-DestCov achieves the lowest perplexity,
followed by O-Dest, and O-One. O-DestCov incorporates
related covariates in addition to Ô¨Åtting parameters of a conditional opportunity model for each category m. It shows
the importance of considering covariates when modeling the
purchase time of a follow-up purchase.
To further analyze the eÔ¨Äect of covariates, we compare
the perplexity of all models in the repurchase data and the
new purchase data in Table 2. As expected, the major gain
is in reducing the perplexity of repurchases. More feature
exploration would be useful to improve the prediction of new
purchases in the future.
Now we compare the estimated purchase time with the actual time of a follow-up purchase in Table 3. All conditional
opportunity models perform better than the baseline model
U nif orm. O-DestCov gives the most accurate estimation of
the purchase time, followed by O-Dest, and O-One. According to MAE, the estimated purchase time from O-DestCov

Table 3: Error between the estimated purchase time
and the actual purchase time. MAE stands for mean
absolute error. MSE stands for mean squared error.
MAPE stands for mean absolute percentage error.

5. EXPERIMENTAL RESULTS
5.1

0.004

The purchase history from 2004-01-01 to 2009-03-08 collected on a real-world e-commerce website, shop.com, is used
for our experiments. We use all purchases that have category
information of the product. Tail users that made less than
5 product purchases are Ô¨Åltered out in the training data,
which follows the similar pre-processing in related work [19,
24]. In addition, 10 possible spam users that made more
than 200 product purchases are Ô¨Åltered out as well. The
remaining data contains 11,351 users and 67,291 products.
There are 105,550 unique (user, product) pairs. This userproduct matrix is quite sparse, with only 0.014% density.
There are 380 categories in total.
To evaluate the conditional opportunity model as in Section 4.1, 10-fold cross validation is used. To evaluate the
opportunity model with the joint purchase probability as
in Section 4.2, we sort all purchase history by time. The
Ô¨Årst 90% is used as the training data (data before 200811-24) and the last 10% is used as the testing data (data
after 2008-11-24). There are 7,014 testing cases in total. At
the product level, there are 1,143 repurchase cases(16.29%)
and 6,269 new purchase cases(89.37%). At the categorical
level, there are 2,850 repurchase cases(i.e. 40.63% cases with
purchase from the same category) and 4,850 new purchase
cases(i.e. 69.14% cases with purchase from a new category).
To train the regression model with SVD as one of the features, the Ô¨Årst half training data is used to train the SVD
model and the second half training data is used to learn coefÔ¨Åcients in the regression model. The number of latent factors
for all SVD-related models is set to 50. In the recommendation step, all models recommend top K (K=5) products to
the user. To save the computation time, Regression.M odel,
Conditional.Opportunity.M odel and Opportunity.M odel rank among top N recommendations from SVD and selects top
K to recommend, where N = 100 and K = 5.
The time density plots of some common transitions from
products in the Baby|Feeding category to the target item
jm are shown in Figure 3. This supports our motivation of
identifying triggering items in the user history. For example, users who purchased from Baby|Feeding would purchase
items in other Baby related categories in the future. The
purchase time of the follow-up purchase does follow diÔ¨Äerent distributions for diÔ¨Äerent products or diÔ¨Äerent covariates
(take the triggering product as a covariate). For example,
users who purchased from the Baby|Feeding category would
purchase products from this category again in one month.
Later on when the baby grows up, they would purchase products from Toys|Board, Card&Dice Games.

0.006

0.008

4.3 Dataset

follow‚àíup purchases
Baby|Feeding‚àí>Baby|Feeding
Baby|Feeding‚àí>Baby|Bathing
Baby|Feeding‚àí>Apparel_&_Accessories|Bras
Baby|Feeding‚àí>Baby|Safety
Baby|Feeding‚àí>Toys|Board,_Card_&_Dice_Games

Analysis of Conditional Opportunity Model

Data
All Purchases

The perplexity of all conditional opportunity models in
Section 4.1.2 are compared in Table 2. All conditional opportunity models have lower perplexity than the baseline
model Uniform. This demonstrates that conditional opportunity models have better predictability of the time-based
purchase probability in the data. Among all conditional op-

Repurchases

New Purchases

310

Error rate
MAE
MSE
MAPE
MAE
MSE
MAPE
MAE
MSE
MAPE

Uniform
159.74
30859.346
16.592
183.337
37728.853
27.895
154.244
29260.204
13.964

O-One
105.279
23322.373
3.796
63.7
9406.591
6.165
114.956
26560.746
3.246

O-Dest
102.617
21920.462
3.763
62.119
8799.832
5.631
112.042
24973.753
3.329

O-DestCov
77.695
14335.505
2.434
34.536
4456.393
0.658
87.736
16634.239
2.847

Table 5: Average utility of email recommendations
in the push-based scenario. Coverage is the percentage of emails that are sent among all possible opportunities. Rec count is the average number of unique
recommendations in a email when the email is sent.

Table 4: Conversion rate of recommendation models
in the zero-query pull-based scenario. Numbers in
bold are signiÔ¨Åcantly better than the corresponding
value in baseline models.
Product level

Model
TopPop
SVD
SVD.util
Regression.Model
Conditional.Opportunity.Model
Opportunity.Model

All purchases
CR@1
CR@5
0.0
0.0155
0.0134
0.0344
0.0287
0.0369
0.0339 0.0525
0.0160
0.0282
0.0289 0.0452

Repurchases
CR@1
CR@5
0.0
0.0936
0.0822
0.2073
0.1750
0.2248
0.2082 0.3202
0.0962
0.1706
0.1750 0.2712

New purchases
CR@1 CR@5
0.0
0.0003
0.0
0.0011
0.0002 0.0003
0.0
0.0003
0.0003 0.0006
0.0005 0.0011

Repurchases
CR@1
CR@5
0.0130
0.1382
0.1309
0.3267
0.1779
0.2453
0.2330 0.3646
0.2467 0.3856
0.3091 0.4495

New purchases
CR@1 CR@5
0.0219 0.0435
0.0066 0.0540
0.0041 0.0511
0.0076 0.0472
0.0144 0.0907
0.0082 0.0816

Model

TopPop

SVD

Utility
Coverage
Rec count

-4.994
1
5

-4.862
1
5

Model

TopPop

SVD

Utility
Coverage
Rec count

-4.823
1
5

-4.515
1
5

Model

TopPop

SVD

Utility
Coverage
Rec count

-4.983
1
5

-4.621
1
5

Model

TopPop

SVD

Utility
Coverage
Rec count

-4.514
1
5

-3.667
1
5

Model

TopPop

SVD

Utility
Coverage
Rec count

-4.992
1
5

-4.828
1
5

Model

TopPop

SVD

Utility
Coverage
Rec count

-4.779
1
5

-4.394
1
5

Category level

Model
TopPop
SVD
SVD.util
Regression.Model
Conditional.Opportunity.Model
Opportunity.Model

All purchases
CR@1
CR@5
0.0204
0.0848
0.0577
0.1688
0.0751
0.1344
0.0999 0.1792
0.1102 0.2154
0.1313 0.2345

is 77 days away(higher or lower) from the actual time. It
is a decent performance given that the total time range is
500 days. Further analysis shows that O-DestCov predicts
more accurately in both the repurchase and the new purchase data.

5.2
5.2.1

Analysis of Opportunity Model
Pull-based Scenario

Now we evaluate the performance of the opportunity model
with the joint purchase probability. The conversion rate
of diÔ¨Äerent recommendation models in the zero-query pullbased scenario is compared in Table 4.
The opportunity model achieves higher conversion rate
at both the product level and the category level. Further
analysis shows that the contribution of the conditional opportunity model is mainly at the category level. It is not
surprising because the model is designed at the category
level. Product-level models can be explored in the future.
The key challenge is to solve the sparsity and scalability
issues.
We further analyze the performance of the conversion rate
in diÔ¨Äerent purchase scenarios. In Table 4, we show the conversion rate of repurchases and new purchases. It is clear
that the major contribution of the opportunity model is in
the repurchase scenario. The observation is consistent with
the evaluation of the conditional opportunity model in Section 5.1: the conditional opportunity model predicts more
accurately in repurchases.

5.2.2

utility set 1
uT P = 3, uF N = 0
uF P = -1, uT N = 0
Threshold = 0.25
Product level
SVD.util Opportunity.Model
-4.768
-4.810
1
1
5
5
category level
SVD.util Opportunity.Model
-4.570
-4.255
1
1
5
5
utility set 2
uT P = 10, uF N = 0
uF P = -1, uT N = 0
Threshold = 0.09
Product level
SVD.util Opportunity.Model
-4.363
-4.477
1
1
5
5
Category level
SVD.util Opportunity.Model
-3.819
-2.951
1
1
5
5
utility set 3
uT P = 3, uF N = -1
uF P = -1, uT N = 0
Threshold = 0.20
Product level
SVD.util Opportunity.Model
-4.710
-4.762
1
1
5
5
Category level
SVD.util Opportunity.Model
-4.463
1
5

-4.069
1
5

Opportunity.Model
Filtering
-0.048
0.023
2.432
Opportunity.Model
Filtering
0.006
0.023
1.081

Opportunity.Model
Filtering
-0.399
0.180
3.007
Opportunity.Model
Filtering
0.282
0.180
1.880

Opportunity.Model
Filtering
-0.066
0.033
2.356
Opportunity.Model
Filtering
0.015
0.033
1.115

purchases in the following week. Among those with followup purchases, the average number of purchases is 2.227.
In the first utility set, the utility uT P for a good recommendation that the user purchases is set to 3. When the system shows a product and the user does not purchase it, the
utility uF P is ‚àí1. The resulting Ô¨Åltering threshold is 0.25. In
this case, Opportunity.M odel.F iltering has a better utility
than other models by Ô¨Åltering out many false alarms. The
average utility at the category level is higher, which is expected. It rewards a recommendation if it matches the user‚Äôs
purchase at the category level, which is an easier task. In
general, the model with higher conversion rate in the pullbased scenario has high utility in the push-based scenario.
In the second utility set, the utility uT P is set to 10, indicating that the user is more tolerant to bad recommendations. Thus the threshold is lower, being 0.09. The coverage
of Opportunity.M odel.F iltering increases while the average utility drops. There is a tradeoÔ¨Ä between the utility
and the recommendation coverage, which can be tuned in a
real-world application by a user or the system designer.
In the third utility set, uF N is set to ‚àí1. It is the penalty
for not recommending a product that would be purchased

Push-Based Scenario

Now we evaluate all models in the push-based scenario. In
the Opportunity.M odel.F iltering model, a product is recommended only if its joint purchase probability is higher
than the threshold. We evaluate the model with three sets
of utility at both the product level (i.e. true positive means
that the user purchased the exact product) and the category
level (i.e. a true positive means that the user purchased a
product in same category as the recommendation). The results are shown in Table 5. There are 3,014 email opportunities in the testing period. 55% of them have follow-up

311

by the user in the following week. Thus the coverage of
Opportunity.M odel.F iltering is higher to avoid missing good
recommendations with the threshold being 0.02. It still
achieves the highest utility among all models.

[8]

6. CONCLUSION AND FUTURE WORK
In this paper, we propose to develop the opportunity model
to predict the probability of a user purchasing a product at
a particular time. This is achieved by modeling the joint
probability of time and product, which can be calculated
by combining a proportional hazards model and a logistic
regression model. The joint probability guides the system
to make the right product recommendation at the right time.
This is just the Ô¨Årst step to tackle the research problem
of capturing the time-based recommendation opportunity.
Besides Weibull distribution, other distributions such as Exponential, Log-logistic, Lognormal, Generalized gamma, can
be explored. Further improvements could be achieved with
better covariates. More systematic approaches of discovering the triggering item could be explored. It would be helpful
to carry out experiments with a real push-based system to
evaluate the eÔ¨Äectiveness of the opportunity model in a real
user study. Due to the limited number of research data available and our own computational limits, we only learn the
category-level conditional opportunity model, which clearly
work well at the category level prediction. Another followup work is to evaluate this approach on a large-scale system
to learn the product-level models, which might lead to better
prediction at the product level.

[9]

[10]
[11]

[12]

[13]

[14]
[15]

[16]

Acknowledgments
[17]

We would like to thank shop.com for sharing the data. This
work was funded by National Science Foundation IIS-0713111
and IIS-0953908. Any opinions, Ô¨Åndings, conclusions or recommendations expressed in this paper are the authors, and
do not necessarily reÔ¨Çect those of the sponsors.

[18]

7. REFERENCES
[1] M. Beal. Variational algorithms for approximate
Bayesian inference. PhD thesis, University of London,
2003.
[2] S. Chen, D. Beeferman, and R. Rosenfeld. Evaluation
metrics for language models. In DARPA Broadcast
News Transcription and Understanding Workshop
(BNTUW), Lansdowne, Virginia, USA, Feb. 1998.
[3] P. Cremonesi, Y. Koren, and R. Turrin. Performance
of recommender algorithms on top-n recommendation
tasks. In Proceedings of the 4th ACM Recommender
systems, pages 39‚Äì46, 2010.
[4] C. Elkan. The foundations of cost-sensitive learning.
In Proceedings of the 17th international joint
conference on Artificial intelligence - Volume 2,
IJCAI‚Äô01, pages 973‚Äì978, 2001.
[5] N. Golbandi, Y. Koren, and R. Lempel. Adaptive
bootstrapping of recommender systems using decision
trees. In Proceedings of the fourth ACM WSDM‚Äô11.
[6] Z. Huang, W. Chung, and H. Chen. A graph model for
e-commerce recommender systems. J. Am. Soc. Inf.
Sci. Technol., 55:259‚Äì274, February 2004.
[7] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative
Ô¨Åltering with decoupled models for preferences and

[19]

[20]

[21]

[22]

[23]

[24]

312

ratings. In Proceedings of the twelfth CIKM, pages
309‚Äì316, New York, NY, USA, 2003. ACM.
Y. S. Kim, B.-J. Yum, J. Song, and S. M. Kim.
Development of a recommender system based on
navigational and behavioral patterns of customers in
e-commerce sites. Expert Syst. Appl., 28:381‚Äì393,
February 2005.
Y. Koren. Factorization meets the neighborhood: a
multifaceted collaborative Ô¨Åltering model. In
Proceeding of the 14th ACM SIGKDD KDD‚Äô08.
Y. Koren. Collaborative Ô¨Åltering with temporal
dynamics. In KDD, 2009.
S. li Huang. Designing utility-based recommender
systems for e-commerce: Evaluation of
preference-elicitation methods. Electronic Commerce
Research and Applications.
R. J. Mooney and L. Roy. Content-based book
recommending using learning for text categorization.
In DL ‚Äô00, pages 195‚Äì204, 2000.
D. Parra-Santander and P. Brusilovsky. Improving
collaborative Ô¨Åltering in social tagging systems for the
recommendation of scientiÔ¨Åc articles. Web Intelligence
and Intelligent Agent Technology, 1:136‚Äì142, 2010.
C. D. R. Regression models and life tables. Journal of
the Royal Statistic Society, B(34):187‚Äì202, 1972.
S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme.
Factorizing personalized markov chains for next-basket
recommendation. In Proceedings of the 19th WWW.
G. Shani, D. Heckerman, and R. I. Brafman. An
mdp-based recommender system. J. Mach. Learn.
Res., 6:1265‚Äì1295, 2005.
E. Shmueli, A. Kagian, Y. Koren, and R. Lempel.
Care to comment?: recommendations for commenting
on news stories. In Proceedings of the 21st
international conference on World Wide Web, WWW
‚Äô12, pages 429‚Äì438, New York, NY, USA, 2012. ACM.
J. Wang, B. Sarwar, and N. Sundaresan. Utilizing
related products for post-purchase recommendation in
e-commerce. In Proceedings of the 5th ACM
Recommender systems.
J. Wang and Y. Zhang. Utilizing marginal net utility
for recommendation in e-commerce. In Proceedings of
the 34th ACM SIGIR‚Äô11, pages 1003‚Äì1012, 2011.
J. Wang, Y. Zhang, and T. Chen. UniÔ¨Åed
recommendation and search in e-commerce. In
Information Retrieval Technology, pages 296‚Äì305.
Springer Berlin Heidelberg, 2012.
J. Wang, Y. Zhang, C. Posse, and A. Bhasin. Is it
time for a career switch? Proceedings of the 22nd
International World Wide Web Conference, 2013.
L. J. Wei. The accelerated failure time model: A
useful alternative to the cox regression model in
survival analysis. Statistics in Medicine,
11(14-15):1871‚Äì1879, 1992.
L. Xiang, Q. Yuan, S. Zhao, L. Chen, X. Zhang,
Q. Yang, and J. Sun. Temporal recommendation on
graphs via long- and short-term preference fusion. In
Proceedings of the 16th ACM SIGKDD KDD‚Äô10.
G. Zhao, M. L. Lee, W. Hsu, and W. Chen. Increasing
temporal diversity with purchase intervals. In
Proceedings of the 35th ACM SIGIR.


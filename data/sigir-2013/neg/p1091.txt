Accurate and Robust Text Detection: A Step-In for Text
Retrieval in Natural Scene Images
Xu-Cheng Yin
Xuwang Yin

∗

School of Computer and
Communication Engineering,
University of Science and
Technology Beijing, Beijing
100083, China

Kaizhu Huang

Hong-Wei Hao

Department of Electrical and
Electronic Engineering,
Xi’an Jiaotong-Liverpool
University, Suzhou 215123,
China

Institute of Automation,
Chinese Academy of
Sciences, Beijing 100090,
China

kaizhu.huang@xjtlu.edu.cn

hongwei.hao@ia.ac.cn

xuchengyin@ustb.edu.cn
xuwangyin@gmail.com
ABSTRACT

1.

We propose and implement a robust text detection system,
which is a prominent step-in for text retrieval in natural
scene images or videos. Our system includes several key
components: (1) A fast and effective pruning algorithm is
designed to extract Maximally Stable Extremal Regions as
character candidates using the strategy of minimizing regularized variations. (2) Character candidates are grouped
into text candidates by the single-link clustering algorithm,
where distance weights and threshold of clustering are learned
automatically by a novel self-training distance metric learning algorithm. (3) The posterior probabilities of text candidates corresponding to non-text are estimated with an character classifier; text candidates with high probabilities are
then eliminated and finally texts are identified with a text
classifier. The proposed system is evaluated on the ICDAR
2011 Robust Reading Competition dataset and a publicly
available multilingual dataset; the f measures are over 76%
and 74% which are significantly better than the state-of-theart performances of 71% and 65%, respectively.

Text in images contains valuable information and is exploited in many content-based image and video applications,
such as content-based web image search, video information
retrieval, mobile based text analysis and recognition, especially for text retrieval in natural scene images. Due to complex background, variations of font, size, color and orientation, text in natural scene images has to be robustly detected
before being recognized or retrieved.
Recently, Maximally Stable Extremal Region (MSER) based
text detection methods, which actually fall into the family
of connected component based methods but use MSERs [1]
as character candidates, have become the focus of several
recent projects [5, 3, 2, 6].
Although the MSER based method is the winning method
of the benchmark data, i.e., ICDAR 2011 Robust Reading
Competition [5] and has reported promising performance,
there remains several problems to be addressed. First, as the
MSER algorithm detects a large number of non-characters,
on one hand, it may still have room for further improvement in terms of the accuracies; on the other hand, it tends
to be slow because of the computation of complex features.
Second, current approaches [3, 4] for text candidates construction is time consuming and error pruning.
We propose a robust and accurate MSER based scene text
detection method. First, we designed a fast and accurate
MSERs pruning algorithm; the number of character candidates to be processed is significantly reduced with a high
accuracy. Second, we propose a novel self-training distance
metric learning algorithm that can learn distance weights
and clustering threshold simultaneously and automatically;
character candidates are clustered into text candidates by
the single-link clustering algorithm using the learned parameters. Third, we propose to use a character classifier to
estimate the posterior probabilities of text candidates corresponding to non-text and remove text candidates with high
probabilities. By integrating the above ideas, we built an
accurate and robust scene text detection system.

Categories and Subject Descriptors
I.4 [Image Processing and Computer Vision]: Scene
Analysis–Object Recognition, Segmentation–Region Growing

Keywords
Scene text detection, maximally stable extremal regions,
single-link clustering, distance metric learning
∗Currently (from Jan 2013 to Jan 2014), Xu-Cheng Yin is
a visiting scholar in the Center for Intelligent Information
Retrieval, University of Massachusetts Amherst.

Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact
the owner/author(s).
SIGIR’13, July 28-August 1, 2013, Dublin, Ireland
ACM 978-1-4503-2034-4/13/07.

2.

INTRODUCTION

SYSTEM OVERVIEW

The structure of our novel MSER based text detection
system, as well as the sample result of each stage is presented
in Figure 1, which includes the following stages:

1091

Second, experiments on a multilingual dataset [4] are also
conducted. The training dataset contains 248 images and
the testing dateset contains 239 images.

Original image

Character candidates
extraction

Table 2: Performance (%) comparison of text detection algorithms on the multilingual dataset.
Methods
Recall Precision
f
Speed (s)
Scheme-I
63.23
79.38
70.39
0.22
Scheme-II
68.45
82.63
74.58
0.22
Pan et al.’s [4]
65.9
64.5
65.2
3.11

Text candidates
construction

Text candidates
elimination

The performance of our system (include Scheme-I and
Scheme-II) and Pan et al.’s method [4] is presented in Table 2. The main difference between Scheme-I and SchemeII is that the character classifier in the first scheme is trained
on the ICDAR 2011 training set while the character classifier in the second scheme is trained on the multilingual
training set. The result comparison between Scheme-I and
Scheme-II in Table 2 shows that the performance of the
proposed system is significantly improved because of the incorporating of the Chinese-friendly character classifier.
Finally, we have setup an online demo of our proposed system at “http://kems.ustb.edu.cn/learning/yin/dtext”.
We also develop an application software of camera-based realtime scene text detection in Android Phones and Tablets.
Acknowledgments This is supported by National Basic
Research Program of China (2012CB316301) and National
Natural Science Foundation of China (61105018, 61175020).

Text candidates
classification

Figure 1: Flowchart of the proposed system.
1) Character candidates extraction. character candidates
are extracted with MSERs; most of the non-characters are
reduced by the proposed MSERs pruning algorithm using
the strategy of minimizing regularized variations.
2) Text candidates construction. distance weights and
threshold are learned simultaneously using a novel metric
learning algorithm; character candidates are clustered into
text candidates by the single-link clustering algorithm using
the learned parameters.
3) Text candidates elimination. the posterior probabilities
of text candidates corresponding to non-text are measured
using the character classifier and text candidates with high
probabilities for non-text are removed.
4) Text candidates classification. text candidates corresponding to true text are identified by the text classifier.
An AdaBoost classifier is trained to decide whether an text
candidate corresponding to true text or not.
For more details we refer the reader to [7, 8].

3.

4.

REFERENCES

[1] J. Matas, O. Chum, M. Urban, and T. Pajdla. Robust
wide baseline stereo from maximally stable extremal
regions. In Proceedings of BMVC, volume 1, pages
384–393, 2002.
[2] L. Neumann and J. Matas. A method for text
localization and recognition in real-world images. In
Proceedings of the 10th ACCV, volume 3, pages
770–783, 2011.
[3] L. Neumann and J. Matas. Real-time scene text
localization and recognition. In Proceedings of IEEE
CVPR, pages 3538–3545, 2012.
[4] Y.-F. Pan, X. Hou, and C.-L. Liu. A hybrid approach
to detect and localize texts in natural scene images.
IEEE Trans. Image Processing, 20(3):800–813, 2011.
[5] A. Shahab, F. Shafait, and A. Dengel. ICDAR 2011
robust reading competition challenge 2: Reading text in
scene images. In Proceedings of ICDAR, pages
1491–1496, 2011.
[6] C. Shi, C. Wang, B. Xiao, Y. Zhang, and S. Gao. Scene
text detection using graph model built upon maximally
stable extremal regions. Pattern Recognition Letters,
34(2):107–116, 2013.
[7] X. Yin, X.-C. Yin, H.-W. Hao, and K. Iqbal. Effective
text localization in natural scene images with MSER,
geometry-based grouping and Adaboost. In Proceedings
of ICPR, pages 725–728, 2012.
[8] X.-C. Yin, X. Yin, K. Huang, and H.-W. Hao. Robust
text detection in natural scene images. CoRR
abs/1301.2628, 2013.

EXPERIMENTS AND DEMOS

First, we perform experiments on ICDAR 2011 Competition dataset. The performance of our system, together
with Neumann and Matas’ method [3], a very recent MSER
based method by Shi et al. [6] and the top 3 scoring methods
(Kim’s, Yi’s and TH-TextLoc) from ICDAR 2011 Competition are presented in Table 1. As can be seen from Table 1,
our method produces much better recall, precision and f
measure over other methods on this dataset. The average
processing speed of the proposed system on a general Linux
laptop is 0.43s per image.
Table 1: Performance (%) comparison of text detection algorithms on ICDAR 2011 data.
Methods
Recall Precision
f
Our Method
68.26
86.29
76.22
Shi et al.’s method [6]
63.1
83.3
71.8
Kim’s Method
62.47
82.98
71.28
Neumann and Matas [3]
64.7
73.1
68.7
Yi’s Method
58.09
67.22
62.32
TH-TextLoc System
57.68
66.97
61.98

1092


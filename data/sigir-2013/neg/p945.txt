Tagcloud-based Explanation with Feedback for
Recommender Systems
Wei Chen

Wynne Hsu

Mong Li Lee

School of Computing, National University of Singapore, Singapore
{weichen,whsu,leeml}@comp.nus.edu.sg

ABSTRACT

bought “Mulan" also bought “Toy Story". User-based explanation
of recommendations looks at the rating profile of a user u and finds
the set of users U with similar rating profiles. The items rated positively by U will be recommended to u. The main drawback of
item-based and user-based explanations of recommendations is that
different users may like an item for different reasons. For example,
some may like “Mulan" because it has good animation whereas
user u bought “Mulan" because of its filial piety theme. In this
case, recommending “Toy Story” to u may not be suitable.
Feature-based explanation utilizes predefined categories and ontologies. The work in [2] uses features such as genre, director and
cast to explain the recommended movies. However, good explanation of recommendations remains a challenging task as many items
do not have predefined categories or ontologies and creating them
are domain dependent, laborious and sometimes infeasible. Furthermore, items in recommender systems are very diverse and encompasses photos, video and music. These items may not have
readily available textual content to provide the semantics for explanation.
Social tagging has become a common online activity of web
users. This has generated a rich set of tags for products, movies,
videos clips, news articles, blogs. All these tags capture the semantics of items from users’ points of view, using a ubiquitous
vocabulary for heterogeneous domains of objects. In this work, we
propose to use social tags to bridge the gap from the limited text description and the limited availability of pre-defined categories and
ontologies to the rich semantic feature space of items.
Table 1 shows the quaternary relations among users, tags, ratings
and items. For example, u1 likes the movie “F orrest Gump” and
tags it with the tag “P sychology”. We observe that an item is often
associated with tags that provide the semantic features for characterizing the item. As shown in Table 1, the tag “comedy” highlights the light-hearted nature of the movie “T oy Story”. We can
also infer users’ preference for certain aspects of an item based on
the tags used and the rating information. For example, u1 does not
seem to like comedies since he tags “T oy Story” as “comedy”
and rates them with “dislike” (see Table 1). In contrast, u2 tags the
same movie as “comedy” and rates them with “like”. In addition,
tags can serve to highlight the latent associations between an item
and the user. For example, a system may recommend “T oy Story”
to u3 since u3 likes and tags “F orrest Gump” as comedy.
The work in [3] utilizes a 4-order tensor to model users, items,
tags and ratings in a social tagging system. A multi-way latent semantic analysis is applied on the tensor, and dimensionality reduction is performed using the higher-order analogue of matrix singular value decomposition. The singular values obtained after dimension reduction denote the latent features for both users and items.
However, it is difficult to attach semantic meaning to these latent

Personalized recommender systems aim to push only the relevant
items and information directly to the users without requiring them
to browse through millions of web resources. The challenge of
these systems is to achieve a high user acceptance rate on their
recommendations. In this paper, we aim to increase the user acceptance of recommendations by providing more intuitive tag-based
explanations of why the items are recommended. Tags are used as
intermediary entities that not only relate target users to the recommended items but also understand users’ intents. Our system also
allows tag-based online relevance feedback. Experiment results on
the Movielens dataset show that the proposed approach is able to
increase the acceptance rate of recommendations and improve user
satisfaction.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Search and Retrieval

Keywords
Tensor factorization, Recommendation, Social tags, Personalization, Explanation

1. INTRODUCTION
Existing recommender systems utilize different approaches such
as content filtering and collaborative filtering to find the relevant
items and information directly to the users. However, oftentimes
users do not know why items are recommended to them, and the
acceptance rate of these recommendations is not high. This has
led to low users’ satisfaction and distrust towards the recommendations. Recent works aim to address this problem by explaining
the systems’ recommendations to users. Explanations of recommendations fall into one of three categories: (a) item-based [1], (b)
user-based [1], and (c) feature-based [2].
Item-based explanation of recommendations assumes that users
who have bought similar items have similar interests. For example,
if a user u is interested to buy the DVD “Mulan", Amazon.com
would also recommend item “Toy Story" to u as other users who
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

945

Table 1: Quaternary relations among users, tags, ratings and
items
User
Tag
Rating
Item
1
u1
psychology
like
Forrest Gump
2
u1
comedy
dislike
Toy Story
3
u1
psychology
like
Beautiful Mind
4
u2
comedy
like
Forrest Gump
5
u2
comedy
like
Toy Story
6
u3
comedy
like
Forrest Gump
features and therefore providing explanations on why the items are
recommended to users proved to be impossible.
In this work, we overcome this limitation by utilizing the parallel
factor (PARAFAC) model [4] to extract the latent features of users
and items and map them to a common basis in terms of tags. These
tags capture the semantic features of items from users’ point of
views and allow us to generate explanations that are intuitive to
users in the form of tagclouds. We develop a recommender system
that allows users to provide feedback on the recommended items.
Based on the feedback, we incrementally update the users’ profile
to generate a new list of recommendations. Experiment results on
the Movielens dataset show that the proposed approach is able to
increase the acceptance rate of recommendations and improve user
satisfaction.

(a) Before feedback

2. SYSTEM OVERVIEW
Figure 1 shows the framework of the proposed recommender
system. The Repository contains users’ rating and social tagging
activities and user profiles. The Watcher monitors log user activities such as the tags they use, the ratings they give to items, etc.
We provide an interface for users to choose tags that are used by
other users (e.g, Pixar, Disney, animation, TomHanks, cgi.etc) or
add their own tags to the movies. Besides that, user can rate the
item based on his/her opinion.

(b) After feedback
Figure 2: Screenshots of recommendation system
are key factors that characterize the user. Note that a user can
choose different levels of summarization by controlling the number
of tags displayed. Figure 2(b) shows the new list of items recommended after the user provides his/her feedback by clicking on the
thumb-up icon for “T om Hanks” and “Adventure”.

User

Receive Recommendation and explanation

Monitor user activities

3.
Ask for Recommendation

Top-N
Recommendation
Watcher

Respository

Recommender
User feedback

PROPOSED METHOD

We model Table 1 as a 4-order tensor with dimensions 3×2×2×
3. The tuple (u1 ,pyschology,like,“F orest Gump”) corresponds
to the entry A(1,1,1,1). The value of this tensor entry is 1 since
(u1 ,pyschology,like,“F orest Gump”) can be found in Table 1.
On the other hand, the tuple (u1 ,comedy,like,“F orest Gump”)
corresponds to A(1,2,1,1) but the value of this entry is 0 as the
tuple does not exist in Table 1.
The work in [3] uses Higher Order Singular Value Decomposition (HOSVD) to capture the underlying relationships among usertag-item-rating by reducing the rank of the original tensor to lower
rank such that the effect of noise on the underlying population is
minimized. We have the approximate tensor Â with a lower rank
(c1 · · · c4 )

Top-N
Recommendation
explanation by Tag
cloud

Advisor

Figure 1: Recommendation System Overview
Based on the user profiles, the Recommender generates personalized recommendation and provides explanation for the recommended items. The Advisor shows the top-N items to the user,
and accepts feedback from the user if s/he is not satisfied with the
recommendations. Based on the feedback, the Recommender will
compute a new list of recommendations for the user.
Figure 2(a) shows a screenshot of our recommender system. A
red (blue) colored tag indicates that it is often associated with positively (negatively) rated items. A black colored tag means that
it is neutral. From the user and item tagclouds, a user will realize that “T oy story” is recommended to him/her because these
clouds have tags in common “classic”, “disney” “imdb top 250”
and “animation”. The context to aid user understanding, e.g.,
“disney” “animation”, “classic”, “imdb top 250” and “Oscar”

Â = Ŝ ×1 Û

(1)

×2 Û

(2)

· · · ×4 Û

(4)

(1)

where Û (i) is the latent features representation (e.g.users, etc.)
and Ŝ is the approximate core tensor such that the frobenius norm
||A − Â||2F is minimized [3]. User/Item/Tag recommendation can
be generated based on the Â [3]. However, one drawback of such
model is that reason why we recommend item to user is not clear,
which is suffered by most of the model based recommender algorithms.
In order to provide an intuitive explanation for the recommendation, our idea is to map the underlying relationships among user-

946

tag-item-rating to a common basis in terms of tags so that it is
meaningful and understandable to the users. To achieve this, we
extract the latent features of users, tags, items and map them into
a common space. Figure 3 shows the mapped 2D space of users,
items, and tags for our running example.
From the distribution, we observe that “T oy Story” and u3 are
close together, suggesting that the two are rather similar. In addition, the tag closest to u3 and “T oy Story” is comedy. In other
words, the dominant feature in u3 and “T oy Story” is comedy.
Hence, the recommender system can explain to u3 that “T oy Story”
is recommended because he/she likes comedy and “T oy Story”
is a comedy.
The extraction of the latent features of users, tags, and items and
mapping them into a common space requires a special decomposition model that allows a one-to-one mapping of dimension across
each mode. Here, we adopt the PARAFAC model [4] to carry out
further tensor decomposition on the approximate core tensor Ŝ to
obtain a set of projection matrices P̂ (i) (1 ≤ i ≤ 4).
Ŝ =

R
∑
⃗ (1)
⃗ (2)
⃗ (4)
P̂j ⊗ P̂j ⊗ · · · P̂j

Comedy

1
U2

0.5

Beautiful
Mind
0.5

(2)

×2 Uˆ′

(2)

×3 Uˆ′

(3)

×4 Uˆ′

(4)

(1)
(2)
(3)
where Uˆ′
∈ R|U |×r , Uˆ′
∈ R|V |×r , Uˆ′
∈ R|R|×r and
(4)
|T
|×r
Uˆ′
∈R
(i)
As such, we have the latent features Uˆ′ extracted for users, tags,
and items mapped to a same r dimension space. In this mapped
space, we will characterize both users and items using the tags
based on the cosine similarity between users/items to tags. Once
this is done, the recommender system can automatically generate
the explanation for the "why" question using tags.
To provide further insights on the recommendation, we categorize tags into three groups depending on how often they are associated with positively rated items, negatively rated items, or mixed
rating by the user. The categorization of a tag t for a user u is obtained by computing the total tensor values for each rating over all
the items.
∑
∑
pref (u, t) =
Â(u, i, t, “like”) −
Â(u, i, t, “dislike”)
i∈V

1

Alternatively, the user may choose to adjust his/her profile description to more accurately reflect his/her current interests. Suppose a user u likes the artist “T im Allen”, he can click on the
thumb-up icon (see Figure 2(a)). If he does not like “T im Allen”,
he will click on the thumb-down icon. For each thumb-up on the tag
t, we search for movie m that has been tagged using t by users other
than u and replace weight of the tensor element A(u, t, “like”, m)
by a small constant c = 1/q where q is the number of users who
tagged movie m with tag t. Similarly, for each thumb-down action, the weight of tensor element A(u, t, “dislike”, m) will be
replaced by a small constant c = 1/q. . With each update of the
tensor elements, we can adopt the online PCA technique [5] to update the latent feature matrice Û (i) , 1 ≤ i ≤ 4.

⃗ (i)
where P̂j denotes the j th column of matrix P̂ (i) and P̂ (i) ∈
ci ×r
R
(1 ≤ i ≤ 4).
(i)
By substitute the Equation (2) into Equation (1), let Uˆ′
=
(i)
(i)
Û · P̂ (1 ≤ i ≤ 4), we have
(1)

U1
Psychology

Figure 3: Distribution of users, tags, and items in r = 2 dimensional space.

j=1

Â = Ŝ ′ ×1 Uˆ′

Forrest
Gump

Toy Story
U3

5.

i∈V

We say that t is a positive tag for u if pref (u, t) > 0, negative if
pref (u, t) < 0, and neutral if pref (u, t) = 0.

4. ADAPTIVE FEEDBACK RECOMMENDATION
After receiving the recommendations and the corresponding explanations, sometimes the users may find the recommendations unsuitable due to inaccurate profile descriptions. A novel feature
of our recommendation framework is its ability to allow users to
provide feedback and dynamically adjust the recommendation list
based on the feedback.
In our running example, suppose u3 is not happy with the recommendation of “T oy Story”. S/he is able to rate the recommendation “T oy Story” with the rating “dislike”. This is equivalent
to changing the weight of the tensor element A (u3 ,“Comedy”,
“dislike”,“T oy Story”) to 1.

EXPERIMENTAL RESULTS

We implemented our algorithms in MATLAB and developed our
recommender system as a web application using ASP.NET with
MYSQL server Database. In our experiments, we set r =50.
We obtain 4 years of data (Dec 2005 to Jan 2009) from the publicly available MovieLens dataset 1 . This data comprises of two
files. The first file contains users’ tags on different movies and the
second file contains users’ ratings on different movies. The ratings
are based on a scale of 1 to 5, with 1 being bad and 5 being excellent. By joining these two files over users and movies, we obtain
the quadruple < user, movie, tag, rating >. We have a total of
24563 tuples with 2,026 users, 5,088 movies, and 9,078 tags.
We pre-process these tuples to obtain a subset such that each
user, movie and tag occur at least 10 times in the dataset. We also
filter out those tags that have been used on only 1 item by less than
5 users. We further standardize the tags by stemming and removing
stop words. The resulting dataset has 11122 tuples with 201 users,
501 movies, and 404 tags.
We carried out two sets of experiments to evaluate our proposed
approach. The first set of experiments is a user study to demonstrate the effectiveness of using tag-based recommendations with
explanations in increasing user satisfaction and acceptance. The
second set of experiments shows that updating the recommendations through user feedback is able to increase user acceptance.

5.1

Evaluation of Explanation Styles

In order to evaluate the user acceptance of the items recom1

947

http : //www.grouplens.org/node/73

mended, we conduct an extensive user study to compare 3 styles
of explanations.

We also ask the participants to explicitly express their preferences for each explanation style. The rating is performed on a scale
of 1 to 5 with 1 being the least preferred and 5 being the most preferred. Table 3 shows the survey results with µq and σq denote
the mean and standard deviation of the survey ratings respectively.
We observe that the participants strongly preferred tagcloud-based
explanation style.

1. Item-based Explanation[6]. This approach computes the
top − k most similar items users rated and tagged before.
It has the format "Item X is recommended, because you have
tagged and rated items Y." The similarity (influence) between
X and Y is computed based on the cosine similarity of the
items’ ratings and is provided along with the recommendation.

Table 3: Evaluation of Explanation Styles
Explanation style
µd
σd
µq
σq
Item-based
0.56 0.82 2.56 0.91
Feature-based
0.47 1.22 2.17 0.86
Tagcloud-based
0.03 0.73 4.06 0.74

2. Feature-based Explanation[2]. This approach shows the
features of items recommended to the user. It has the format
"Item X is recommended, because it contains features a,b....".

5.2

3. TagCloud Explanation. This approach uses a tagcloud to
summarize the tags used for characterizing the user profile
and the recommended item.
Table 2 shows the different explanations for the recommended
item “Jurassic Park".
Table 2: Example explanations for recommended movie.
Method
RecommenExplanation
dation

Item-based

Evaluation of Feedback

In this set of experiments, we evaluate the effectiveness of users’
feedback in improving user acceptance of our recommended items.
Users are given a list of top 10 recommendations by our system,
and asked to provide ratings for these items. They are allowed to
give feedback on the recommendations that they are not satisfied
with. After each feedback, the system will generate a new list of
top 10 recommendation list to the user. We repeat these rounds of
feedback up to 5 times.
We use the following evaluation metrics.
Mean Absolute Error
∑
5−ru,i
where ru,i
(MAE) which is given by M AE = i∈Items
N
is the rating given by user u for item i, r̂u,i is the predicted rating
and N is the number of items recommended; Precision measures
the proportion of the correctly recommended items for top-N items
with rating 5
and is defined as P recision(N ) = N umber of items
;
N
for top-k
Average precision (AP) is the average of the precision
∑

Jurassic Park

N

Feature-based

Jurassic Park

TagCloud

Jurassic Park

P recision(k)

items, 1 ≤ k ≤ N and is defined as AP (k) = k=1 N
Table 4 shows the results for each round of feedback. We observe
a 9% improvement in MAE, 13.8% improvement in Precision(10)
and 41 % improvement in AP between round 1 and round 5. Note
that 50 % of the users stop giving feedback after round 2, implying
that they are satisfied with the recommended items. The results
obtained in round 3 is comparable to round 5, indicating that we are
able to achieve near optimal values in just a few rounds of feedback.

We have a total of 30 participants in our online user study. This
study has a data collection phase and an evaluation phase.
In the data collection phase, the goal is to construct users’ profile
based on their ratings and tagging activities. A user is asked to rate
(on a scale of 1 to 5) and tag two sets of movies. The first set
of movies contains the top-40 most popular movies in MovieLens.
The second set of movies are selected from the top-200 movies in
MovieLens. These movies have the highest variance in their user
ratings. In order to ensure that there is a reasonable overlap in the
tags used, users have to choose from a pre-determined list of tags.
In the evaluation phase, the system will show each user the 3
different styles of explanation that corresponds to a list of movies.
We remove the movie title and ask the user to rate solely based
on the information provided in the explanation. We call these ratings explanation ratings and the ratings obtained during the data
collection phase the actual ratings.
The explanation style that minimizes the difference between the
explanation ratings and actual ratings indicates that the style is effective. Table 3 shows the results of the user study. We use µd
and σd to denote the mean and standard deviation of the differences between explanation ratings and actual ratings. It is clear
that tagcloud-based explanation has the lowest mean and standard
deviation compared to item-based and feature-based explanation,
indicating that it is the most intuitive and easily understood by the
users.

M AE
P (10)
AP

6.

Table 4: Results of User Feedback
round 1 round 2 round 3 round 4
1.04
1.06
0.91
1
0.36
0.37
0.41
0.41
0.2522
0.3132
0.3525
0.3485

round 5
0.94
0.41
0.3582

REFERENCES

[1] J. Herlocker, J. A. Konstan, and J. Riedl, “Explaining
collaborative filtering recommendations,” in CSCW, 2000, pp.
241–250.
[2] N. Tintarev, “Explanations of recommendations,” in RecSys,
2007, pp. 203–206.
[3] C. Wei, W. Hsu, and M. L. Lee, “A unified framework for
recommendations based on quaternary semantic analysis,” in
SIGIR, 2011.
[4] R. A. Harshman, “Foundations of the PARAFAC procedure:
Models and conditions for an" explanatory" multi-modal
factor analysis,” UCLA Working Papers in Phonetics, 1970.
[5] S. Papadimitriou, J. Sun, and C. Faloutsos, “Streaming pattern
discovery in multiple time-series,” ser. VLDB, 2005.
[6] M. Bilgic and R. J. Mooney, “Explaining recommendations:
Satisfaction vs. promotion,” in IUI, 2005.

948


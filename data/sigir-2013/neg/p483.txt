Modeling Click-through Based Word-pairs for Web Search
Jagadeesh Jagarlamudi

∗

Jianfeng Gao

Department of Computer Science
University of Maryland
College Park, USA

Microsoft Research
One Microsoft Way
Redmond, WA 98052, U.S.A.

jfgao@microsoft.com

jags@umiacs.umd.edu

ABSTRACT

Keywords

Statistical translation models and latent semantic analysis (LSA) are two eﬀective approaches to exploiting clickthrough data for Web search ranking. While the former
learns semantic relationships between query terms and document terms directly, the latter maps a document and the
queries for which it has been clicked to vectors in a lowerdimensional semantic space. This paper presents two document ranking models that combine the strengths of both
the approaches by explicitly modeling word-pairs. The ﬁrst
model, called PairModel, is a monolingual ranking model
based on word-pairs derived from click-through data. It
maps queries and documents into a concept space spanned
by these word-pairs. The second model, called Bilingual
Paired Topic Model (BPTM), uses bilingual word translations and can jointly model query-document collections written in multiple languages. This model uses topics to capture
term dependencies and maps queries and documents in multiple languages into a lower dimensional semantic sub-space
spanned by the topics. These models are evaluated on the
Web search task using real world data sets in three diﬀerent
languages. Results show that they consistently outperform
various state-of-the-art baseline models, and the best result
is obtained by interpolating PairModel and BPTM.

Click-through Data, Latent Semantic Analysis, Topic Models, Multilingual IR, Translation Model, Web Search

1. INTRODUCTION
Web search engines till date rely strongly on matching
words in a query-document pair. But very often, words tend
to be either synonymous or polysemous resulting in a concept being expressed in diﬀerent ways. It is well known
that pure lexical matching is inaccurate and often leads to
suboptimal performance [19, 32]. This problem has been
addressed in mainly two ways:
• By using pairwise word associations to capture the
probability of a document word translating into a query
word [5]. The pairwise associations are typically learnt
using document’s content and its title [26], based on
click-through data [3, 25, 14] or using query expansion
techniques [35, 27].
• By representing documents and queries in a lower dimensional semantic space, in which words are identiﬁed by their semantics and not by their lexical form
[13, 18]. Thus a query and document pair can have a
non-zero similarity even though they don’t share any
terms.

Categories and Subject Descriptors

The use of click-through data has proved to be eﬀective
in both the approaches. Statistical translation based approaches, ﬁrst, learn pairwise associations between query
and document words and then use these translation probabilities to rank the documents (Sec. 2.1) [14, 3]. On the
other hand, topic modeling based approaches treat a document and the set of queries for which it has been clicked as an
aligned query document pair and learn a shared topic distribution [15] (Sec. 2.2). They use the shared topic distribution
to rank documents. A serious limitation of these topic modeling based approaches is that they require aligned query
document pairs. But, there are lot of user queries without
any click information rendering their application limited.1
Notice that both these kinds of approaches harness diﬀerent aspects of the click-through data. In speciﬁc, translation models use click-through data to mine pairwise word
associations while topic modeling based approaches exploit
alignment information to learn a shared topic distribution.

H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; I.2.6 [Artiﬁcial Intelligence]:
Learning; I.5.4 [Pattern Recognition]: Applications—Text
Processing

General Terms
Learning, Algorithms, Experimentation
∗Work done during his internship at Microsoft Research.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

1
In the literature, click-through data usually refers to clicked
query document pairs. But in this paper we refer to both
clicked and not-clicked query document pairs. We use
aligned and unaligned to distinguish between these two sets.

483

1
2

The celebration of Thanksgiving will be incomplete
without the legendary Turkey bird. The customary
dinner reminds of the ‘Four Wild Turkeys’ served · · ·
Turkey, known oﬃcially as the Republic of Turkey
is a Eurasian country located in Western Asia and
in East Thrace in Southeastern Europe. · · ·

Table 1: Example documents where the term
‘turkey’ is used in diﬀerent contexts. Relevant context words are colored in Blue.

So it is natural to investigate if exploiting these two aspects
together will yield any further improvements.
With this goal, we aim to design models which can use
pairwise word associations to jointly model an aligned and
unaligned query-document collections. We achieve this by
using word-pairs (e.g., Table 2) to disambiguate the usage of
terms. To understand the intuition, consider the occurrence
of a term like ‘turkey’ in a document or a query. This term
can mean the “Turkey bird” or the “Turkey country”. Our
approach tries to identify its most relevant concept based
on its context words. For example, in the ﬁrst document
of Table 1, the occurrence of terms like ‘thanksgiving’ and
‘dinner’ along with ‘turkey’ indicates that it is used in the
bird concept while the occurrence of terms like ‘republic’ and
‘country’, in the second document, indicates that it is used in
the country concept. In our models, we try to disambiguate
the term with the help of word-pairs. In this particular example, the bird concept is captured by associating the term
to the word-pairs “turkey:thanksgiving” and “turkey:dinner”
while the country concept is identiﬁed by associating it with
“turkey:country” and “turkey:republic”. By linking two related words, via a word-pair, we gather the evidence from
both the words to make better judgements about of each of
the words. Thus, we aim to build better document models
which in turn lead to better ranking models.
Using this idea, we propose two models which explicitly use word-pairs to model a query-document collection.
Our ﬁrst model, called PairModel, is a monolingual model.
It uses monolingual word-pairs derived from click-through
data to model term dependencies in a query-document collection. It maps queries and documents into a concept space
spanned by these word-pairs (Sec. 3). As shown in Table 2,
the word-pairs capture diﬀerent types of term correlations
such as morphological variations, misspellings, term relatedness, etc.. By accounting for these diﬀerent variations,
PairModel builds better document models. The use of term
co-occurrences to build better query or document models
is not new [34], but the way we use it (i.e., by combining
word-pairs and topic models) is novel.
Our second model is a bilingual model called Bilingual
Paired Topic Model (BPTM). It uses bilingual word-pairs,
that are translations of each other say between French and
English, to model a bilingual query-document collection (Sec. 4).
Unlike PairModel, the word-pairs in BPTM are word translations and do not capture other types of semantic term
correlations. So, we introduce topics to capture the semantic relatedness. This model maps queries and documents
of both languages into a common lower dimensional subspace. Thus BPTM addresses the lexical gap problem and
also leverages the abundant training data available in a resource rich assisting language (such as English) to improve

484

ranking in a resource poor search language. While the use
of assisting language to improve search language’s ranking is
not new [20, 10], the way we use it (i.e., via topic modeling)
is novel.
PairModel exploits term dependencies from queries and
documents within the search language (French) while BPTM
uses information gathered from the assisting (English) language to make better relevance judgements. So, these models are complimentary to each other and can be interpolated.
Our experiments (Sec. 5) in French and German languages,
using English as the assisting language, show that the combined model outperforms both the individual models and
also beats various state-of-the-art baseline systems by a signiﬁcant margin.2

2. RELATED WORK
Many strategies have been proposed to bridge the lexical
gap between queries and documents using the click-through
data. Click-through data is also shown to be eﬀective in the
learning to rank framework [1], but here we discuss the work
that is most relevant to our problem and our approach.

2.1 Statistical Translation Based Approaches
In Language Modeling (LM) framework [29], documents
are ranked based on the likelihood of generating a query.
Statistical translation based approaches address the lexical
gap by ranking the documents based on the likelihood of
translating into a query. Let q = {q1 , . . . qNq } be a query
and d = {w1 , . . . wNd } be a document, then a word based
translation model [5] ranks the documents based on:


P (q|d) =
P (q|d) =
P (q|w)P (w|d)
(1)
q∈q

q∈q w∈d

where P (w|d) is the unigram probability of the word w in
d, and P (q|w) is the probability of the document word w
translating into the query word q. In these methods, a major challenge is the estimation of the translation probabilities
P (q|w). An ideal training data would be a large amount of
aligned query-document pairs (in which each of the document is judged as relevant to the query). Due to the lack
of such training data, [5] resorts to some synthetic querydocument pairs while [26] uses the title-document pairs for
estimating the translation probabilities. Click-through data
has been explored to determine relationships between terms
in queries and documents [3, 25]. However, these relationships and their probabilities are created using ad hoc similarity measures. Gao et al. [14] take a word alignment based approach popular in the Statistical Machine Translation community [8]. They treat an aligned query-document pair as a
parallel sentence pair in two diﬀerent languages and use IBM
Model 1 to learn the translation probabilities. They show
an improved performance by using translation probabilities
learned from an year worth of click-through data.
Wei and Croft [34] discuss several co-occurrence based
methods to identify term associations and their eﬀectiveness
for information retrieval. Moreover, lexical gap problem is
also addressed using query expansion with automatic relevance feedback (e.g., pseudo relevance feedback or PRF)
[35]. Though these techniques are shown to be eﬀective on
TREC benchmark data sets [35, 27, 37, 9], their applicability to a commercial Web search engine is limited because
2

A shorter version of this document is available at [22].

turkey
turkey
turkey
turkey
government
colleges
university
addiction
camera
camera

generating pseudo-relevant documents requires multi-phase
retrieval, which is prohibitively expensive.

2.2 LSA Based Approaches
Latent Semantic Analysis (LSA) based approaches assume
that both queries and documents lie in a lower dimensional
sub-space and try to learn this space [13]. Probabilistic Latent Semantic Analysis (PLSA) [18] assumes that each document is a Multinomial distribution over T topics (called
document-topic distribution) where each of the topics is in
turn a Multinomial distribution over words (called topicword distribution). Like in LM framework, the relevance of
a document towards a query is assumed to be proportional
to the likelihood of it generating the query. Latent Dirichlet
Allocation (LDA) generalizes PLSA to unseen documents
by employing a conjugate Dirichlet prior on the documenttopic distributions [6]. Though, LDA is superior to PLSA
in theory, its eﬀectiveness for IR, as demonstrated in [33],
has not been compared against PLSA.
Recently, Gao et al. [15] proposed a generative model
called Bilingual Topic Model (BLTM) for Web wearch. They
show that, by including the click-through data, their model
achieves better performance compared to the PLSA. They
assume that an aligned query and document pair share the
document-topic distribution. Given this document-topic distribution, the query and the document are assumed to be
independent and are generated separately. During the ranking stage, they keep the topic-word distributions ﬁxed and
fold in the unseen documents to learn their document-topic
distributions. Finally, for a given query q, they rank the
documents as follows:
P (q|d) =


q∈q

P (q|d) =

T


P (q|z)P (z|d)

Table 2: Example monolingual word-pairs.
word ‘govenment’ is misspelled purposefully.

The

collections as well. Thus our models combine the strengths
of these individual approaches. As shown in Table 2, the
word-pairs used for PairModel capture diﬀerent types of semantic term correlations, so this model does not need topics.
In contrast, BPTM uses bilingual word translations and can
not account for the diﬀerent types of variations and so it
uses topics to learn the semantic space.
As explained in Sec. 1, our models use word-pairs to disambiguate the concept in which a term is used. The usage
of term co-occurrences to build better document models is
not new [4]. For example, most of the approaches discussed
in Section 2.2 inherently use term co-occurrences in their
process. But our approach uses only a subset of selected
word-pairs (Sec. 5.2). As argued in [23], considering all possible pairwise associations can be noisy and hence using a
pre-selected set of word-pairs is desirable.

(2)

3. PAIR MODEL

q∈q z=1

In this section, we propose our model assuming that we
have monolingual pairwise word associations. An example
set of word-pairs is shown in Table 2.3 Our model is independent of the dictionary’s source.
The most important aspect of our model is that we treat
a word-pair as a hidden variable, i.e., when we see a term we
model the concept in which it is used as a hidden variable
and try to infer it based on the context. The order of words
in a word-pair doesn’t carry any signiﬁcance, i.e., “addiction:rehab” is same as “rehab:addiction”. By grouping two
related words together we eﬀectively combine the evidence
of both words so that each word can help make an appropriate decision about the other word. Moreover, by linking
evidence from related words, we move beyond bag-of-word
based models and, since these words can lie anywhere in the
document, our approach is diﬀerent from other higher order
models which consider n-gram relationships between words
[30, 31].
We ﬁrst describe our model for aligned query-document
pairs and later discuss, brieﬂy, on extending it to unaligned
queries and documents. We assume that each aligned querydocument pair is a distribution over word-pairs or concepts
referred to as concept distribution. From now on, we use
concept and word-pair interchangeably. Each concept is in
turn a Binomial distribution over its two component words.
Notice that there are no topics in this model and the only
hidden variables are concepts. This is the primary diﬀerence

Notice that this approach exploits the alignment information
between queries and documents to learn the sub-space and
hence it is limited to aligned data sets.

2.3 Dictionary Based Semantic Models
On the other hand, there are approaches that learn semantic sub-space using word-pairs [21, 7, 38]. These approaches usually model unaligned bilingual document collections using bilingual dictionaries, but they can be modiﬁed to model unaligned query-document collections using
monolingual word-pairs. In [21], each document is assumed
to be a Multinomial distribution over T bilingual topics. A
bilingual topic is a Multinomial distribution over bilingual
concepts (c) and each of these concepts generates a word
depending on the document language. In these models, the
probability of generating a string s = (w1 , . . . , wNs ) given a
document d is given by:

 
P (s|d) =
P (wi |d) =
P (wi |c)P (c|z)P (z|d) (3)
wi ∈s

thanksgiving
bird
country
istanbul
govenment
college
colleges
rehab
canon
D3000

wi ∈s c,z

where z = 1 . . . T is the bilingual topic indicator.
In this paper, we propose models that use ideas from the
above mentioned approaches. More speciﬁcally, we 1) use
IBM model 1 to learn word-pairs from the click-through
data (Sec. 2.1), 2) exploit the association between an aligned
query-document pair (Sec. 2.2) and 3) ﬁnally use the wordpairs, derived in step 1, as proxy for the concepts in the dictionary based approaches to model unaligned query-document

3

485

For conciseness, we refer to this as monolingual dictionary.

c

γ

q

Nq

ψ

φ
c

w

document as it is triggered for both the words ‘turkey’ and
‘thanksgiving’. Likewise, the concept “turkey:bird” also becomes more probable when the word ‘bird’ is seen. Similarly,
in the second document, the words ‘country’ and ‘republic’
will cause the concept distribution to peak for the country sense compared to the bird sense. When we link all
the terms to their most relevant concepts and gather these
statistics over all queries and documents, we obtain statistics that better ﬁt this particular data set and hence they
tend to be more accurate than the translation probabilities
of the original dictionary (as evidenced in our experiments
in Sec. 5.2) resulting in better ranking models.
In our model, word-pairs enable us to leverage the term
correlations within a document or a query. At the same time,
the fact that an aligned query-document pair share concept
distribution means that it also leverages term correlations
across a query-document pair.

β

|C|

Nd
(Q,D)

Figure 1: Graphical notation of the PairModel,
the concept distribution is shared across an aligned
query-document pair.
between our PairModel and other related generative models
such as JointLDA [21] and BLTM [15].
Formally,
 we assume that an aligned query-document pair
(q, d) = (q1 , . . . , qNq ), (w1 , . . . , wNd ) share the concept
distribution ψ(q,d) 4 which is drawn from a Dirichlet distribution with symmetric prior γ. For each word in the querydocument pair, we ﬁrst draw a concept (c) from the concept
distribution ψ(q,d) and then draw a word from the words
associated with the concept. Let |C| be the total number
of concepts, then we assume the following generative story
for generating an aligned query-document pair. The corresponding graphical notation is shown in Fig. 1.

3.1 Inference
In [2], authors show that MAP inference performs comparably to the best Bayesian inference methods for generative
models such as LDA. So, we use Expectation Maximization [12] algorithm to learn the MAP values for (φ, ψ). The
E-step involves ﬁnding the posterior probabilities, i.e., the
probability of associating each term with a concept, as follows:
P (w|φc )P (c|ψ(q,d) )
P (c|w, (q, d)) = 
(4)

c P (w|φc )P (c |ψ(q,d) )

1. For each concept c = 1 . . . |C|, choose φc ∼ Beta(β, β)
2. For each aligned query-document pair
(a) Choose ψ(q,d) ∼ Dir(γ)

For each concept c, P (w|φc ) is non-zero for only the two
words that are part of this concept. So, the above posterior
probability is non-zero for only those concepts that can generate the given word. Because of this, although there are a
total of O(V 2 ) possible concepts, only a tiny fraction of them
will have non-zero probability in a given document. Moreover, this set can be precomputed based on the document
words and can be stored in an appropriate data structure for
eﬃcient processing. Again, because on an average a word
has a small number of associated concepts, most of the terms
in the summation term in the denominator of Eq. 4 are zeros
and hence it can also be computed eﬃciently.
The M-step updates the parameters based on the posterior probabilities estimated in the E-step. Let n(q, q) denote the frequency of a query word q in the query q and,
similarly, n(w, d) denote the frequency of a word w in the
document d. Moreover, let N (q, c, q) = n(q, q)P (c|q, (q, d))
and N (w, c, d) = n(w, d)P (c|w, (q, d)) then,


P (c|ψ(q,d) ) ∝ (γ − 1) +
N (q, c, q) +
N (w, c, d)

(b) For each document term i = 1 . . . Nd
• Select a concept ci ∼ Mult(ψ(q,d) )
• Select a word wi ∼ Bin(φci )
(c) For each query term i = 1 . . . Nq
• Select a concept ci ∼ Mult(ψ(q,d) )
• Select a word qi ∼ Bin(φci )
Since the size of the monolingual dictionary is limited, there
will be some words that do not have any pairwise associations. For example, the word ‘world’ is not part of the
extremely small dictionary provided in Table 2. To handle
these Out-of-Dictionary words, we add dummy concepts of
the form word:word (“world:world” in this particular case).
Notice that this concept can generate only one word ‘world’
with a probability of 1. The model can be easily extended to
unaligned data, in which case the generative story is limited
to either a query or a document.
To understand how this model uses context words to disambiguate the concept associated with a term and improve
the search ranking, consider the example documents from
Table 1 and the term ‘turkey’. Based on the input monolingual dictionary, the word ‘turkey’ has four possible concepts
associated with it (as shown in Table 2). When the term
‘turkey’ is seen in the ﬁrst document, then all the four concepts are equally likely to have generated this term, so all
of them get equal probability for this document. But when
we see its context words, say ‘thanksgiving’ then the probability of the concept “thanksgiving:turkey” increases for this

q∈q

P (w|φc ) ∝

(β − 1) +



w∈d



N (w, c, q) + N (w, c, d)

(q,d)

3.2 PairModel Variants
In PairModel, we force an aligned query-document pair to
share the concept distribution. Instead we can allow them to
have diﬀerent concept distributions and then take an average
of them to denote the concept distribution of the pair. The
corresponding graphical notation is shown in Fig. 2. During inference, we learn ψq and ψd independently and then
ψ +ψ
use ψ = q 2 d as the resulting concept distribution of the
document. We refer to this model as PairModel(Averaged)
in the rest of the paper.

4

We use ψ instead of the traditional θ to remind the reader
that this is not a distribution over topics, instead it is a
distribution over the word-pairs.

486

ψq

c

q

Nq

γ

φ
ψd

c

w

1 . . . n. The queries and documents across diﬀerent languages are assumed to be comparable (e.g., from the same
time period) but not necessarily translations of each other.
The underlying idea behind BPTM is to jointly model
bilingual collections such that useful knowledge can be transferred across languages. The joint modeling is motivated
by the previous study [20], which shows that training a
ranker on a bilingual data is more eﬀective than than learning a ranker in English and transferring it to French. Note
that simply replacing word-pairs of PairModel with bilingual
word translations does not lead to a model that is diﬀerent
from a document’s unigram model because the model cannot capture any inter-word dependencies in documents of the
same language. For example, the probability of a word-pair
(“camera:caméra”) in a particular French document depends
only on the French word ‘caméra’ and is independent of other
French words. Therefore, in addition to the use of bilingual
translations, BPTM also uses bilingual topics. These bilingual topics map the queries and documents in diﬀerent languages into a common lower dimensional semantic space. In
that sense, BPTM bears resemblance to JointLDA [21] and
BLTM [15] but there are some key diﬀerences. First of all,
unlike BLTM where a topic is a distribution over words, a
topic in BPTM is a distribution over bilingual word translation pairs (or concepts).5 Second, unlike JointLDA which
does not make use of alignment information between query
and document, BPTM assumes that a query and its paired
document share the same topic distribution.
We now describe BPTM more formally. We assume that
an aligned query-document pair share the topic distribution
θ(q,d) which is a multinomial distribution over T bilingual
topics and is drawn from a Dirichlet distribution with symmetric prior (α). Each bilingual topic (ψk ) is a multinomial
distribution over concepts. Finally, depending on the language of the query-document pair, these concepts generate
words. Given a concept and the language, there is only one
option for choosing the word and it is deterministic. To explain words that are not present in the bilingual dictionary,
we add dummy translations for both Out-of-Dictionary English and French words. A dummy translation for an English
word can only generate a English word and can not generate French words and vice versa. Jagarlamudi and Daumé
III [21] showed that these dummy translations lead to deﬁcient probability models and suggested adding a dependency
link between the document language and the concept variable. Following their argument, let I(ci , ld ) denote a binary
indicator variable that denotes whether the concept ci can
generate a word from the language ld , then the generative
process of BPTM is as follows. The corresponding graphical
notation is shown in Fig. 3.

β

|C|

Nd

Figure 2: Graphical notation for the PairModel (Averaged), query and document do not share the concept distribution.
In another variant, we run PairModel without any wordpairs. As stated earlier, we add dummy concepts of the form
“word:word” for Out-of-Dictionary words. In this variant,
we use dummy concept for each word. Thus, the model
reduces to a unigram language model whose parameters,
shared by queries and documents, are estimated on the concatenation of queries and documents. We refer to this model
as PairModel(–Pairs) in the experimental section (Sec. 5.2).
Finally, we can use posterior regularization to constrain
the concepts sampled for a query and document to match
with each other. But [15], shows that posterior regularization brings only a minor improvement so we skip this variant
in our experimental section.

3.3 Document Ranking
We use the LM framework to rank documents. Following
[36, 14], we score the relevance of documents given a query
using a mixture model


P (q|d) =
λ1 Pmx (q|d) + (1 − λ1 )P (q|C) where
q∈q

Pmx (q|d)

=

λ2 Pml (q|d) + (1 − λ2 )Psys (q|d)

(5)

where Pml (q|d) is the maximum likelihood estimate of the
query word q in the document and P (q|C) is the unigram
probability of the query word in the entire collection. And
Psys (q|d) is the probability of q in the given document whose
value varies among diﬀerent ranking models. In PairModel,
Psys (p|d) is estimated as

P (q|c)P (c|d)
(6)
Psys (q|d) =
c|q∈c

where c|q ∈ c denotes the set of all concepts that have the
query word q as one of them.

4.

BILINGUAL PAIRED TOPIC MODEL

Bilingual Paired Topic Model (BPTM) uses training data
from an assisting language to improve ranking of documents
in a search language. We assume that the assisting language (English) has richer resources, such as larger amounts
of click-through data, document and query collections, that
are useful for building a better Web search ranker. For concreteness, we consider the task of ranking French documents
using English as an assisting language.
In what follows, we will ﬁrst describe the way aligned
query-document collections are modeled by BPTM. Then
we extend BPTM to model unaligned query-document collections. We assume that we have aligned query-document
collections (which are extracted from click-through logs) in
both languages (qei , dei ), (qfj , dfj ) for i=1 . . . m and j =

1. For each topic k = 1 . . . T , choose ψk ∼ Dir(γ)
2. For each aligned query-document pair
(a) Choose l(q,d) ∼ Bin( 12 ).
(b) Choose θ(q,d) ∼ Dir(α)
(c) For each document term i = 1 . . . Nd
• Select a topic zi ∼ Mult(θ(q,d) )
• Select a concept ci ∼ Mult(ψzi ) · I(ci , l(q,d) )
5

We advise the reader to distinguish that a concept in
BPTM refers to a word translation pair while it refers to
a semantically related word pair in the PairModel.

487

γ

α

ψ

T

z

c

q

z

c

w

Nq

θ

l

Nd

P (c|ψz ) ∝ (γ − 1) +

• Select a word qi ∼ P (qi |ci , l(q,d) )

N (c, z, q, q, l) +

w,c



N (c, z, w, w, l)

w|w∈c

4.2 Document Ranking
We ﬁrst train BPTM model on the bilingual query-document
collections. Then, we keep the topic-concept distributions
(ψ) ﬁxed and fold in the test documents to get their topic
distributions (θ). We use the same mixture model described
in Sec. 3.3 to rank the documents. Finally, the Psys (q|d)
required to compute Eq. 5 is computed as follows:

Psys (q|d) =
P (q|c)P (c|z)P (z|d)
(9)

To understand the generative process, consider generating an English aligned query-document pair. First, choose
a topic mixture say 70% of education and 30% of sports.
Then, we generate the query term by term. For the ﬁrst
term, choose a topic, say ‘education’, and then choose a concept from the education topic, let it be “university:université”.
We then generate the ﬁrst English query term ‘university’
from the concept. If we were to generate the French query
then we would have chosen ‘université’ instead. This process
repeats until all words in the query and its aligned document
are generated. Like in PairModel, BPTM can be trivially
extended to generating queries and documents that are not
aligned. In such a case, the generative process is limited to
either a query or a document.
In BPTM, we use bilingual word-pairs which are translation equivalents where as in the PairModel we use monolingual word-pairs that are semantically related. Because of
this distinction, BPTM doesn’t inherit all the advantages of
the PairModel (as evidenced in Sec. 5.3). We can use semantically related bilingual word-pairs but it is very diﬃcult
to obtain such word-pairs.

c,z

5. EXPERIMENTS
In this section, we evaluate our models against state-ofthe-art baseline systems in three languages: English, German and French. We ﬁrst compare PairModel with diﬀerent
baselines on monolingual Web Search task, in Sec. 5.2, and
then move on to evaluating BPTM in Sec. 5.3.

5.1 Experimental Setup

4.1 Inference
Again we use EM algorithm to derive the parameter update equations. In the E-step, we estimate the posterior
probabilities and then use them to update the MAP estimates in the M-step. The E-step involves estimating:

=

q,c

where w ∈ c denotes that the word w is one of the two
words represented by c. Given a concept c and the language
l, there is only one option for choosing the word and hence
P (w|c, l) need not be estimated.

• Select a topic zi ∼ Multi(θ(q,d) )

P (c|ψz )I(c, l)


c P (c |ψz )I(c , l)
P (z|θ(q,d) )P (c|z, l)


 
z  ,c P (z |θ(q,d) )P (c |z , l)



q|q∈c

• Select a concept ci ∼ Mult(ψzi ) · I(ci , l(q,d) )

P (c, z|w, d, l)

En(all)
6K
190K
32M
500K
489K

n(w, d)P (c, z|w, (q, d), l) then the M-step involves:


N (c, z, q, q, l) +
N (c, z, w, d, l)
P (z|θ(q,d) ) ∝ (α − 1) +

(d) For each query term i = 1 · · · Nq



En
5.3K
49K
2.1M
500K
489K

(Q,D)

• Select a word wi ∼ P (wi |ci , l(q,d) )

=

Fr
5K
54K
133K
76K
82K

Table 3: Training and test data statistics.

Figure 3: Graphical notation for the Bilingual
Paired Topic Model (BPTM).

P (c|z, l)

De
4K
44K
128K
110K
100K

# of queries
Test
# docs
Training #(q, d) pairs
Vocab Size
Dictionary Size

(7)
(8)

To compute the posterior probability for a query word, simply replace the pair w, d with q, q in Eq. 8.
As before, let n(q, q) denote the frequency of the query
word q in the query q and, similarly, n(w, d) be the frequency of the word w in the document d. Moreover, let
N (c, z, q, q, l) = n(q, q)P (c, z|q, (q, d), l) and N (c, z, w, d, l) =

488

Since our ranking models rely on click-through data, we
can not evaluate our models on standard TREC data sets.
Therefore, following previous studies of using user log for
Web search ranking [1, 14, 15], we use proprietary datasets
that have been developed for building a commercial Web
search engine and compare our models with state-of-theart ranking models that are originally developed for TREC
data sets [27] as well as approaches that use click-through
data [14, 15]. We evaluate our models on data sets collected
in three diﬀerent languages, English, French, and German.
The queries in all the three languages are sampled from a
year of search engine query logs. Queries are “de-duped” so
that only unique queries remain. To reﬂect a natural query
distribution, we do not try to control the quality of these
queries. For example, in our query sets, around 20% are
misspelled queries, and around 20% are navigational queries
and 10% are transactional queries, etc.. Second, for each
query, we collect Web documents to be judged by issuing
the query to Bing. Subsequently, query-document pairs are
manually judged on a scale of 0 to 4, with 0 being totally
irrelevant and 4 being most relevant. For all the three data
sets, we ﬁltered the queries that have less than ten relevant

JMLM
RM
WTM
BLTM
PairModel(–Pairs)
PairModel(Averaged)
PairModel
Δ over best baseline

ndcg@1
28.70
31.30
31.79
34.70
34.74
34.64
35.02∗
+0.32

English
ndcg@3
37.54
40.21
40.77
43.16
43.46
43.40
43.46∗
+0.30

ndcg@10
48.66
50.82
51.31
53.03
53.17
53.10
53.26∗
+0.23

ndcg@1
34.59
36.18
36.54
37.26
35.74
38.28
39.55∗
+2.29

German
ndcg@3 ndcg@10
43.79
56.20
45.48
57.84
46.26
58.63
46.50
58.33
45.05
57.45
47.02
58.63
47.64∗
58.98
+1.14
+0.35

ndcg@1
38.22
40.31
40.09
40.03
38.94
40.34
40.94∗
+0.63

French
ndcg@3
46.36
48.60
48.89
48.36
47.54
48.42
48.95
+0.06

ndcg@10
60.57
62.51
63.06
62.49
61.82
62.30
62.58
-0.48

Table 4: Comparison of PairModel with state-of-the-art baseline systems. In each column, the best system
is bolded, the second best system is italicized and ∗ denotes statistical signiﬁcance improvement compared
to the best baseline measured by t-test at p-value of 0.05.
parameter values. After learning the parameter values, the
documents are ranked using Eqs. 5 and 6.
Table 4 shows the results of diﬀerent systems on English,
German and French data sets. Across all the languages,
JMLM smoothing does poorly because of the lexical gap
problem. As expected, RM and WTM outperform JMLM
demonstrating the eﬀectiveness of addressing the term mismatch problem using co-occurrence statistics. BLTM performs signiﬁcantly better than WTM on English but is indistinguishable on German and French. This is largely due
to the size of training data we used to learn BLTM, which
is considerably larger in English than in other languages as
shown in Table 3. The order of the baseline systems is consistent with what has been reported in the previous literature
[14, 15].
Recall that PairModel without word-pairs (PairModel(–
Pairs) in Sec. 3.2) reduces to a unigram language model
whose parameters are estimated from both the document
title and the queries for which the document is clicked. As
shown in Table 4, the performance of PairModel(–Pairs) is
not consistent across diﬀerent languages. It outperforms
WTM and BLTM in English but underperforms in German
and French. We speculate that this result is due to the fact
that, on average, English documents have rich click data
than German and French documents.
On the other hand, using word-pairs but neglecting the
alignment between query-document pairs, as indicated by
PairModel(Averaged) row of Table 4, is indistinguishable
from PairModel(–Pairs) model on English, but is signiﬁcantly better in other languages. This shows the eﬀectiveness of using word-pairs especially when the click data is
smaller. This model compares favorably to the state-of-theart baselines (i.e., WTM and BLTM).
Finally, PairModel which uses both the word-pairs and the
alignment information between query and document pairs
outperforms not only the variants, but also the baseline systems in most cases. The last row of the Table 4 shows the
improvement of this model compared to the best of the four
baseline systems. It achieves a signiﬁcant improvement of
2.29 points at ndcg@1 for German. Overall, PairModel performed best and one of its variants performed second best.
Although PairModel and WTM use same set of wordpairs, the signiﬁcantly better performance of PairModel indicates that our model seems to have the capability to adapt
the translation probabilities to the data set. To verify this,
we ran a separate experiment where we (re-)estimate the
translation probabilities for the original pairs based on the

documents. For most of the experiments, we include documents with at least one clicked query. To evaluate the effectiveness of diﬀerent systems in leveraging unaligned documents, we prepare a separate English data set, referred to
as En(all), by including queries and documents that do not
have any user click information. For all the data sets, the
click information is extracted from query logs using a process similar to [17]. The training and test set statistics are
shown in Table 3. Notice that the number of test queries
is much larger than the typical 50 queries used in standard
TREC evaluation settings.
We use the following baseline systems. JMLM: This is
the unigram language model of the document with JelinekMercer smoothing. RM: Relevance model [27], is one of the
state-of-the-art PRF methods developed for the LM framework. The number of expansion terms and the number of
top-ranked documents used for query expansion are optimized via cross validation. WTM: The third baseline is a
word based translation model, a variant of statistical translation model, as implemented in [14]. We use same dictionaries for WTM and PairModel. BLTM: The ﬁnal baseline
is the Bilingual Topic Model [15].
The interpolation parameters in all the systems, λ1 and
λ2 , are estimated using 2-fold cross validation. We split the
data into two halves, ﬁnd the best interpolation parameters on one half using grid search and use them for testing
on the other half. We report averaged results on both the
splits. Finally, we use Normalized Cumulative Discounted
Gain (ndcg) [24] to evaluate the ranking against the human
judgements. We report ndcg at ranks 1, 3, and 10.

5.2 Monolingual Web Search Results
In this section we compare PairModel with the baseline
systems. PairModel requires a monolingual dictionary of
word-pairs. For English, this dictionary is learnt from a
year worth of query logs (as in [14]). For German and
French languages, we learn the dictionaries from the training data of aligned query-document pairs which is much
smaller compared to the data used for English. For all the
three languages, we run IBM Model 1 on the aligned querydocument pairs and then ﬁlter all the word-pairs with conditional translation probability less than a threshold of 0.005.
For quicker I/O, we keep only those word-pairs in which
both the words are seen in our vocabulary and the resulting
dictionary statistics are also shown in Table 3. We use the
dictionary to ﬁt PairModel and its variants and estimate the

489

ndcg@1
31.79
32.49
+0.70

WTM
WTM (Adapted dict.)
Δ over original

English
ndcg@3
40.77
41.32
+0.55

ndcg@10
51.31
51.64
+0.33

German
ndcg@3 ndcg@10
46.26
58.63
47.58
59.49
+1.32
+0.86

ndcg@1
36.54
38.04
+1.50

French
ndcg@3
48.89
49.36
+0.47

ndcg@1
40.09
40.70
+0.61

ndcg@10
63.06
63.39
+0.33

Table 5: Performance of WTM model with adapted translation dictionary.
36%

40%
JMLM
BLTM
PairModel(−Pairs)
PairModel

35%
34%

43%

39%

42%
JMLM
BLTM
PairModel(−Pairs)
PairModel

38%

33%

37%

32%

36%

39%

31%

35%

38%

30%

34%

37%

29%

33%

36%

28%

32%

Baselines

D

QD

QDC

(a) English data set

Baselines

40%

QD

D

JMLM
BLTM
PairModel(−Pairs)
PairModel

41%

QDC

35%

(b) German data set

Baselines

D

QD

QDC

(c) French data set

Figure 4: Performance (ndcg@1) of PairModel under diﬀerent resource settings. JMLM uses only titles (D)
while BLTM uses titles, queries, and click data (QDC).
guages, probably due to the availability of relatively larger
amounts of click-through data in English.

posterior probabilities learnt by PairModel. Let c12 denote
the word-pair w1 : w2 and let {c |w ∈ c } denote the set of
concepts that have w as on of their words, then
P (w1 |w2 ) =

#(w1 , w2 )
#(w1 : w2 )
N (c12 )
= 
= 


#(w2 )
w #(w : w2 )
c |w2 ∈c N (c )

where N (c) denote the expected number of times this concept is assigned to any of the words and is given by:

 

N (c) =
N (q, c, q) +
N (w, c, d)
(q,d)

q∈q & q∈c

w∈d & w∈c

N (q, c, q) and N (w, c, d) are as deﬁned in Sec. 3.1. For
every word-pair of the input dictionary, we re-estimate its
translation probability and use this re-weighted dictionary
as input to WTM. Table 5 shows the results with the reestimated dictionary. This clearly conﬁrms that our model
learns to tune the translation probabilities for this data set.

JMLM
WTM
BLTM
PairModel(–Pairs)
PairModel(Averaged)
PairModel
Δ over best baseline

ndcg@1
26.30
28.85
31.24
30.30
32.25
32.23
0.99

English (All)
ndcg@3 ndcg@10
31.84
43.80
34.76
47.42
36.85
49.36
35.61
47.44
37.10
48.88
37.13
48.91
0.28
-0.45

Table 6: Performance of all the models after adding
unaligned documents and queries (in English).
In the ﬁnal monolingual experiment, we evaluate the effectiveness of PairModel by adding unaligned queries and
documents. Table 6 shows the results on this data set. As
expected, this decreased the performance of all the systems,
but notably PairModel is still able to better identify the relevant documents at rank 1. But the improvements decrease
(compared to BLTM model) at higher ranks.

5.2.1 Variation with the Data
To better understand the model, we test the eﬀectiveness
of PairModel with varying resources. Speciﬁcally, we trained
the model on document titles only (D), document titles +
queries but without click information (QD) and document
titles + queries + click data (QDC). Fig. 4 shows the results.
The x-axis marks the resource setting and the y-axis marks
the ndcg@1 scores.
Except in French, performance of PairModel increases as
we add queries and their alignment information. Moreover,
PairModel achieves signiﬁcantly higher improvements in resource poor situations, which is justiﬁable as exploiting pairwise relations is expected to be more useful when there is
not enough evidence for a word on its own. Another interesting observation is that, in German and French, even with
only documents PairModel beats the state-of-the-art BLTM
model. In the QDC setting, the performance of BLTM is
closer to that of PairModel in English than in other lan-

5.3 Bilingual Web Search Results
In this section, we report our bilingual results on German
and French. Our aim is to test the eﬀectiveness of wordpairs, in using assist language training data, to improve the
accuracy in a search language and is not to build a competitive multilingual IR algorithm. So in this section we mainly
resort to comparing with the same baselines and not with
the state-of-the-art multilingual IR algorithms like [10, 11,
20].
We use the same data sets and the experimental setup
as described in Sec. 5.1 and report results on Web Search
task in French and German using English as the assisting

490

Monolingual
Bilingual

BLTM
BPTM
Δ over BLTM
BPTM+PairModel
Δ over BLTM

ndcg@1
37.26
37.38
+0.12
39.66∗
+2.40

German
ndcg@3 ndcg@10
46.50
58.33
46.58
58.48
+0.08
+0.15
47.73∗
59.04∗
+1.23
+0.71

ndcg@1
40.03
40.85∗
+0.82
42.25∗
+2.22

French
ndcg@3
48.36
49.01∗
+0.65
50.01∗
+1.65

ndcg@10
62.49
62.73
+0.24
63.42∗
+0.93

Table 7: Bilingual IR results on French and German. For comparison purposes, we have also shown the
scores of best monolingual baseline system (BLTM). Again ∗ denotes statistically signiﬁcant improvement
compared to BLTM as measured by t-test at p-value of 0.05.
i.e., for emerging languages such as French and German.
We have also observed that, signiﬁcant improvements can be
obtained by using a resource rich assisting language which
presumably has more click-through data. To this end, our
second model uses bilingual dictionaries to map queries and
documents of both the languages into a common lower dimensional sub-space. Hence, it can use training data from
a data rich assisting language to improve ranking in a resource poor language. Experimental analysis indicates that
the performance of this model depends on the quality and
the coverage of bilingual dictionaries. Since PairModel and
BPTM models exploit diﬀerent collections, search and assisting language resources respectively, they are complimentary to each other and hence can be combined. The combined model gave superior results compared to the individual
models and also the baseline systems.
We have used word-pairs derived from click-through data
for the monolingual model. Though, in principle, our model
does not depend on the source of these word-pairs, its eﬀectiveness for the Web search task will probably depend on the
source. Moreover, for BPTM, we used bilingual word-pairs
that are likely to be translations of each other and, again,
such word-pairs may not be ideal for the Web search task.
In this paper, our primarily goal is to show the utility of
modeling word-pairs and is not to evaluate the suitability of
the word-pairs – although the latter task is equally important. In future, we would like to study the eﬀect of diﬀerent sources on the ﬁnal performance. Moreover we would
like to move from word-pairs to small bilingual clusters, so
that the model can eﬀectively combine evidence from querydocument pairs with-in and across languages.

language. For both these language pairs, we used statistical
dictionaries learnt using Giza++ [28] on parallel data used
for training a commercial MT system. We remove all translation pairs that have conditional translational probability
less than 0.001 and keep only those pairs in which both the
words are seen in our vocabularies. After the ﬁltering, we
are left with 181K and 269K word-pairs in En–De and En–Fr
language pairs.
As explained in Sec. 1, PairModel exploits evidence from
the search language while BPTM uses evidence from the
assisting language so we also report the results of a combined model, ‘BPTM+PairModel’. We use query wise interpolation to combine these models, i.e., we ﬁrst score the
documents independently using the two models (described
in sections 3.3 and 4.2) and then interpolate the document
scores using a variant of Powell Search algorithm [16]. Table
7 shows the results.
We remind the reader that the major diﬀerence between
BLTM and BPTM is that BPTM models query-document
collections of both search and assisting languages while BLTM
models only search language query-document collection. We
expect the eﬀectiveness of BPTM to depend on the coverage and quality of the bilingual word translations. Comparing BPTM with BLTM, we observe that BPTM is able to
get 0.82 and 0.65 ndcg improvements at ranks 1 and 3 in
French6 but it gives almost the same performance in German. This is justiﬁable because of the poor quality dictionary for En–De language pair. The rich morphology and
the compound word phenomenon of German limits the coverage of the En–De dictionary. The combined model, as denoted by ‘BPTM+PairModel’, improves over both BPTM
and PairModel and the improvements are higher in French
(again because of the high quality dictionary). While the
reader might think that the combination of BLTM and PairModel can perform as good as BPTM+PairModel, we argue
that BPTM is a better choice than BLTM since it uses assisting language query-document collection and hence is more
likely to be complementary than BLTM.

6.

7. REFERENCES
[1] E. Agichtein, E. Brill, and S. Dumais. Improving web
search ranking by incorporating user behavior
information. In SIGIR ’06, pages 19–26, New York,
NY, USA, 2006. ACM.
[2] A. Asuncion, M. Welling, P. Smyth, and Y. W. Teh.
On smoothing and inference for topic models. UAI
’09, pages 27–34, Arlington, Virginia, United States,
2009. AUAI Press.
[3] R. Baeza-Yates and A. Tiberi. Extracting semantic
relations from query logs. In Proceedings of the 13th
ACM SIGKDD, KDD ’07, pages 76–85, New York,
NY, USA, 2007. ACM.
[4] J. Bai, J.-Y. Nie, G. Cao, and H. Bouchard. Using
query contexts in information retrieval. In Proceedings
of the SIGIR ’07, pages 15–22, New York, NY, USA,
2007. ACM.

DISCUSSION

In this paper, we proposed two models that explicitly use
word-pairs to model aligned and unaligned query document
collections. Our models combine the strengths of the previous click-through based approaches to lexical gap and,
hence, achieve statistically signiﬁcant improvements compared to the state-of-the-art baseline systems. The improvements are especially promising when the click data is small,
6
The improvements in French are statistically signiﬁcant as
measured by the t-test with p-value of 0.05

491

[5] A. Berger and J. Laﬀerty. Information retrieval as
statistical translation. SIGIR ’99, pages 222–229, New
York, NY, USA, 1999. ACM.
[6] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent
dirichlet allocation. Journal of Maching Learning
Research, 3:993–1022, 2003.
[7] J. Boyd-Graber and D. M. Blei. Multilingual topic
models for unaligned text. In Uncertainty in Artificial
Intelligence, 2009.
[8] P. F. Brown, V. J. D. Pietra, S. A. D. Pietra, and
R. L. Mercer. The mathematics of statistical machine
translation: parameter estimation. Comput. Linguist.,
19:263–311, June 1993.
[9] G. Cao, J.-Y. Nie, J. Gao, and S. Robertson. Selecting
good expansion terms for pseudo-relevance feedback.
SIGIR ’08, pages 243–250, New York, NY, USA, 2008.
ACM.
[10] M. K. Chinnakotla, K. Raman, and P. Bhattacharyya.
Multilingual PRF: english lends a helping hand. In
SIGIR ’10, pages 659–666, NY, USA, 2010. ACM.
[11] M. K. Chinnakotla, K. Raman, and P. Bhattacharyya.
Multilingual pseudo-relevance feedback: performance
study of assisting languages. In ACL ’10:, pages
1346–1356, Morristown, NJ, USA, 2010.
[12] A. P. Dempster, N. M. Laird, and D. B. Rubin.
Maximum Likelihood from Incomplete Data via the
EM Algorithm. Journal of the Royal Statistical
Scociety, Series B, 39(1):1–38, 1977.
[13] S. T. Dumais. Latent semantic analysis. Annual
Review of Information Science and Technology,
38(1):188–230, 2004.
[14] J. Gao, X. He, and J.-Y. Nie. Clickthrough-based
translation models for web search: from word models
to phrase models. In Proceedings of the CIKM ’10,
pages 1139–1148, New York, NY, USA, 2010. ACM.
[15] J. Gao, K. Toutanova, and W.-t. Yih.
Clickthrough-based latent semantic models for web
search. In Proceedings of the SIGIR ’11, pages
675–684, New York, NY, USA, 2011. ACM.
[16] J. Gao, Q. Wu, C. Burges, K. Svore, Y. Su, N. Khan,
S. Shah, and H. Zhou. Model adaptation via model
interpolation and boosting for web search ranking. In
EMNLP ’09, pages 505–513, NJ, USA, 2009.
[17] J. Gao, W. Yuan, X. Li, K. Deng, and J.-Y. Nie.
Smoothing clickthrough data for web search ranking.
SIGIR ’09, pages 355–362, New York, NY, USA, 2009.
ACM.
[18] T. Hofmann. Probabilistic latent semantic indexing. In
Proceedings of the SIGIR ’99, pages 50–57, New York,
NY, USA, 1999. ACM.
[19] J. Huang, J. Gao, J. Miao, X. Li, K. Wang, F. Behr,
and C. L. Giles. Exploring web scale language models
for search query processing. In Proceedings of the
WWW ’10, pages 451–460, New York, NY, USA,
2010. ACM.
[20] J. Jagarlamudi and P. Bennett. Fractional similarity:
Cross-lingual feature selection for search. In
Proceedings of the ECIR ’11. Springer, 2011.
[21] J. Jagarlamudi and H. Daumé III. Extracting
multilingual topics from unaligned comparable

[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]

492

corpora. In Proceedings of the ECIR ’10, volume 5993,
pages 444–456, Milton Keynes, UK, 2010. Springer.
J. Jagarlamudi and J. Gao. Modeling click-through
based word-pairs for web search. In Proceedings of the
WWW ’12 Companion, pages 537–538, New York,
NY, USA, 2012. ACM.
J. Jagarlamudi, R. Udupa, H. Daumé III, and
A. Bhole. Improving bilingual projections via sparse
covariance matrices. In Proceedings of the EMNLP
’11, pages 930–940, Edinburgh, Scotland, UK., July
2011. Association for Computational Linguistics.
K. Järvelin and J. Kekäläinen. IR evaluation methods
for retrieving highly relevant documents. In SIGIR
’00, pages 41–48, New York, NY, USA, 2000. ACM.
H. Z. Ji-Rong Wen, Jian-Yun Nie. Query clustering
using user logs. ACM Trans. Inf. Syst., 20:59–81,
January 2002.
R. Jin, A. G. Hauptmann, and C. X. Zhai. Title
language model for information retrieval. SIGIR ’02,
pages 42–48, New York, NY, USA, 2002. ACM.
V. Lavrenko and W. B. Croft. Relevance based
language models. In Proceedings of the SIGIR ’01,
pages 120–127, New York, NY, USA, 2001. ACM.
F. J. Och and H. Ney. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19–51, 2003.
J. M. Ponte and W. B. Croft. A language modeling
approach to information retrieval. SIGIR ’98, pages
275–281, New York, NY, USA, 1998. ACM.
F. Song and W. B. Croft. A general language model
for information retrieval. In Proceedings of the CIKM
’99, pages 316–321, New York, NY, USA, 1999. ACM.
M. Srikanth and R. Srihari. Biterm language models
for document retrieval. In Proceedings of the SIGIR
’02, pages 425–426, New York, NY, USA, 2002. ACM.
K. Wang, X. Li, and J. Gao. Multi-style language
model for web scale information retrieval. In
Proceeding of the SIGIR ’10, pages 467–474, New
York, NY, USA, 2010. ACM.
X. Wei and W. B. Croft. Lda-based document models
for ad-hoc retrieval. In SIGIR ’06, pages 178–185,
New York, NY, USA, 2006. ACM.
X. Wei and W. B. Croft. Modeling term associations
for ad-hoc retrieval performance within language
modeling framework. ECIR’07, pages 52–63, Berlin,
Heidelberg, 2007. Springer-Verlag.
J. Xu and W. B. Croft. Query expansion using local
and global document analysis. In Research and
Development in Information Retrieval, SIGIR ’96,
pages 4–11, New York, NY, USA, 1996. ACM.
X. Xue, J. Jeon, and W. B. Croft. Retrieval models
for question and answer archives. SIGIR ’08, pages
475–482, New York, NY, USA, 2008. ACM.
C. Zhai and J. Laﬀerty. Model-based feedback in the
kl-divergence retrieval model. In Proceedings of the
CIKM ’01, 2001.
D. Zhang, Q. Mei, and C. Zhai. Cross-lingual latent
topic extraction. In Proceedings of the ACL ’10, pages
1128–1137, Stroudsburg, PA, USA, 2010.


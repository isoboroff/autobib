Learning Hidden Variable Models for Blog Retrieval
Mengqiu Wang
Computer Science Department
Stanford University
Stanford, CA 94305, USA

mengqiu@cs.stanford.edu

~ is a feature vector of the passage s, and θ~ is
where f (s)

ABSTRACT
We describe probabilistic models that leverage individual
blog post evidence to improve blog seed retrieval performances. Our model offers a intuitive and principled method
to combine multiple posts in scoring a whole blog site by
treating individual posts as hidden variables. When applied
to the seed retrieval task, our model yields state-of-the-art
results on the TREC 2007 Blog Distillation Task dataset.

the corresponding weight vector. Z is the partition function computed by summing over all possible relevance assignments. f~(si , sj , zi , zj ) are passage correlation features
(cosine-sim, URL overlapping) and ~g (si , zi ) are passage relevance feature (e.g., rank, score).

Categories and Subject Descriptors

We evaluated our models on TREC 2007 Blog Distillation Track dataset. We would first obtain top 5 ranked passages for each document using Indri’s LM-based retrieval
system, and then apply our model to re-rank each document. Training and testing is done by performing 5-fold
cross-validation. We compare our models with four strong
baselines. The first two are the Indri language model passage and document retrieval systems (Indri-psg, Indri-doc).
The third one is the CMU system, which gives the best performance in TREC 2007 and 2008 evaluations [1]. The last
one is the ReDDE federated search algorithm used in [2].
Our IND model showed significant improvements over the
Indri passage and document retrieval baselines (58.5% and
9.4% relative improvements). The RBM model gained a small
improvement over the IND model, and significantly outperformed the baseline CMU and ReDDE models.

3.

H.3.3 [Information Storage and Retrieval]: Retrieval
Models

General Terms
Design, Algorithms, Experimentation, Performance

Keywords
Learning to Rank, Passage Retrieval, Blog Retrieval

1.

INTRODUCTION

In blog seed retrieval tasks, we are interested in finding
blogs with relevant and recurring interests for given topics. Rather than ranking individual blog posts, whole sites
are ranked (i.e. all posts within a blog). We propose two
discriminatively trained probabilistic models that model individual posts as hidden variables.

2.

Baseline

PROBABILISTIC PASSAGE MODELS

0.3596

Indri-doc 0.3284

RBM

0.3702

0.3385 RBM+cosine sim 0.3779
0.3150

RBM+url

0.3685

CONCLUSIONS

In this paper, we introduced two probabilistic models that
model individual blog posts as hidden variables for blog seed
retrieval tasks. Our models produced state-of-the-art results
on TREC 2007 Blog Distillation dataset.

5.

~ θ
~
−f (s)

1
Z

IND

ReDDE

4.

This work

Indri-psg 0.2267
CMU

We make a modeling assumption that given a set of topranked passages of a document, the document is relevant if
any one of the passages is relevant.
The first independent model (IND) assumes that the relevance of a specific top-ranked passage si is independent of
the relevance of any other passage in ~s. We use the logistic
function to model the relevance of a passage. Our second
model (RBM) takes a step further and exploit the correlations among individual passages in a Restricted Boltzmann
Machine framework.

P (~ẑ|~s)) =

BLOG SEED RETRIEVAL

P (z = 0|s) = e −f (s)
~ θ
~
1+e
P
P s| ~
exp( i<j θ~f~(si , sj , zi , zj ) + |~
g (si , zi ))
i=1 β~

REFERENCES

[1] J. Elsas, J. Arguello, J. Callan, and J. Carbonell.
Retrieval and feedback models for blog distillation. In
Proceedings of TREC, 2007.
[2] J. Elsas, J. Arguello, J. Callan, and J. Carbonell.
Retrieval and feedback models for blog feed search. In
Proceedings of SIGIR, 2008.

Copyright is held by the author/owner(s).
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
ACM 978-1-60558-896-4/10/07.

922


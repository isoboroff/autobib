Aspect Presence Verification Conditional on Other
Aspects
Dmitri Roussinov
University of Strathclyde
16 Richmond Street, Glasgow, UK G1 1XQ
+44 141 548 3706

dmitri.roussinov@cis.strath.ac.uk

Categories and Subject Descriptors

(up to a certain length) from the document (e.g. polar station,
oil drilling proposed, expedition ships, etc.) rather than relying
on a finite number of expansion terms. 2) Considering the
problem of aspect verification conditional on the presence of
other, often easier to establish aspects. E.g., in a document
about Antarctica, station is a good indication of the exploration
theme, while not necessary so in unrestricted context. 3)
Modeling subsumption of indicators, e.g. if the word station is a
part of train station then its connection to the exploration theme
is weaker.

H.3.3 [Information Search and Retrieval]: Retrieval
models; – Retrieval Models

2. FRAMEWORK

ABSTRACT
I have shown that the presence of difficult query aspects that are
revealed only implicitly (e.g. exploration, opposition,
achievements, cooperation, risks) can be improved by taking
advantage of the known presence of other, easier to verify query
aspects. The approach proceeds by mining a large external
corpus and results in substantial improvements in re-ranking the
subset of the top retrieved documents.

Here, I considered the simplest, but a common situation with the
two aspects in a query, each can be specified by one or more
keywords: 1) Ap is already known to be present in the document
d and 2) the other aspect Am, explicit representation of which is
missing in the document, thus simply referred below as the
“missing” aspect. While Am is typically a difficult aspect to
verify, as I have demonstrated here, the task of estimating the
presence of Am conditional on the presence of Ap happens to be
easier.
As the possible indicators of the aspect implicit presence, I
considered all the sequences of words (up to length of 3) in a
document. For each indicator i, the algorithm estimated
P(Am|i,Ap) , the probability of the occurrence of Am within the
proximity (e.g. same sentence) of i, conditional on the
occurrence of Ap. In order to do that, a regression (M5P model
tree [6]) was trained independently for each topic, using the
normalized frequency counts obtained from Microsoft’s Bing
search engine as independent variables. For example, the high
ratio
#((station NEAR exploration) AND Antarctica)/#(station AND A
ntarctica) would indicate the high probability of occurrence of
exploration near the word station in the external corpus,
conditional on the presence of Antarctica. The snippets returned
by Bing for the query representing both aspects (e.g. antarctica
NEAR exploration) served as training examples, thus no
parameter tuning was necessary. The advantage of using M5P
was learning automatically the reliability thresholds for the
frequency counts.
The subsumption step of the algorithm discarded all the subsequences (e.g. station) within the word sequences (e.g. train
station) for which the reliable estimates of the conditional
probabilities were obtained. This resulted in the average of 531
preserved indicators per document, with 90% of the strongest
100 indicators having 2 or more words, some of those presented
in Table 2 below. To rank the documents, the sum of all the
conditional probability estimates over all the remaining
indicators was treated as the total number of “implied”
occurrences of the missing aspect:

General Terms
Algorithms, Experimentation, Theory.

Keywords
Information retrieval, machine learning, external corpus.

1. INTRODUCTION
It has been noticed that a common reason for the search results
to be of poor quality is missing one or more aspects of the user
information need [1], where an aspect can be represented by a
subset of query words. E.g., in the query antarctica exploration,
the word antarctica is relatively rare and specific. Along with
its same-stem variants, it explicitly occurs in virtually all
documents about Antarctica. On the other side, the word
exploration, capturing the other aspect of the query, is not only
more frequent, but also represents a higher level concept (theme,
topic, etc.), often revealing itself only implicitly by such
statements like “… scientists began to collect data…” The
ranking of the retrieved documents by currently state-of-the-art
algorithms would be primarily determined by antarctica, mildly
affected by the explicit occurrence of the word exploration, and
not affected by the implicit presence of the exploration theme.
Although techniques aimed at detecting and representing
missing aspects have been suggested [2][3] they have not been
yet methodologically studied or revealed convincing
improvements. I suggest that it was because they were
essentially limited to the bag-of-words representations and the
query expansion models. On the contrary, this research builds
on the prior works studying the prediction of occurrence of
given words (concepts) in a given text context (e.g. a sentence)
such as [5][7]. Specifically, I proceeded by the exploring the
following innovations:
1) Going beyond the bag of words by looking for the indicators
of implicit aspect presence among all the sequences of words
Copyright is held by the author/owner(s).
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
ACM 978-1-60558-896-4/10/07.

865

tf m =

∑

stemming and pseudo-relevance feedback using Lemur retrieval
engine default settings. Since the approach here involves an
external corpus, to make a fair comparison, I also involved B2
obtained and optimized the same way as in [4], which was
essentially an application of a relevance model with an external
corpus (here, using Bing’s snippets).

P ( Am | i , Ap ) , and the bm25 formula was

i⊂ d

applied.

3. EMPIRICAL EVALUATION
B1

B2

Entire
Web
0.65**
0.16

4. CONCLUSIONS

Wikipedi
a only
.53*
.14

As the results in Table 1 indicate, it was possible to significantly
improve verifying the presence of the difficult implicit aspects
by the techniques suggested here. Also, no specific topic has
been harmed as a result. While the actual impact on a larger set
of topics remains to be seen, I have nevertheless been able to
handle a very common scenario with the implicit presence of a
difficult aspect (e.g. exploration) and the explicit presence of an
easier aspect (e.g. Antarctica). Although the dataset involved in
experiments here was very small, it still represented the top
ranked results from the state of the art techniques, and thus
being able to improve them by re-ranking has great practical
implications. The ablation studies (not reported here due to the
space limitations) confirmed that each of the novelties 1-4 stated
in the introduction was crucial. While sending queries to a
search portal delayed the processing substantially, in order to
achieve the real time speeds, future implementations can make
use of the processed large corpus data such as Google’s 1T or a
faster access to a search engine index.

MAP
0.39
0.43
Standard
0.13
0.11
Deviation
% change
+51%
-9%
n/a
+23%
over B2
Table 1. The results of the evaluation. Statistically
significant differences at the levels of 0.05 and .1 are
marked with ** and * accordingly.
Since the approaches studied here involved a large number of
time-consuming external queries, I built a small but “clean”
data set that was sensitive enough to evaluate various
configurations and the overall verification accuracy of the
techniques suggested here based on the top ranked documents
retrieved by bm25 ranking function (described as B1 below)
using the HARD 2005 TREC topics, which are known to be
difficult and often result in missing aspects [1]. I chose only
those topics in which 1) It was possible to interpret the title as
consisting of missing and present aspects. 2) The present aspect
was occurring in at least 90% of the top 20 documents. 3) The
missing aspect was not explicitly occurring in more than half of
the top 20 documents. This left me with 18 topics, some
examples of them listed in Table 2. Only up to 20 top ranked
irrelevant and relevant documents were selected, and only those
that did not have the missing aspect mentioned explicitly. I also
removed (approx. 10% of) the documents assessed by TREC as
irrelevant but still having both aspects present in order to reduce
the sensitivity of the evaluation to the details supplied only in
the narratives of the topics and thus not available to neither the
baseline nor the suggested algorithms. The resulting data set
was almost “balanced” with approximately 15 negative and 10
positive examples on average per each topic. I compared the
performance against two strong baselines: B1 was obtained by
applying bm25 ranking formula using the topic titles only, with

5. REFERENCES
[1] Buckley, C. Why current IR engines fail. SIGIR 2004.
[2] Collins-Thompson, K., Callan, J. Query expansion using
random walk models. CIKM 2005.
[3] Crabtree, D.W., Andreae, P. Gao, X. Exploiting
underrepresented query aspects for automatic query
expansion. SIGKDD 2007.
[4] Diaz, F. and Metzler, D. Improving the estimation of
relevance models using large external corpora. SIGIR 2006.
[5] Edmonds, P. Choosing the word most typical in context
using a lexical co-occurrence network, ACL 1997.
[6] Monz, C. Model Tree Learning for Query Term Weighting
in Question Answering. Advances in Information Retrieval,
Volume 4425/2007, pp. 589-596.
[7] SzeWang F., Roussinov, D., Skillicorn, D.B. Detecting
Word Substitutions in Text. IEEE TKDE, 2008.

Table 2. Top indicators of implicit aspect presence for some topics. The missing aspects are underlined. Bold font highlights the
indicators that are specific to the present aspect.
Topic
Strongest Indicators of Presence
Transportation train caught fire, people were killed, caused by sparks, the midst of, described the crash, in spite
of, millions of dollars, quickly as possible, billions of dollars, around the corner, was caused by,
Tunnel
turned into a, the worst, rescue, emergency, explosion, coal, killed, fire
Disasters
Black Bear
were forced to, bear attempted to, fire, the bear was, officials say, reduced, kill, defense,
Attacks
occurred in, officials said, carcass, attract, documented, bear was sighted, dangerous, killed
by, ripped, threatening
Iran will ship, minister to visit, delegation will visit, positive, visit to Iraq, oil exports, Iranian
Iran Iraq
delegation, normalizing, relations, the joint, agreement with Iran, mutual, to bilateral, visit to Iran,
Cooperation
accepted an invitation, invitation to visit, normalization, war ended in, the withdrawal of, gesture
Journalist Risks journalist was shot, press freedom, murdered, circumstances, in prison, Iraq, Russia, body, killer,
gunned down, win, posed, detained

866


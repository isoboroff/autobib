On the Mono- and Cross-Language
∗
Detection of Text Reuse and Plagiarism
Alberto Barrón-Cedeño

NLE Lab. ELiRF Research Group
DSIC, Universidad Politécnica de Valencia
Valencia, Spain

lbarron@dsic.upv.es

ABSTRACT

One of the main weaknesses of currently available models
is that they are unable to detect cross-language plagiarism.
Approaching the detection of this kind of plagiarism is of
high relevance, as the most of the information published is
written in English, and authors in other languages may find
it attractive to make use of direct translations.
Our experiments, carried out over parallel and a comparable corpora, show that models of “standard” cross-language
information retrieval are not enough. In fact, if the analysed
source and target languages are related in some way (common linguistic ancestors or technical vocabulary), a simple
comparison based on character n-grams seems to be the option. However, in those cases where the relation between
the implied languages is weaker, other models, such as those
based on statistical machine translation, are necessary [3].
We plan to perform further experiments, mainly to approach the detection of cross-language plagiarism. In order to do that, we will use the corpora developed under
the framework of the PAN competition on plagiarism detection (cf. PAN@CLEF: http://pan.webis.de). Models that
consider cross-language thesauri and comparison of cognates
will also be applied.

Plagiarism, the unacknowledged reuse of text, has increased
in recent years due to the large amount of texts readily available. For instance, recent studies claim that nowadays a high
rate of student reports include plagiarism, making manual
plagiarism detection practically infeasible.
Automatic plagiarism detection tools assist experts to analyse documents for plagiarism. Nevertheless, the lack of standard collections with cases of plagiarism has prevented accurate comparing models, making differences hard to appreciate. Seminal efforts on the detection of text reuse [2]
have fostered the composition of standard resources for the
accurate evaluation and comparison of methods.
The aim of this PhD thesis is to address three of the main
problems in the development of better models for automatic
plagiarism detection: (i) the adequate identification of good
potential sources for a given suspicious text; (ii) the detection of plagiarism despite modifications, such as words substitution and paraphrasing (special stress is given to crosslanguage plagiarism); and (iii) the generation of standard
collections of cases of plagiarism and text reuse in order to
provide a framework for accurate comparison of models.
Regarding difficulties (i) and (ii) , we have carried out
preliminary experiments over the METER corpus [2]. Given
a suspicious document dq and a collection of potential source
documents D, the process is divided in two steps. First,
a small subset of potential source documents D∗ ⊂ D is
retrieved. The documents d ∈ D∗ are the most related to
dq and, therefore, the most likely to include the source of
the plagiarised fragments in it. We performed this stage
on the basis of the Kullback-Leibler distance, over a subsample of document’s vocabularies. Afterwards, a detailed
analysis is carried out comparing dq to every d ∈ D∗ in order
to identify potential cases of plagiarism and their source.
This comparison was made on the basis of word n-grams,
by considering n = {2, 3}. These n-gram levels are flexible
enough to properly retrieve plagiarised fragments and their
sources despite modifications [1]. The result is offered to the
user to take the final decision. Further experiments were
done in both stages in order to compare other similarity
measures, such as the cosine measure, the Jaccard coefficient
and diverse fingerprinting and probabilistic models.

Categories and Subject Descriptors
H.3 [Information Storage and Retrieval]: Miscellaneous

General Terms
Experimentation

Keywords
Text similarity, plagiarism detection, cross-language plagiarism detection

1. REFERENCES

[1] A. Barrón-Cedeño, P. Rosso, and J. Benedı́. Reducing
the Plagiarism Detection Search Space on the Basis of
the Kullback-Leibler Distance. In A. F. Gelbukh,
editor, CICLing 2009, volume LNCS (5449), pages
523–534, Mexico City, Mexico, 2009. Springer.
[2] P. Clough, R. Gaizauskas, S. Piao, and Y. Wilks.
Measuring Text Reuse. In Proceedings of Association
for Computational Linguistics (ACL2002), pages
152–159, Philadelphia, PA, 2002.
[3] M. Potthast, A. Barrón-Cedeño, B. Stein, and
P. Rosso. Cross-Language Plagiarism Detection.
Language Resources and Evaluation, Special Issue on
Plagiarism and Authorship Analysis, 2010.

∗Partially funded by the CONACYT Mexico 192021 grant
and the Text-Enterprise 2.0 TIN2009-13391-C04-03 project.
Copyright is held by the author/owner(s).
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
ACM 978-1-60558-896-4/10/07.

914


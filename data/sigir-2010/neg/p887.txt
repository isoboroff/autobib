Author Interest Topic Model
Noriaki Kawamae

NTT Comware
1-6 Nakase Mihama-ku Chiba-shi, Chiba 261-0023 Japan

kawamae@gmail.com

ABSTRACT
This paper presents a hierarchical topic model that simultaneously captures topics and author’s interests. Our proposed model, the Author Interest Topic model (AIT), introduces a latent variable with a probability distribution over
topics into each document. Experiments on a research paper
corpus show that AIT is very useful as a generative model.

Categories and Subject Descriptors

Figure 1: Graphical models: In this figure, shaded
and unshaded variables indicate observed and latent
variables, respectively. An arrow indicates a conditional dependency between variables and the plates
indicate a repeated sampling with the iteration number shown. This figure shows that each author produces words from a set of topics that are preferred
by the author in (a), persona associated with the author in (b), each document class in (c). In learning
a document written by multiple authors, AIT makes
copies of the document and associates one copy with
each author.

H.3.1 [Content Analysis and Indexing]:

General Terms
Algorithms, experimentation

Keywords
Topic Modeling, Latent Variable Modeling

1.

INTRODUCTION

Attention is being focused on how to model users’ interests in several fields. A model of interest allows us to infer
which topics each user prefers and to measure the similarity between them in terms of their interests. For example,
the Author-Topic(AT) [3] groups all papers associated with
a given author by using a single topic distribution associated with this author. Author-Persona-Topic(APT) [2] introduces a persona, which is also a latent variable, under a
single given author. Thus, these models allow each author’s
documents to be divided into one or more clusters, each with
its own separate topic distribution specific to that persona
This paper presents the Author Interest Topic(AIT) model;
it is a generalization of known author interest models such as
AT and APT. AIT allows a number of possible latent variables to be associated with author’s interest, while previous
models limit this number. Therefore, AIT can describe a
wider variety of authors’ interests than other models, which
reduces the perplexity. Moreover, AIT can infer the overall
interest in the training data and so can assign probabilities
to previously unseen documents.

2.

describe the generative process. For modeling each author’s
interest, our proposal, AIT, incorporates document class cd ;
it provides an indicator variable that describes which mixture of topics each document d takes, into d. Accordingly,
AIT represents documents of similar topics as the same document class in the same way that topic models represent cooccurrence words as the same topic variable. Therefore, the
difference between AIT and AT, APT is that rather than
representing author’s interest as a mixture of topic variables
θa (AT) or θPa (APT) in each document layer, AIT represents
each author’s interest as a mixture of document classes ψa
in each author layer. Although both θa (AT) and θPa (APT)
are associated with only authors, the document class can be
shared among authors. This class allows AIT to represent
documents having similar topics as the same document class
by merging parameters; this reduces the number of possible
parameters without losing generality. Accordingly, as the
size of training data is increased, relatively fewer parameters are needed. On the contrary, the parameters of the
other models track the order of authors and so experience
linear growth with the size of the training data. Moreover
we decide the number of latent variables following CRP [1].
Consequently, AIT increases the number of possible latent
variables for explaining all authors’ interests.
AIT employs Gibbs sampling to perform inference approximation. In the Gibbs sampling procedure, we need to cal-

AUTHOR INTEREST TOPIC MODEL

This section details our model. Table 1 shows the notations used in this paper. Figure 1 shows graphical models to
Copyright is held by the author/owner(s).
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
ACM 978-1-60558-896-4/10/07.

887

Table 2: Perplexity of AT, APT and AIT: This difference between AIT and APT is significant according to one-tailed t-test with the number of samples
G = 100. For fair comparison, the number of topic
variables T was fixed at 200, the number of document classes J was fixed at 40(AIT). Results that
differ significantly by t-test p < 0.01, p < 0.05 from
APT are marked with ’**’, ’*’ respectively. The
value of Avg means the average computing time for
each iteration in gibbs sampling.

Table 1: Notations used in this paper
SYMBOL DESCRIPTION
A
number of authors
number of document classes
J
T
number of topics
number of documents
D
number of unique words
V
Ad
authors associated with document d
number of documents written by author a
Da
Nd
number of word tokens in document d
ai
author associated with ith token in document d
pd
persona associated with document d
cd
document class associated with document d
topic associated with the ith token in document
zdi
d
wdi
ith token in document d
ψa
multinomial distribution of document classes
specific to author a (ψa |γ ∼ Dirichlet(γ) )
θj
multinomial distribution of topics specific to interest j (θj |δ ∼ Dirichlet(δ) )
multinomial distribution of words specific to
φt
topic t (φt |β ∼ Dirichlet(β) )

Iteration
AT
APT
AIT

culate the conditional distributions. The predictive distribution of adding interest class cd in documents written by
author a to topic cd = j is given by
8
P
Q
Γ( t njt\d +δt )
Γ(njt +δt )
tP
>
Q
,
n
>
aj\d
<
t Γ(njt\d +δt ) Γ( t njt +δt )
if j is
an
existing
class
class
P (j|c\d , a, z, γ, δ) ∝
P
Q
>
n
+δt )
Γ(njt +δt )
>
tP
: γj Γ(
Q t jt\d
, otherwise
Γ(n
+δt ) Γ(
njt +δt )
jt\d

t

t

(1)
where naj\d represents the number of documents assigned to
j in all documents written by author a, except d, and njt\di
represents the total number of tokens assigned to topic t
in the documents associated with document class j, except
token di.
The predictive distribution of adding word wdi in document d written by a to topic zd = t is given by
8
ntw\di +βw
>
P
>
< njt\di Vv (ntv\di +βv ) ,
if t is an existing class
P (t|j, z\di , w, β, δ) ∝
>
>
: δt PVntw\di +βw , otherwise
(n
+β )
v

tv\di

4000
1488
1304
1217∗∗

6000
1343
1180
1103∗∗

8000
1339
1059
988∗∗

10000
1333
1027
964∗∗

Avg
3.2s
10.4s
11.7s

δ were set at 0.1, 10(APT),1(AIT) and 1, respectively. We
ran single Gibbs sampling chains for 10000 iterations on machines with Dual Core 2.66 GHz Xeon processors.
To measure the ability of a model to act as a generative
model, we computed test-set perplexity under estimated parameters and compared the resulting values.
Perplexity, which is widely used in the language modeling
community to assess the predictive power of a model, is algebraically equivalent to the inverse of the geometric mean
per-word likelihood (lower numbers are better). Table 2
shows the results of the perplexity comparison. This table
shows that AIT yielded significantly lower perplexity on the
test set than AT or APT, which shows that AIT is better
as a topic model. This is due to the ability of AIT to allow
the document class to be shared across authors and to group
documents under the various topic distributions rather than
grouping documents by a given author or persona under a
few topic distributions. This implies that clustered documents contain less noise than otherwise. If the number of
document classes is overly restricted, the difference between
the observed data and the data generated by the model under test increases, which raises the perplexity.

4. CONCLUSION
Our proposed model, AIT, supports the expression of topics in text documents and can identify the interests of authors in these documents. Future work includes extending
AIT by taking other metadata such as time, references and
link structure into account, for tracking the dynamics of interests and topics.

v

(2)
where ntw\di represents the total number of tokens assigned to word w in topic t, except token di, and njt\di
represents the total number of tokens assigned to topic t in
all tokens assigned to j, except token di.

3.

2000
1529
1454
1321∗∗

5. REFERENCES

EXPERIMENTS

[1] D. J. D. Aldous. Exchangeability and related topics,
volume 1117 of Lecture Notes in Math. Springer, Berlin,
1985.
[2] D. Mimno and A. McCallum. Expertise modeling for
matching papers with reviewers. In KDD, pages
500–509, 2007.
[3] M. Steyvers, P. Smyth, M. Rosen-Zvi, and T. L.
Griffiths. Probabilistic author-topic models for
information discovery. In KDD, pages 306–315, 2004.

We focus here on the extraction of interests from given
documents, and demonstrate AIT’s performance as a generative model. The dataset used in our experiments consisted
of research papers in the proceedings of ACM CIKM, SIGIR,
KDD, and WWW gathered over the last 8 years (2001-2008).
We removed stop words, numbers, and the words that appeared less than five times in the corpus. Accordingly, we
obtained a total set of 3078 documents and 20286 unique
words from 2204 authors. Additionally, we applied both AT
and APT to this dataset for training and comparison.
In our evaluation, the smoothing parameters β, γ and

888


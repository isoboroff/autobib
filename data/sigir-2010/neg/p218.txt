Serendipitous Recommendations via Innovators
Noriaki Kawamae

NTT Comware
1-6 Nakase Mihama-ku Chiba-shi, Chiba 261-0023 Japan

kawamae@gmail.com

ABSTRACT
To realize services that provide serendipity, this paper assesses the surprise of each user when presented recommendations. We propose a recommendation algorithm that focuses on the search time that, in the absence of any recommendation, each user would need to find a desirable and
novel item by himself. Following the hypothesis that the degree of user’s surprise is proportional to the estimated search
time, we consider both innovators’ preferences and trends for
identifying items with long estimated search times. To predict which items the target user is likely to purchase in the
near future, the candidate items, this algorithm weights each
item that innovators have purchased and that reflect one or
more current trends; it then lists them in order of decreasing
weight. Experiments demonstrate that this algorithm outputs recommendations that offer high user/item coverage, a
low Gini coefficient, and long estimated search times, and so
offers a high degree of recommendation serendipitousness.

Categories and Subject Descriptors
H.3.3 [Information filtering]: Information filtering by ranking

General Terms
Algorithms, experimentation

Keywords
Personalization, Ranking, Serendipitous Recommendations,
Innovator, User Flow, Collaborative filtering, Trend

1.

INTRODUCTION

Collaborative filtering(CF) aims to improve the user’s experience and discovery by providing a better interface to the
potentially overwhelming set of choices. The volume of items
now exceeds the ability of any individual to accurately assess
their desirability. This information overload problem is also

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.

218

serious for many service providers and thus has heightened
demands for personalized recommendations. CF is used in
web-based services, where there are a vast numbers of items
such as Web pages, digital music, and video contents for
browsing(download or purchase), and is regarded as one of
the most promising recommendation algorithms.
Traditional CF algorithms focus on optimizing accuracy
measurements such as precision/recall and neglect other factors, e.g, novelty and serendipity. For example, many CF
algorithms use similarity scores between all pairs of users
in an attempt to improve the top-N precision, and present
items in proportion to their popularity among like-minded
users [10] [12]. However, the most popular items in any log
collection are the ones that a given user will recognize with
high probability, or be broadly familiar with. Hence, highly
accurate recommendations appear far too obvious and of
little help to users, and seem to fail to enhance user satisfaction [3] [17]. In fact, recommendation systems that appropriately discount popularity lead to an increase in the
total sales volume [2] [4]. Moreover, novel and serendipitous
recommendations are necessary to broaden the user’s view
in the recommendation flow.
In this paper, we aim to emphasize the surprise of each
user with the recommendation, instead of posing the typical CF task: how well will the user like a candidate item?
For this goal, our algorithm focuses on the estimated search
time that the user would take to find the item by himself.
This algorithm is based on the assumption that an item recently purchased by the innovator will surprise the follower
(the other user) more than other items. Namely, this item
will have a longer estimated search time than other items
meaning that the purchased item would be time-consuming
for the user to find. Following this idea, we extend the Personal Innovators Degree (PID) [8] into the Personal Innovator Probability (PIP) for identifying innovators and define
a User flow probability (UFP) for measuring how likely the
user is to purchase the item just after purchasing an arbitrary item. In ranking candidate items for a given user, this
algorithm weights each item by both PIP and UFP scores
of the most latest purchases of his/her personal innovators
and including trends.
One key advance of our algorithm is that it reduces the
time spent by the user in seeking novel items compared to
the conventional alternatives. This earned time is in proportion to the difference between the estimated purchase time
when the target user is likely to purchase the item without
any recommendation and the time when this item is recommended to the user. To weight items in proportion to the

value of this difference, we use the time lead and the number
of users in both PIP and UFP. We define PIP using the purchase time offset, the number of users, and the relationship
over multiple steps. Likewise, UFP is determined by using
these time factors and the multiple steps. Consequently, we
weight item serendipitousness by innovators and then item
novelty by trends, where this weight is in proportion to the
length of estimated search time.

2.

Figure 1: Reducing search time by basing recommendations on the estimated purchase time: For
example, t̂a2 denotes the estimated purchase time
when user a would purchase item i2 without a recommendation

RELATED WORK

Novelty and serendipity metrics measure the degree of
“non-obviousness”of recommendations with the goal of avoiding “cherry-picking” [6]. The system of [16] can infer whether
an item, one that is considered relevant, contains any novel
information as indicated by five proposed measures that are
intended to capture redundancy. Yang et al [15] define novelty in terms of user knowledge, and his/her degree of interest in an item. Ziegler et al [17] propose a topical diversification approach to balance and diversify personalized
recommendation lists; the goal is to use intra-list similarity to reflect the complete spectrum of the user’s interests.
Fouss et al [5] incorporate Euclidean commute time distance,
which is one of random-walk-based techniques, when computing the similarities of nodes. Recently, Celma et al [2]
presented two complementary methods to analyze and evaluate novel recommendations. The item-centric evaluation
method involves analyzing the item-based recommendation
network to detect whether the intrinsic topology of the network has a pathology that hinders novel recommendations.
The user-centric evaluation aims to measure the perceived
quality of the recommendations.
Although these approaches focus on providing novel and
serendipitous recommendations, they ignore the dynamics,
which describes the changes in user preferences over time.
For example, new items are different from old items in terms
of their serendipity, even if they share almost the same popularity. While the former items are novel and as such are
unknown to many people, the latter items have been recognized but not purchased by them. Identifying these differences is valuable if the serendipitous recommendation flow
is to retrieval worthwhile items for the user.
To distinguish these differences, recommendation algorithms need to consider both the change in user preferences
and the trends of items in computing user-user and itemitem relationships, respectively. In this paper, we use PIP,
which measures how much earlier the innovator purchased
the item, to compute user-user relationships and UFP, which
measures how likely the user will be to purchase each item
just after purchasing an arbitrary item to determine itemitem relationships.

3.

traditional content-based information filtering systems do
not provide. To provide a clear example of the difference
between novelty and serendipitousness, consider the case
in which a simple recommendation system presents movies
to a user whose favorite director is “James Cameron”. If
the system recommends his latest movie “Avatar(2009)” to
these users, this movie is certainly novel, but probably not
serendipitous. Since the user is his fan, he is likely to already
know of that movie via advertisements, discussion groups,
or like-minded friends, or will find it in the near future.
On the other hand, however, a recommender system that
shows “Princess Mononoke(1997)”, which has themes similar
to “Avatar”, and which is not an obvious recommendation,
provides serendipity to the user. Because this is a foreign
movie produced by a different director, many users would
take much longer for find it by themselves in the absence
of any help. Consequently, serendipitous recommendations
need to find the users with well-proven predictive ability
(innovators) and use their logs.
First, we propose to use “time” as a novel view for quantifying serendipity. As shown in Figure 1, time here means the
difference between the time at which target user ua would
purchase items (estimated time) i2 (t̂a2 ), i3 (t̂a3 ), and the
times at which these items are recommended to user t0 . Our
algorithm is based on the assumption that this difference is
useful as a measure of serendipity, since items with long estimated search times will surprise the user. Accordingly, the
proposed recommendation algorithm ranks items in decreasing order of this difference; it yields serendipitous items and
greatly reduces the time need for the user to find these items.
For example, |t̂a3 -t0 | indicates a longer acquisition delay for
ua than |t̂a2 -t0 |. Moreover, i3 seems to offer more serendipity to ua than i2 . That is, serendipitous recommendations
are real time-savers for consumers.
Second, we focus on “innovative” consumers for identifying
the user logs that contain serendipitous items. In Figure 1,
ub is an innovator for ua . Among like-minded consumers,
innovators become aware of items well before their release
and purchase these items soon after their release. According to Rogers’ innovator theory, the early consumers who
focus on undiscovered or unreleased items are called “innovative” [13]. The purchase logs of innovators include more
serendipitous items that other like-minded consumers would
like to acquire but have not yet become aware of.
Actually, many innovators can be found in CD/DVD purchase logs. Innovators are able to discover even poorlymarketed movies (e.g. Napoleon Dynamite(2004), The Visitor(2007) and The Hangover(2009), which become popu-

RECOMMENDATION FOCUSED ON
ESTIMATED PURCHASE TIME

Here, we intuitively explain why the estimated purchase
time is useful for improving serendipitousness and explain
the ideas behind our algorithm.
A serendipitous recommendation helps the user find a surprisingly interesting item he might not have otherwise discovered [6]. The distinction between novelty and serendipitousness is important when evaluating collaborative filtering algorithms, because the potential for serendipitous recommendations is one facet of collaborative filtering that

219

4. RECOMMENDATION VIA PERSONAL
INNOVATOR PROBABILITY AND USER
FLOW PROBABILITY
4.1 Personal Innovator Probability

Figure 2: Typical temporal flow of consumers observed in purchase history logs: The direction denotes the purchase order time

lar long after its release) ahead of others. These movies,
once “discovered,” are rapidly acquired by like-minded followers. Since Cameron likes the films of Hayao Miyazaki,
like “Princess Mononoke”,“Nausicaa: Valley of the wind(1984)”,
and “Laputa: Castle in the Sky(1986)”, where themes are
pacifism, harmony with nature, flying aircraft, floating castles, etc, and has watched these films, innovative consumers
get to know this fact and then watch these movies, too. Consequently, innovators have the shortest offset, |t̂ui j − t0 | of
innovator ui for item j.
Although innovators discover serendipitous items ahead of
others, these items lose their serendipitousness over time. In
Figure 1, i3 better satisfies ub ’s preference than i2 , since ub
will be purchased i3 after i2 . Therefore we incorporate the
trend of items in computing item-item relationships. Figure 2 shows a simple example of consumer transitions for
three items: ia , i1 and i2 . Let ia be the specified item,
i.e., the item observed in the log of the target user. Since
CF processes user purchase logs to decide which candidate
items are to be recommended to the target user, its quality
depends on how to weight items i1 and i2 for the user who
has purchased ia given the preference order of this user.
Conventional algorithms based on item-item similarity compute the similarity scores among items using the number of
consumers who purchased both items. This is because the
underlying assumption of these algorithms is that those who
agreed in terms of past behavior will tend to agree in the
future, and the similarity score is proportional to the degree of agreement. For example, in Figure 2, each item of
set i1−3 has been purchased by the same users in common
with ia , and thus each item is treated equally according to
the similarity defined for ia . Accordingly, CF assigns equal
weights to i1−3 .
We, however, need to differentiate these items by focusing
on the order of item purchase time. Here, i3 was purchased
by three users after ia , while i2 was purchased by three users
before ia . As stated before, we naturally assume that i3
better matches the future preferences of users who have just
purchased ia than i1 or i2 , and will be preferred by them.
Accordingly, i3 is a more appropriate item for a user who
has purchased ia than i1 or i2 . Therefore, information on
item purchase time is useful in identifying the trend in items.
Consequently, it is more reasonable to compare the number
of common users as well as purchase times in computing
item-item relationships.

220

The aim of personal innovator probability (PIP) is to identify the innovators. We extend PID to model how innovators are followed by multiple users and steps for ranking how
likely each user is to be an innovator among all users. This
approach is based on the assumption that if uc is an innovator for ua and ud is an innovator for uc , ud seems to be
more useful to ua than uc . The aim of PID is to weight
user logs appropriately given a target user and to identify
logs that match the precedence preference of the target user.
PID consists of two time factors and one item factor, and is
given by:
X
PID(ub , ua ) =
r(i; b, a) × w(i; a) × v(i).
(1)
i∈Cab

Here, Cab is the set of common items that both ua and
ub have purchased, r(i; b, a) denotes the degree of ub as a
personal innovator to ua for common item i, w(i; a) denotes
how recently ua purchased common item i, and v(i) denotes
how important common item i is as a discriminator of likeminded users. We describe each of the factors below:
8
t −T
t
−T
< exp(− b,it̄i i ) − exp(− a,it̄i i ),
(2)
r(i; b, a) =
if tb,i ≤ ta,i
:
0, otherwise

where Ti denotes the release time of i and t̄i denotes the
average time i was purchased after its release, ta,i and tb,i
denote the times at which ua and ub purchased i, respectively.
ea,i
w(i, a) = exp(−
),
(3)
ēa

where ea,i denotes the time passed since ua purchased i, and
ēa denotes the average of ea,i over all items purchased by
ua .
v(i) =

1
,
log(1 + Ui )

(4)

where Ui denotes the number of users who purchased i (taken
from the logs).
It is clear that determining the user-user relationships via
common items will encounter the problem of data sparseness, since the ratio of users who share common items decreases rapidly in inverse proportion to the number of items.
To solve this problem, our approach is to model the innovator relationship as an ergodic Markov chain; this guarantees the convergence of the power of the Markov chainbased matrix as follows: First, we define innovator probability p(b|a) according to the Bayesian rule:
p(b|a) =

PID(ub , ua )
,
Σu PID(u, ua )

(5)

where p(b|a) represents the probability that, given ua , how
likely ub is to be regarded as the best innovator among all
users for ua . The innovator probability p(b|a) is a relative
measure since it is normalized over all users and selects b
from among all users, while PID is a absolute measure. Second, we define the revised innovative probability ṗ(b, a) for

implementing the ergodic Markov chain.
8
< p(b|a),
if Σu ṗ(u, a) 6= 0
ṗ(b, a) =
: 1
, otherwise
U

We assume that the stay period at item i follows an exponential distribution with shift-rate qi . According to the property
of exponential distributed random variables, ti with rate qi
is given by

(6)

E(ti ) =

Moreover, we consider the revised innovator probability as
the primitive matrix P̈ for making the Markov chain ergodic:
eeT
,
P̈ = αṖ + (1 − α)
U

(7)

u

1
1
(β P̈ )2 +···+
(β P̈ )N−1 +···)exp(−β),
2!
(N − 1)!
(8)
1
where N!
assigns lower weight to longer paths, β is a parameter to control the effects of transitivity, and exp(−β) is
a normalization factor. The larger β is, the more strongly
are longer paths weighted. Clearly, PIP enables us to identify users who could not, according to PID, be regarded as
innovators. We call innovator relationship p̄(b|a) the Personalized Innovator Probability P IP (ub , ua ), and use it instead
of P ID(ub , ua ).
P̄ = ((β P̈ )+

where tu,ij denotes the time that user u took to move from
item i to item j. Determining qij from Eq. (10), we gain
qij = qi pij

t→∞

t→∞

P ′ (t) = P (t)Q

(13)

0

P(0) = I,

(15)

where I is the identity matrix. The solution is
P (t) = etQ =

∞
X
(tQ)n
.
n!
n=0

(16)

We then get the transition matrix function that satisfies the
Kolmogorov forward and backward equations. If Q can be
diagonalized by Q = MDM−1 , then
P (t) =

∞
X
M (tD)n M −1
= M etD M −1 .
n!
n=0

(17)

For large Q, a Taylor approximation can also be used,
t
P (t) ≈ lim (I + Q )n .
n→∞
n

j6=i

(18)

Consequently, UFP consists of u(ib |ia , ∞) and is given by:

which represents the chain from item i with rate qi . When
the stochastic process leaves item i, it will next settle on
item j with probability pij , which is independent
P of the time
spent at item i, and that satisfies pii = 0 and j6=i pij = 1.
Accordingly, we gain
i 6= j.

i 6= j.

where P (t) denotes the transition matrix with the ij-th elements of matrix pij . Formally, when the state space is finite,
the transition probability can be estimated by using

The aim of user flow probability (UFP) is to follow trends,
and detect novel items by employing the idea discussed in
the previous section. UFP weights each item appropriately
given a specified item; it is an estimate of how many consumers will purchase this item after the specified item. We
consider the function of consumers who have purchased item
b at t after a in assessing transition probability pab , and use
this probability to predict which item will be purchased.
Similar to PIP, we model the probability by using CTMC,
which satisfies the Markov property; it takes its value from
a set called the state space. Continuous-time Markov processes are most easily defined by specifying the transition
rates qij , and these are typically given as the ij-th elements
of the transition rate matrix Q, which contains all information about the transitions of the Markov chain. For the
probabilities to be conserved, i.e., to add up to one, the
off-diagonal elements of Q must be non-negative and the
diagonal elements, which we call jump-rate, must satisfy
X
qi =
qij ,
(9)

if

if

To predict the trends at time t = tf , we calculate the
probability of the user flows from item i to others in the
period[0, tf ], u(j|i, tf ), which are the ij-th elements of matrix U with
Z tf
P (t)dt,
(14)
lim U (tf ) = lim

4.2 User flow probability

qij
qi

(11)

Figure 3 shows the age of a DVD rating, i.e., the time passed
since the release of an item as the horizontal axis, and the
number of users who rated a DVD of that age as the vertical
axis as determined from actual online music and video download services in Japan. Details of the data will be described
in a later section. The fitting lines, exponential functions
of time, are also shown, where the number of users who
evaluated an item decreases exponentially as the item ages.
This figure supports our approach of utilizing exponential
distributions.
Given the jump-rate, we calculate the transition probability from item i to item j as
X
pij =
qi exp(−qi tu,ij ).
(12)

where P̈ is the innovator probability matrix consisting of
p(b|a); e is the column vector of all ones and α is a weight
parameter. By this definition, P̈ is constructed as a primitive stochastic matrix that models the probabilities of personal innovator transition and that converges to a stationary
distribution. Finally, we calculate the innovator relationship over multiple steps and paths over the users. Since
short paths indicate a more direct relationship among users
and more important innovators, we consider assigning lower
weights to long paths:

pij =

1
.
qi

UFP(ib , ia ) = lim u(ib |ia , t).
t→∞

(19)

Unlike the traditional item-item relationship based on pairwise similarity, UFP ranks how similar users will become
finally; it prevents novel items from being overwhelmed by
well-known items with high popularity.

(10)

221

1e+06

Input: user logs
Output: item ranking p(i|ua )

disnumusers
fitting line

Ni : Number of users who purchased item i
I: Total number of unique items observed in user logs
Nu : Number of items purchased by user u
U : Total number of unique users observed in user logs
T0 : Present time (=the time to recommend items)

100000

10000

calculate t̄i and ēu for all items and users
for i = 1 to
PI ido
t̄i ← N1i N
j=1 (tj,i − Ti ) Eq. (2)
end for
for u = 1 toPU do
PNu
1
u
ēu ← N1u N
i=1 (T0 − tu,i ) = Nu
i=1 eu,i Eq. (3)
end for

1000

100

0

500

1000

1500

2000

2500

Figure 3: Distribution of the number of users who
rated a DVD at a specific age of the DVD (time
passed since its release) in Netflix. The horizontal
axis corresponds to DVD age (measured in days)
while the vertical axis shows the number of users
who rated DVDs of that age.

calculate P IP (ub , ua ) on each pair of ua and ub
for a = 1 to U do
for b = 1 to U do P
P IP (ub , ua ) ←
i∈Cab w(i; a) × r(i; b, a) × v(i)
Eq. (1), (4), (5), (6), (7) and (8)
end for
end for

4.3 Recommendation based on both PIP and
UFP

calculate U F P (ib , ia ) on each pair of ua and ub
for a = 1 to I do
for b = 1 to I do
UFP(ib , ia )
←
u(ib |ia , ∞)
Eq. (11), (12), (14)and (19)
end for
end for

We identify the informative logs for target user ua by using PIP and then recommend items to ua according to the
weight based on both PIP and UFP. By using PIP defined
in Eq. (8), p(ib |ua ), the probability that ua will purchase
item ib , is defined as follows:
X
p(ib |ua ) ∝
UFP(ib , ia )δ(ia |uj )PIP(uj , ua ),
(20)
j

rank items for each target user ua
for a = 1 to P
U do
p(i|ua ) ← b UFP(i, j)δ(j|ub )PIP(ub , ua ) Eq. (20)
rank items in descending order of p(i|ua )
end for

where, δ(ia |uj ) represents the evidence that uj has purchased item ia , namely, δ(ia |uj ) = 1 when ia is in the purchase history logs of uj , otherwise δ(ia |uj ) = 0. Clearly,
p(ib |ua ) becomes high when there are many personal innovators with high PIP and high UFP who purchased i. When
p(ib |ua ) is computed for all items, i, we can simply recommend the top-N items, the N largest p(ib |ua ), to ua . In
order to avoid creating a list of “trivial” recommendations,
we must remove items that have already been purchased by
the target user, from the recommendation list before presenting it to the target user.
A recommendation algorithm based on UFP and PIP is
shown in Figure 4. This figure shows that we can calculate PIP over each pair of users by comparing just their
purchase history logs in a manner similar to conventional
methods. The computational cost of this process is linear,
O(I), against the number of items, I, and thus is no more
expensive than the conventional methods. The very low calculation costs of UFP and PIP mean that they can be easily
introduced into any personalized recommendation service.

5.

Figure 4: Recommendation Algorithm

5.1.1 Content download services
The first purchase log data set is a group of music download purchase records from April 1st, 2005 to July 31st, 2006.
It lists 44,527 items purchased by 84,620 users. Each purchase record consists of title of music purchased, artist name,
CD album title, purchase time stamp, and price. The second set is a set of movie video download purchase records
from September 1st, 2005 to February 28th, 2006. It lists
4,064 items purchased by 7,537 users. Each purchase record
consists of the title of the video purchased, director’s name,
purchase time stamp, and price. Most items in these data
sets are “newly released” items that became available for
purchase from the service as soon as they were first released
as a CD or Video (DVD).

EXPERIMENTS

5.1 Data sets

5.1.2 Netflix

We conducted simulations on the following four data sets,
two of which consist of purchase histories obtained from real
on-line music and video download services in Japan, one
from the rating logs in Netflix, and one from search query
logs.

Netflix contains a set of 100,480,507 rating records from
Nov 11th, 1999 to Dec 31st, 2005, that list 17,770 movies
rated by 480,189 users. We first selected only those users
who rated at least 20 movies and movies that were rated by

222

at least 100 users. This pre-processing downsized the data
set to 85,730,203 rating records from Nov 11th, 1999 to Dec
31st, 2005; it consists of 9,264 movies rated by 136,589 users.
Each rating record consists of movie title id, user id, rating,
and timestamp.
Unlike the first two purchase log data sets, Netflix consists of user rating logs of movies with multi-valued ratings.
We have to convert the ratings to binary values, namely
the value is 1 (purchase) if the user rates an item, and 0
(no purchase) otherwise and made two data sets, Netflix(o),
Netflix(p), in the same manner as in [8].

ated performance by two coverage measures, the Gini coefficient, the elapsed time, and the difference time. The values
of the two coverage terms, Gini coefficient, avg elapsed and
avg difference results are shown in Table 2.

5.3.1 Coverage: IC & UC
As the coverage measures, we calculated the percentage of
the number of unique items appearing in the top-N recommendation list from the total number of unique items; we
denote this coverage measure as “Item coverage”(IC). The
item coverage of a recommender system is a measure of the
size of the item domain in the system from which the system can recommend [6]. Systems with lower coverage may
be less valuable to users, since they can offer only limited
choices in assisting users to make decisions. We also calculated the percentage of the number of users to whom each
method could recommend any item from the total number
of all users who purchased any item in the test period; we
denote this coverage measure as “User coverage”(UC).

5.1.3 Query logs
The data set Query was generated from a search engine
server log from April 1st, 2006 to May 31st, 2006. This
data set consists of 35,325,842 query records, each of which
consists of query keyword id, user id, and timestamp.

5.2 Experiment design
Our approach aims to predict which piece of music, video
or movie (query) a user will purchase (submit) given the past
purchase history of the user. We conducted simulations to
evaluate the predictive performance of recommendations via
K fold cross-validation where the original data was partitioned into K subsamples at random. Of the K subsamples,
a single subsample was retained as the validation data for
testing the model, and the remaining K - 1 subsamples were
used as training data. We repeated this process K times,
with each of the K subsamples being used just once as the
validation data. Each subsample was divided into two periods: a learning period and a test period. We call the data in
the test period the test data and that in the learning period
the learning data; K was set to 10.
In the simulations, we treated each user in the test data
as a target user to whom we applied each of the recommendation methods by using user logs collected from the
learning data. We then presented the top N ranked items
to the target user and confirmed that these recommended
items existed in the test data. This is the traditional ranking based recommendation scenario. To evaluate the quality
of the proposed method, we used top N precision, a measure
commonly used for evaluating the predictive performance of
CF [9].

5.3.2 Gini
The Gini coefficient is a measure of the statistical dispersion of the distribution of users over items and is defined as
the ratio of the areas on the Lorenz curve diagram; it takes
values between 0 and 1. A low Gini coefficient indicates that
the distribution is flat, while a high Gini coefficient indicates
that the distribution is extremely biased: 0 corresponds to
perfect equality (every item has been purchased by exactly
the same number of users) and 1 corresponds to perfect inequality (where one item is purchased by all users, while
none of the other items are purchased by any user). In other
words, a result with a high Gini coefficient means that a few
particular items tend to be ranked highly by most users and
thus recommendations are not strongly personalized.

5.3.3 AE
The elapsed time measures how much time has passed
from each item’s release day to its day of purchase by each
user. A short elapsed time indicates that the item is novel.
We measured the average over all user-item pairs in the test
data that each method could predict and denote this as avg
elapsed (AE).

5.3 Comparison of Personalization Performance
We applied a total of nine proposed and conventional recommendation methods to the data sets and compared the
precision of their top-N recommendations (N values were 1,
5 and 10). Popular recommends the most popular items during the last one month of the learning period and thus it is
not personalized to the user. Pearson and Cosine are based
on user similarity as measured by Pearson’s correlation coefficient and cosine similarity, respectively. On the other hand,
Item is based on content similarity as measured by Pearson’s correlation coefficient proposed in [1]. bPLSA is based
on Probabilistic Latent Semantic Analysis [7] with Bernoulli
distribution. MEA is the maximum entropy approach proposed in [11]. EABIF represents the early-adoption-based
information-flow approach proposed in [14]. PIP+UFP is
the proposed method. In this paper, we set α = 1 in Eq. (7),
β = 1 and N = 5 in Eq. (8). The results are shown in Table 1.
In addition to the top-N precision above, we also evalu-

5.3.4 AD
The difference time is the difference between the observed
time when each user u purchased item i in the test data
without recommendations tui and the time when divided
into two periods (learning/test) t0 (Music:July 1st, 2006,
Video:February 15th, 2006, Netflix(h),Netflix(p):December
1th, 2005, Query:May 31th, 2006) and defined over each user
and each item, as discussed in Section 2. Therefore, an item
with a large difference, |tui − t0 |, indicates a time-consuming
item for u; that is, it takes a long time for u to find this
item on his/her own in the absence of any recommendation.
We measured the average over all user-item pairs that each
method could predict and denote this as the avg difference
(AD).

5.3.5 Comparison of top-N precision
From Table 1, we can see that PIP+UFP offers the highest accuracy like PID. These results can be explained by
the characteristics of the data sets; they consist of “luxury items”. When an individual user desires and purchases

223

Table 1: Top N precision of personalized recommendations yielded by applying different methods to Music,
Video, Netflix, and Query data sets. Results that indicate a significant inter-method difference, t-test p < 0.01,
p < 0.05, are marked with ’**’, ’*’, respectively.
Data set top N Popular Cosine Pearson Item bPLSA MEA EABIF PID
PIP PIP+UFP
Video
1
8.31
8.31
7.35
7.20
12.44
13.21
19.88
25.11 23.16
22.85
27.73
27.75
24.51
24.02
28.36
28.93
36.27
42.22 39.52
38.22
5
34.23
34.26
30.26
29.65
32.62
33.14
41.02
46.02 44.23
46.12
10
Music
1
6.90
6.91
6.10
5.98
10.78
10.86
16.32
22.41 20.37
21.57
23.01
23.03
20.34
19.93
21.23
22.52
29.83
35.74 32.26
34.38
5
10
32.25
31.47
29.84
27.85
31.02
31.26
36.97
39.22 37.56
39.87∗
Net(h)
1
5.12
5.32
4.76
5.23
5.63
5.77
7.59
8.74
8.03
8.52
5
6.33
7.21
6.35
8.12
8.59
8.61
9.78
12.03 10.59
11.58
10
7.56
8.46
7.22
10.21
10.98
10.97
13.44
16.51 15.33
16.82∗
Net(P)
1
5.83
6.01
5.26
6.68
6.71
7.22
8.31
9.77
9.03
9.52
7.27
7.54
6.98
10.37
10.94
10.96
12.77
15.12 14.21
14.78
5
10
8.32
9.57
8.51
12.86
13.12
13.05
15.28
17.93 16.67
18.04∗∗
Query
1
4.66
4.82
5.16
5.68
6.31
6.35
7.25
7.65
7.03
7.13
6.89
6.92
6.73
7.52
10.88
10.90
13.66
14.27 13.87
14.31
5
10
7.14
8.32
8.38
9.52
11.65
11.34
14.23
15.88 14.98
15.23

and PIP is that the former considers only pairwise comparison, while PIP uses an ergodic Markov chain to model how
innovators are followed through multiple steps. Accordingly,
PIP enables us to discover more items that would take more
time to discover because of these multiple steps than is possible with the other methods; it can recommend surprisingly
interesting items that might not otherwise be discovered.
As shown in Table 2, the results that the proposed method
yields the shortest, on average, elapsed time indicate that it
is best at identifying novel items. Because these items are
so new th they are not yet generally known to many other
like-minded users, users would take some time for them to
find the items by themselves. Accordingly they are novel
items and their popularity is low. Since UFP suppresses
well-known items in the recommendations, it cannot offer
high top-N precision in the simulation comparison. However, PIP improves the IC and ED; it can identify more
novel items since its Gini coefficient is close to 0.

these items, they are generally motivated by their preferences rather than their needs. PIP+UFP differentiates likeminded users by using time decay factors to assign higher
weights to more recently purchased items, and introduces
the trend of items into item ranking. Consequently, the proposed method ranks items that match the latest preferences,
which improves the precision.

5.3.6 Comparison of Coverage, Gini, AE and AD
From Table 2, we can see that PIP + UFP exhibits the
highest user/item coverage, the lowest Gini coefficient, close
to 0, and the longest average difference. Although the top-N
results don’t show the significant improvement of the proposed algorithm, this result indicates that PIP + UFP can
rank and recommend various different items with much less
bias than the other methods. In fact, those conventional algorithms, which do not consider the dynamics of user preference or the user-user relationship, achieve lower item coverage and higher Gini coefficients, close to 1. They use logs
of like-minded users who are later adopters as well as earlier
adopters and thus recommend generally popular and trivial
items. With regard to user coverage, the algorithms that employ the dynamics of the user-user relationship offer slightly
lower values than the others. Although users who are innovators are not covered by EABIF, PID anyway, PIP +
UFP algorithms can recommend some novel items to these
innovators, most of these items have not yet been purchased
by the others, which raises precision.

6.

7. CONCLUSION
The contribution of this paper to the recommendation research field is to show the impact of trends on the transition
probability of items, and that the estimated time offset to
purchase in the absence of recommendations is a useful metric of serendipitousness. Our approach offers improvements
on the user/item coverage, the Gini coefficient, the elapsed
time, the difference in estimated time, and the predictive
performance simultaneously.
Following the hypothesis that items that innovators have
recently purchased offer serendipity and will be adopted by
their like-minded users more willingly than items purchased
by others, we use PIP for identifying innovators and define
UFP that estimates how likely the user is to finally purchase
each item.
In future work, we would like to extend the proposed
model to incorporate user specialty and level of expertise
in a particular domain, and apply this extended model to
personalized information retrieval more generally.

DISCUSSION

Here, we discuss the potential of the proposed algorithm
from the viewpoints of serendipity and novelty in recommendation flow.
Although we are not able to distinguish the effect of innovators from that of trends from our experiments completely,
the fact that the PIP improves AD, supports our assumption
that innovators know more serendipitous items than the others. As shown in Table 2, EABIF and PID, which include
the time factors, offers longer AD than others (i.e. those
without time factors). The main difference between PID

224

Table 2: Comparison of various methods as applied to Music, Video, Netflix, and Query data sets: Results
that indicate significant inter-method difference, t-test p < 0.01, p < 0.05, are marked with ’**’, ’*’, respectively.
Data set
Music

Video

Netflix(h)

Netflix(p)

Query

8.

Evaluation
UC
IC
Gini
AE
AD
UC
IC
Gini
AE
AD
UC
IC
Gini
AE
AD
UC
IC
Gini
AE
AD
UC
IC
Gini
AE
AD

Popular
100
6.50
0.51
15.73
8.52
100
8.43
0.46
22.25
5.45
100
5.36
0.72
27.86
15.67
100
5.88
0.67
26.54
15.33
100
3.22
0.92
13.92
4.21

Cosine
98.9
6.90
0.47
39.74
3.38
99.2
8.87
0.42
42.27
5.52
92.3
6.12
0.76
40.53
13.58
90.9
5.93
0.62
38.24
12.25
82.3
3.35
0.91
14.22
2.38

Pearson
98.9
6.91
0.51
38.53
3.21
99.2
8.72
0.47
40.74
5.87
92.3
6.17
0.74
41.74
13.47
90.9
5.85
0.63
39.52
12.36
82.3
3.37
0.91
14.43
2.41

Item
98.9
6.10
0.49
38.57
3.12
99.2
12.31
0.43
41.43
5.79
92.3
6.88
0.71
40.75
13.31
90.9
7.21
0.58
39.38
12.96
82.3
3.41
0.91
14.57
2.27

REFERENCES

bPLSA
98.9
5.98
0.51
38.46
3.55
99.2
11.56
0.46
40.58
5.23
92.3
9.54
0.69
41.24
13.85
90.9
6.35
0.61
39.89
12.51
82.3
3.38
0.90
14.23
2.33

MEA
98.9
11.21
0.47
36.62
3.46
99.2
12.32
0.29
41.36
5.88
92.3
10.19
0.62
40.32
13.21
90.9
9.74
0.56
39.01
12.78
82.3
3.35
0.91
14.93
2.16

EABIF
97.7
19.55
0.45
26.21
8.69
98.6
18.55
0.22
33.23
6.18
91.5
10.32
0.58
41.71
16.68
90.3
11.1
0.52
38.86
16.24
77.3
4.21
0.83
14.88
4.98

PID
97.7
20.81
0.37
22.23
8.97
98.6
33.12
0.22
28.68
7.32
91.5
12.75
0.48
31.23
16.87
90.3
15.88
0.48
29.12
16.43
77.3
5.88
0.81
13.22
6.22

PIP
100
21.53
0.35
17.52
9.06
100
30.22
0.20
24.76
7.95
100
13.37
0.44
28.42
18.51
100
15.92
0.42
27.23
18.19
100
5.92
0.77
12.82
6.56

PIP+UFP
100
22.34∗∗
0.31∗∗
12.39∗∗
9.26∗∗
100
34.32∗
0.19
17.62∗∗
8.38∗
100
14.53∗
0.41∗
19.72∗
19.53∗
100
16.21∗
0.38∗
18.96∗∗
18.72∗
100
5.95
0.77
10.69∗
6.69∗

[9] J. Konstan, B. Miller, J. H. D. Maltz, L. Gordon, and
J. Riedl. Grouplens: Applying collaborative filtering
to usenet news. Communications of the ACM,
40(3):77–87, 1997.
[10] G. Linden, B. Smith, and J. York. Amazon.com
recommendations: Item-to-item collaborative filtering.
IEEE Internet Computing, 7(1):76–80, 2003.
[11] D. Pavlov and D. Pennock. A maximum entropy
approach to collaborative filtering in dynamic, sparse,
high-dimensional domains. In NIPS, pages 1441–1448,
2002.
[12] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and
J. Riedl. An open architecture for collaborative
filtering of netnews. In CSCW, pages 175–186. ACM
Press, 1994.
[13] E. M. Rogers. Diffusion of Innovations. The Free
Press, New York, 1995.
[14] X. Song, C. Lin, B. Tseng, and M. Sun. Personalized
recommendation driven by information flow. In ACM
SIGIR, pages 509–516, 2006.
[15] Y. Yang and J. Z. Li. Interest-based recommendation
in digital library. Journal of Computer Science,
1(1):40–46, 2005.
[16] Y. Zhang, J. Callan, and T. Minka. Novelty and
redundancy detection in adaptive filtering. In ACM
SIGIR, pages 81–88, 2002.
[17] C.-N. Ziegler, S. M. McNee, J. A. Konstan, and
G. Lausen. Improving recommendation lists through
topic diversification. In WWW, pages 22–32, 2005.

[1] J. K. B. Sarwa, G. Karypis and J. Riedl. Item-based
collaborative filtering recommendation algorithms. In
WWW, pages 285–295, 2001.
[2] Ò. Celma and P. Lamere. A new approach to
evaluating novel recommendations. In ACM Recsys,
pages 179–186, 2008.
[3] D. Cosley, S. Lawrence, and D. M. Pennock. Referee:
An open framework for practical testing of
recommender systems using researchindex. In VLDB,
pages 35–46, 2002.
[4] D. Fleder and K. Hosanagar. Blockbuster culture’s
next rise or fall: The impact of recommender systems
on sales diversity. In SSRN eLibrary, pages 697–712,
2007.
[5] F. Fouss, J.-M. Renders, A. Pirotte, and M. Saerens.
Random-walk computation of similarities between
nodes of a graph with application to collaborative
recommendation. IEEE Transaction on Knowledge
and Data Engineering, 19(3):355?369, 2007.
[6] J. L. Herlocker, J. Konstan, L. Terveen, and J. Riedl.
Evaluating collaborative filtering recommender
systems. ACM Transactions on Information Systems,
22(1):5–53, 2004.
[7] T. Hofmann. Collaborative filtering via gaussian
probabilistic latent semantic analysis. In ACM SIGIR,
pages 259–266, 2003.
[8] N. Kawamae, H. Sakano, and T. Yamada. Personalized
recommendation based on the personal innovator
degree. In ACM Recsys, pages 329–332, 2009.

225


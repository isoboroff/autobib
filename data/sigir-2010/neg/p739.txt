Robust Music Identification Based on Low-Order Zernike
Moment in the Compressed Domain
Wei Li, Yaduo Liu, Xiangyang Xue
School of Computer Science and Technology, Fudan University
825 Zhangheng Road, Shanghai 201203, P.R. China

weili-fudan@fudan.edu.cn, duoyal@gmail.com , xyxue@fudan.edu.cn
is very robust and a 5s unknown query music fragment which
might have been contaminated by various severe audio signal
distortions is still sufficient to retrieve its original near-duplicate
copy from our test dataset which is composed of 1822 popular
songs, with an average top-5 precision rate of more than 90%.

ABSTRACT
In this paper, we devise a novel robust music identification
algorithm utilizing compressed-domain audio Zernike moment
adapted from image processing techniques as the pivotal feature.
Audio fingerprint derived from this feature exhibits strong
robustness against various audio signal distortions including the
challenging pitch shifting and time-scale modification.
Experiments show that in our test dataset composed of 1822
popular songs, a 5s music query example which might have
been severely corrupted is still sufficient to identify its original
near-duplicate copy, with more than 90% top five precision rate.

2. ALGORITHM DESCRIPTION
2.1 MDCT-Granule Auditory Image
To calculate Zernike moment in the compressed domain, we
have to first construct 2-D auditory images from 1-D MP3
encoded bit stream. Two preprocessing steps i.e. frequency
alignment and granule grouping are needed. Frequency
alignment incorporates the 576 original MDCT coefficients that
are differently distributed in long- and short-window types of
granules into 192 unified new frequency lines to obtain
approximately the same frequency resolution, and forms the Y
axis of an auditory image. Granule grouping puts N continuous
granules into a slot to reinforce the statistical steadiness and
constitute the X axis of an auditory image.
For the kth auditory image as shown in Fig.1, its pixels fk(x, y)

Categories and Subject Descriptors
H.3.3 [Information Systems]: Information Search and Retrieval

General Terms
Algorithms, Experimentation

Keywords
Music identification; Zernike moment; Robustness

forms an M×N matrix, where the y axis represent N new MDCT
coefficients and the x axis mean M time-domain granules, i.e. a
slot. It is known that sounds located in the low-middle frequency
range cover the main content most vital to the human auditory
system and are more robust than high frequency components.
Therefore, we pick out the 2nd to the 51st new MDCT values to
act as the y axis, which roughly corresponds to 300 – 5840 Hz of
real frequency. M is set to 50 granules to form the x axis.

1. INTRODUCTION
Music identification is a technique that uses audio fingerprint
to recognize the near-duplicate original copy from a music
database given an unknown input query example that might
have been severely corrupted by various audio signal distortions.
To date, a number of algorithms have been published with rather
high retrieval performance and most of them operate on the
PCM wave format. However, with the mature of CD quality
audio compression techniques and the fast growing of the
Internet, it will be interesting and meaningful in practice if audio
features are directly extracted from the compressed domain and
used for music identification in the database.
So far, only a few algorithms that perform music information
retrieval (MIR) directly on the compressed domain have been
proposed [1-5], research in this field is still in its infancy. The
above methods achieved certain retrieval achievements, while
they didn't consider or obtain compellent results to the most
central problem of audio identification, i.e. robustness.
Moreover, previously used features principally follow the line of
MDCT coefficient and its derived spectral energy.
In this paper, we develop a new compressed-domain feature
to achieve high robustness in audio fingerprinting based on
Zernike moment which has been widely used in image related
research fields. To the authors’ knowledge, this is the first
attempt that Zernike moment is used for robust audio
identification in the compressed domain. Experiments show that
the fingerprint derived from low-order audio Zernike moments

Figure. 1 An illustration of constructed auditory image

2.2 MDCT Zernike Moments and Fingerprints

With the above preparations, the Zernike moment of the kth
auditory image is calculated as below

A

Copyright is held by the author/owner(s).
SIGIR’10, July 19–23, 2010, Geneva, Switzerland
ACM 978-1-60558-896-4/10/07.

n

1

π

f x, y V

,

x, y

1

where n is the moment order, and m must be subject to the
condition that n |m| is nonnegative and even.

739

retrieval, this is an intrinsic deficiency compared with our
method.

Generally speaking, low-order moments characterize the basic
component of a signal, while higher order ones depict the high
frequency details. Therefore we take the sum of Zernike
moments of order
2 as the final feature and further derive
the audio fingerprint sequence, see formula (2) and (3).

Retrieval precision rate under various distortions
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%

2
| |
| | %
k
k 1
0 if Z mn
 Z mn
k  0,1,2,..., N slot  1 (3)
S (k )  
k
k 1
1 if Z mn  Z mn

2.3 Fingerprint Matching
The emphasis of this paper is to invest the effectiveness of
this Zernike moment based compressed-domain audio feature.
Therefore we perform straightforward exhaustive matching
between the query example and those stored recordings using bit
error rate (BER) as the similarity measure.

3. EXPERIMENTS

top‐1

We first set up a music database composed of 1822 distinct
MP3 format popular songs (30s, 64kbps) and a corresponding
fingerprint database. Query examples include 5s-long excerpts
cut from selected database songs and their distorted copies.
Next we need to determine a reasonable BER threshold T
under a specific false positive rate (FPR). Fingerprint bits are
assumed to be random i.i.d. (independent and identically
distributed) and error bits are modeled by normal distribution. In
accordance to the method of reference [5], FPR equals 4.3907e005 when 0.32 is set as the threshold, this is acceptable for
practical applications, accordingly we use 0.32 as the boundary
to distinguish whether two fingerprints are matched or not
Given 100 randomly chosen query examples, the top-1, 5, 10
retrieval precision rates with 0.32 as the BER threshold are
averaged and shown in Figure 2.
It can be seen that this proposed MDCT Zernike moment
based fingerprint shows very good identification precision, even
under severe audio signal processing like heavy lossy
recompression, volume modulation, echo addition, noise
interference and various frequency wrapping such as band-pass
filtering, equalization, pitching shifting (±10%) etc. The only
deficiency is that under pitch reserved time-scale modifications
(TSM), only ±3% TSM can be resisted. This weakness is
essentially caused by the fixed data structure of the MP3
compressed bit stream. In this case, implicit synchronization
methods based on salient local regions can’t be applied. The
only way to resist serious time-domain desynchronization is to
increase the overlap between contagious slots and design more
steady fingerprints, whereas the overlap has an upper limit of
100% (96% has been used in this paper) and discovering more
powerful features is neither an easy work.
Compared with other related compressed-domain algorithms
in the introduction whose best top-5 precision rate is 90% [4]
under a relatively clean environment (no robustness results are
reported in [1-4], and pitching shifting and TSM are not
considered in [5] ), our algorithm obviously outperforms those
methods with the top-5 precision rates bigger than 90% even
under severe audio signal processing such as MP3
compression@32kbps, equalization, ±10% pitch shifting and
±2% time-scale modification etc. What is more important,
previous arts are not actually working in the way of fragment

top‐5

top‐10

Figure 2. Retrieval results under various distortions

4. CONCLUSION
We propose a novel and practical music identification
algorithm which works directly on the MP3 encoded bit stream
by constructing the MDCT-granule auditory images and then
calculating the audio Zernike moments. This algorithm achieves
promising retrieval precision even if the 5s query examples are
severely degraded by various audio distortions.

5. ACKNOWLEDGMENTS
This work is jointly supported by NSFC (60873255), 973
Program (2010CB327906), Shanghai Leading Academic
Discipline Project (B114).

6. REFERENCES
[1] C. C. Liu and P. J. Tsai, "Content-based retrieval of MP3
music objects," proceeding of the ACM international
conference on information and knowledge management
2001, pp. 506-511.
[2] W. N. Lie and C. K. Su, "Content-based retrieval of MP3
songs based on query by singing," proceeding of the IEEE
international conference on acoustics, speech, and signal
processing (ICASSP 2004), pp. 929-932.
[3] T. H. Tsai and J. H. Hung, "Content-based retrieval of MP3
songs for one singer using quantization tree indexing and
melody-line tracking method," proceeding of the IEEE
international conference on acoustics, speech, and signal
processing (ICASSP 2006), pp. 505-508.
[4] T. H. Tsai and Y. T. Wang, "Content-based retrieval of
audio example on MP3 compression domain," proceeding
of the IEEE workshop on multimedia signal processing
(MMSP 2004), pp. 123- 126.
[5] Y. H. Jiao, B. Yang, M. Y. Li and X. M. Niu, "MDCTbased perceptual hashing for compressed audio content
identification," proceeding of the IEEE workshop on
multimedia signal processing (MMSP 2007), pp. 381-384.

740


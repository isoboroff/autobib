Can Search Systems Detect Users’ Task Difficulty?
Some Behavioral Signals
Jingjing Liu, Chang Liu, Jacek Gwizdka, Nicholas J. Belkin
School of Communication and Information, Rutgers University
4 Huntington Street, New Brunswick, NJ 08901, USA

{jingjing, changl}@eden.rutgers.edu, {jacekg, belkin}@rutgers.edu
ABSTRACT

existing classification methods, one classifies tasks as closed
(specified factual answer(s)) or open-ended (unspecified
answer(s)), and with single or multiple answer(s). It was found
that for open-ended tasks, users spent more overall time and
performed more moves than for closed tasks [4]. Like task
difficulty, there is also a need to look at the behavioral factors
which are real-time detectable to differentiate task types.

Categories and Subject Descriptors

One such behavioral signal that is good for real-time detection is
document dwell time, which measures how long a user reads the
retrieved document. Dwell time has been studied as a potential
factor for predicting document usefulness [6] but not in
conjunction with task difficulty yet. In addition, previous studies
tended to look at mean dwell time on all behaviors including time
reading both search result list pages and content pages, as well as
time (re)formulating queries. We think that mean dwell time on
the content pages only would be more informative since the
content pages are what users really focus on in finding
documents. In addition, the first dwell time of a content page, i.e.,
the dwell time each page was first shown to users, could be easily
tracked by the system in earlier phases of an information-seeking
session; thus it would be helpful to see if it can help predict task
difficulty.

In this paper, we report findings on how user behaviors vary in
tasks with different difficulty levels as well as of different types.
Two behavioral signals: document dwell time and number of
content pages viewed per query, were found to be able to help the
system detect when users are working with difficult tasks.

H.3.3 [Information Storage and Retrieval]: Information Search
and Retrieval – relevance feedback, search process.

General Terms

Performance, Experimentation, Human Factors.

Keywords

Dwell time, First dwell time, Queries, Task type, Task difficulty.

1. INTRODUCTION

Despite the fact that search engines have done a good job with
some easy tasks, for example, “when and where will SIGIR 2010
be held?”, people still have difficulties in finding information for
difficult tasks, for example, “which food additives pose a risk to
your physical health?”[2]. Better search systems are needed that
can help people more easily locate desired information in difficult
tasks, meanwhile, it is also important for the system to be able to
detect when the users are working with difficult tasks.

Another behavioral signal which could be good for real time
tracking is the number of viewed documents per query. These
signals are named “section-level” factors in this study, different
from task-level ones that cannot be captured until the end of a
task. We wanted to see if section-level behaviors can suggest task
difficulty levels and task types, and if so, how.

Task difficulty has been attracting much research attention and
has been found to be a significant factor influencing users’ search
behaviors and search performance. In difficult tasks, users are
more likely to visit more web pages ([2], [3]), issue more queries
([1], [3]), and spend longer time on search result pages ([1]), and
so on. However, the behavioral and performance aspects
addressed in most previous work have focused mainly on the
overall task level, so that the variable parameters cannot be
obtained until the end of the whole task. Therefore, it is not easy
or practical for systems to detect task difficulty in real time based
on the previously examined behavioral aspects. More work is
needed to explore behavioral signals for systems to learn
dynamically if users are dealing with a difficult task so that they
can adapt search towards the user’s specific situation.

2. METHOD

Data came from a lab experiment that was designed to explore
users’ behavioral differences in different types of tasks. The study
had 12 search tasks: 8 of them were created by Toms et al. [5], 4
of which were open-ended tasks and the other 4 were multipleitem closed tasks; the remaining 4 were created by us, and were
single-item closed tasks. Participants were asked to conduct 6
tasks of different types on the English Wikipedia. For each task,
each participant was allowed to choose between two tasks of the
same type but on different topics. Each experiment session was
1.5 to 2 hours long, and user interaction with the computer was
logged. Participants were 48 students (17 females and 31 males),
with an average age of 27 years. After completing each task, users
were asked to rate the difficulty level of the task based on a 5point scale. For the purpose of the current analysis, we chose 8
tasks out of 12: 4 were open-ended tasks and the other 4 were
single-item closed tasks.

Task type is another factor that has attracted much attention in
studying searchers’ behavioral differences. Among the many
Copyright is held by the author/owner(s).
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
ACM 978-1-60558-896-4/10/07.

845

Table 1. User behavioral differences in different tasks
Factor
Level

Factors

Sectionlevel
factors
Tasklevel
factors

# of content pages per query
First dwell time (sec.)
Average dwell time (sec.)
Task completion time (sec.)
# of queries
# of content pages viewed

Tasks of different difficulty levels
Mean (Standard Deviation)
t/Z (p value)
Easy
Difficult
3.29 (4.34)
3.75 (3.27)
1.63(.103)
23.20 (25.91)
29.41 (31.17)
3.29(.001*)
20.52 (26.01)
24.33 (28.42)
3.29(.001*)
342 (271)
684 (382)
7.01(.000*)
2.29 (1.91)
4.78 (2.83)
6.66(.000*)
6.82 (8.07)
13.43 (9.67)
5.89(.000*)

* means significant differences were detected.

Tasks of different types
Mean (Standard Deviation)
Closed
Open-ended
2.67 (2.84)
4.22 (4.82)
29.81 (29.47)
24.64 (28.28)
25.43 (29.75)
21.15 (26.12)
305 (227)
580 (382)
2.27 (2.05)
3.94 (2.70)
5.18 (5.76)
12.80 (10.27)

t/Z (p value)
3.98(.000*)
2.99(.003*)
2.40(.016*)
6.94(.000*)
5.40(.000*)
6.80(.000*)

3.3 Predicting Task Difficulty and Task Type

3. RESULTS & DISCUSSION
3.1 Behavior Differences with Task Difficulty

Results show that longer first dwell time (about 29 seconds) or
longer average dwell time (about 24-25 seconds) was associated
with both difficult tasks and closed tasks. It is hard to say if the
longer first dwell time on a document and the longer average
dwell time were due to users dealing with a difficult task or a
closed task. Hence, it would be difficult to make a prediction that
users are having difficulty based solely on dwell time. However,
the number of content pages viewed per query can help
differentiate task type, and can be used to help determine if the
longer dwell time suggests that users are facing more difficult
tasks.

We first looked at users’ behavioral differences in tasks of
different difficulty levels (Table 1). The original rating scale was
5-point, which was appropriate for users to evaluate. In our
analysis, the difficulty scores were collapsed into 2 groups based
on the distribution (scores 1-3 into a “difficult” group, and scores
4-5 into an “easy” group), which was more appropriate for the
system to differentiate difficulty levels.
Examining the task-level factors, i.e., task completion time,
number of queries, and number of content pages viewed, we
found that more difficult tasks were associated with longer task
completion time, more queries, and more content pages. These
patterns are consistent with findings of previous studies.

4. CONCLUSIONS

First dwell time and average dwell time can be useful for systems
to instantly assess user behaviors. We found that dwell time
measures alone cannot reliably predict if users are facing difficult
tasks. However, taking into account the number of content pages
per query can help make a more correct prediction of task
difficulty. Future studies will make use of these findings in
system design.

Considering the three section-level factors, i.e., first dwell time,
average dwell time, and number of content pages viewed per
query, our results show that more difficult tasks were associated
with longer first dwell time and longer average dwell time than
easier tasks. Dwell times thus seem to be indicators of difficulty
levels of the tasks. However, the numbers of content pages
viewed by users per query did not differ between easy and
difficult tasks. This suggests that although users issued more
queries in difficult tasks, they did not necessarily view more
content pages per query. Users viewed roughly the same numbers
of documents per query in tasks of different difficulty levels. In
difficult tasks, they just reformulated queries more often.

5. ACKNOWLEDGMENTS

This research is sponsored by IMLS grant LG#06-07-0105.

6. REFERENCES

[1] Aula, A., Khan, R. & Guan, Z. (2010). How does search
behavior change as search becomes more difficult? Proc.
CHI, 35-44.

3.2 Behavior Differences with Task Type

[2] Gwizdka, J., Spence, I. (2006). What can searching behavior
tell us about the difficulty of information tasks? A study of
Web navigation. Proc. of Annual Meeting of the American
Society for Information Science and Technology ’06.

We also looked at users’ behavioral differences between two
types of tasks (Table 1). With respect to the task-level factors,
open-ended tasks were associated with longer completion time,
more queries, and more content pages viewed. These patterns are
consistent with findings in previous studies.

[3] Kim, J. (2006). Task difficulty as a predictor and indicator of
web searching interaction. Proc. CHI, 959-964.

For the section-level factors, it was found that closed tasks were
associated with fewer content pages viewed per query, longer first
dwell time, and longer average dwell time. It was reasonable to
see that users spent longer dwell time on documents in the closed
tasks because these tasks required users to look for a specific
piece of information in a document and to judge its relevance
according to its correctness with respect to the task question. By
contrast, in the open-ended tasks, users could make a judgment of
the overall relevance of the document based on any piece of
information on the page. That closed tasks elicited fewer content
pages per query was also reasonable considering that the users
only needed to look for one fact or piece of information, unlike in
the open-ended tasks, where users had to collect as much
information as possible.

[4] Marchionini, G. (1989). Information-seeking strategies of
novices using a full-text electronic encyclopedia. Journal of
the American Society for Information Science, 40(1), 54-66.
[5] Toms, E., MacKenzie, T., Jordan, C., O’Brien, H., Freund,
L., Toze, S. et al. (2007). How task affects information
search. Workshop Pre-proceedings in Initiative for the
Evaluation of XML Retrieval (INEX), 337-341.
[6] White, R., & Kelly, D. (2006). A study of the effects of
personalization and task information on implicit feedback
performance. Proc. CIKM , 297-306.

846


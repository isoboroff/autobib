Hashtag Retrieval in a Microblogging Environment
Miles Efron
Graduate School of Library and Information Science
University of Illinois at Urbana-Champaign
501 E. Daniel St., Champaign, IL, 61820, USA

mefron@illinois.edu

ABSTRACT

For a user’s topical query q, we wish to find a list of k tags
that are relevant to the information need represented by q.
The task involves accepting a keyword query and returning
a ranked list of hashtags. We approach hashtag retrieval as
a type of entity search [1, 2].
Finding useful hashtags offers benefits that are particular
to the microblog setting:

Microblog services let users broadcast brief textual messages
to people who “follow” their activity. Often these posts contain terms called hashtags, markers of a post’s meaning, audience, etc. This poster treats the following problem: given
a user’s stated topical interest, retrieve useful hashtags from
microblog posts. Our premise is that a user interested in
topic x might like to find hashtags that are often applied
to posts about x. This poster proposes a language modeling approach to hashtag retrieval. The main contribution
is a novel method of relevance feedback based on hashtags.
The approach is tested on a corpus of data harvested from
twitter.com.

• Tags to follow : A user may wish to find hashtags that
he or she can track on an ongoing basis.
• Result display: If users are searching for tweets, people, or posted URLs, returned units of retrieval could
be grouped into clusters by their associated hashtags.
• Query expansion: Hashtags provide leverage for query
expansion during relevance feedback.

Categories and Subject Descriptors

The task we address aims to support these actions. This
poster explicitly treats only the last item: query expansion.
More specifically, we are concerned with query expansion in
service to hashtag retrieval.

H.3.3 [Information Search and Retrieval]: Relevance
Feedback

General Terms
2.

Experimentation, Performance, Theory

Keywords
microblog, twitter, hashtag, relevance feedback

1.

MODEL

Let C be a corpus containing n tweets. Among these n
tweets we have m distinct hashtag types. We induce m language models, one per hashtag. To fit a tag ti ’s language
model we analyze the set of tweets containing ti , fitting
a multinomial over the vocabulary words, with probability
vector Θi . The maximum likelihood estimator for θwi , the
probability of a word w given Θi , is the number of times
w occurs in the set of tweets containing ti divided by this
set’s total word count. We smooth estimated models Θ̂ by
Bayesian updating with Dirichlet priors (µ = 2000). Given a
query q generated by the query model Θq , we rank hashtags
in decreasing order of the negative KL divergence between
their models and Θq [3]:

INTRODUCTION

Microblogging services allow users to post brief textual
messages that are broadcasted to the user’s “followers.” Today, the most visible microblogging service is twitter.com
where users post so-called tweets of no more than 140 characters. While many tweets are inconsequential, others contain information of broad interest, as well as links to external
resources (e.g. photos or websites). This poster proposes an
approach to one aspect of microblog IR: retrieving hashtags
on a topic of interest to a searcher.
Many tweets are marked with so-called hashtags. A hashtag is a character string preceded by a # sign. Hashtags
often signal aspects of a tweet’s meaning such as its topic or
its intended audience. Thus #sigir2010 ostensibly marks
tweets related to the 2010 SIGIR conference. A person who
is interested in a topic, say vegetarian recipes, might want
to find hashtags that are often applied to posts about vegetarian recipes, veganism, healthy eating, etc.

r(ti , q) = −D(Θq ||Θi )
where unless otherwise noted the calculation uses
maximum likelihood estimator for Θq .

2.1

(1)
L
Θ̂M
,
q

the

Hashtag Query Expansion

We propose restricting the added query terms to those
candidates that are hashtags, stripping candidates of their
leading #. The topical nature of hashtags motivates this
operation.
Let rk be the set of the k top-ranked hashtags (by Eq. 1).
Here we set k = 25. We define Θr , a multinomial parameter
vector that has non-zero probability over the tags in rk and
zero probability for all other terms. We derive a feedback

Copyright is held by the author/owner(s).
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
ACM 978-1-60558-896-4/10/07.

787

L
query model: Θ̂f b = (1 − λ)Θ̂M
+ λΘ̂r where λ is a tunq
able parameter on (0, 1) that we fix at 0.2 (a value chosen
empirically). As for Θ̂r , we propose two variants:

We tested four experimental conditions:
1. Baseline, no feedback: simple KL divergence
2. Baseline, with feedback: KLD retrieval with divergence minimization feedback (divergence minimization
gave stronger results than mixture model feedback) [3]
3. Hashtag-based query expansion (HFB1 and HFB2)
4. Hashtag query expansion with association measure (HFB2a).

• HFB1 : Non-zero elements of Θ̂r are uniformly distributed.
IDF (ti )
• HFB2 : each non-zero θ̂ri is proportional to max
IDF

For all feedback, five terms were added to the initial query,
with a weight of 0.2. The baseline feedback model used the
top 10 documents. No stemming or stoplists were applied.
Runs returned the top 25 tags for each query.
We report three statistics (Table 2): Mean average precision (MAP), normalized discounted cumulative gain (NDCG)
at 15, and precision at 10 (P10). All runs using hashtagbased feedback gave results that were statistically significantly
better than the baseline run using standard term-based feedback.

where IDF (ti ) is the inverse document frequency for tag i
and max IDF is the IDF for a tag with document frequency
1. Feedback information enters retrieval by using Θ̂f b for
the query model in Eq. 1.

2.2

Hashtag Association

Given the previous definition of rk , let X be the k × k
matrix where for two tags ti and tj in rk , xij gives the
number of times ti occurs (across the corpus) in a tweet
that also contains tj . Also let xii = 1. We normalize X
so that its columns (rows) are of unit length. Let a tag’s
association with the retrieved tags rk be:
a(ti , rk ) =

k
X

xij .

Table 2: Retrieval effectiveness. All HFB runs show
statistically significant improvement over the baseline feedback run on all three measures (p < 0.05 on
a randomization test). † indicates p < 0.01.

(2)

j

Method
Baseline, no FB
Baseline, FB
HFB1
HFB2
HFB2a

Eq. 2 is large if a tag co-occurs with many other tags in
rk . Large values for Eq. 2 suggest that a tag has a strong
presence in the “neighborhood” of the query. We combine
Eq. 1 with Eq. 2, leading to the ranking score, ra (ti , q) =
r(ti , q) + log a(ti , rk ). Runs using ra are designated HFB1a
or HFB2a (depending on the HFB used).

3.

EVALUATION

4.

P10
0.7034
0.7138
0.7483
0.7414
0.7483

CONCLUSIONS

In future work we will identify additional features of hashtags (e.g. from author-based statistics) for use in IR. We will
also undertake a more thorough empirical evaluation. The
main work, however, lies in defining the relevant problems,
applications, and user needs in IR from microblogs.

5.

REFERENCES

[1] K. Balog, L. Azzopardi, and M. de Rijke. A language
modeling framework for expert finding. Inf. Process.
Manage., 45(1):1–19, 2009.
[2] C. Macdonald and I. Ounis. Using relevance feedback
in expert search. Proc. of 29th European Conf. on
Information Retrieval, Springer LNCS, 4425:431–443,
2007.
[3] C. Zhai and J. Lafferty. Model-based feedback in the
language modeling approach to information retrieval.
In CIKM01: Proc. of the 10th Intl Conference on
Information and Knowledge Management, pages
403–410, 2001.

Table 1: Test collection summary statistics
Number of tweets
3,414,330
Number of hashtag types
50,097
Number of hashtag tokens
571,861
Number of users
874,892
Number of queries
39
Median number relevant tags 28.5

2

NDCG
0.6110
0.6209
0.6431†
0.6388†
0.6488†

Table 2 suggests that hashtags provide useful information for relevance feedback. While the baseline (term-based)
feedback run was only slightly more effective than the baseline run without feedback, all tag-based feedback runs performed better than the term-based baseline feedback model.
HFB2 (using IDF weighting for feedback tags) gives marginal
improvement over uniformly weighted expansion, while our
association measure gives a bit more of an edge. However,
the differences among the three test conditions are slight.

We gathered data over a 24-hour period using Twitter’s
streaming API1 (cf. Table 1). 29 topical queries were created based on the author’s interaction with Twitter. Relevance judgments were obtained using the Amazon Mechanical Turk service2 . For each query, we created a pool of
tags to be judged using runs from three systems: simple
KL divergence, KL divergence on a Porter-stemmed corpus, and Rocchio relevance feedback using a TF-IDF model.
Each judger was shown a keyword query, a candidate tag, a
paragraph-long description of what would make a tag “useful,” and a sample of recent tweets using the tag. Judgers
ranked each query-tag pair on a four-point scale from 0 (not
useful) to 3 (definitely useful). Each query-tag pair was
judged by 5 judgers. Usefulness scores were obtained by taking both the mean and median of these 5 scores (we report
results based only on means). We take tags with usefulness
> 1 to be relevant (graded relevance is used for NDCG).

1

MAP
0.4268
0.4381
0.4605
0.4617†
0.4684†

http://api.twitter.com
http://www.mturk.com

788


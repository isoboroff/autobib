Temporally-Aware Algorithms for Document Classification

∗

Thiago Salles

Leonardo Rocha

Gisele L. Pappa

Fed. Univ. of Minas Gerais
Computer Science Dep.
Belo Horizonte, Brazil

Fed. Univ. São João Del Rei
Computer Science Dep.
of São João Del Rei, Brazil

Fed. Univ. of Minas Gerais
Computer Science Dep.
Belo Horizonte, Brazil

tsalles@dcc.ufmg.br

lcrocha@ufsj.edu.br

glpappa@dcc.ufmg.br

Fernando Mourão

Wagner Meira Jr.

Marcos Gonçalves

Fed. Univ. of Minas Gerais
Computer Science Dep.
Belo Horizonte, Brazil

Fed. Univ. of Minas Gerais
Computer Science Dep.
Belo Horizonte, Brazil

Fed. Univ. of Minas Gerais
Computer Science Dep.
Belo Horizonte, Brazil

fhmourao@dcc.ufmg.br

meira@dcc.ufmg.br

mgoncalv@dcc.ufmg.br

ABSTRACT

Keywords

Automatic Document Classiﬁcation (ADC) is still one of the
major information retrieval problems. It usually employs a
supervised learning strategy, where we ﬁrst build a classiﬁcation model using pre-classiﬁed documents and then use
this model to classify unseen documents. The majority of
supervised algorithms consider that all documents provide
equally important information. However, in practice, a document may be considered more or less important to build
the classiﬁcation model according to several factors, such
as its timeliness, the venue where it was published in, its
authors, among others. In this paper, we are particularly
concerned with the impact that temporal eﬀects may have
on ADC and how to minimize such impact. In order to deal
with these eﬀects, we introduce a temporal weighting function (TWF) and propose a methodology to determine it for
document collections. We applied the proposed methodology to ACM-DL and Medline and found that the TWF of
both follows a lognormal. We then extend three ADC algorithms (namely kNN, Rocchio and Naı̈ve Bayes) to incorporate the TWF. Experiments showed that the temporallyaware classiﬁers achieved signiﬁcant gains, outperforming
(or at least matching) state-of-the-art algorithms.

Classiﬁcation and Clustering, Text Mining

1. INTRODUCTION
Text classiﬁcation is still one of the major information retrieval problems, and developing robust and accurate classiﬁcation models continues to be a relevant demand, as a consequence of the increasing complexity and scale of current
application scenarios, such as the Web. The task of Automatic Document Classiﬁcation (ADC) aims to create models
that associate documents with semantically meaningful categories, and these models are key for building spam ﬁlters
and topic directories, identifying documents writing style,
creating digital libraries, and guiding a user’s search on the
World Wide Web.
ADC usually follows a supervised learning strategy, in
which a classiﬁcation model is built using some training (preclassiﬁed) documents and later employed to classify a new
set of unseen documents. The majority of supervised algorithms consider that all documents provide equally important information. However, in practice, a document may be
considered more or less important to build the classiﬁcation
model according to several factors, such as its timeliness, the
venue where it was published in, its authors, among others.
In this work we are particularly concerned with the impact that temporal eﬀects may have on ADC and how to
minimize such impact. Consider, for instance, the terms
pheromone and ant colony. Before the 1990s, they referred
exclusively to documents in the area of Natural Sciences.
However, after the introduction of the technique of Ant Colony Optimization in the area of Artiﬁcial Intelligence, these
terms became relevant for classifying Computer Science documents too. Previous work has demonstrated that temporal
eﬀects, such as the variation of the strenght of term-class relationship over time, may have a signiﬁcant impact on ADC,
and strategies for assessing these eﬀects and their impact on
ADC have already been devised [19].
In general, methods proposed to deal with temporal effects are based on three main approaches: instance selection,
instance weighting, and ensembles. Instance selection [20]
uses heuristics to decide which instances should be used (or
the time intervals that contain those instances) to create
a classiﬁcation model. However, tuning these heuristics to
select the most relevant documents is a challenge, since we

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval; I.5.4 [Applications]: Text processing;

General Terms
Algorithms, Experimentation
∗
This work was partially supported by CNPq, CAPES,
FINEP, Fapemig, and INWEB.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGIR’10, July 19–23, 2010, Geneva, Switzerland.
Copyright 2010 ACM 978-1-60558-896-4/10/07 ...$10.00.

307

may easily gather too many or too few documents. Methods
based on instance weighting [11] may ameliorate this problem 1 . However, this strategy raises the additional challenge
of determining the weighting functions and their parameters, which are collection-dependent and usually performed
in ad-hoc way. Finally, approaches based on ensembles, that
correspond to the combination of various classiﬁcation models generated from diﬀerent classiﬁcation algorithms, present
the challenge of how to manage, eﬃciently, several models
simultaneously [7].
This paper proposes a strategy to incorporate temporal
models to document classiﬁers, aiming to address the two
main drawbacks of instance selection and instance weighting
approaches. Our strategy is based on the evolution of the
term-class relationship over time, captured by a metric of
dominance. We start by determining a temporal weighting
function for a collection according to its characteristics. We
found that this function follows a lognormal distribution for
the datasets we used.
The next step is to incorporate the temporal weighting
function to ADC algorithms and we propose two strategies
that follow a lazy classiﬁcation approach. In both strategies, the weights assigned to each example depend on the
notion of a temporal distance δ, deﬁned as the diﬀerence
between the time of creation p of a training example and a
reference time point pr . The ﬁrst strategy, named temporal
weighting on documents, weights training instances according to δ. The second strategy, called temporal weighting on
scores, is based on an ensemble of classiﬁers, one for each
pair class c,time point p. In this case, the scores (e.g.,
similarities, probabilities) returned by the respective classiﬁers for each pair c, p are weighted according to δ. The
combined weighted scores are then used to take the ﬁnal
classiﬁcation decision. We speciﬁcally show how these two
strategies are implemented in three traditional ADC algorithms, namely, Rocchio, k Nearest Neighbors (KNN), and
Naı̈ve Bayes.
We evaluated our strategies using two actual digital libraries that span for decades, ACM-DL and MedLine, and
achieved signiﬁcant improvements on classiﬁcation eﬀectiveness for all classiﬁers. For instance, the temporal-aware version of Naı̈ve Bayes outperformed by up to 10% the state-ofthe-art classiﬁer (SVM), while presenting an execution time
up to hundreds of times faster.

2.

cument Classiﬁcation brings three main challenges to text
mining [17]. The ﬁrst one, and most relevant to this research, is the notion of context and how it may be exploited
towards better classiﬁcation models. Previous research in
document classiﬁcation identiﬁed two essential forms of context: neighbor terms that are close to a certain keyword [14]
and terms that indicate the scope and semantics of the document [2]. The second challenge is creating the models
incrementally [10]. The third challenge has to do with the
computational eﬃciency of the document classiﬁers. Methods for Adaptive Document Classiﬁcation usually follow an
instance selection approach, as they select semantic contexts
based on, for instance, the co-occurrence of terms, not taking into account all documents in the training set.
Concept or topic drift [22] comprises another relevant set
of eﬀorts to deal with temporal eﬀects in classiﬁcation. To
deal with concept drift, a prevailing approach in the literature is to completely retrain the classiﬁer according to
a sliding window. This involves instance selection and instance weighting techniques [12, 11, 23, 15]. The method
presented in [12], for instance, maintains a window with
documents suﬃciently “close” to the current target concept
and automatically adjusts the window size so that the estimated generalization error is minimized. In [11], the methods presented either maintain an adaptive time window on
the training data, select representative training examples, or
weight the training examples. In [23] the authors describe a
set of algorithms that react to concept drift in a ﬂexible way
and can take advantage of situations where contexts reappear. The main idea of these algorithms is to keep only a
window of currently trusted examples and hypothesis, and
store concept descriptions in order to reuse them if a previous context reappears. Unlike previous works, which use a
single window to determine drift in the data, in [15] the authors present a method that uses three windows of diﬀerent
sizes to estimate the change in the data. While algorithms
that use a window of ﬁxed size impose hard constraints over
drift patterns, those that use heuristics to adjust the window size to the current extent of concept drift often involve
lots of parameters to be calibrated. The approach proposed
in this paper relies on statistical properties of the collection
to assess the temporal eﬀects, solving such drawbacks, while
promoting a high quality classiﬁcation.
Other common approach to deal with concept drift focuses on the combination of various classiﬁcation models
generated from diﬀerent algorithms (ensembles) for classiﬁcation, pruning or adapting the weights according to recent
data [21, 13, 7]. In [21], the authors propose a boosting-like
method to train a classiﬁer ensemble from data streams.
It naturally adapts to concept drift and allows to quantify
the drift in terms of its base learners. The algorithm was
shown to outperform learning algorithms that ignore concept drift. In this same direction, Kolter et al. [13] present
a technique that maintains an ensemble of base learners,
predicts instance classes using a weighted-majority vote of
these “experts”, and dynamically creates and deletes experts
in response to changes in performance. In [7], a method that
builds an ensemble of classiﬁers using Genetic Programming
(GP) to inductively generate decision trees is presented.
However, how to manage, eﬃciently, several models simultaneously remains a challenge. To address such drawback,
we propose an approach based on the combination of vari-

RELATED WORK

Although document classiﬁcation is a widely studied subject, the analysis of temporal aspects in this class of algorithms is quite recent – it has been studied just in the
last decade. As previously mentioned, strategies to deal
with these eﬀects involve one or more of three approaches,
namely: instance selection, instance weighting, and ensembles. Here we review the most relevant works of two broad
areas where there has been signiﬁcant eﬀorts in terms of
temporal eﬀects on classiﬁcation: adaptive document classiﬁcation and concept drift.
Adaptive Document Classiﬁcation [4] encompasses a set
of techniques related to temporal aspects with the goal of
improving the eﬀectiveness of document classiﬁers through
their incremental and eﬃcient adaptation. Adaptive Do1
The ﬁrst strategy may be seem as an instance weighting
strategy with binary weights.

308

derived from the MedLine collection, and has 861.454 documents, classiﬁed into 7 distinct classes related to Medicine
and created between the years of 1970 and 1985. In both
collections, each document is assigned to a single class.
We start by deﬁning the temporal granularity of the weighting function, which should be the minimum time interval between relevant changes in the collection (e.g., days, weeks, or
years). Since both collections contain scientiﬁc documents,
it is intuitive that a year granularity is representative, once
documents are usually published yearly (scientiﬁc conferences are usually annual).
The simplest approach would be to use a pulse function at
temporal distance 0, that is, the pulse magnitude is proportional to the term dominance associated with the training
documents produced in the same year of the test document.
However, as pointed by [19], considering a larger time interval instead of a single time point is better, since the inﬂuence decreases with the increase of the temporal distance.
We then need to determine the time period that must be
considered, which we call stability period. Notice that each
term may present a diﬀerent stability period for each year
when it occurred in the collection. We ﬁrst determine the
stability period for each term and then combine them, as
follows.
One approach for the ﬁrst step is presented in [20], where
a stability period St,r of a term t, considering the reference time point pr in which the test document was created,
consists of the largest continuous period of time, starting
from pr and growing both to the past and the future, where
Dominance(t, c) > α (for some predeﬁned α and any class
c). In the case of the collections ACM-DL and Medline, we
investigated diﬀerent values for α when computing stability periods and, as they lead to similar results, we adopted
α = 50%, ensuring that the terms will have a high degree of
exclusivity with some class.
We then combine the stability periods St,r for each term
t and each reference time point pr in the collection. A
diﬃculty in this case is related to the fact that a term
may present diﬀerent stability periods for diﬀerent reference
years. In order to avoid this problem, we mapped all the
time points in a stability period to temporal distances, where
the reference year is considered as distance 0. For instance,
a term t1 may have diﬀerent stability periods when considering the years 1989 or 2000 as a reference. More speciﬁcally,
if the stability period of t1 is {1999,2000,2001} regarding
pr = 2000, and {1988,1989,1990} regarding pr = 1989, these
periods would be both mapped to {-1,0,1}. Considering St
as the set of temporal distances that occur on the stability
periods of term t (considering all reference moments r, then
St = {δ ← pn − pr |∀rpn ∈ St,r }. Making the stability periods easily comparable is important because our real interest
is to know what kind of distribution this temporal distances
follow w.r.t. diﬀerent terms.
The next step is to determine the function expression and,
towards this goal, we considered the stability period of each
term as a random variable (RV), where the occurrence of
each possible temporal distance in its stability period is an
event. More formally, as Table 1 shows, we are interested
in the frequencies of the temporal distances δ1 to δn , for
terms t1 to tk . An interesting property that we may test is
whether these RV’s are independent. This hypothesis can
be corroborated by the Fisher’s Exact Test to assess the
independence of each RVi and RVj , ∀i = j [3], where, as

ous classiﬁcation models, but with a simpler way to manage
them.
Another approach that can be easily compared to ours,
and is based on instance selection, is the one proposed in [20].
In [20], the authors introduce the concept of temporal context, deﬁned as a subset of the documents collection that
minimizes the impact of temporal eﬀects in classiﬁers’ performance. An algorithm named Chronos was proposed to
identify these contexts based on the stability of the terms in
the training set. The temporal contexts were then used to
sample the training documents for the classiﬁcation process.
Hence, training documents that were considered to be outside the temporal context were discarded by the classiﬁer.
In contrast with the aforementioned works, here we propose an approach to classify documents in scenarios where
we may have information about both the past and the future,
and this information may change over time. It should be noticed, however, that our approach may be easily adapted
for scenarios where we only have past information, such
as Adaptive Document Classiﬁcation and Concept Drift.
Moreover, we address the drawbacks of which instances to
select by approximating a temporal weighting function using
a lognormal distribution, and may easily tune its parameters
using statistical methods.

3.

TEMPORAL WEIGHTING FUNCTION

As mentioned before, the potential impact that certain
temporal eﬀects have on term-class relationships may have a
great inﬂuence on the results of the classiﬁcation process, as
showed in [19]. Thus, incorporating information about these
changes into the classiﬁcation process has the potential to
improve its eﬀectiveness.
We address this issue through a temporal weighting function (TWF) that quantiﬁes the inﬂuence of a training document while classifying a test document, as a function of
the temporal distance between their creation times. We distinguish two major steps in determining such function: its
expression and its parameters. The expression is usually
harder to determine, since it may express the generative process behind the function, while the parameters are usually
obtained using approximation strategies.
Intuitively, given a test document to be classiﬁed, the
TWF must set higher weights to training documents that
are more similar to that test document w.r.t. the strength
of term-class relationships. One metric that expresses such
strength is the dominance [20], since the more exclusive a
term is to a given predeﬁned class, the stronger this relationship. Dominance can be formally deﬁned as:
Ntc
,

c Ntc

Dominance(t, c) = P

where Ntc stands for the number of documents in class c
that contain term t.
For ease of understanding, before we continue the discussion about the temporal weighting function, we describe the
two document collections for which we want to determine the
functions: ACM Digital Library (ACM-DL) and the MedLine. The ACM-DL has 24.897 documents containing articles related to Computer Science created between the years
of 1980 and 2002. We considered only the ﬁrst level of the
taxonomy adopted by ACM, including 11 categories, which
did not vary during this period of time. The second one is

309

δ1
δ2
..
.
δn
Table 1:

t1
f11
f21

t2
f12
f22

...
...
...

tk
f1k
f2k

D
Pk δ
f1i
Pi=1
k
i=1 f2i

Param.
a1
b1
c1
a2
b2
c2

Pk
fn1 fn2 . . . fnk
i=1 fni
Temporal distances versus terms

Adj. R2

ACM-DL
Conf. Interval
(0.288, 0.362)
(-0.309, 0.253)
(3.117, 4.154)
(0.589, 0.643)
(-0.395, 0.470)
(20.93, 23.35)

Value
0.089
-0.013
1.635
0.901
0.092
24.51

0.990

Medline
Conf. Interval
(0.066, 0.113)
(-0.349, 0.324)
(1.099, 2.17)
(0.891, 0.911)
(-0.130, 0.314)
(23.71, 25.3)
0.992

Table 2: Estimated parameters for both collections,
with 99% confidence intervals.

mentioned, each RV represents the occurrence of a temporal
distance δ for a term t.
We applied this test to both ACM-DL and Medline and
obtained a p-value of 0.99 through a Monte Carlo simulation,
which allows us to state that the random variables considered are indeed independent. Thus, the observed variability
of occurrences of δ for diﬀerent terms is a result of independent eﬀects [16]. However, it is still not clear whether the effects responsible for the observed variability can be additive
(leading to a normal distribution) or multiplicative (leading
to a lognormal distribution). We then apply a statistical
normality test. According to D’Agostino’s D-Statistic Test
of Normality [6], with 0.01 signiﬁcance level, we found that
the lognormal distribution best ﬁts both the ACM-DL and
Medline collections, as presented in Table 3.
Consider that the RV Dδ related to the occurrences of δ,
which represents the distribution of each δi over all terms
t, is lognormally distributed if lnDδ is normally distributed.
More generally, since δi are RV’s under the independence
assumption with ﬁnite mean and
P variance, then, by the Central Limit Theorem, lnDδ = n
i=1 lnδi will asymptotically
approach a normal distribution and, by deﬁnition, converges
to a lognormal distribution [5]. For a lognormal distribution,
the asymptotically most eﬃcient method for estimating its
associated parameters relies on a log-transformation [16].
Using a Maximum Likelihood method, we estimated those
parameters for both collections, and then back-transformed
them, as shown in Table 2. We considered a 3-parameter
−

Value
0.325
-0.028
3.636
0.616
0.037
20.14

β = 1, for each possible temporal distance between the creation time of test document d and the training documents
for both the ACM-DL and the Medline collections.
Data
Original
Log-Transformed

ACM-DL
4.497e−6
0.2144

Medline
0.002762
0.6802

Table 3: D’Agostino’s D-Statistic Test of Normality.
Bold-face for tests that we can not reject the null
hypothesis of normality.

(a) ACM-DL Collection

(x−bi )2
2c2
i

gaussian function, F = ai e
. The parameter ai is
the height of the curve’s peak, bi is the position of the centre of the peak, and ci controls the width of the curve. The
last one, also called the shape parameter, reﬂects the nature
of the variations of term-class relationships over time. Since
abrupt or smooth variations lead to small or greater stability
periods, respectively, the shape of the distribution changes
accordingly, being a matter of parameter estimation to capture such distinct natures. We performed two curve ﬁtting
procedures, considering a single gaussian F and a mixture
of two gaussians, given by G = G1 + G2 , where each Gi denotes a gaussian function. The last one was the model that
best ﬁtted Dδ , and its parameters are presented in Table 2,
along with the goodness of ﬁtting measure Adjusted-R2 . The
Adjusted-R2 measure denotes the percentage of variance explained by the model and, for both collections, the obtained
model explains 99% of such variance.
The greater the frequency of δ on stability periods, the
more suitable training documents created in δ are to build
an accurate classiﬁcation model, making the modelling of the
Temporal Weighting Function as a lognormal distribution an
eﬀective strategy. To account for the problem faced when
the scale of the score is not compatible with the algorithm
input, we include a scaling factor β ∈ R, that is algorithm
speciﬁc and will be deﬁned in Section 5.
Figure 1 shows the distribution of temporal scores, when

(b) MedLine Collection
Figure 1: Fitted temporal weighting function with
log-transformed data.

4. TEMPORALLY-AWARE ADC
This section shows how three well-known text classiﬁers,
namely Rocchio, KNN and Naı̈ve Bayes [18], can be modiﬁed to take into account the temporal weighting function
deﬁned in Section 3. The three algorithms are modiﬁed following two strategies: temporal weighting on documents and
temporal weighting on scores, as detailed below.

4.1 Temporal Weighting on Documents
The temporal weighting on documents strategy weights
each training document by the temporal weighting function
according to its temporal distance to the test document d ,
as detailed next.
The strategy to incorporate the weight of each training
document to a given classiﬁer depends inherently on the
characteristics of the classiﬁcation algorithm being modiﬁed.
For example, while Rocchio and KNN classify new instances

310

neighbor documents in the vector space. Determining the
test document’s class from the k nearest neighbors training
documents may not be ideal in the presence of term-class relationships that vary considerably over time. To deal with it,
we apply the proposed temporal weighting function during
the computation of similarities among d and the documents
in the training set, aiming to select the closest documents,
in terms of both similarity and temporality.
Let s be the cosine similarity between a training document
d and d . If d is similar to d but is temporally distant,
then it is moved away from d , reducing the probability of
being among the k nearest documents of d . Let T W F (δ) be
the temporal weight associated with the temporal distance
between the time of creation of documents d and d . Then,
the documents’ similarity is given by:

based on a distance metric, Naı̈ve Bayes is a probabilistic
classiﬁer that assigns to a test document the most probable
class that would have generated d , adopting some naı̈ve assumptions such as positional and conditional independence
of terms.
In the case of distance-based classiﬁers, the temporal weighting function can be easily applied when calculating the
distance between the training and test documents, by weighting each training document (T F -IDF vector) by its associated temporal weight. In the case of the Naı̈ve Bayes, the
temporal function can be used to weight the impact of each
training example in both the a priori and conditional probabilities, in order to generate a more accurate a posteriori
probability.
Rocchio Rocchio is an eager classiﬁer that uses the centroid of a class to ﬁnd boundaries between classes. As an
eager classiﬁer, Rocchio does not require any information
from d to create a classiﬁcation model. Hence, we will have
to adapt it to become a lazy classiﬁer when using the temporal weighting function, since the weights depends on the
creation time of a test document.
The centroid of a class is deﬁned as the average value of all
its training examples. When classifying a new document d ,
Rocchio associates it to the class represented by the centroid
closest to d . In order to make Rocchio a lazy classiﬁer, we
have to change the separation boundaries of classes according to the temporal weights produced by our function.
Hence, it needs to calculate each Rocchio’s class centroid
based on the creation time pr of a test document d . Consider the set of training documents d of class c. This set can
be partitioned into subgroups of documents created at the
same temporal distance δ from pr , i.e., subgroups of documents created at a temporal distance of 1 or −1 , 2 or −2,
→
and so on. The centroid −
μ c for class c is deﬁned by weighting the documents vector representations with the score produced by the temporal function T W F (δ), obtained using the
temporal distance δ between the creation time point of d and
→
d . Thus, a centroid −
μ c is given by:
−
→
μc =

1
Dc

sim(d, d ) ← cos(d, d ) · T W F (δ).
Both training and classiﬁcation procedures are presented
in Algorithm 2.
Algorithm 2 KNN-TWF-Doc:
Weighting on Documents

1: function getKNearestNeighbors(D, d , k)
2:
for each d ∈ D do
3:
sim(d, d ) ← cos(d, d ) · T W F (δ)
4:
priorityQueue.insert(sim, d)
5:
return priorityQueue.first(k)
6: function Classify(D, d , k)
7:
knn ← getKNearestNeighbors
(d , D, k)
P
8:
return {arg maxc knn.nextDoc(c)}
c

Naı̈ve Bayes Naı̈ve Bayes is a probabilistic learning method that aims to infer a model for each class, assigning to d
the class associated to the most probable model that would
have generated d . Here we adapt the Multinomial Naı̈ve
Bayes approach [18], since it is widely used for the probabilistic text classiﬁcation. Similarly to the previously deﬁned
“temporal weighting on documents” approaches, here we apply the temporal weighting function on the information used
by the learning method, namely the relative frequencies of
documents and terms, as follows:

!
X−
→
dδ · T W F (δ) ,

X
d∈Dc

δ∈Δ

P
P
Y
p (Ncp · T W F (δ))
p (ftcp · T W F (δ))
PP
·
,
P (d |c) = η· P
(N
·
T
W
F
(δ))
(ft cp · T W F (δ))
p
p


where Dc is the number of documents in class c, Δ is the
set of all possible temporal distances between the training
→
−
documents and the test document d , and dδ ∈ Dc is a
training document with temporal distance δ from d .
This approach redeﬁnes the centroid’s coordinates in the
vectorial space considering document’s representativeness on
class c w.r.t. the reference time point pr . Both training and
classiﬁcation procedures are presented in Algorithm 1.



t∈d

1: function Train(C, D)
2:
Dc,δ ← {d : d, c, δ ∈ D}
!
P
P−
→
→
−
3:
μ c ← D1c 
dδ · T W F (δ)
δ∈Δ

4.2 Temporal Weighting on Scores

−
4:
return {→
μ c : c ∈ C}
5: function Classify({μc : c ∈ C}, d )
→
−
−
6:
return arg max cos(→
μ , d )
c

p t ∈V

where η denotes a normalizing factor, Ncp is the number
of training documents of D assigned to class c and created
at time point p, Np is the number of training documents
created at time point p, ftcp stands for the frequency of occurrence of term t in training documents of class c that were
created on time point p and, ﬁnally, δ denotes the temporal
distance between time point p and the creation time of d .
The main goal of this strategy is to reduce the impact
that temporally distant information have when estimating a
posteriori probabilities. Algorithm 3 presents this strategy.

Algorithm 1 Rocchio-TWF-Doc: Rocchio with Temporal
Weighting on Documents

d∈Dc

KNN with Temporal

A more sophisticated approach to exploit the temporal
weighting function considers the “scores” produced by the
traditional classiﬁers, as listed in Algorithm 4. By score we
mean: (i) the smallest distance from the test document d
to a class centroid for Rocchio; (ii) the smallest sum of the

c

KNN KNN is a lazy classiﬁer that assigns to a test document d the majority class among those of its k nearest

311

Algorithm 3 Naı̈ve Bayes TWF-Doc: Naı̈ve Bayes with
Temporal Weighting on Documents

the best value of k was 50. The intuition for the traditional KNN to perform better with smaller values of k is
that, as the number of neighbors increases, the variation on
term-class relationships also increases, and the probability
of misclassiﬁcation increases. When considering temporal
information by means of the proposed temporal weights, in
contrast, more consistent information becomes available, allowing a more accurate model.
As discussed in Section 4, the TWF scale must be compatible with the classiﬁers scores, ensuring that it eﬀectively improves the classiﬁer’s decision rules without dismissing them.
We empirically tested three values for β: 1, 10, and 100. The
best value of each version of each classiﬁer was considered.
For Rocchio and KNN, the best results were obtained with
β = 1. For Naı̈ve Bayes, the best value was β = 10. This is
due to the multiplicative nature of this classiﬁer: many conditional probabilities are multiplied, leading to even smaller
values.

1: function Classify(D,
d )
P

(Ncp ·T W F (δ))
Pp
p (Np ·T W F (δ))
P
Q
(ftcp ·T W F (δ))
← t∈d P P p
(f 
·T W F (δ))
p
t ∈V
t cp

2:

aP riori[c] ←

3:

termCond[c]

4:

return {arg maxc η · aP riori[c] · termCond[c]}

distances of the K-nearest neighbors to document d assigned
to class c in the case of KNN; or (iii) the probability to
generate d with the model associated to some class c for
Naı̈ve Bayes. From now on, we refer to this approach as
temporal weighting on scores.
Let C and P be the set of classes and creation time points
of the training documents. First, each training document
class c ∈ C is associated with the corresponding creation
time point p ∈ P, generating a new class deﬁned as c, p.
Then, we use a traditional classiﬁcation algorithm to generate scores for each new class c, p. Note that this scenario
isolates term-class relationship variations, since it considers
only one time point. To decide to which class c the document d should be assigned to, we sum up all the scores
c, p, for all pr ∈ P, weighting them by the T W F (δ), where
δ = p − pr corresponds to the temporal distance between p
and the creation moment of d . At the end of this process,
d will be assigned to the class c with highest score, as listed
in Algorithm 4.

5.2 Experiments
After setting the parameters, we perform experiments comparing the traditional and the proposed temporally-aware
versions of Rocchio, KNN and Naı̈ve Bayes. The results
for the ACM-DL and Medline collections are reported in
Tables 4 and 5. In both tables, each line presents the results achieved by the versions of the classiﬁers identiﬁed in
the ﬁrst row and column. The values obtained for MacroF1
(“macF1 ”) and accuracy (“acc.”) are reported, as well as
the percentage diﬀerence between values achieved by the
temporally-aware methods and the traditional version of the
classiﬁers. This percentage diﬀerence is followed by a symbol that indicates whether the variations are statistically
signiﬁcant according to a 2-tailed paired t-test, given a 99%
conﬁdence level.  denotes a signiﬁcant positive variation,
• a non signiﬁcant variation and  a signiﬁcant negative
variation.
As we can see in Tables 4 and 5, all modiﬁed versions
of Rocchio and KNN achieved better results than the baseline in ACM-DL. In Medline, the versions on score achieved
gains, while the versions on documents were statistically the
same as the baseline. In particular, Rocchio with TWF on
scores presents the most signiﬁcant improvements in both
collections, with gains up to +18.87 and +11.46 for MacroF1
and Accuracy, respectively. Similarly, KNN with TWF on
scores achieves the best results among all KNN variations,
with gains of +8.85% and +3.80% for MacroF1 and Accuracy in the ACM-DL collection. In the case of Rocchio, the
improvements achieved using the TWF can be explained by
the fact that, in the traditional version, the documents are
summarized in a unique representative vector (centroid), aggregating documents from distinct creation time points, and
aﬀecting the prediction ability of the classiﬁer. In the case of
KNN, the deﬁnition of class boundaries is done considering
each training document independently. KNN assumes that
documents of same class are located close by on the vectorial space. By using the TWF, the k nearest documents are
reorganized, and the most temporally relevant are placed
closer to the example being classiﬁed.
The Naı̈ve Bayes with TWF on documents presents better
results for MacroF1 on both ACM-DL and Medline, and better Accuracy in Medline. Note that the best improvement
was achieved in MacroF1, pointing out that this strategy
eﬀectively reduces the Naı̈ve Bayes bias towards the most

Algorithm 4 TWF-Sc: Temporal Weighting on Scores
1: function Classify(d, C, P, D)
2:
for each c ∈ C do
3:
for each p ∈ P do
4:
c ← c.p
5:
score[c]+ =TraditionalClassifier(d, D, c ) · T W F (δ)
6:
return {arg maxc score}

5.

RESULTS

In order to evaluate the impact that the proposed TWF
has on the classiﬁcation task, we evaluate both the traditional and temporally-aware versions of Rocchio, KNN and
Naı̈ve Bayes in the ACM-DL and Medline collections, and
contrast them. The methods were compared using two standard information retrieval measures: Accuracy and macro
average F1 (MacroF1 ). While the Accuracy measures the
classiﬁcation eﬀectiveness over all decisions, the MacroF1
measures the classiﬁcation eﬀectiveness for each individual
class and averages them. All experiments were executed using a 10-fold cross-validation [1] procedure considering training, validation and test sets. The parameters were set using
the validation set, and the eﬀectiveness of the algorithms
measured in the test partition.

5.1 Parameter settings
In order to run the experiments, two important parameters had to be set: the value of k for KNN and the scaling
factor β.
We ﬁrst performed some experiments with KNN to deﬁne the value of k. This parameter signiﬁcantly impacts
the quality of classiﬁer, and must be carefully chosen. Four
values were tested for each version of the traditional and
temporally-aware algorithms: 30, 50, 150, and 200. For the
traditional version of the algorithm k = 30 presented better
results, while for both temporally-aware versions of KNN

312

Algorithm
Metric
Baseline
TWF
on documents
TWF
on scores

Rocchio
macF1 (%)
acc.(%)
55.12
66.42
57.24
68.64
(+3.85) 
(+3.34) 
59.07
71.54
(+7.17) 
(+7.71) 

KNN
macF1 (%)
acc.(%)
61.80
72.29
63.40
73.98
(+2.59) 
(+2.34) 
64.18
74.56
(+3.85) 
(+3.14) 

Naı̈ve Bayes
macF1 (%)
acc.(%)
57.33
73.69
60.78
74.14
(+6.02) 
(+0.61) •
40.62
48.76
(-41.14) 
(-51.13) 

Table 4: Results obtained when incorporating TWF to Rocchio, KNN, and Naı̈ve Bayes – ACM-DL
Algorithm
Metric
Baseline
TWF
on Documents
TWF
on scores

Rocchio
macF1 (%)
acc.(%)
55.36
70.17
56.21
70.83
(+1.53) •
(+0.94) •
65.81
78.21
(+18.87) 
(+11.46) 

KNN
macF1 (%)
acc.(%)
73.33
84.63
73.94
84.07
(+0.83) •
(+0.66) •
76.82
87.01
(+4.54) 
(+2.81) 

Naı̈ve Bayes
macF1 (%)
acc.(%)
76.81
84.69
81.58
87.48
(+6.21) 
(+3.29) 
51.54
48.02
(-49.03) 
(-76.36) 

Table 5: Results obtained when incorporating TWF to Rocchio, KNN, and Naı̈ve Bayes – Medline
the score in a coarse-grained representation of a document.
Hence, one could argue that the TWF is more suitable to the
“on scores” approach. The deﬁnition of a temporal weighting
for each term independently is left for future work.
Finally, we also compared the best version of the methods previously proposed, i.e., KNN with TWF on scores and
Naı̈ve Bayes with TWF on documents, to the state of the art
classiﬁer Support Vector Machine [8], in terms of eﬀectiveness (classiﬁcation quality) and eﬃciency (execution time).
We run an eﬃcient SVM implementation, SVM Perf [9],
which is based on the maximum-margin approach and can
be trained in linear time. We used an one-against-all [18]
methodology to adapt binary SVM to multi-class classiﬁcation, since the collections present 11 (ACM-DL) and 7
(MedLine) classes. The results are presented in Table 7.
For ACM-DL collection, the signiﬁcant gains are of 3.74%
and 2.66% in macroF1 and accuracy, respectively. For MedLine collection, the most signiﬁcant gains are of 12.87% and
5.06% in macroF1 and accuracy, respectively. Considering
that SVM is a state of the art classiﬁer, and that both collections are very unbalanced (which signiﬁcantly diﬃculties
classiﬁcation), our results evidence the quality of the proposed solution, with better performance.

frequent classes. However, in contrast with Rocchio and
KNN, the Naı̈ve Bayes with TWF on scores performs poorly
in both collections. We attribute this to two major weaknesses of traditional Naı̈ve Bayes version. First, when facing
skewed data distributions, Naı̈ve Bayes unwittingly prefers
larger classes over others, causing decision boundaries to be
biased. Second, when data is scarce, there is not enough
information to perform accurate estimates, leading to bad
results.
The skewness of data distribution among classes c, p can
be quantiﬁed by the Coeﬃcient of Variation CV = σμ of their
sizes, where σ and μ stand for the standard deviation and
mean. To explore the impact of data skewness on Naı̈ve
Bayes, we sampled MedLine, creating two sub-collections
composed by the least and most frequent classes c, p, minimizing data skewness. While the entire collection presents
CV = 1.33, the sub-collections with the least and most frequent classes present CV equal to 0.57 and 0.43, respectively. As we can observe in Tables 5 and 6, the greater the
CV, the worse are the results.
ACM-DL has an even more skewed data distribution over
each time point, preventing us to sample it in sub-collections
with smaller CV. Figure 2 shows that in the ACM-DL collection data scarcity is also prominent, contributing to the
poor performance. Notice that 70% of classes c, p have
less than 100 documents, a number too low to guarantee
accurate estimates.

6. CONCLUSION AND FUTURE WORK
This work discussed the impact that temporal eﬀects may
have in ADC, and proposed two new strategies for instance
weighting that leads to more accurate classiﬁcation. We
started by proposing a methodology to model a Temporal
Weighting Function (TWF) that captures changes in termclass relationships for a given period of time. For our real
datasets, we showed that TWF follows a lognormal distribution, whose parameters may easily be tuned using statistical methods. In order to incorporate this TWF to classiﬁers, we presented two approaches: TWF on documents and
TWF on scores. TWF on documents weights each training
document by the TWF according to its temporal distance
to the test document. TWF on scores, in contrast, takes
into account scores produced by the traditional classiﬁers
on scenarios without temporal variability on term-class relationships, performing a weighted sum of them, where the
weights come from the TWF. Both strategies were incorporated to three traditional classiﬁers, namely Rocchio, KNN,
and Naı̈ve Bayes.
Results with the traditional versions of these classiﬁers
and the temporally-aware ones showed that considering temporal information signiﬁcantly improves the results of the

0.5

Relative Frequencies (%)

0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0

50 100 150 200 250 300 350 400 450 500 550 600 650 700 750

Size

Figure 2: c, p sizes – ACM-DL
As observed, using TWF on scores in most cases led to
better results than those applying TWF on documents. We
believe this is because, in many applications, terms present
distinct evolutive patterns, and the proposed function neglects this fact. Hence, when the temporal TWF is applied on documents, all terms are multiplied by the same
score (i.e., using a ﬁne-grained representation of the document), given in function of the temporal distance δ. Thus,
we consider an uniform evolution among terms. In contrast,
the TWF on scores minimizes this problem, as it applies

313

Naı̈ve Bayes
Metric
Baseline
TWF
on Scores

Least frequent classes c, p
CV
macF1 (%)
acc.(%)
87.32
88.10
0.57
92.03
92.21
(+5.40) 
(+4.66) 

Most frequent classes c, p
CV
macF1 (%)
acc.(%)
91.09
91.92
0.43
93.19
93.86
(+2.31) 
(+2.12) 

Table 6: Results obtained for the least and most frequent classes c, p sampling for Naı̈ve Bayes – Medline
Collection
Metric
SVM
KNN with
TWF on scores
Naı̈ve Bayes with
TWF on documents

macF1 (%)
60.07
64.18 (+6.84)

60.78 (+1.18)
•

ACM-DL
acc.(%)
73.03
74.56 (+2.09)

74.14 (+1.52)
•

Time (s)
4200
62
51

macF1 (%)
72.28
76.82 (+5.90)

81.58 (+12.87)


Medline
acc.(%)
83.27
87.01 (+4.49)

87.48 (+5.06)


Time (s)
1300000
4757
2840

Table 7: Results obtained when adding TWF on scores to KNN and TWF on Documents to Naı̈ve Bayes
versus SVM for both collections
[10] Y. S. Kim, S. S. Park, E. Deards, and B. H. Kang.
Adaptive web document classiﬁcation with mcrdr. In
ITCC ’04, Volume 2, page 476, Washington, DC,
USA, 2004. IEEE Computer Society.
[11] R. Klinkenberg. Learning drifting concepts: Example
selection vs. example weighting. Intell. Data Anal.,
8(3):281–300, 2004.
[12] R. Klinkenberg and T. Joachims. Detecting concept
drift with support vector machines. In P. Langley,
editor, ICML ’00, pages 487–494, Stanford, US, 2000.
Morgan Kaufmann Publishers, San Francisco, US.
[13] J. Kolter and M. Maloof. Dynamic weighted majority:
A new ensemble method for tracking concept drift.
Technical report, Department of Computer Science,
Georgetown University, Washington, DC, June 2003.
[14] S. Lawrence and C. L. Giles. Context and page
analysis for improved web search. IEEE Internet
Computing, 2(4), 1998.
[15] M. M. Lazarescu, S. Venkatesh, and H. H. Bui. Using
multiple windows to track concept drift. Intell. Data
Anal., 8(1):29–59, 2004.
[16] E. Limpert, W. A. Stahel, and M. Abbt. Log-normal
distributions across the sciences: Keys and clues.
BioScience, 51(5):341–352, 2001.
[17] R. Liu and Y. Lu. Incremental context mining for
adaptive document classiﬁcation. In Proc. of the 8th
ACM SIGKDD, pages 599–604. ACM Press, 2002.
[18] C. D. Manning, P. Raghavan, and H. Schtze.
Introduction to Information Retrieval. Cambridge
University Press, New York, NY, USA, 2008.
[19] F. Mourao, L. Rocha, R. Araújo, T. Couto,
M. Gonçalves, and W. Meira Jr. Understanding
temporal aspects in document classiﬁcation. In Proc.
of the WSDM ’08, 2008.
[20] L. Rocha, F. Mourao, A. Pereira, M. A. Gonçalves,
and W. Meira Jr. Exploiting temporal contexts in text
classiﬁcation. In Proc. of the CIKM ’08, 2008.
[21] M. Scholz and R. Klinkenberg. Boosting classiﬁers for
drifting concepts. Intell. Data Anal., 11(1):3–28, 2007.
[22] A. Tsymbal. The problem of concept drift: Deﬁnitions
and related work. Technical report, Department of
Computer Science, Trinity College, Dublin, Ireland,
December 2004.
[23] G. Widmer and M. Kubat. Learning in the presence of
concept drift and hidden contexts. Machine Learning,
23(1):69–101, 1996.

traditional classiﬁers. Also, both temporally-aware KNN
and Naı̈ve Bayes achieved better results than SVM, with
better performance. Considering that SVM is a state of the
art classiﬁer, and that both collections are very unbalanced,
our results evidence the quality of our solution, coupled with
an eﬃcient implementation.
Given the results obtained when comparing SVM to the
temporal versions of KNN and Naı̈ve Bayes, as a future
work, we will incorporate temporal information to the SVM
classiﬁer, by deﬁning kernel functions that use the proposed
TWF. We also plan to reﬁne our TWF, in order to account
for distinct evolutive patterns that terms may present, by
means of a more sophisticated statistical analysis. Moreover, similarly to time, social and geographical aspects may
induce variations on term-class relationships, and we will
also explore those dimensions in order to achieve an even
better classiﬁcation quality.

7.

REFERENCES

[1] L. Breiman and P. Spector. Submodel selection and
evaluation in regression – the x-random case.
International Statistical Review, 60:291–319, 1992.
[2] N. H. M. Caldwell, P. J. Clarkson, P. A. Rodgers, and
A. P. Huxor. Web-based knowledge management for
distributed design. IEEE Intelligent Systems,
15(3):40–47, 2000.
[3] D. B. Clarkson, Y.-a. Fan, and H. Joe. A remark on
algorithm 643: Fexact: an algorithm for performing
ﬁsher’s exact test in r x c ACM Trans. Math. Softw.,
19(4):484–488, 1993.
[4] W. W. Cohen and Y. Singer. Context-sensitive
learning methods for text categorization. ACM Trans.
Inf. Syst., 17(2):141–173, 1999.
[5] S. K. Crow EL. Log-normal distributions: Theory and
application. New York: Dekker, December 1988.
[6] P. E. D’Agostino R.B. Tests for departure from
normality. Biometrika, 60:613–622, 1973.
[7] G. Folino, C. Pizzuti, and G. Spezzano. An adaptive
distributed ensemble approach to mine
concept-drifting data streams. In ICTAI ’07, Volume
2, pages 183–188, Washington, DC, USA, 2007. IEEE
Computer Society.
[8] T. Joachims. Making large-scale support vector
machine learning practical. Advances in kernel
methods: support vector learning, pages 169–184, 1999.
[9] T. Joachims. Training linear svms in linear time. In
Proc. of the 12th ACM SIGKDD Conference, pages
217–226, New York, NY, USA, 2006. ACM.

314


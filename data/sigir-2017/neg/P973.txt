Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Sentence-level Sentiment Classification with Weak Supervision
Fangzhao Wu

Jia Zhang

Zhigang Yuan

Tsinghua University
Microsoft Research Asia
wufangzhao@gmail.com

Electronic Engineering
Tsinghua University
zhangjia14@mails.tsinghua.edu.cn

Electronic Engineering
Tsinghua University
yuanzg14@mails.tsinghua.edu.cn

Sixing Wu

Yongfeng Huang∗

Jun Yan

Electronic Engineering
Tsinghua University
wu-sx15@mails.tsinghua.edu.cn

Electronic Engineering
Tsinghua University
yfhuang@tsinghua.edu.cn

Microsoft Research Asia
Beijing, China
junyan@microsoft.com

ABSTRACT

Existing methods for sentence-level sentiment classification are
mainly based on supervised learning techniques [4, 5, 9, 13]. The
sentiment labels of sentences are generally required in these methods to train sentence-level sentiment classifiers. However, it is very
difficult to obtain the fine-grained sentiment labels of sentences [15].
In addition, manually annotating sufficient sentences for training
is costly and time-consuming [12].
A common observation in sentiment analysis field is that sentiment labels of documents are generally easy to obtain, for example,
from the star-rated consumer reviews on e-commerce and review
websites [15]. Although a document may contain sentences with
different sentiments, most of the sentences in an opinionated document usually have the same sentiment with this document [16].
For example, a positive document usually contains more sentences
with positive sentiment than sentences with negative sentiment.
Thus, the sentiment labels of documents can provide useful coarsegrained supervision information for learning sentence-level sentiment classifiers. In addition, many general-purpose sentiment
lexicons for example SentiWordNet [1] have been built, and they
contain a large number of general sentiment words as well as their
sentiment labels. Since words are the basic elements to express
sentiments in a sentence, the sentiment labels of words may also
be useful to train sentence-level sentiment classifiers. Besides, although it is difficult to obtain the sentiment labels of sentences, the
sentiment relations between sentences are relatively easy to infer in
many cases. For example, a review in Kitchen domain may be “My
pot worked well, but after a while it leaks”. Since the former and
the latter sentences are connected by the adversative conjunction
“but”, we can infer that they probably convey different sentiments.
Moreover, it is also not difficult to extract the sentiment relations
between many words from unlabeled sentences [6]. For example,
an unlabeled sentence in Kitchen domain may be “Maintenance is
easy and quick”. Since the words “easy” and “quick” are used to
describe the same opinion target (i.e., “maintenance”) in the same
sentence, we can infer that these two words probably convey the
same sentiment in this domain.
Motivated by above observations, in this paper we propose an
approach for sentence-level sentiment classification which does not
need the sentiment labels of sentences. Our approach can exploit
the sentiment information in labeled documents and labeled words,
which are much easier to obtain. A unified framework is proposed
to fuse these two types of weak supervision information to learn
the sentence-level sentiment classifier. In addition, the contextual

Sentence-level sentiment classification is important to understand
users’ fine-grained opinions. Existing methods for sentence-level
sentiment classification are mainly based on supervised learning.
However, it is difficult to obtain sentiment labels of sentences since
manual annotation is expensive and time-consuming. In this paper,
we propose an approach for sentence-level sentiment classification
without the need of sentence labels. More specifically, we propose
a unified framework to incorporate two types of weak supervision,
i.e., document-level and word-level sentiment labels, to learn the
sentence-level sentiment classifier. In addition, the contextual information of sentences and words extracted from unlabeled sentences
is incorporated into our approach to enhance the learning of sentiment classifier. Experiments on benchmark datasets show that our
approach can effectively improve the performance of sentence-level
sentiment classification.

KEYWORDS
sentiment classification; sentence-level; weak supervision

1

INTRODUCTION

Sentence-level sentiment classification is an important research
topic in sentiment analysis and opinion mining field [11]. Compared with coarse-grained sentiment analysis methods for example
document-level sentiment classification, analyzing sentiments at
sentence level can provide more detailed information on why an
opinion holder likes or dislikes an opinion target, such as a product
or a movie, which is useful for consumers to make more informed
decisions and is helpful for companies to improve their products
and services [15]. Thus, sentence-level sentiment classification has
attracted increasing attentions in recent years and is a hot research
topic in sentiment analysis field [5, 12].
∗ Corresponding

author.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGIR’17, August 07-11, 2017, Shinjuku, Tokyo, Japan
© 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00
DOI: http://dx.doi.org/10.1145/3077136.3080693

973

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

3 THE PROPOSED APPROACH
3.1 Contexts of Sentences and Words

sentiment information of sentences and words is also incorporated
into our approach to enhance the learning of sentiment classifier.
Experiments are conducted on benchmark sentiment datasets. The
experimental results show that our approach can effectively improve the performance of sentence-level sentiment classification,
and outperform many state-of-the-art methods.

2

Although sentiment labels of sentences are difficult to obtain, in
many cases the sentiment relations between them are much easier
to infer [16]. For example, two adjacent sentences from a review in
Kitchen domain may be “It cleaned quickly and required no seasoning. Also, it’s a really pretty skillet.” Since these two sentences are
connected by the coordinating conjunction “also”, they probably
convey the same sentiment. Another example is “These dishes look
very nice on your table, but they have many problems.” Since the
two sentences are connected by the adversative conjunction “but”,
we can infer that they may have opposite sentiments. Motivated
by above observations, we explore to extract the sentiment relations between sentences based on coordinating and adversative
conjunctions. If two adjacent sentences are connected by coordinating conjunctions “and”, “also”, “besides”, and “in addition”, then
we regard that they have the same-sentiment relation. Similarly, if
two adjacent sentences are connected by adversative conjunctions
“however”, “but”, and “although”, then we assume they have the
opposite-sentiment relation.
Inspired by [6, 8], we also extract the sentiment relations between
words. First, if two words have the same POS tag, and they are
connected by coordinating conjunction “and” or used to describe the
same target in the same sentence, then we regard they convey the
same sentiment. Second, if two words are connected by adversative
conjunction “but” and have the same POS tag, then they are assumed
to have opposite sentiments. Since a pair of words may convey
different sentiment relations in different contexts, we propose to
compute the overall sentiment relation score by aggregating all
their sentiment relations extracted from unlabeled sentences. More
specifically, the relation score between words i and j is defined as

RELATED WORK

The coarse-grained sentiment information in labeled documents
has been exploited in several previous works on sentence-level
sentiment classification [5, 12, 14, 15]. These works can be roughly
classified into two categories. The first one is training sentencelevel sentiment classifier only based on labeled documents without
the need of labeled sentences. For example, Täckström and McDonald [15] proposed a sentence-level sentiment classification method
based on hidden conditional random fields (HCRF) which trains
sentiment classifiers for sentences using star-rated reviews. Qu et
al. [12] proposed a weakly supervised multi-experts model (MEM)
which utilizes labeled documents to infer a set of base predictors
using phrase-level predictions, language heuristics, co-occurrence
counts, etc. Then these base predictors are combined in a unified
probabilistic framework to build sentiment classifiers for sentences.
The second category is combining coarse-grained document labels
with fine-grained sentence labels for sentence-level sentiment classification. For example, in [14] two semi-supervised latent variable
models were proposed to incorporate both labeled documents and
labeled sentences to train sentence-level sentiment classifiers. Similarly, Guan et al. [5] proposed a weakly-supervised deep embedding
method which first learns sentence embeddings based on labeled
documents, and then trains sentence-level sentiment classifiers
on the top of these sentence embeddings using labeled sentences.
The difference between our approach and the methods in the first
category is that besides the document-level supervision, our approach can also exploit the sentiment information in word-level
supervision. The difference between our approach and the methods
in the second category is that our approach does not rely on the
availability of labeled sentences, which are very expensive and
time-consuming to obtain.
The contexts of sentences have also been explored in several
existing sentence-level sentiment classification methods. For example, in [15] and [14] the adjacent sentences are assumed to share
the same sentiment in both model learning and sentiment prediction. However, adjacent sentences may have different even opposite
sentiments [16]. In [12], similar sentences are constrained to have
similar sentiments. The sentence similarity is measured by word
sequence kernel. However, sentences with similar word sequences
may also have different sentiments due to the existence of negation.
In [16], the sentiment relations between sentences are extracted
using a discourse tagger. However, feature engineering and manual
annotation are required to train the discourse tagger, both of which
are time-consuming. Our approach does not rely on the discourse
tagger, and the sentiment relations between sentences are extracted
using several simple rules, making our approach much easier to
implement. In addition, to our best knowledge, the sentiment relations between words have seldom been considered in existing
sentence-level sentiment classification methods.

N i,S j −N i,Oj

, where Ni,S j and Ni,Oj represent the frequencies
of words i and j having the same or opposite sentiments in the
unlabeled sentences, and α 0 is a positive smoothing factor. If two
words have a higher frequency to share the same sentiment than
opposite sentiments, then they will have a positive relation score.
Note that Si, j can be negative. In this paper we focus on sentiment
similarity relations between words, and only keep positive relation
scores. Thus, the range of Si, j is [0, 1].
Si, j =

3.2

N i,S j +N i,Oj +α 0

The Model of Our Approach

First we introduce several notations. Assume there are M labeled
documents, and the i t h document consists of mi sentences. Denote
xi, j ∈ RV ×1 as the feature vector of the jt h sentence in the i t h
document, where V is the size of feature set. Denote yi as the
sentiment label of the i t h document. Following many previous
works [5], in this paper we focus on binary sentiment classification,
and yi ∈ {+1, −1}. Denote p ∈ RV ×1 as the word-level sentiment
labels extracted from existing sentiment lexicons. If the i t h word
is labeled as positive (or negative) in these sentiment lexicons,
then pi = +1 (or pi = −1). In other cases, pi = 0. Denote the
contextual sentiment relations between unlabeled sentences as
{(xi,1 , xi,2 , Ri ), i = 1, 2, ..., N }, where Ri ∈ {+1, −1} is the relation
score of the i t h sentence pair xi,1 and xi,2 , and N is the total number
of sentence pairs. Ri = 1 means xi,1 and xi,2 probably convey the

974

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 1: The statistics of the datasets.

same sentiment, and Ri = −1 means they may convey opposite
sentiments. Denote S ∈ RV ×V as the sentiment similarities between
words, where Si, j ∈ [0, 1] is similarity score between words i and j.
The goal of our approach is to incorporate the document-level
supervision, the word-level supervision, and the contextual information of sentences and words to train an accurate sentence-level
sentiment classifier. The objective function of our approach is:

w

+α
+γ

V
Õ

M
Õ
i =1

log(1 + exp(−

m
yi Õi T
w xi, j ))
m i j =1

log(1 + exp(−yi pi w i )) − β

i =1
V Õ
V
Õ
i =1 j=1

Book
DVD
Electronics

N
Õ

T

Ri w

i =1

xi, 1 xTi, 2 w

#Document
975,194
124,438
23,009

0.8
0.75

(1)

Fscore

arg min L(w) =

Labeled Sentences
#Positive #Negative #Total
160
165
355
164
264
428
161
240
401

0.7
0.65

S i, j |w i − w j | + λ kw k22,

Doc
Word
Doc+Word
Doc+Word+Con_Sen
Doc+Word+Con_Word
All

0.6

where α, β, γ and λ are non-negative parameters for word-level
supervision, sentiment relations between sentences, sentiment similarities between words, and L 2 -norm regularization, respectively.
Following many previous works [2, 11], here we select linear classifier for sentence-level sentiment classification, and its parameter
ÍM
y Í i
T
is w ∈ RV ×1 . In the term i=1
log(1 + exp(− mii m
j=1 w xi, j )) we
incorporate the coarse-grained document-level supervision. Instead
of directly using sentiment labels of documents for sentences, in
our approach we constrain the average sentiment score of the sentences in a document is consistent with the label of this document.
The classification loss function used in this term is log loss. By
Í
the term Vi=1 log(1 + exp(−yi pi w i )) we incorporate the word-level
supervision into learning sentiment classifier for sentences, where
w i is the i th element in w. We hope the sentiment classifier learned
by our approach can accurately predict the sentiments of words
ÍN
in existing sentiment lexicons. By the term i=1
Ri wT xi,1 xTi,2 w
we incorporate the information of sentiment relations between
sentences. If two unlabeled sentences have same-sentiment (or
opposite-sentiment) relation, then we constrain the sentiment classifier assigns the same (or opposite) sentiment label to them. We
incorporate the sentiment similarities between words into our apÍ Í
proach by the term Vi=1 Vj=1 Si, j |w i − w j |. It is motivated by
graph-guided fused lasso [3]. If two words have strong sentiment
similarity with each other, then we constrain their weights in the
sentiment classification model are more close. The L 2 -norm regularization term in Eq. (1) is used to control model complexity.

0.55

Book

DVD

Electronics

Figure 1: Performance of our approach with different combinations of sentiment information.
The word-level supervision was extracted from Bing Liu’s sentiment lexicon3 [7]. We used half of the documents as labeled documents to provide document-level supervision, and used the others
to extract the contextual sentiment relations between sentences
and the sentiment similarities between words. Following [2], unigrams and bigrams were used to construct feature vectors. All
the experiments were repeated ten times independently, and the
average results were reported.

4.2

Model Effectiveness

First we conducted experiments to explore the effectiveness of
the model of our approach. More specifically, we want to verify
whether combining document-level and word-level supervision
performs better than using each of them independently. In addition,
we want to verify whether the contextual information of sentences
and words is useful for learning sentiment classifiers of sentences.
Experimental results are shown in Fig. 1, where Doc and Word mean
document-level and word-level supervision respectively. Con_Sen
and Con_Word represent contextual information of sentences and
words respectively. All means all information is incorporated.
Fig. 1 shows that the performance of our approach with only
document-level supervision is limited. This is because a document
usually contains multiple sentences and some of them may convey
opposite sentiments. Thus, the sentiment labels of documents can
only provide coarse-grained information for sentence-level sentiment classification. In addition, the performance of word-level
supervision is also suboptimal, because sentences not containing
any of general sentiment words in sentiment lexicons will be easily
misclassified. According to Fig. 1, by incorporating both documentlevel and word-level supervision, the performance of our approach
can be significantly improved. It indicates that these two types of
supervision contain complementary information with each other,
and combining them together is more effective than using them

4 EXPERIMENTS
4.1 Datasets and Experimental Settings
In our experiments the sentiment dataset built by Täckström and
McDonald1 [15] was used. The sentiment labels of the sentences in
this dataset were manually annotated. Three domains were involved
in our experiments, i.e., Book, DVD, and Electronics. In addition, we
used the Amazon sentiment dataset crawled by Blitzer et al.2 [2] to
obtain labeled documents in these domains. The sentiment labels
of documents were automatically inferred from their ratings. The
detailed statistics of these datasets are illustrated in Table 1.
1 https://github.com/oscartackstrom/sentence-sentiment-data
2 https://www.cs.jhu.edu/~mdredze/datasets/sentiment/

3 https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html

975

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

independently. Besides, the contextual sentiment relations between
sentences can improve the performance of our approach, because
via these relations many unlabeled sentences are incorporated into
the learning process to provide useful constraints over the outputs
of the sentence-level sentiment classifier. In addition, the sentiment
similarities between words are also useful. This is probably because these similarities contain rich information of domain-specific
sentiment words. Moreover, incorporating all types of sentiment
information can further improve the performance of our approach,
indicating that they can collaborate with each other in our approach.

4.3

labeled data is scarce. HCRF [15] and MEM [12] utilize sentiment
labels of documents to learn sentence-level sentiment classifiers.
Our approach performs better than both of them, because our approach can exploit not only document-level but also word-level
supervision for learning sentence-level sentiment classifiers. Although SSLVM [14], WDE [5], and PR [16] exploit sentiment labels
of both sentences and documents, our approach can still outperform them, which validates the effectiveness and advantage of our
approach in sentence-level sentiment classification.

5

Performance Evaluation

In this paper we present an approach for sentence-level sentiment
classification. Our approach does not rely on the fine-grained sentiment labels of sentences, which are difficult to obtain. Instead, our
approach can exploit both document-level and word-level supervision to learn sentence-level sentiment classifiers. In addition, the
contextual information of sentences and words is incorporated into
our approach to enhance the learning of sentiment classifier. Experiments on benchmark datasets show our approach can effectively
improve the performance of sentence-level sentiment classification.

In this section we evaluate the performance of our approach by
comparing it with several baseline methods, including: 1) SVM, LR,
and LS, i.e., support vector machine, logistic regression, and least
square method, which are trained on labeled sentences; 2) CNN,
convolutional neural network for sentence classification [9]; 3) ParaVec, the paragraph vector method [10]; 4) HCRF, the hidden conditional random fields method [15]; 5) SSLVM, the semi-supervised
latent variable model [14]; 6) MEM, the weakly supervised multiexperts model [12]; 7) WDE, the weakly supervised deep embedding
method [5]; 8) PR, the sentence sentiment classification method
with posterior regularization [5]; 9) SSWS, our sentence-level sentiment classification method with weak supervision. For baseline
methods which need fine-grained labels in model learning, we used
half of the labeled sentences for training and the others for test.
Experimental results are shown in Table 2. The performance metric
is macro-averaged Fscore.

ACKNOWLEDGMENTS
This work is supported by the Ministry of Science and Technology of China under Grant No.: 2016YFB0800402 and the National
Natural Science Foundation of China under Grant Nos.: U1536201,
U1536207, and U1405254.

REFERENCES
[1] Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SentiWordNet
3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining.
In LREC. 2200–2204.
[2] John Blitzer, Mark Dredze, Fernando Pereira, and others. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.
In ACL. 440–447.
[3] Xi Chen, Qihang Lin, Seyoung Kim, Jaime G Carbonell, Eric P Xing, and others. 2012. Smoothing proximal gradient method for general structured sparse
regression. The Annals of Applied Statistics 6, 2 (2012), 719–752.
[4] Cícero Nogueira dos Santos and Maira Gatti. 2014. Deep Convolutional Neural
Networks for Sentiment Analysis of Short Texts. In COLING. 69–78.
[5] Ziyu Guan, Long Chen, Wei Zhao, Yi Zheng, Shulong Tan, and Deng Cai. 2016.
Weakly-Supervised Deep Learning for Customer Review Sentiment Classification.
In IJCAI. 3719–3725.
[6] Vasileios Hatzivassiloglou and Kathleen R McKeown. 1997. Predicting the semantic orientation of adjectives. In EACL. 174–181.
[7] Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In
KDD. 168–177.
[8] Sheng Huang, Zhendong Niu, and Chongyang Shi. 2014. Automatic construction
of domain-specific sentiment lexicon based on constrained label propagation.
Knowledge-Based Systems 56 (2014), 191–200.
[9] Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In
EMNLP. 1746–1751.
[10] Quoc V Le and Tomas Mikolov. 2014. Distributed Representations of Sentences
and Documents.. In ICML, Vol. 14. 1188–1196.
[11] Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on
Human Language Technologies 5, 1 (2012), 1–167.
[12] Lizhen Qu, Rainer Gemulla, and Gerhard Weikum. 2012. A Weakly Supervised
Model for Sentence-level Semantic Orientation Analysis with Multiple Experts.
In EMNLP. 149–159.
[13] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning,
Andrew Ng, and Christopher Potts. 2013. Recursive Deep Models for Semantic
Compositionality Over a Sentiment Treebank. In EMNLP. 1631–1642.
[14] Oscar Täckström and Ryan McDonald. 2011. Semi-supervised Latent Variable
Models for Sentence-level Sentiment Analysis. In ACL. 569–574.
[15] Oscar Täckström and Ryan T. McDonald. 2011. Discovering Fine-Grained Sentiment with Latent Variable Structured Prediction Models. In ECIR. 368–374.
[16] Bishan Yang and Claire Cardie. 2014. Context-aware Learning for Sentence-level
Sentiment Analysis with Posterior Regularization. In ACL. 325–335.

Table 2: The performance of different methods.

SVM
LR
LS
CNN
ParaVec
HCRF
SSLVM
MEM
WDE
PR
SSWS

Book
0.6580
0.6694
0.6560
0.6885
0.6204
0.7021
0.7142
0.7207
0.7099
0.7255
0.7428

DVD
0.7071
0.7218
0.7086
0.7689
0.7508
0.7566
0.7821
0.7846
0.7629
0.7931
0.8082

CONCLUSION

Electronics
0.6717
0.6684
0.6668
0.6753
0.6585
0.7615
0.7906
0.7865
0.7726
0.7859
0.8017

According to Table 2, although no labeled sentence is used in our
approach, it can outperform these baseline methods on sentencelevel sentiment classification. Table 2 shows that when labeled sentences are scarce, the performance of directly applying supervised
learning methods such as SVM, LR and LS to learn sentence-level
sentiment classifier is limited. CNN [9] can obtain relatively better
performance than SVM, LR and LS, probably because it can incorporate the information in pretrained word embeddings and capture
local context information. However, its performance is still suboptimal because the labeled samples are insufficient to learn accurate
parameters for the neural networks. Although ParaVec [10] can
incorporate unlabeled data to learn nonlinear and dense representations of sentences, its performance is still unsatisfactory when

976


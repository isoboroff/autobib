SIRIP 1: Start-Ups and Beyond

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Spotify: Music Access At Scale
Fernando Diaz
Spotify
New York, NY
diazf@acm.org

ABSTRACT

2

Spotify provides users with access to a massive repository of streaming music. While some aspects of music access are familiar to the
information retrieval community (e.g. semistructured data, item
recommendation), nuances of the music domain require the development of new models of user understanding, intent modeling,
relevance, and content understanding. These models can be studied
using the large amount of content and usage data at Spotify, allowing us to extend previous results in the music information retrieval
community. In this presentation, we will highlight the research
involved in developing Spotify and outline a research program for
large scale music access.

One of the most important resources provided by a large-scale
production system is large-scale user interaction data. Such data
allows system designers to understand the breadth of user behavior,
with respect to intent, taste, and interaction. While we believe that
web search queries can be placed into categories such as ‘navigational’ or ‘informational’, we do not yet have a similar taxonomy
for music intents. And while we have an understanding of user musical taste in aggregate, we need better understand how it changes
with time for a specific user. Finally, because users are listening
to music in various degrees of engagement with the product (e.g.
cooking, searching for music, studying), feedback is much more
context-specific than in, for example, web search.

CCS CONCEPTS

3

• Information systems → Music retrieval;

SEARCH AND RECOMMENDATION

When a user expresses a music need, Spotify combines its user
and content understanding to determine the right action to take.
An active search for music might be for a known item such as a
specific artist or track, or it might be more descriptive such as ‘good
study music’. On the other hand, a request for a recommendation
can be much vaguer than an active search. In this case, the system
may need to also use the salient parts of user’s context in order to
disambiguate his or her intent.

ACM Reference format:
Fernando Diaz. 2017. Spotify: Music Access At Scale. In Proceedings of SIGIR
’17, August 07-11, 2017, Shinjuku, Tokyo, Japan, 1 pages.
https://doi.org/http://dx.doi.org/10.1145/3077136.3096471

1

USER UNDERSTANDING

CONTENT UNDERSTANDING

Content understanding refers to the development of algorithms
for meaningfully representing audio content. One approach is to
understand the raw audio content [1]. Here, techniques from signal
processing and related disciplines allow for the development of
rich features by hand. Increasingly, deep neural networks have the
ability to automatically learn meaningful features from raw audio
[2, 3].
A complementary approach to learning from raw audio is to
understand the cultural context of audio content. For example, the
fact that a song was produced by a certain musician in a certain
location might be a valid representation if, say, the user only knows
about the musician or location. A system can gather rich cultural information from metadata repositories but, if limited or unavailable,
they might be crawled from publicly available sources [4].
When combined, these approaches can significantly improve
over using either alone [5].

REFERENCES
[1] M. A. Casey, R. Veltkamp, M. Goto, M. Leman, C. Rhodes, and M. Slaney. Contentbased music information retrieval: Current directions and future challenges. Proceedings of the IEEE, 96(4):668–696, April 2008.
[2] E. J. Humphrey, J. P. Bello, and Y. Lecun. Feature learning and deep architectures:
New directions for music informatics. J. Intell. Inf. Syst., 41(3):461–481, Dec. 2013.
[3] A. van den Oord, S. Dieleman, and B. Schrauwen. Deep content-based music
recommendation. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and
K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 26,
pages 2643–2651. Curran Associates, Inc., 2013.
[4] B. Whitman and S. Lawrence. Inferring descriptions and similarity for music from
community metadata. In ICMC, 2002.
[5] B. Whitman and P. Smaragdis. Combining musical and cultural features for
intelligent style detection. In ISMIR, 2002.

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGIR ’17, August 07-11, 2017, Shinjuku, Tokyo, Japan
© 2017 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5022-8/17/08.
http://dx.doi.org/10.1145/3077136.3096471

1349


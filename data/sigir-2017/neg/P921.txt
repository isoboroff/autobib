Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Label Aggregation for Crowdsourcing with Bi-Layer Clustering
Jing Zhang

Victor S. Sheng

School of Computer Science and
Engineering, Nanjing University of
Science and Technology,
200 Xiaolingwei Street,
Nanjing 210094, China
jzhang@njust.edu.cn

Department of Computer Science,
University of Central Arkansas,
Conway, AR 72035, U.S.A.
ssheng@uca.edu

1

Tao Li

School of Computer Science, Florida
International University,
2
School of Computer Science, Nanjing
University of Posts and
Telecommunications, China
taoli@cs.fiu.edu

Clustering, crowdsourcing, inference, label aggregation

depressing facts that (1) none of these algorithms significantly
outperforms the others in most cases; and (2) under a situation
that labelers exhibit low qualities, all of them are mediocre.
The mainstream label aggregation methods are generalpurpose and agnostic, following the same prerequisite that no
prior knowledge (including instance features) can be utilized to
infer integrated labels except for the collected noisy labels. Just
because of this, improving the accuracy of label aggregation faces
great challenges. Since features carry valuable information that
can be used to identify and categorize instances, it might be
unwise to completely ignore the features of the instances in label
aggregation. This paper investigates a completely novel train of
thought to address the crowdsourced label aggregation by jointly
utilizing the noisy labels and the instance features in a general
way. The proposed method is still general-purpose for multiple
application domains. Principally, it utilizes instance features to
remedy the integrated labels that are probably falsely inferred,
which significantly improves the accuracy of label aggregation.

1 INTRODUCTION

2 THE PROPOSED METHOD

Crowdsourcing provides an effective and low cost solution to
collect labels from non-expert workers in open Internet based
marketplaces. Due to the lack of knowledge of these workers, the
quality of labels collected may be very low. A common approach
to address this issue is to collect multiple labels for the same
instance from different workers. Then, a label aggregation
algorithm is utilized to infer the true label for each instance. The
inferred label is also named as integrated label. During the past
several years, the agnostic label aggregation algorithms that solely
utilize crowdsourced multiple noisy labels have been widely
studied. These studies tried to model the complexities of the
crowdsourced labeling from different perspectives, such as
reliability [1, 3, 5, 7, 12], confusion matrices [8, 10, 13, 16],
intentions [1, 6], and biases [4, 11] of labelers, and difficulties of
instances [1, 6, 11, 12]. One common objective of these studies is to
improve the accuracy of label aggregation. However, this is not
easy to achieve. Two comprehensive empirical studies on a large
number of real-world data sets [9, 15] have revealed some

2.1 Preliminaries and Motivations

ABSTRACT
This paper proposes a novel general label aggregation method for
both binary and multi-class labeling in crowdsourcing, namely BiLayer Clustering (BLC), which clusters two layers of features – the
conceptual-level and the physical-level features – to infer true
labels of instances. BLC first clusters the instances using the
conceptual-level features extracted from their multiple noisy labels
and then performs clustering again using the physical-level
features. It can facilitate tracking the uncertainty changes of the
instances, so that the integrated labels that are likely to be falsely
inferred on the conceptual layer can be easily corrected using the
estimated labels on the physical layer. Experimental results on two
real-world crowdsourcing data sets show that BLC outperforms
seven state-of-the-art methods.

KEYWORDS

Let D  { xi , yi , li }iI1 be a crowdsourced labeled data set, where
xi , yi and li are the features, the unknown true label, and the
multiple noisy label set of instance i respectively. Its unknown true
label yi belongs to a set of classes C  {ck }kK1 and element li( j )
provided by worker j in the multiple noisy label set belongs to set
C  {0} , where 0 indicates that labeler j does not provide any label
for instance i. The goal of label aggregation is to estimate the true
label yˆ i for instance i and simultaneously minimize the average
inference error over the entire data set D. The average inference
error can be defined as:
  1 I   i1 I  yˆi  yi  , given {l1 , l2 ,..., l I } ,
I

(1)

where I() is an indicator function.
The proposed method is inspired by [14], where a clusteringbased algorithm GTIC was proposed to infer the true labels of
instances. In [14], the conceptual-level features were extracted to
describe instances. Such features were derived from the noisy
labels obtained from the crowd, reflecting the judgments of
workers. The conceptual-level feature vector for instance i is
defined as  (i )  [1(i ) ,2(i ) ,..., K(i ) , z(i ) ] , where 0   k(i )  1 is the
probability of instance i belonging to class k ( 0  k  K for K-class
K
labeling). For all K classes, we have  k 1k(i )  1 . Parameter  k( i )
can be calculated by Bayesian MAP estimation as follows:

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by
others than ACM must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee. Request permissions from Permissions@acm.org.
SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan
© 2017 ACM ISBN 978-1-4503-5022-8/17/08…$15.00.
http://dx.doi.org/10.1145/3077136.3080679

921

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

N

ˆk(i )   N k(i )   k  1

(i )



  j 1 j  K ,
K

Clustering with Conceptual-Level Features

(2)

where N (i ) and N k( i ) count the total noisy labels and those
belonging to class k on instance i respectively, and   (1,..., K ) ,
( k  0 ) are the hyper parameters of a Dirichlet distribution,
which can be simply set to 1 under an agonistic condition. In
addition, parameter  z( i ) in  (i ) is defined as follows:

 z(i )   k 1 (ˆk(i )1  ˆk(i ) ) / K .
K 1

Supervision
by Physical
Layer
xi
di1

(3)

di3

After constructing the conceptual-level features for each
instance, they are fed to a K-Means clustering algorithm, which
divides all of the instances into K clusters {G1( c ) ,..., GK( c ) } . Each
cluster Gk( c ) is assigned a class label  ( k ) , which also serves as the
integrated labels for all instances in Gk( c ) . All class labels
{ (1) ,...,  ( K ) } are determined as follows:
K

{ (1) ,...,  ( K ) }  arg max 
 ( k )C

k 1

| Gk( c ) |  i1 I(li( k )   ( k ) )

Clustering with Physical-Level Features

Figure 1: Principle of the proposed BLC method
Algorithm Bi-Layer Clustering (BLC)
Input: A sample set D in which each instance has a multiple
noisy label set and has no true label. The number of classes is K.
Output: A sample set D’ with assigned integrated labels.
1. Generate the conceptual-level features (Eq. (2) and Eq. (3)) and
infer an integrated label yˆ i for each instance xi , using Eq. (4).
Calculate the uncertainty U i( c ) of each instance xi based on
the clusters {G1( c ) ,..., GK( c ) } obtained, using Eq. (5).
2. Choose an instance ok(c)  arg min x G( c ) Ui(c) as the initial
i
k
centroid of cluster k on the physical layer. Run a K-Means
clustering with the Euclidean distance on the physical-level
features of instances. This forms clusters {G1( p ) ,..., GK( p ) } .
Calculate the uncertainty U i( p ) of each instance xi based on
these clusters {G1( c ) ,..., GK( c ) } , using Eq. (5).
3. Interpret the class memberships of the clusters {G1( p ) ,..., GK( p ) }
with the integrated labels from the clusters {G1( c ) ,..., GK( c ) } (issue
2 in Section 2.3.) Each instance xi in Gk( p ) is obtained an
estimated label on the physical layer, denoted by  i .
4. Select the instances with high uncertainties from
{G1( c ) ,..., GK( c ) } , denoted by  ( c ) . Meanwhile, select the
instances with small uncertainties from {G1( p ) ,..., GK( p ) } ,
denoted by  ( p ) . (issue 3 in Section2.3)
5. Find the instances, each of which xi satisfies
xi  ( ( c )   ( p ) ) and yˆi  i ,
denoted by a set  . For each xi   , let yˆi  i .
6. Return the sample set D’, in which each instance xi is
assigned an integrated label yˆ i .

|L( k ) |

| L( k ) |

,

(4)

s.t.      
where L( k ) is the noisy label set of cluster Gk( c ) and li( k ) is the ith
element in the set. For xi  Gk( c ) , let yˆi   ( k ) .
Obviously, GTIC solely utilizes the conceptual-level features of
instances to perform clustering for inferring the true labels We
cannot help asking whether the original features of instances (socalled physical-level features) could further improve the accuracy
of label aggregation. As we know, when the features are complex
enough (e.g., high dimensional and heterogeneous), human
judgements are not always better than those of machines.
Furthermore, instances with similar feature values tend to be
clustered together. The falsely induced crowdsourced labels can be
corrected by the notion of the near neighbor similarity. For
example, if we know the exact label of an instance, then its near
neighbors would most likely have the same label, which would
compensate the weakness of human judgments. Thus, the key is to
find out the most uncertain instances judged by humans and
remedy their labels by clustering with the physical-level features.
(1)

(2)

di2

(K )

2.2 The Bi-Layer Clustering Aggregation
Fig. 1 illustrates the principle of the proposed bi-layer clustering
(BLC) method. BLC has two main clustering processes, one at the
conceptual layer and the other at the physical layer. First, we infer
the true labels for all instances by running a clustering algorithm
with the conceptual-level features. The instances in each cluster
will be assigned the same integrated label. Second, we run a
distance-based clustering algorithm (e.g., K-Means) with the
physical-level features of the instances to group instances with
similar physical-level feature vectors together. Third, we use the
clusters on the physical layer to correct the integrated labels of
instances inside the intersection areas of the clusters on the
conceptual layer, because those instances might be assigned
wrong integrated labels with a high probability. As Fig. 1
illustrates, the integrated labels of instances highlighted in red
edges on the conceptual layer are changed according to their
corresponding cluster labels on the physical layer. Note that the
instances highlighted in red edges lie in the intersection areas of
the clusters on the conceptual layer, but not in the intersection
areas of the clusters on the physical layer. The main steps of the
proposed method are presented in Algorithm BLC below.

2.3 Refinement
Issue 1: Uncertainty estimation. BLC takes a unified distancebased uncertainty measure on both conceptual and physical layers.
We believe that the final centroid of each cluster has the least
uncertainty, comparing to the other instances in the same cluster,
because it represents the typical example for its cluster. On the
contrary, the instances whose distances to all centroids are almost
the same have the highest uncertainty. Referring to Fig. 1 again,
we can calculate the uncertainty of instance xi in a yellow circle
based on the distances from itself to the centroids in purple circles.
The uncertainty of instance xi is measured by the entropy as
follows: (Note that the asterisk * represents “c” or “p” for the
conceptual and physical layer clustering respectively.)
K

U i(*)  
k 1

922

d ( xi(*) , ok(*) )



K
l 1

d ( xi(*) , ol(*) )

log

d ( xi(*) , ok(*) )



K
l 1

d ( xi(*) , ol(*) )

,

(5)

Short Research Paper

c1
G1

0

c2

c3

c4

0 18

c5

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

c6

2 0 22

G1

c1

c2

0

0 18

c4

c6

G2

15

1 14

G4

2

5

1 14

G6

0

4

5 8

G2

2

0 70 21

G4

10

G4

10

5

1

2 14

G5

30 5

0 23 10

G5

30 5

0 23 16 10

G6

24 0

4

G6

24 0

4

G3

G5

5 8

0 18

Table 2: Intermediate and final experimental results
Item
AdultCrowd
LeavesCrowd
ACCGTIC
74.3%
62.2%
227
173
|  (c ) |
68.7%
36.4%
ACC(  ( c ) )
470
138
|  ( p) |

c6

5

0 16 9 23

8

c4

0 16 23

7 15
20 0

5 0

c3

G1

G3

2

c2

2 22

G2

2

7 15

c3

2 22

0 16 23

G2

c6

c1

ACC(  ( p ) )
ACCPHY
||
ACC*(  ( c ) )
ACCBLC

c5

Figure 2: Interpretation of the class memberships of
the clusters (results in the first three iterations)
Table 1: Two real-world crowdsourcing data sets
Item
AdultCrowd
LeavesCrowd
#instances
600
384
#classes
2
6
#features
14
64
#labelers
73
83
#labels/instance
20
10
total labels
12000
3840
(*)
i

where U  and U  are the average uncertainties of the instances in
 (*) and  (*) respectively.

3 EXPERIMENTS

where d ( x , o ) is the normalized distance between instance xi
and centroid ok . d ( xi(*) , o(*)
k ) is defined as follows:
d ( xi(*) , ok(*) )  dist ( xi(*) , ok(*) ) Dk(*) ,
(6)

3.1 Experimental Setup
Two real-world data sets were used in our experiments. Data set
AdultCrowd was created from the UCI data set Adult, which is to
predict whether the annual income of a person exceeds $50,000.
We extracted 600 instances from its original data set and posted
them on Amazon Mechanical Turk (AMT) to obtain labels. Data
set LeavesCrowd was created from the UCI data set One-Hundred
Plant Species Leaves, which contains contour images of different
leaves. We extracted 384 instances from six different species, i.e.,
maple (96), alder (48), eucalyptus (48), poplar (48), oak (96), and tilia
(48), and posted them on AMT, asking crowd workers to select
correct species after reading the examples. The characteristics of
the above two data sets are listed in Table 1.
Since there is no general agnostic label aggregation method
that directly utilizes the instance features before, we compare our
method BLC with seven existing methods MV, DS [2], ZC [3], SDS
[13], Minimax [16], IWMV [7] and GTIC [14].

(*)
k

where dist ( x , o ) is the distance between instance xi and
centroid ok and Dk(*) is a normalization factor. Dk(*) is defined as
the average distance of n instances inside the cluster whose
centroid is ok . That is,
Dk(*)  1 n2   i1  j i1 dist ( xi(*) , x (*)
j ) .
n1

n

(7)

Issue 2: Interpretation of the class memberships of the
clusters on the physical layer. In step 3, each cluster obtained
by the physical layer clustering should be designated a class,
whose value is also assigned to the estimated label  i of instance
xi . Since K-Means is unsupervised, the interpretation of the
meanings of clusters should be addressed with the help of the
integrated labels obtained in step 1. First, we create a matrix
M K K , in which row k represents the cluster Gk( p ) and column k
represents class ck. Element mij counts the number of instances in
Gi( p ) whose integrated labels are class cj. That is,
mij   x G I  yˆn  c j  .
(8)
n

63.0%
47.4%
57
52.0%
69.3%

UT  arg minT[1,    ]{1iT U i  U   T  j    U j  U  } , (9)

(*)
k

(*)
i

83.0%
81.3%
81
83.3%
79.8%

3.2 Experimental Results
Effectiveness of BLC. In our first experiment, we investigate the
effectiveness of the proposed BLC method. In this experiment, all
of the crowdsourced labels in each data set were utilized. The
intermediate experimental results in Table 2 show how BLC
improves the performance of GTIC [14].
On AdultCrowd, after inferred on the conceptual layer via GTIC
[14], all instances are assigned integrated labels. The accuracy
ACCGTIC of GTIC is 74.3%. Then, on the conceptual layer, the
integrated labels of all instances are divided into two categories:
high uncertainty group  ( c ) and low uncertainty group  (c) .
Group  ( c ) has 227 instances, occupying 37.8% of AdultCrowd. The
accuracy of  ( c ) (ACC(  ( c ) )) is 68.7%, lower than ACCGTIC (74.3%).
BLC uses the physical layer clustering to improve the accuracy of
 ( c ) . After the physical layer clustering, we obtain a low
uncertainty set  ( p ) , which has 470 instances (occupying 78.3% of
AdultCrowd), and whose accuracy ACC(  ( p ) ) is as high as 83.0%.
Note that the accuracy (ACCPHY) of the physical layer clustering is
81.3%. Comparing the two sets  ( c ) and  ( p ) , the integrated
labels of 81 instances (|Ω|) are replaced with their estimated labels

( p)
i

Then, we find the maximum element mab in the matrix.
Consequently, the class membership of Ga( p ) is set to cb. For
example, in Fig. 2, m35 is the maximum element. We have
G3( p )  c5 . After that, all elements in row a and column b are
removed. The dimensions of the matrix reduce. This procedure
repeats until all clusters have been assigned classes. Again, as Fig.
2 shows, we have G5( p )  c1 and G3( p )  c5 in the second and the
third iteration respectively. Later on, we have G2( p )  c6 ,
G6( p )  c4 and G4( p )  c2 . Finally, all clusters are assigned
different class labels.
Issue 3: Select the instances with high (or low)
uncertainties. In step 4, we must specify the criteria which define
the high uncertainties on the conceptual layer and the low
uncertainties on the physical layer. We can sort all instances in
ascending order of their uncertainties and find a cut point U T . U T
divides the sorted instances into high and low uncertainty sets,
denoted by  (*) and  (*) respectively. U T can be obtained by
solving the following objective function:

923

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

85

proposed method BLC always significantly outperforms all the
seven state-of-the-art methods. The increment of the accuracy lies
within the range 5% ~ 10% (in an absolute value).

80

Accuracy (%)

75
70

MV
DS
SDS

65
60

Minimax
IWMV
GTIC

50
45
70

4 CONCLUSIONS

ZC

55

The traditional general-purpose agnostic label aggregation
methods can hardly improve the accuracy because they
completely ignore the features of the data. To break through this
bottleneck, this paper proposed a novel method BLC that takes the
features of instances into account. BLC first utilizes the
conceptual-level features extracted from crowdsourced labels to
infer the true labels of instances by clustering. Then, the instances
with high probabilities to be falsely inferred by the conceptual
layer clustering are corrected with the help of the clustering
results on the physical layer. Experimental results on two realworld data sets show that the proposed method outperforms seven
state-of-the-art label aggregation methods.

BLC

1 2 3 4 5 6 7 8 9 10 11 1213 14 1516 17 1819 20
(a) #labels per instance (AdultCrowd)

Accuracy (%)

65
60

MV
DS
SDS

55

ZC
Minimax

50
45

IWMV
GTIC
BLC

1

2
3
4
5
6
7
8
9
(b) #labels per instance (LeavesCrowd)

10

Figure 3: Comparison results on two real-word data sets
obtained from the physical layer. After remedying, the accuracy of
the high uncertainty instances ACC*(  ( c ) ) on the conceptual
layer increases to 83.3%. Finally, the overall accuracy (ACCBLC) on
the whole data set is 79.8%, which is much higher than ACCGTIC
(74.3%).
On LeavesCrowd, we extract high uncertainty instances on the
conceptual layer whose accuracy is only 36.4% and elevate their
accuracy to 52.0% with the help of the estimated labels obtained
from physical layer clustering. There exists an interesting
phenomenon. Because LeavesCrowd includes six classes, the
accuracy of its physical layer clustering is rather low (ACCPHY =
47.4%) and that of low uncertainty instances on the physical layer
is also not high (ACC(  ( p ) ) = 63.0%). However, the low accuracy
on its physical layer clustering does not prevent us from obtaining
good results. The absolute increment of the accuracy of  ( c )
reaches 15.6%. Consequently, ACCBLC is significantly higher than
both ACCGTIC and ACCPHY.
Comparisons with seven state-of-the-art methods. To
make more comprehensive comparisons, we investigate their
performance with various numbers of crowdsourced labels per
instance. In AdultCrowd, each instance has 20 crowdsourced labels,
namely the original crowdsourced label set. We conducted 20
rounds of experiments. In the nth round ( 1  n  20 ), for each
instance, we randomly select n labels from the original
crowdsourced label set. Then, we evaluate the performance of all
eight label aggregation methods. Because the n labels for each
instance are randomly selected, for each round we repeated the
experiments 10 times. The average accuracy and the standard
deviation of each method are reported in Fig. 3(a). Since each
instance of LeavesCrowd has 10 crowdsourced labels, there are
totally 10 comparison rounds, showing in Fig. 3(b).
Fig. 3 shows that on the binary labeling data set AdultCrowd,
the differences among the seven existing methods are not
significant, because all these methods perform well under the
binary condition. On the multi-class data set LeavesCrowd, when
the numbers of crowdsourced labels per instance are small (  4 ),
both MV, IWMV and GTIC perform well among the seven existing
methods. As the number of crowdsourced labels per instance
increases, GTIC has a slight advantage among the seven existing
methods. However, under all conditions on both data sets, the

ACKNOWLEDGMENTS
This work was partially supported by the National Natural Science
Foundation of China under Grant 61603186 and Grant 91646116,
the Natural Science Foundation of Jiangsu Province, China, under
Grant BK20160843, the China Postdoctoral Science Foundation
under Grant 2016M590457, the Postdoctoral Science Foundation of
Jiangsu Province, China, under Grant 1601199C, and the Scientific
and Technological Support Project of Jiangsu Province, China,
under Grant BE2016776.

REFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]

924

W. Bi, L. Wang, J.T. Kwok, and Z. Tu. Learning to predict from crowdsourced
data. In UAI, pages 82–91, 2014.
A.P. Dawid and A.M. Skene. Maximum likelihood estimation of observer errorrates using the EM algorithm. Applied Statistics, 28(1): 20–28, 1979.
G. Demartini, D.E. Difallah, and P. Cudré-Mauroux. ZenCrowd: leveraging
probabilistic reasoning and crowdsourcing techniques for large-scale entity
linking. In WWW, pages 469–478, 2012.
E. Kamar, A. Kapoor, and E. Horvitz. Identifying and accounting for taskdependent bias in crowdsourcing. In AAAI HCOMP, pages 92–101, 2015.
D.R. Karger, S. Oh, and D. Shah. Iterative learning for reliable crowdsourcing
systems. In NIPS, 24: 1953–1961, 2011.
A. Kurve, D.J. Miller, and G. Kesidis. Multicategory crowdsourcing accounting
for variable task difficulty, worker skill, and worker intention. IEEE TKDE, 27(3):
794-809, 2015.
H. Li and B Yu. Error rate bounds and iterative weighted majority voting for
crowdsourcing. arXiv preprint arXiv:1411.4086, 2014.
V.C. Raykar, S. Yu, L.H. Zhao, C. Florin, G.H. Valadez, L. Bogoni, and L. Moy.
Learning from crowds. JMLR, 11: 1297–1322, 2010.
A. Sheshadri and M. Lease. SQUARE: a benchmark for research on computing
crowd consensus. In AAAI HCOMP, pages 56–164, 2013.
M. Venanzi, J. Guiver, G. Kazai, P. Kohli, and M. Shokouhi.. Community-based
bayesian aggregation models for crowdsourcing. In WWW, pages 155–164, 2014.
P. Welinder, S. Branson, P. Perona, and S.J. Belongie.. The multidimensional
wisdom of crowds. In NIPS, 23: 2424–2432, 2010.
J. Whitehill, P. Ruvolo, T. Wu, J. Bergsma, and J. Movella. Whose vote should
count more: optimal integration of labels from labelers of unknown expertise. In
NIPS, 22: 2035–2043, 2009.
Y. Zhang, X. Chen, D. Zhou, and M.I. Jordan. Spectral methods meet EM: a
provably optimal algorithm for crowdsourcing. In NIPS, 27: 1260–1268, 2014.
J. Zhang, V.S. Sheng, J. Wu, and X. Wu. Multi-class ground truth inference in
crowdsourcing with clustering. IEEE TKDE, 28(4): 1080–1085, 2016.
Y. Zheng, G. Li, Y. Li, C. Shan, and R. Cheng. Truth inference in crowdsourcing:
Is the problem solved? In VLDB Endowment, 10(5), 2017.
D. Zhou, S. Basu, Y. Mao, and J.C. Platt. Learning from the wisdom of crowds by
minimax entropy. In NIPS, pages 2195–2203, 2012.


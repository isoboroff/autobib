Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Event Early Embedding: Predicting Event
Volume Dynamics at Early Stage
Zhiwei Liu1 , Yang Yang1∗ , Zi Huang2 , Fumin Shen1 , Dongxiang Zhang1 , Heng Tao Shen1 ,
1

Center for Future Media and School of Computer Science and Engineering, University of Electronic Science
and Technology of China 2 The University of Queensland

ABSTRACT

consuming information, such as breaking news, topics and
events. Numerous research endeavors have been dedicated to
characterizing social messages [3] and events. For instance,
on Twitter2 , tweets are attached with timestamps, which can
assist detecting the information flow [12] and depicting the
growth and decay of certain events [7, 8].
In this paper, we study the problem of predicting about
time-series volume of events. Different from majority of existing work [1, 6] that build mathematic models to fit certain
types of mature events, we utilise the limited information to
foresee their future volume dynamics.
To facilitate the understanding of the organization of social
data, we first clarify several concepts, including topic, event,
volume and social noise. If a set of messages are related to
some common subject [2], we define the set of messages as
a topic. Generally, each topic comprises various underlying
constituent parts which lie in different periods. Each constituent part reveals some important aspects of the topic.
Hence, we define the constituent part as event.
We define volume illustrating the total number of messages in a predefined time window. Particularly, in Twitter,
topic volume denotes the number of tweets with the same
hashtags published in a certain time window (e.g., daily and
hourly). Similarly, the searching interest volume is another
type of topic volume provided in Google Trends3 . Event
volume is the number of messages in a constituent part
of a topic. For instance, Figure 1 shows the topic volume
dynamics of Apple in Google Trends. As seen, this topic
is composed of several events, such as Swift for iOS, Apple
Special Event.
The volume of an event rises from the emergence of the
event and decays to zero when the event ends. However,
events are not always readily intelligible within a topic in
that there also exists social noise. In our context, we define
social noise as the ever-lasting irrelevant part to the events
(analogous to white noise in signal processing).
To make a prediction of event volume, most existing work
only consider the volume feature. However, the content information is also useful because events with the same content
information, which implies people’s attitude, often have similar dynamics. Thus, we predict the future dynamics of events
at early stage with both volume and content feature. Our
predicting method is based on locally linear embedding algorithm [10]. For a new coming event, we try to find its
neighbors and construct its future dynamics from previous

Social media has become one of the most credible sources for
delivering messages, breaking news, as well as events. Predicting the future dynamics of an event at a very early stage
is significantly valuable, e.g, helping company anticipate marketing trends before the event becomes mature. However,
this prediction is non-trivial because a) social events always
stay with “noise” under the same topic and b) the information obtained at its early stage is too sparse and limited
to support an accurate prediction. In order to overcome
these two problems, in this paper, we design an event early
embedding model (EEEM) that can 1) extract social events
from noise, 2) find the previous similar events, and 3) predict
future dynamics of a new event. Extensive experiments conducted on a large-scale dataset of Twitter data demonstrate
the capacity of our model on extract events and the promising performance of prediction by considering both volume
information as well as content information.

CCS CONCEPTS
•Information systems → Information retrieval; Web
mining; Information systems applications;

KEYWORDS
social events; volume dynamics; content information; early
prediction
ACM Reference format:
Zhiwei Liu1 , Yang Yang1∗ , Zi Huang2 , Fumin Shen1 , Dongxiang Zhang1 , Heng Tao Shen1 ,. 2017. Event Early Embedding:
Predicting Event
Volume Dynamics at Early Stage. In Proceedings of SIGIR ’17,
August 07-11, 2017, Shinjuku, Tokyo, Japan, , 4 pages.
DOI: http://dx.doi.org/10.1145/3077136.3080700

1

INTRODUCTION

Recent years have witnessed the tremendous power of social
media reshaping the ways of generating, distributing and
∗

Corresponding author: Yang Yang

Permission to make digital or hard copies of all or part of this work
for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage
and that copies bear this notice and the full citation on the first page.
Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee. Request permissions
from permissions@acm.org.
SIGIR ’17, August 07-11, 2017, Shinjuku, Tokyo, Japan
© 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00
DOI: http://dx.doi.org/10.1145/3077136.3080700

2
3

997

https://twitter.com/
https://www.google.com/trends/

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Given a set of n tweets corresponding to a certain topic T,
denoted as T = {ti }n
i=1 . The i-th tweet ti is represented as
a triplet (tpi , ci , tsi ), where tpi is the topic-word ti belonging
to, ci indicates ti ’s content and tsi represents the timestamp.
We further define V = (V (t))|lt=1 and C = (C(t))|lt=1 as the
volume sequence and content sequence, respectively. Here,
V (t) is the number of the tweets in the topic T during the
t-th time interval (e.g., 1 hour), C(t) is the corresponding
collective contents, and l is the length of T’s life cycle.
Suppose T comprises of m events, denoted as {Ej }|m
j=1 ,
where Ej = (Vj , Cj , sj , qj ), Vj = (Vj (t))|lt=1 is the sequence
of tweet volume of Ej and Cj is the collective content of
Ej . Let sj and qj be the start time and end time of Ej ,
respectively. Here we have 1 ≤ sj < qj ≤ l. At any time
before the starting point or after the ending point, the event
volume is 0. By defining the volume of social noise in the
topic as ξ = (ξ(t))|lt=1 , we model the topic volume as below:

Figure 1: Search Interest for Apple. The blue line
is the weekly topic volume of Apple, which is the
hybrid of 5 events and random social noise volume.
After denoising with our method, we can extract the
5 events volume shown in the red area.

V (t) =

events volume. The major contributions of our model are
summarized as follows:

4

(1)

EVENT EARLY EMBEDDING
MODEL

In this section, we elaborate the proposed Event Early
Embedding Model (EEEM). Our model has two important
parts. The first part is the collection of event corpus so than
the new events can be matched with some previous events.
The second part is prediction part, where the future volume
dynamics of a event can be predicted by applying our event
early embedding algorithm.

The rest of the paper is organized as follows. We review
the related work in Section 2. In Section 3, we present
some preliminaries and the details of the proposed model.
Experiments are reported and analyzed in Section 4, followed
by the conclusion in Section 5.

4.1

Social Denoising and Event Extraction

As illustrated in Figure 1, compared to the fast fluctuation
of the volume of social events, the slight variation of noise
volume hints us to make the assumption that the volume of
social noise is an time-invariant constant. Thus, the topic
volume model is simplified as

RELATED WORK

In this section, we discuss some existing works about the
social event prediction.
One of the most important task in event prediction is to
predict the future popularity of tweets [5, 9]. The volume
of event is also the value of popularity of the event though
different from our definition of event. Previous work claim
that modeling the collective behavior of users of a social media
site allows the prediction of popularity of items from the users’
early reaction [9]. After that, another generative model
of predicting the final popularity of tweet is proposed [11].
Different from previous work, in this work, we study how to
predict the future volume of a new event based on limited
information (e.g., 24 hours). We try to predict the numerical
value at every time point so that the dynamic trends of events
can be observed clearly.

3

Vj (t) + ξ(t), t = 1, 2, . . . , l.

j=1

• Early Prediction: We propose a novel event early embedding model to predict event volume trend
given limited data at a very early stage.
• Multi-Feature Fusion: We construct a new event
using both the volume feature and content feature.
• Novel Evaluation Metric: We define a novel divergence function evaluating the difference of our
prediction and ground truth.

2

m
X

V (t) =

m
X

Vj (t) + ξ.

(2)

j=1

Performing integral with time-average for an infinite interval, we arrive at
Z
Z
m
1 T
1 TX
lim
V (t)dt = lim
Vj (t)dt + ξ.
(3)
T →∞ T
T →∞ T
0
0 j=1
It is observable that the sharp variation in topic volume
normally corresponds to the emergence of events, which is
similar to the impulse in a signal. Hence, we may conclude
that most power of topic volume is from social noise. Another
assumption is that under the same topic, different events do
not overlap with each other in view of occurring time. Thus,
as T → ∞, we have
Z
m
m Z
1 X qj
1 TX
lim
Vj (t)dt = lim
Vj (t)dt.
(4)
T →∞ T
T →∞ T
0 j=1
j=1 sj

PRELIMINARY AND PROBLEM
DEFINITION

In this section, we present some preliminary information of
this work.

998

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Since in Eq. (4), the denominator is infinite while the
numerator is finite, thus the value is 0. Substituting Eq. (4)
into Eq. (3), we can obtain
Z
1 T
ξ = lim
V (t)dt.
(5)
T →∞ T
0

reconstruction error:
"T
#
k
e
X
1 X (q)
2
2
|Ve (t) −
ε(w) =
wj Vej (t)| + γ||w||
(9)
2Te t=1
j=1
where Vej is the early volume of corresponding neighbor to wj
and γ is the regularization factor. The weight wj summarizes
the contribution of the jth event at early stage.
Finally, we construct the future volume dynamics, in particular, given a new event at its early stage, the predictive
volume dynamics V (q) (t) of the new event is

Now, we can extract the volume of social events by subtracting the volume of social noise from the volume of topic:
m
X

Vj (t) = V (t) − ξ.

(6)

j=1

Then, we smooth the value such that all the event volume
is greater than zero. Now, we can detect events as the
longest sub-sequences of consecutive non-zero members in
the sequence of the denoised topic volume {V (t) − ξ}|lj=1 .
Figure 1 presents an illustration of the denoising results on
“Apple”, and the red area parts is the extracted events.

4.2

V (q) (t) =

(10)

where V (q) is the predictive volume of the new event E(q) ,
Vj (t) is volume of the neighbors corresponding with the
weight wi . The underlying principle of the model (10) is that
the early volume dynamics of a event is an early embedding
of the future dynamics thus we learn the weights from the
early stage and the future dynamics of new event can be
predicted by reconstruct the dynamics from the neighbors.

In this part, we try to predict the new event volume future
dynamics given only the early stage information. The basic
idea is that we want to reconstruct the new events volume
dynamics by a linear combination of its neighbors.
First we will use the early information to find the neighbors. However, previous events {Ej }|N
j=1 consist of the whole
information of the event from the beginning to the end. Thus,
in case of confusion, we separate the event early information
denoting as {Eej = (Vej , Cej , sj , sj + Te )}, in which Vej is
the event early volume, Cej is the event early content, and
Te is the early time duration.
Given the new event’s early information Ee(q) , we represent
(q)
(q)
the two types of early stage features vectors as xv and xc .
We propose the following similarity-level merge to facilitate
knn search:
(q)

wj Vj (t),

j=1

Event Dynamics Prediction

S (e) (Ee(q) , Eej ) = S (v) (xvj , xv ) · S (c) (x(q)
c , xcj ),

k
X

5

EXPERIMENTAL EVALUATION

In this section, we evaluate the proposed EEEM for predicting
the future volumes of social events at very early stage.

5.1

Data

For evaluation, we employed the Twitter dataset published
by [4]. The dataset contains 10, 681, 232 tweets posted from
2013-08-01 to 2013-11-30. We regarded the trending hashtags
(e.g., #iPad) as topics, which results in 18, 399 topics. We
sorted all the topics in descending order of the topic volume
and kept the top 5, 000 topics as our experimental data.

5.2

(7)

Event Volume Dynamics Prediction

We applied social noise reduction in 5000 topics and selected
the events lasting more than 48 hours so that the event volume
dynamics is long enough, which gives us 16707 samples in
total. We sorted these events in ascending order of their start
time, and chose the top 16507 events to form the historical
event corpus and the rest latest 200 events as new events
samples.

where S (e) (·) is the similarity factor of the new event and
previous event, which is a product of S (v) (·) and S (c) (·),
the volume similarity and content similarity respectively.
(q)
(q)
S (v) (xv , xv ) and S (c) (xc , xc ) are defined as

(q)

kxv − xv k
(v)
(q)


S
(x
,
x
,
v) =

v
(q)

max(kxv − xv k)
(8)
(q)
 (c) (q)

x>
c xc


,
 S (xc , xc ) =
(q)
kxc kkxc k

5.2.1 Evaluation Metric. Here we define a Divergence D(V ∗ , V g )
to characterize the difference between our predicted sequence
V ∗ and the true volume sequence V g of the given event:

where k·k is the `2 norm and max(·) find the maximum value.
(q)
(q)
Note that in order to make S (v) (xv , xv ) and S (c) (xc , xc )
comparable, we project volume feature and content feature to
the scale of [0,1] by considering a maximum as denominator
and cosine similarity respectively.
From the similarity of new event and previous events,
we can find k neighbors which are k most similar events.
To find the reconstruction coefficient vector w, inspired by
LLE algorithm [10], we try to minimize the following early

D(V ∗ , V g ) =

Dist(V ∗ , V g )
,
Sim(V ∗ , V g )

where Dist(·, ·) and Sim(·, ·) are defined as

l
X

(V ∗ (t) − V g (t))2

∗
g

p
,

 Dist(V , V ) =
V g (t) + 1
t=1




∗
g

 Sim(V , V ) =

999

~∗·V
~g
V
,
~ ∗ kkV
~ gk
kV

(11)

(12)

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

600
volume + content feature
volume feature
content feature

60

event volume

560
M

540
520

40
30
20

500

10

480

0

0

5

10

15

20

groud truth
volume + content feature
volume feature
content feature

30
20
10
0

0

time (day)

460
5

10

15

20

25
k

30

35

40

45

50

5

10

15

20

time (day)

(a) D (v+c) = 18.5,D (v) = 18.8,(b) D (v+c) = 1.30,D (v) = 40.3,
D (c) = 1526
D (c) = 3.49

Figure 2: Measurement (sum of logarithm of divergence) of k w.r.t. three types of feature.

Figure 3: Fusion of feature v.s. Single feature.
provide a novel evaluation metric. Extensive experiments on
a large-scale Twitter dataset demonstrated the effectiveness
of our methods.

~ ∗ and V
~ g are the vector versions4 of V ∗ and V g ,
where V
respectively.
While Dist(·, ·) measures the absolute difference between
the two volume dynamics, Sim(·, ·) is the cosine similarity,
which guarantees that even if the absolute distance is somehow far, but we still regard it as a better prediction since
the prediction has a similar variant shape of dynamics to the
real dynamics.

ACKNOWLEDGMENTS
This work was supported in part by the National Natural
Science Foundation of Chinaational Natural Science Foundation of China under Project 61572108, Project 61632007
and Project 61502081, the National Thousand-Young-Talents
Program of China, and the Fundamental Research Funds
for the Central Universities under Project ZYGX2014Z007,
Project ZYGX2015J055 and Project ZYGX2016J080.

5.2.2 Optimization of Parameter. In this part, we optimizing our parameter based on the evaluation result. Given a
test event, we use Eq. (10) to predict the volume and then
exploit Eq.(11) to compute the divergence value. We utilize
the sum of the logarithm of the divergence values of all the
testing samples as evaluation measurement, denoted as M,
as shown in Eq.(13):
X
M=
log(D).
(13)

REFERENCES
[1] C. Bauckhage, K. Kersting, and F. Hadiji. Mathematical models
of fads explain the temporal dynamics of internet memes. In
Proceedings of the ICWSM 2013, 2013.
[2] J. Bian, Y. Yang, and T. Chua. Multimedia summarization for
trending topics in microblogs. In CIKM, pages 1807–1812, 2013.
[3] J. Bian, Y. Yang, and T. Chua. Predicting trending messages
and diffusion participants in microblogging network. In The
37th International ACM SIGIR Conference on Research and
Development in Information Retrieval, SIGIR ’14, Gold Coast
, QLD, Australia - July 06 - 11, 2014, pages 537–546, 2014.
[4] H. Cai, Z. Tang, Y. Yang, and Z. Huang. Eventeye: Monitoring
evolving events from tweet streams. In Proceedings of the ACM
MM’14, pages 747–748, 2014.
[5] H. Cai, Y. Yang, X. Li, and Z. Huang. What are popular: Exploring twitter features for event detection, tracking and visualization.
In ACM MM, pages 89–98, 2015.
[6] X. He, M. Gao, M. Kan, Y. Liu, and K. Sugiyama. Predicting the
popularity of web 2.0 items based on user comments. In SIGIR,
pages 233–242, 2014.
[7] K. Y. Kamath and J. Caverlee. Discovering trending phrases on
information streams. In Proceedings of the 20th CIKM 2011,
pages 2245–2248, 2011.
[8] N. Kanhabua and W. Nejdl. Understanding the diversity of tweets
in the time of outbreaks. In 22nd WWW ’13, pages 1335–1342,
2013.
[9] K. Lerman and T. Hogg. Using a model of social dynamics to predict popularity of news. In Proceedings of the 19th WWW’2010,
pages 621–630, 2010.
[10] S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction
by locally linear embedding. Science, 290(5500):2323–2326, 2000.
[11] Q. Zhao, M. A. Erdogdu, H. Y. He, A. Rajaraman, and
J. Leskovec. SEISMIC: A self-exciting point process model for
predicting tweet popularity. In Proceedings of the 21th ACM
SIGKDD, pages 1513–1522, 2015.
[12] Q. Zhao, P. Mitra, and B. Chen. Temporal and information flow
based event detection from social text streams. In Proceedings
of the Twenty-Second AAAI, pages 1501–1506, 2007.

We set γ fixed with value 0.1. Additionally, we set the
early time duration T e as 24 hours. We tune k in the range
of {1, 2, . . . , 50}. The experimental results are shown in
Figure 2.
5.2.3 Individual Prediction Study. The number of neighbors
is set to 35 as before and the early duration T e is set to 24.
In Figure 3, We show two illustrative predictions of using
differ feature. The divergence of each individual prediction
is denoted as D(v+c) , D(v) and D(c) , respectively.

6

40
ground truth
volume + content feature
volume feature
content feature

50

event volume

580

CONCLUSION

In this work, we studied the problem of predicting event
volume with limited early information. In the context of
social media, we formally defined the concepts of topic, event,
volume and social noise. Furthermore, we view the future
dynamics as a high dimensional embedding generating from
the early low dimensional event dynamics. We proposed a
novel prediction model, termed event early embedding model
(EEEM), to reconstruct a new event from its k neighbors
based on both volume and content features. Additionally, we
~ ∗ and V
~ g may have different lengths. To
In practice, we find that V
make them comparable, we simply expand the shorter one with value
0 to meet the length of the longer one.

4

1000


Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Multitask Learning for Fine-Grained Twitter Sentiment Analysis
Georgios Balikas

Simon Moura

Massih-Reza Amini

Univ. Grenoble Alps, CNRS, Grenoble
INP - LIG / Coffreo
Georgios.Balikas@imag.fr

Univ. Grenoble Alps, CNRS, Grenoble
INP - LIG
Simon.Moura@imag.fr

Univ. Grenoble Alps, CNRS, Grenoble
INP - LIG
Massih-Reza.Amini@imag.fr

ABSTRACT

the others and this would benefit the performance. Knowing that a
tweet is “Positive” in the ternary setting narrows the classification
decision between the VeryPositive and Positive categories in the
fine-grained setting. From a research perspective this raises the
question of whether and how one may benefit when tackling such
related tasks and how one can transfer knowledge from one task
to another during the training phase.
Our focus in this work is to exploit the relation between the sentiment classification settings and demonstrate the benefits stemming
from combining them. To this end, we propose to formulate the
different classification problems as a multitask learning problem
and jointly learn them. Multitask learning [3] has shown great
potential in various domains and its benefits have been empirically
validated [5, 15, 16, 22] using different types of data and learning
approaches. An important benefit of multitask learning is that it
provides an elegant way to access resources developed for similar
tasks. By jointly learning correlated tasks, the amount of usable
data increases. For instance, while for ternary classification one can
label data using distant supervision with emoticons [10], there is
no straightforward way to do so for the fine-grained problem. However, the latter can benefit indirectly, if the ternary and fine-grained
tasks are learned jointly.
The research question that the paper attempts to answer is the
following: Can twitter sentiment classification problems, and finegrained sentiment classification in particular, benefit from multitask
learning? To answer the question, the paper brings the following two main contributions: (i) we show how jointly learning the
ternary and fine-grained sentiment classification problems in a multitask setting improves the state-of-the-art performance,1 and (ii)
we demonstrate that recurrent neural networks outperform models
previously proposed without access to huge corpora while being
flexible to incorporate different sources of data.

Traditional sentiment analysis approaches tackle problems like
ternary (3-category) and fine-grained (5-category) classification
by learning the tasks separately. We argue that such classification
tasks are correlated and we propose a multitask approach based on
a recurrent neural network that benefits by jointly learning them.
Our study demonstrates the potential of multitask models on this
type of problems and improves the state-of-the-art results in the
fine-grained sentiment classification problem.

KEYWORDS
Text Mining; Sentiment Analysis; Deep Learning; Multitask Learning, Twitter Analysis; biLSTM; Text classification
ACM Reference format:
Georgios Balikas, Simon Moura, and Massih-Reza Amini. 2017. Multitask
Learning for Fine-Grained Twitter Sentiment Analysis . In Proceedings of
SIGIR ’17, August 07-11, 2017, Shinjuku, Tokyo, Japan, , 4 pages.
DOI: http://dx.doi.org/10.1145/3077136.3080702

1

INTRODUCTION

Automatic classification of sentiment has mainly focused on categorizing tweets in either two (binary sentiment analysis) or three
(ternary sentiment analysis) categories [8]. In this work we study
the problem of fine-grained sentiment classification where tweets
are classified according to a five-point scale ranging from VeryNegative to VeryPositive. To illustrate this, Table 1 presents examples of
tweets associated with each of these categories. Five-point scales
are widely adopted in review sites like Amazon and TripAdvisor,
where a user’s sentiment is ordered with respect to its intensity.
From a sentiment analysis perspective, this defines a classification
problem with five categories. In particular, Sebastiani et al. [17]
defined such classification problems whose categories are explicitly
ordered to be ordinal classification problems. To account for the
ordering of the categories, learners are penalized according to how
far from the true class their predictions are.
Although considering different scales, the various settings of
sentiment classification are related. First, one may use the same
feature extraction and engineering approaches to represent the
text spans such as word membership in lexicons, morpho-syntactic
statistics like punctuation or elongated word counts [2, 14]. Second,
one would expect that knowledge from one task can be transfered to

2

MULTITASK LEARNING FOR TWITTER
SENTIMENT CLASSIFICATION

In his work, Caruana [3] proposed a multitask approach in which a
learner takes advantage of the multiplicity of interdependent tasks
while jointly learning them. The intuition is that if the tasks are correlated, the learner can learn a model jointly for them while taking
into account the shared information which is expected to improve
its generalization ability. People express their opinions online on
various subjects (events, products..), on several languages and in
several styles (tweets, paragraph-sized reviews..), and it is exactly
this variety that motivates the multitask approaches. Specifically
for Twitter for instance, the different settings of classification like

Publication rights licensed to ACM. ACM acknowledges that this contribution was
authored or co-authored by an employee, contractor or affiliate of a national government. As such, the Government retains a nonexclusive, royalty-free right to publish
or reproduce this article, or to allow others to do so, for Government purposes only.
SIGIR ’17, August 07-11, 2017, Shinjuku, Tokyo, Japan
© 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.
978-1-4503-5022-8/17/08. . . $15.00
DOI: http://dx.doi.org/10.1145/3077136.3080702

1 An open implementation of the system for research purposes is available at https:
//github.com/balikasg/sigir2017.

1005

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

XT

XT −1

X1

LSTM

LSTM

LSTM

LSTM

LSTM

LSTM
biLSTM

X1

X2

Multitask outputs

...

softmax1

H1

HM

XT

Additional Features

HA

softmaxN

Figure 1: The neural network architecture for multitask learning. The biLSTM output is transformed by the hidden layers H 1 , H M and is led to N output layers, one for each of the tasks. The lower part of the network can be
used to incorporate additional information.

Beyond frustrated with my #Xbox360 right now,
VeryNegative and that as of June, @Microsoft doesn’t support it.
Gotta find someone else to fix the drive.
@Microsoft Heard you are a software company.
Why then is most of your software so bad that it
Negative
has to be replaced by 3rd party apps?
@ProfessorF @gilwuvsyou @Microsoft
@LivioDeLaCruz We already knew the media
Neutral
march in ideological lockstep but it is nice of him
to show it.
PAX Prime Thursday is overloaded for me with
@Microsoft and Nintendo indie events going
Positive
down. Also, cider!!! :p
I traveled to Redmond today. I’m visiting with
VeryPositive @Microsoft @SQLServer engineers tomorrow - at
their invitation. Feeling excited.

Table 1: The example demonstrates the different levels of sentiment a tweet may convey.
Also, note the Twitter-specific use of language
and symbols.

dashed line) is fed with embeddings {X 1 , . . . , XT } that correspond
to the T words of a tokenized tweet. Notice, as discussed above, the
biLSTM consists of two LSTMs that are fed with the word sequence
forward and backwards. On top of the biLSTM network one (or
more) hidden layers H 1 transform its output. The output of H 1
is led to the softmax layers for the prediction step. There are N
softmax layers and each is used for one of the N tasks of the multitask setting. In tasks such as sentiment classification, additional
features like membership of words in sentiment lexicons or counts
of elongated/capitalized words can be used to enrich the representation of tweets before the classification step [14]. The lower part
of the network illustrates how such sources of information can
be incorporated to the process. A vector “Additional Features” for
each tweet is transformed from the hidden layer(s) H A and then is
combined by concatenation with the transformed biLSTM output
in the H M layer.

binary, ternary and fine-grained are correlated since their difference lies in the sentiment granularity of the classes which increases
while moving from binary to fine-grained problems.
There are two main decisions to be made in our approach: the
learning algorithm, which learns a decision function, and the data
representation. With respect to the former, neural networks are
particularly suitable as one can design architectures with different
properties and arbitrary complexity. Also, as training neural network usually relies on back-propagation of errors, one can have
shared parts of the network trained by estimating errors on the
joint tasks and others specialized for particular tasks. Concerning the data representation, it strongly depends on the data type
available. For the task of sentiment classification of tweets with
neural networks, distributed embeddings of words have shown
great potential. Embeddings are defined as low-dimensional, dense
representations of words that can be obtained in an unsupervised
fashion by training on large quantities of text [21].
Concerning the neural network architecture, we focus on Recurrent Neural Networks (RNNs) that are capable of modeling shortrange and long-range dependencies like those exhibited in sequence
data of arbitrary length like text. While in the traditional information retrieval paradigm such dependencies are captured using
n-grams and skip-grams, RNNs learn to capture them automatically [7]. To circumvent the problems with capturing long-range
dependencies and preventing gradients from vanishing, the long
short-term memory network (LSTM) was proposed [11]. In this
work, we use an extended version of LSTM called bidirectional
LSTM (biLSTM). While standard LSTMs access information only
from the past (previous words), biLSTMs capture both past and
future information effectively [7, 12]. They consist of two LSTM
networks, for propagating text forward and backwards with the
goal being to capture the dependencies better. Indeed, previous
work on multitask learning showed the effectiveness of biLSTMs
in a variety of problems: [1] tackled sequence prediction, while
[22] and [13] used biLSTMs for Named Entity Recognition and
dependency parsing respectively.
Figure 1 presents the architecture we use for multitask learning.
In the top-left of the figure a biLSTM network (enclosed by the

3

EXPERIMENTAL SETUP

Our goal is to demonstrate how multitask learning can be successfully applied on the task of sentiment classification of tweets. The
particularities of tweets are to be short and informal text spans. The
common use of abbreviations, creative language etc., makes the
sentiment classification problem challenging. To validate our hypothesis, that learning the tasks jointly can benefit the performance,
we propose an experimental setting where there are data from two
different twitter sentiment classification problems: a fine-grained
and a ternary. We consider the fine-grained task to be our primary
task as it is more challenging and obtaining bigger datasets, e.g. by
distant supervision, is not straightforward and, hence we report
the performance achieved for this task.
Ternary and fine-grained sentiment classification were part of
the SemEval-2016 “Sentiment Analysis in Twitter” task [19]. We use
the high-quality datasets the challenge organizers released.2 The
dataset for fine-grained classification is split in training, development, development_test and test parts. In the rest, we refer to these
splits as train, development and test, where train is composed
2 The

datasets are those of Subtasks A and C, available at http://alt.qcri.org/
semeval2016/task4/.

1006

Short Research Paper

Train
Dev.
Test
Ternary

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

|D |

VeryNeg.

Neg.

Neutr.

Pos.

VeryPos.

7,292
1,778
20,632
5,500

111
29
138
-

884
204
2,201
785

2,019
533
10,081
1,887

3,726
887
7,830
2,828

432
125
382
-

Also, SVMcs is an SVM with linear kernel that employs the crammersinger strategy [6] for the multi-class problem. Logistic regression
(LR) is another type of linear classification method, with probabilistic motivation. Again, we use two types of Logistic Regression
depending on the multi-class strategy: LRovr that uses an one-vsrest approach and multinomial Logistic Regression also known as
the MaxEnt classifier that uses a multinomial criterion.
Both SVMs and LRs as discussed above treat the problem as a
multi-class one, without considering the ordering of the classes. For
these four models, we tuned the hyper-parameter C that controls
the importance of the L2 regularization part in the optimization
problem with grid-search over {10−4 , . . . , 104 } using 10-fold crossvalidation in the union of the training and development data and
then retrained the models with the selected values. Also, to account
for the unbalanced classification problem we used class weights to
penalize more the errors made on the rare classes. These weights
were inversely proportional to the frequency of each class. For the
four models we used the implementations of Scikit-learn [20].
For multitask learning we use the architecture shown in Figure
1, which we implemented with Keras [4]. The embeddings are
initialized with the 50-dimensional GloVe embeddings while the
output of the biLSTM network is set to dimension 50. The activation function of the hidden layers is the hyperbolic tangent. The
weights of the layers were initialized from a uniform distribution,
scaled as described in [9]. We used the Root Mean Square Propagation optimization method. We used dropout for regularizing the
network. We trained the network using batches of 128 examples
as follows: before selecting the batch, we perform a Bernoulli trial
with probability p M to select the task to train for. With probability
p M we pick a batch for the fine-grained sentiment classification
problem, while with probability 1 − p M we pick a batch for the
ternary problem. As shown in Figure 1, the error is backpropagated
until the embeddings, that we fine-tune during the learning process.
Notice also that the weights of the network until the layer H M are
shared and therefore affected by both tasks.
To tune the neural network hyper-parameters we used 5-fold
cross validation. We tuned the probability p of dropout after the hidden layers H M , H 1 , H A and for the biLSTM for p ∈ {0.2, 0.3, 0.4, 0.5},
the size of the hidden layer H M ∈ {20, 30, 40, 50} and the probability
p M of the Bernoulli trials from {0.5, 0.6, 0.7, 0.8}.5 During training,
we monitor the network’s performance on the development set and
apply early stopping if the performance on the validation set does
not improve for 5 consecutive epochs.
Experimental results Table 3 illustrates the performance of the
models for the different data representations. The upper part of
the Table summarizes the performance of the baselines. The entry
“Balikas et al.” stands for the winning system of the 2016 edition
of the challenge [2], which to the best of our knowledge holds the
state-of-the-art. Due to the stochasticity of training the biLSTM
models, we repeat the experiment 10 times and report the average
and the standard deviation of the performance achieved.
Several observations can be made from the table. First notice
that, overall, the best performance is achieved by the neural network architecture that uses multitask learning. This entails that

Table 2: Cardinality and class distributions of the datasets.

by the training and the development instances. Table 2 presents
an overview of the data. As discussed in [19] and illustrated in the
Table, the fine-grained dataset is highly unbalanced and skewed
towards the positive sentiment: only 13.6% of the training examples
are labeled with one of the negative classes.
Feature representation We report results using two different feature sets. The first one, dubbed nbow, is a neural bag-of-words that
uses text embeddings to generate low-dimensional, dense representations of the tweets. To construct the nbow representation, given
the word embeddings dictionary where each word is associated
with a vector, we apply the average compositional function that
averages the embeddings of the words that compose a tweet. Simple compositional functions like average were shown to be robust
and efficient in previous work [18]. Instead of training embeddings
from scratch, we use the pre-trained on tweets GloVe embeddings
of [21].3 In terms of resources required, using only nbow is efficient
as it does not require any domain knowledge. However, previous
research on sentiment analysis showed that using extra resources,
like sentiment lexicons, can benefit significantly the performance
[2, 14]. To validate this and examine at which extent neural networks and multitask learning benefit from such features we evaluate
the models using an augmented version of nbow, dubbed nbow+.
The feature space of the latter, is augmented using 1,368 extra features consisting mostly of counts of punctuation symbols (’!?#@’),
emoticons, elongated words and word membership features in several sentiment lexicons. Due to space limitations, for a complete
presentation of these features, we refer the interested reader to [2],
whose open implementation we used to extract them.4
Evaluation measure To reproduce the setting of the SemEval
challenges [19], we optimize our systems using as primary measure
the macro-averaged Mean Absolute Error (MAE M ) given by:
MAE M =

|C |
X
1 X 1
|h (x i ) − yi |
|C | j =1 |Te j |
x i ∈Te j

where |C | is the number of categories, Tej is the set of instances
whose true class is c j , yi is the true label of the instance x i and
h(x i ) the predicted label. The measure penalizes decisions far from
the true ones and is macro-averaged to account for the fact that
the data are unbalanced. Complementary to MAE M , we report the
performance achieved on the micro-averaged F 1 measure, which is
a commonly used measure for classification.
The models To evaluate the multitask learning approach, we
compared it with several other models. Support Vector Machines
(SVMs) are maximum margin classification algorithms that have
been shown to achieve competitive performance in several text
classification problems [19]. SVMovr stands for an SVM with linear
kernel and an one-vs-rest approach for the multi-class problem.
3 urlhttp://nlp.stanford.edu/data/glove.twitter.27B.zip

5 Overall, we cross-validated 512 combinations of parameters. The best parameters
were: 0.2 for all dropout rates, 20 neurons for H M and p M = 0.5.

4 https://github.com/balikasg/SemEval2016-Twitter_Sentiment_Evaluation

1007

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

nbow

nbow+
0.445

SVMovr
SVMcs
LRovr
MaxEnt
Balikas et al. [2]
biLSTM (single task)
biLSTM+Multitask

0.840
0.946
0.836
0.842
-

0.714
0.723
0.712
0.715
0.719

0.827±0.017
0.786±0.025

0.694±0.04
0.685±0.024

0.469

0.481

F1
0.45

0.359
0.30

0.251

0.15

Table 3: The scores on MAE M for the systems. The best (lowest) score is shown in bold and is achieved in the multitask
setting with the biLSTM architecture of Figure 1.

SVMcs

MaxEnt

SVMovr

LRovr

biLSTM biLSTM+
Multitask

Figure 2: F 1 scores using the nbow+ representations. The best
performance is achieved with the multitask setting.
Lastly, while our approach mainly relied on the foundations of [3],
the internal mechanisms and the theoretical guarantees of multitask
learning remain to be better understood.

the system makes use of the available resources efficiently and
improves the state-of-the-art performance. In conjunction with the
fact that we found the optimal probability p M = 0.5, this highlights
the benefits of multitask learning over single task learning. Furthermore, as described above, the neural network-based models
have only access to the training data as the development are hold
for early stopping. On the other hand, the baseline systems were
retrained on the union of the train and development sets. Hence,
even with fewer resources available for training on the fine-grained
problem, the neural networks outperform the baselines. We also
highlight the positive effect of the additional features that previous
research proposed. Adding the features both in the baselines and
in the biLSTM-based architectures improves the MAE M scores by
several points.
Lastly, we compare the performance of the baseline systems with
the performance of the state-of-the-art system of [2]. While [2] uses
n-grams (and character-grams) with n > 1, the baseline systems
(SVMs, LRs) used in this work use the nbow+ representation, that
relies on unigrams. Although they perform on par, the competitive performance of nbow highlights the potential of distributed
representations for short-text classification. Further, incorporating
structure and distributed representations leads to the gains of the
biLSTM network, in the multitask and single task setting.
Similar observations can be drawn from Figure 2 that presents
the F 1 scores. Again, the biLSTM network with multitask learning
achieves the best performance. It is also to be noted that although
the two evaluation measures are correlated in the sense that the
ranking of the models is the same, small differences in the MAE M
have large effect on the scores of the F 1 measure.

4

0.459

5

ACKNOWLEDGEMENTS

This work is partially supported by the CIFRE N 28/2015.

REFERENCES
[1] Héctor Martínez Alonso and Barbara Plank. 2016. Multitask learning for semantic
sequence prediction under varying data conditions. arXiv:1612.02251 (2016).
[2] Georgios Balikas and Massih-Reza Amini. 2016. TwiSE at SemEval-2016 Task 4:
Twitter Sentiment Classification. In SemEval@NAACL-HLT 2016. 85–91.
[3] Rich Caruana. 1997. Multitask Learning. Machine Learning 28, 1 (1997), 41–75.
[4] François Chollet. 2015. Keras. https://github.com/fchollet/keras. (2015).
[5] Ronan Collobert and Jason Weston. 2008. A unified architecture for natural
language processing: deep neural networks with multitask learning. In ICML.
[6] Koby Crammer and Yoram Singer. 2001. On the Algorithmic Implementation of
Multiclass Kernel-based Vector Machines. JMLR 2 (2001), 265–292.
[7] Chris Dyer, Miguel Ballesteros, Wang Ling, Austin Matthews, and Noah A.
Smith. 2015. Transition-Based Dependency Parsing with Stack Long Short-Term
Memory. In ACL. 334–343.
[8] Anastasia Giachanou and Fabio Crestani. 2016. Like It or Not: A Survey of Twitter
Sentiment Analysis Methods. ACM Comput. Surv. 49, 2 (2016), 28:1–28:41.
[9] Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training
deep feedforward neural networks. In AISTATS. 249–256.
[10] Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classification
using distant supervision. CS224N Project Report, Stanford 1 (2009), 12.
[11] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural
computation 9, 8 (1997), 1735–1780.
[12] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF Models for
Sequence Tagging. CoRR abs/1508.01991 (2015).
[13] Eliyahu Kiperwasser and Yoav Goldberg. 2016. Simple and Accurate Dependency
Parsing Using Bidirectional LSTM Feature Representations. TACL (2016).
[14] Svetlana Kiritchenko, Xiaodan Zhu, and Saif M Mohammad. 2014. Sentiment
analysis of short informal texts. JAIR (2014), 723–762.
[15] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Deep Multi-Task Learning
with Shared Memory for Text Classification. In EMNLP. 118–127.
[16] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Recurrent Neural Network
for Text Classification with Multi-Task Learning. In IJCAI. 2873–2879.
[17] Giovanni Da San Martino, Wei Gao, and Fabrizio Sebastiani. 2016. Ordinal Text
Quantification. In SIGIR. 937–940.
[18] Jeff Mitchell and Mirella Lapata. 2010. Composition in Distributional Models of
Semantics. Cognitive Science 34, 8 (2010), 1388–1429.
[19] Preslav Nakov, Alan Ritter, Sara Rosenthal, Fabrizio Sebastiani, and Veselin
Stoyanov. 2016. SemEval-2016 Task 4: Sentiment Analysis in Twitter. In
SemEval@NAACL-HLT. 1–18.
[20] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M.
Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine
Learning in Python. JMLR 12 (2011), 2825–2830.
[21] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove:
Global Vectors for Word Representation. In EMNLP. 1532–1543.
[22] Barbara Plank. 2016. Keystroke dynamics as signal for shallow syntactic parsing.
In COLING. 609–619.

CONCLUSION

In this paper, we showed that by jointly learning the tasks of ternary
and fine-grained classification with a multitask learning model, one
can greatly improve the performance on the second. This opens
several avenues for future research. Since sentiment is expressed in
different textual types like tweets and paragraph-sized reviews, in
different languages (English, German, ..) and in different granularity
levels (binary, ternary,..) one can imagine multitask approaches that
could benefit from combining such resources. Also, while we opted
for biLSTM networks here, one could use convolutional neural
networks or even try to combine different types of networks and
tasks to investigate the performance effect of multitask learning.

1008


Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Entity Set Expansion via Knowledge Graphs
Xiangling Zhang

Renmin University of China
Beijing, China
zhangxiangling@ruc.edu.cn

Yueguo Chen∗

Xiaoyong Du

Renmin University of China
Beijing, China
duyong@ruc.edu.cn

Renmin University of China
Beijing, China
chenjun2013@ruc.edu.cn

Ke Wang

Ji-Rong Wen

Simon Fraser University
Burnaby, Canada
wangk@cs.sfu.ca

Renmin University of China
Beijing, China
jrwen@ruc.edu.cn

similarity between a pair of entities in knowledge graphs (KGs)
which can be adopted to solve the ESE problem. Metzger et al.
[6] propose a solution to ESE called QBEES based on the common
features shared by the seeds. It however ignores the deficiency
(incompleteness) of the KGs which affects the precision. The association rule mining (ARM) algorithm [1] can also be adapted to solve
the ESE problem. However, it lacks of an effective ranking model,
which cannot distinguish the importance of the common features
shared among seeds.
Knowledge graphs such as DBpedia and Freebase are widely
used in the fields of web search and question answering. The facts
in KGs are typically represented by triples (< s, p, o >) describing
the properties of the subjects as well as the relations among entities.
We utilize p − to represent the inverse relation of the predicate p.
The whole KGs can be represented as directed and labeled graphs.
Figure 1 shows an example of a KG. Although huge, exsting KGs
are still incomplete. For example, 71% of people in Freebase lack
place of birth information [4].

ABSTRACT
The entity set expansion problem is to expand a small set of seed
entities to a more complete set of similar entities. It can be applied in applications such as web search, item recommendation
and query expansion. Traditionally, people solve this problem by
exploiting the co-occurrence of entities within web pages, where
latent semantic correlation among seed entities cannot be revealed.
We propose a novel approach to solve the problem using knowledge graphs, by considering the deficiency (e.g., incompleteness)
of knowledge graphs. We design an effective ranking model based
on the semantic features of seeds to retrieve the candidate entities.
Extensive experiments on public datasets show that the proposed
solution significantly outperforms the state-of-the-art techniques.

KEYWORDS
Knowledge Graph; Entity Set Expansion; Entity Search

1

Jun Chen

Renmin University of China
Beijing, China
chenyueguo@ruc.edu.cn

INTRODUCTION

The entity set expansion (ESE) problem is to find similar entities to
a given small set of seed entities. For example, given the seed entities Barack Obama, John Kennedy and Franklin Roosevelt, we
may expect to find entities such as Bill Clinton and Jimmy Carter
because they are all US presidents from the Democratic Party. It
can be widely used in many applications such as web search (search
by examples), item recommendation and query expansion [10].
Traditionally, people solve this problem using a web corpus (e.g.,
SEAL [9] and BBR [2]), by evaluating the similarities between candidate entities and the seeds based on their surrounding contexts
within the corpus. Entities that co-occur more frequently with the
seeds are likely to have higher similarities. Unfortunately, these
methods are time-consuming since both web crawling and entity
extraction are costly. Moreover, common features shared by the
seeds cannot be revealed by these methods. There have been a
number of path-based similarity measures [7, 8] to evaluate the

Steve_Starkey
producer

producer

Contact

Gary_Sinise

Brian_Grazer

starring

producer

Forrest_Gump

Apollo_13_(film)

director

starring

director

director

Philadelphia_(film)

subject

subject

starring
Tom_Hanks

director
subject

Jonathan_Demme

producer

type
starring subject

subject
Robert_Zemeckis

Films_directed_by
_Robert_Zemeckis

Ron_Howard
director

starring

American_films

Film
type

subject
Cast_Away

Edward_Saxon

type
type

producer

Jack_Rapke

Figure 1: A running example, where a dashed triple <
Apollo 13 (f ilm), starrinд,Tom Hanks > is missed.
In this paper, We propose a ranking model to effectively evaluate
the similarity of entities to a small number of given seeds, according
to the semantic correlations (called k-relaxed common semantic features) among entities in knowledge graphs. The model is designed
to handle the incompleteness of knowledge graphs. We use an example of Figure 1 to give a quick view of the idea. Suppose the user’s
intention is Tom Hanks movies where he plays a leading role and he
issues a query of three seeds, Forrest Gump, Apollo 13 (f ilm), and
Philadelphia (f ilm). We may find that two seeds have the same
predicate starrinд to the same entity Tom Hanks, which implies
that Tom Hanks played a role in them. We therefore can apply the
label starrinд and the entity Tom Hanks as a 1-relaxed common

∗ Yueguo

Chen is the corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGIR ’17, August 07–11, 2017, Shinjuku, Tokyo, Japan.
© 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00
DOI: http://dx.doi.org/10.1145/3077136.3080732

1101

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

feature among the given seeds. Based on this common feature, we
can find some other entities (e.g. Cast Away) sharing the same
common feature as the majority of the seeds, and it therefore can
be applied for ranking candidate entities.

CSFs whose length is extended up to h. However, those CSFs longer
than one will not be relaxed to avoid generating too many false
positive CSFs.

2

The ranking model of entities is designed as follows:
Õ
r (e) =
d(π ) ∗ r (π , Q)

3

COMMON SEMMANTIC FEATURE

Definition 2.1 (Semantic Feature). A semantic feature π = ea : P
in a KG K is composed of an anchor entity ea , and a sequence of
labels P = l 1 /l 2 /. . . /ln .
A semantic feature (SF) is used to represent a common feature shared by a set of target entities. For example, to describe
the movies where Tom Hanks played a role, we can apply the SF
π1 =Tom Hanks:starrinд− . For another example, if we want to define people who directed movies where Tom Hanks played a role,
the SF can then be written as: π2 =Tom Hanks:starrinд− /director ,
which has two predicates to define the relation. The length of a SF
is the number of labels (predicates) in P. It can be larger than one
when P is a tandem of several predicates (e.g., π 2 ), although the
cases of length one (a direct relation) are used more often.
If an entity e has a relation P with the anchor entity ea , we say
that e is a target entity of π =ea :P, which is denoted as e |= π . The
set of target entities of a SF π =ea :P is denoted as E(π ) = {e |e |= π }.
For a given set of seed entities, we may find some SFs whose target
entities contain all those seed entities. They are defined as the
common semantic features (shorted as CSFs) of the seeds. We use
Φ(Q) to denote the set of CSFs for the seeds in a query Q. For
example, for the seed entity set {Forrest Gump, Apollo 13 (f ilm),
Philadelphia (f ilm)}, SFs π3 =Film:type − and π 4 =
American f ilms:subject − are their CSFs.
To overcome the deficiency of KGs, we relax the definition of
CSFs as follows.

RANKING MODEL
(1)

π ∈Φ̃(Q ) ∧ e |=π

It is basically an aggregation of the score of each CSF π ∈ Φ̃(Q)
that e satisfies, which is further evaluated as the product of two
components d(π ), and r (π , Q), where d(π ) is the discriminability
of π , and r (π , Q) is the relevance of π to Q.

3.1

Discriminability of CSFs

It is likely that many CSFs can be found from KGs, although only
some of them are useful for finding similar entities of seeds. For
example, to characterize the seeds, π 1 is more specific than π 3
because |E(π1 )|  |E(π 3 )|. We therefore need a measure to evaluate
the discriminability of CSFs on finding similar entities. Intuitively,
the discriminability of π is then defined as:
1
d(π ) =
(2)
|E(π )|
Larger |E(π )| means that entities in E(π ) are more loosely correlated in terms of the constraint of π . It therefore has a smaller
discriminability of the relevant entities.

3.2

Relevance of CSFs

The relevance of a CSF π to the query Q, is evaluated as:
Ö
r (π , Q) =
p(e, π )

Definition 2.2 (k-relaxed CSF). A semantic feature π is a k-relaxed
CSF to a set of m entities in Q, if |E(π ) ∩ Q | ≥ m − k.
A k-relaxed CSF π requires that at least m −k entities of the seeds
are target entities of π , i.e., |E(π ) ∩ Q | ≥ m − k. We use k-CSF to
denote a k-relaxed CSF, and Φk (Q) to represent the set of k-relaxed
CSFs of the seed set Q. To solve the ESE problem using KGs, we
need to follow two steps to rank entities based on the proposed CSF:
1) compute the set of CSFs (Φ̃(Q)) according to the given query Q;
2) retrieve and rank the candidate entities (target entities excluding
the seeds) satisfying the detected CSFs in Φ̃(Q).
As discussed above, due to the limits of the coverage of KGs, there
may be a very small number (or even not any) of CSFs (of length
one) shared by all the seeds in Q, we therefore apply the relaxation
of CSFs by allowing some seeds not satisfying the CSFs. Moreover,
the length of CSFs can be extended to be larger than one, so as to
include more CSFs indicating indirect common features. However,
the relaxation and extension of CSFs will of course generate more
false positives of common features that may not be desired by the
user. In addition, more CSFs will reduce the search performance as
well. The selection of CSFs for ranking entities, therefore has to be
carefully designed.
Let Φhk (Q) be the set of k-CSFs of Q whose length is no more
than h, where k ≥ 0 and h ≥ 1. In our solution, we apply the
Ð
union of two sets for ranking entities, i.e., Φ̃(Q) = Φk1 (Q) Φh0 (Q),
where Φk1 (Q) includes k-CSFs of length one, and Φh0 (Q) includes

(3)

e ∈Q

where p(e, π ) is the probability of e satisfying π . For e |= π , p(e, π )
is naturally evaluated as 1. However, for a relaxed k-CSF, there can
be at most k seeds that do not satisfy π , which may be caused by
the deficiency of the KGs. We therefore need to evaluate p(e, π ) for
those seeds that do not satisfy π . Borrowing the idea of collaborative filtering in recommendation systems, we evaluate p(e, π ) by
considering the likelihood of e satisfying similar CSFs of π .

1

 Í

0
0
0
I (e, π )w (π , π )
p(e, π ) =
π ∈Ψ(π )
Í

0

0
w (π , π )
π ∈Ψ(π )

0

0

if e |= π
otherwise
0

0

where I (e, π ) = 1 if e |= π , otherwise I (e, π ) = 0; w(π , π ) =
0

|E(π )∩E(π ) |
,
|E(π ) |

0

0

0

which determines the weight of π ; Ψ(π ) = {π |π =

Ð 0 0
ea : Px } {π |π = e x : P } with π = ea : P and the length of Px
is one. Obviously, the set of similar CSFs of π , Ψ(π ), is derived by
substituting the anchor entity (from ea to any other e x ) or the path
(from P to any other Px of length one) of π = ea : P respectively.

4

EXPERIMENTS

The DBpedia v3.9 is applied as the KGs of our experiments. Two
test datasets are used in our study. QALD [5], the Question Answering over Linked Data campaign, aims to answer natural language
questions using linked data sources. After removing the redundant

1102

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 1: Comparison on the QALD dataset
solution
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER

seeds
2
2
2
2
2
2
3
3
3
3
3
3
4
4
4
4
4
4
5
5
5
5
5
5
mix
mix
mix
mix
mix
mix

p@5
.377
.340
.147
.507
.503
.547•∗
.453
.393
.170
.557
.550
.613•∗
.420
.363
.197
.557
.527
.613•∗
.410
.350
.173
.520
.503
.563•∗
.447
.373
.183
.517
.537
.633•∗

p@10
.290
.305
.122
.400
.422
.460•∗
.363
.335
.143
.440
.468
.498•∗
.350
.312
.163
.453
.430
.502•∗
.317
.323
.145
.428
.418
.465•∗
.347
.328
.155
.408
.443
.510•∗

p@20
.208
.245
.100
.320
.322
.372•∗
.267
.276
.127
.362
.372
.387•∗
.270
.270
.138
.362
.348
.392•∗
.247
.273
.127
.348
.342
.381•∗
.249
.262
.137
.328
.337
.403•∗

MRR
.550
.446
.264
.654
.662
.699•∗
.591
.505
.270
.688
.665
.773•∗
.539
.526
.308
.668
.716
.801•∗
.535
.515
.282
.638
.665
.726•∗
.592
.477
.292
.626
.646
.799•∗

Table 2: Comparison on the INEX dataset

R-pre
.269
.263
.113
.369
.377
.457•∗
.340
.298
.131
.423
.446
.501•∗
.354
.302
.153
.452
.420
.525•∗
.352
.304
.153
.449
.426
.515•∗
.335
.298
.141
.412
.433
.559•∗

solution
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER
SEAL
BBR
LDSD
QBEES
ARM
ESER

topics, we get a dataset of 60 topics from QALD-2, QALD-3 and
QALD-4. In INEX-XER 2009 (shorted as INEX with 55 topics) [3],
a topic contains a natural language question asking for a list of
entities. In addition, it also provides several seed entities as the
examples of the desired entities. We use the label ESER (for testID)
to indicate that the test is under the default setting. All significant
tests are conducted using a one-tailed t-test at a significance level
of p = 0.05.

4.1

seeds
2
2
2
2
2
2
3
3
3
3
3
3
4
4
4
4
4
4
5
5
5
5
5
5
mix
mix
mix
mix
mix
mix

p@5
.412∗
.304
.219
.392
.319
.400∗
.462∗
.292
.227
.362
.281
.500∗
.423∗
.277
.246
.362
.292
.504?
∗
.377
.300
.300
.246
.315
.492?
∗
.473∗
.323
.262
.423
.350
.515?
∗

p@10
.388∗
.248
.200
.338
.287
.383∗
.433∗
.246
.210
.317
.260
.415∗
.383∗
.235
.235
.312
.256
.446?
∗
.340
.250
.292
.215
.267
.433?
∗
.398∗
.277
.227
.371
.304
.440?
∗

p@20
.331∗
.213
.153
.288
.231
.287∗
.354∗
.211
.172
.255
.216
.311∗
.319∗
.210
.176
.234
.216
.341?
∗
.284
.208
.203
.169
.211
.336?
∗
.305∗
.221
.164
.276
.239
.350?
∗

MRR
.542∗
.418
.461
.556
.496
.551∗
.547∗
.470
.401
.532
.435
.684?
∗
.530∗
.447
.408
.451
.493
.633?
∗
.418
.530
.535
.342
.484
.629?
∗
.644∗
.504
.496
.591
.535
.701?
∗

R-pre
.327∗
.209
.166
.282
.244
.304∗
.377∗
.208
.184
.256
.224
.340∗
.339∗
.213
.179
.229
.222
.376?
∗
.311
.219
.208
.169
.239
.381?
∗
.330∗
.251
.204
.299
.273
.409?
∗

When looking into the impact of the number of seeds m on the
performance of the different solutions, we find that most solutions
perform worst when m = 2, which means that there are not enough
seeds to distinguish the common features shared among the seeds.
When m is enlarged from 2 to 5, the performance of SEAL and ESER
basically increases. However, the growth rate is not significant
when m > 3. For ESER, it benefits more from the enlargement of m
on the INEX dataset than on the QALD dataset. This is reasonable
because more seeds help ESER to discover more CSFs in the INEX
dataset which are more implicit than those in QALD.

An Overall Comparison

We first test the performance of the compared solutions using 5
groups of different numbers of seeds. Note that the mix group
contains topics whose numbers of seeds are between 2 to 5. In
general, LDSD [7] performs worse than the others on both datasets,
which shows that a simple semantic distance approach on entities
of KGs is far from judging effective semantic correlations among
entities. Generally, ESER performs the best on almost all the test
cases, with two exceptions beaten by SEAL [9] on the INEX dataset
when the query contains only 2 or 3 seeds. SEAL benefits a lot from
the usage of Google search engine. The way of using frequent item
sets on predicate-object pairs serves the purpose of finding common
features of seeds. However, the lack of an effective ranking model
causes that ARM [1] performs worse than ESER. The notation ∗
denotes significant difference over ARM, the notation • denotes
significant difference over QBEES [6] in Table 1, and the notation
? denotes significant difference over SEAL in Table 2.

4.2

Effectiveness of The Ranking Model

Two components of ESER affect the performance of its ranking
model: d(π ) and r (π , Q). This experiment is designed to look into
the performance of individual components by varying the overall
ranking model. When a component is not applied in the ranking
model, we simply set it 1. The results of the tests on two datasets are
shown in Table 3 and Table 4 respectively. We apply 4 variations of
the 2 components, with none of them applied as the baseline (in this
case, candidate entities are ranked simply based on the number of kCSFs they satisfy). Note that this experiment is conducted over the
mix of QALD and the mix of INEX datasets individually. The results
show that the 2 individual components can improve the search
performance over the baseline approach (the first row of the two
tables). The best performance is achieved when both components
are applied (ESER), which is exactly the proposed ranking model.

1103

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Table 3: Alternative ranking models on the QALD
testID d (π ) r (π, Q )
q1
1
1
q2 Eqn. 2
1
q3
1
Eqn. 3
ESER Eqn. 2 Eqn. 3

Table 4: Alternative ranking models on the INEX

p@5 p@10 p@20 MRR R-pre
.493 .403 .326 .695 .399
.560∗ .452 .359 .739 .453
.550∗ .442∗ .350∗ .771∗ .462∗
.633∗ .510∗ .403∗ .799∗ .559∗

testID d (π ) r (π, Q ) p@5 p@10
i1
1
1
.435 .350
i2
Eqn. 2
1
.454 .410∗
i3
1
Eqn. 3 .496∗ .427∗
ESER Eqn. 2 Eqn. 3 .515∗ .440∗

Table 5: Strategies of picking CSFs on QALD
testID
q5
q6
q7
q8
q9
q10
q11
q12
q13
q14
ESER
q16
q17
q18

4.3

Φ̃(Q )
Φ01 (Q )
Φ11 (Q )
Φ21 (Q )
Φ31 (Q )
Ð
0
Φ1 (Q ) Φ02 (Q )
Ð
1
Φ1 (Q ) Φ02 (Q )
Ð
1
Φ1 (Q ) Φ12 (Q )
Ð
Φ21 (Q ) Φ02 (Q )
Ð
2
Φ1 (Q ) Φ12 (Q )
Ð
Φ21 (Q ) Φ22 (Q )
Ð
3
Φ1 (Q ) Φ02 (Q )
Ð
3
Φ1 (Q ) Φ12 (Q )
Ð
Φ31 (Q ) Φ22 (Q )
Ð
3
Φ1 (Q ) Φ32 (Q )

p@5
.560
.593
.613∗
.623∗
.583
.607∗
.640∗
.623∗
.640∗
.643∗
.633∗
.647∗
.650∗
.657∗

p@10
.462
.478
.490
.493∗
.482∗
.498∗
.520∗
.507∗
.515∗
.518∗
.510∗
.517∗
.520∗
.523∗

p@20
.371
.383
.384
.386
.394∗
.401∗
.418∗
.402∗
.408∗
.408∗
.403∗
.410∗
.410∗
.412∗

MRR
.663
.719∗
.769∗
.783∗
.714∗
.739∗
.789∗
.786∗
.801∗
.793∗
.799∗
.812∗
.804∗
.812∗

Table 6: Strategies of picking CSFs on INEX
R-pre
.498
.525
.534
.537
.527∗
.549∗
.548∗
.556∗
.553∗
.547∗
.559∗
.556∗
.551∗
.552∗

testID
i5
i6
i7
i8
i9
i10
i11
i12
i13
i14
ESER
i16
i17
i18

Φ̃(Q )
Φ01 (Q )
Φ11 (Q )
Φ21 (Q )
Φ31 (Q )
Ð
0
Φ1 (Q ) Φ02 (Q )
Ð
1
Φ1 (Q ) Φ02 (Q )
Ð
1
Φ1 (Q ) Φ12 (Q )
Ð
Φ21 (Q ) Φ02 (Q )
Ð
2
Φ1 (Q ) Φ12 (Q )
Ð
Φ21 (Q ) Φ22 (Q )
Ð
3
Φ1 (Q ) Φ02 (Q )
Ð
3
Φ1 (Q ) Φ12 (Q )
Ð
Φ31 (Q ) Φ22 (Q )
Ð
3
Φ1 (Q ) Φ32 (Q )

p@5
.458
.500
.492
.512
.485∗
.519∗
.538∗
.508
.527∗
.519∗
.515∗
.531∗
.519∗
.527∗

p@10
.392
.433∗
.429∗
.448∗
.412
.442∗
.473∗
.437∗
.469∗
.469∗
.440∗
.471∗
.469∗
.471∗

p@20
.299
.328∗
.332∗
.344∗
.324
.347∗
.345∗
.350∗
.349∗
.347∗
.350∗
.349∗
.347∗
.346∗

MRR
.578
.672∗
.697∗
.717∗
.611
.675∗
.696∗
.701∗
.721∗
.720∗
.701∗
.721∗
.720∗
.720∗

R-pre
.349
.387∗
.390∗
.396∗
.381∗
.408∗
.418∗
.409∗
.421∗
.418∗
.409∗
.421∗
.418∗
.416∗

solution may also work by discovering some common semantic
features shared by the seeds.

Impacts of Selecting CSFs

ESER has two parameters that determine the set Φ̃(Q) of CSFs
used for retrieving and ranking entities, and therefore affect the
search performance. One is the parameter k used in discovering
k-CSFs. The other is the parameter h used for constraining the
length of CSFs. In this experiment, we test the impacts of these two
parameters using the mix of QALD and the mix of INEX. The results
are shown in Table 5 and Table 6. The significant tests are compared
with the baselines (q5 and i5) where k = 0 and h = 1. For q5∼q8
and i5∼i8, we set h = 1, and enlarge k from 0 to 3. According to
the results, the performance basically increases when k is enlarged,
showing the effectiveness of k-relax CSFs for picking CSFs when
the length of CSFs is limited to one.
When studying the impacts of relaxing 2-hop CSFs, we find that
it may slightly reduce the search performance (e.g., q13 and q14
v.s. q12) on the QALD dataset. However, for INEX dataset, a small
relaxation (k = 1) of 2-hop CSFs is helpful. This is also because
INEX has a lower mapping quality and the relaxation does help
to retrieve more CSFs. Considering that the relaxation of 2-hop
CSFs often incurs more false positive CSFs, and therefore drops the
Ð
search performance, we apply Φ31 (Q) Φ02 (Q) as the default setting
of Φ̃(Q) for picking CSFs.

5

p@20 MRR R-pre
.271 .661 .309
.313∗ .689 .362
.319∗ .725∗ .365∗
.350∗ .701 .409∗

6

ACKNOWLEDGMENTS

This work is supported by the National Science Foundation of China
under grant (No. 61472426 and 61432006), 863 key project under
grant No. 2015AA015307, the open research program of State Key
Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Science (No. CARCH201510), the
ECNU-RUC-InfoSys Joint Data Science Lab, and a gift from Tencent.

REFERENCES
[1] Ziawasch Abedjan and Felix Naumann. 2013. Improving RDF Data Through
Association Rule Mining. Datenbank-Spektrum 13, 2 (2013), 111–120.
[2] Krisztian Balog, Marc Bron, and Maarten de Rijke. 2011. Query modeling for
entity search based on terms, categories, and examples. ACM Trans. Inf. Syst. 29,
4 (2011), 22.
[3] Gianluca Demartini, Tereza Iofciu, and Arjen P. de Vries. 2009. Overview of the
INEX 2009 Entity Ranking Track. In INEX. 254–264.
[4] Xin Dong and Evgeniy Gabrilovich et al. 2014. Knowledge vault: a web-scale
approach to probabilistic knowledge fusion. In KDD ’14, New York, USA, August
24-27, 2014. 601–610.
[5] Vanessa Lopez, Christina Unger, Philipp Cimiano, and Enrico Motta. 2013. Evaluating question answering over linked data. J. Web Sem. 21 (2013), 3–13.
[6] Steffen Metzger, Ralf Schenkel, and Marcin Sydow. 2014. Aspect-Based Similar
Entity Search in Semantic Knowledge Graphs with Diversity-Awareness and
Relaxation. In WI and IAT. 60–69.
[7] Alexandre Passant. 2010. dbrec - Music Recommendations Using DBpedia. In
ISWC. 209–224.
[8] Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S. Yu, and Tianyi Wu. 2011. PathSim: Meta Path-Based Top-K Similarity Search in Heterogeneous Information
Networks. PVLDB 4, 11 (2011), 992–1003.
[9] Richard C. Wang and William W. Cohen. 2009. Automatic Set Instance Extraction
using the Web. In ACL. 441–449.
[10] Jinxi Xu and W. Bruce Croft. 1996. Query Expansion Using Local and Global
Document Analysis. In SIGIR 1996. 4–11.

CONCLUSIONS

In this paper, we address the problem of entity set expansion by
using KGs. We propose a concept called common semantic feature,
to describe the common features shared by the seed entities, as
the basis of discovering and ranking candidate entities. Through
extensive experimental studies, we find that the proposed solution
is very suitable for ESE topics which have good coverage of entities
and predicates (relations) in the KGs. Even for those topics that
do not have good information coverage in KGs, our noise-resistant

1104


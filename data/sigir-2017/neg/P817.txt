Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Personalized Query Suggestion Diversification
Wanyu Chen

Fei Cai

Science and Technology on Information Systems
Engineering Laboratory
National University of Defense Technology
Changsha, China
wanyuchen@nudt.edu.cn

Science and Technology on Information Systems
Engineering Laboratory
National University of Defense Technology
Changsha, China
caifei@nudt.edu.cn

Honghui Chen

Maarten de Rijke

Science and Technology on Information Systems
Engineering Laboratory
National University of Defense Technology
Changsha, China
chh0808@gmail.com

Informatics Institute
University of Amsterdam
Amsterdam, The Netherlands
derijke@uva.nl
try to cover multiple search aspects. In existing models for diversifying query suggestions, a user’s personal information has hardly
been explored. We combine the advantages of personalization and
diversification and propose a Personalized Query Suggestion Diversification (PQSD) model, where personalization ensures that
suggested queries are close to a user’s specific search intent and
diversification helps to generate multiple-aspect queries to increase
the likelihood of a suggested query being clicked, that is helpful to
diversifying web search results [10].
PQSD consists of two stages. In the first, we develop a greedy
query suggestion diversification model (G-QSD) where a user’s
search context, e.g., queries and clicks, is used to generate a diversified ranked list of queries; to this end, we use co-occurrences as
well as semantic similarity. In the second stage, we inject a user’s
long-term search behavior information into the G-QSD model using
Bayes’ rule. To determine a query’s aspects, we collect clicked documents and extract descriptions of those documents based on the
Open Directory Project (ODP).1 Then, we use topic modeling [2] to
obtain a topic distribution of document descriptions and queries.
We compare the performance of PQSD against a state-of-the-art
query suggestion baseline on the AOL query log. The results show
the effectiveness of PQSD in terms of query suggestion ranking and
diversification. In particular, our PQSD model gains an improvement of around 1.35% and 6.39% in terms of MRR and α-nDCG,
respectively, over a competitive baseline [11].
Our contributions are: (1) A model for personalized query suggestion diversification (PQSD) that incorporates a user’s short-term
search context in their current session and their long-term search
history to detect search interests; (2) An analysis of the performance of PQSD under various search context selection strategies;
PQSD yields better performance when the search context consists
of queries with clicked documents rather than all queries.

ABSTRACT
Query suggestions help users refine their queries after they input an
initial query. We consider the task of generating query suggestions
that are personalized and diversified. We propose a personalized
query suggestion diversification model (PQSD), where a user’s
long-term search behavior is injected into a basic greedy query
suggestion diversification model (G-QSD) that considers a user’s
search context in their current session. Query aspects are identified
through clicked documents based on the Open Directory Project
(ODP). We quantify the improvement of PQSD over a state-of-theart baseline using the AOL query log and show that it beats the
baseline in terms of metrics used in query suggestion ranking and
diversification. The experimental results show that PQSD achieves
the best performance when only queries with clicked documents
are taken as search context rather than all queries.
ACM Reference format:
Wanyu Chen, Fei Cai, Honghui Chen, and Maarten de Rijke. 2017. Personalized Query Suggestion Diversification. In Proceedings of SIGIR ’17, August
07–11, 2017, Shinjuku, Tokyo, Japan., 4 pages.
DOI: http://dx.doi.org/10.1145/3077136.3080652

1

INTRODUCTION

Modern search engines offer query suggestions to help user formulate a good query and thus to get their intended search results to
address their information needs. Previous work on query suggestion mainly focuses on recommending semantically related queries
in response to a user’s input query [14]. Such strategies cannot
handle queries with uncertain search aspects, especially for different users with diverse search intents. Hence, diversification of
query suggestions has been studied [11], where suggested queries
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR ’17, August 07–11, 2017, Shinjuku, Tokyo, Japan.
© 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.
978-1-4503-5022-8/17/08. . . $15.00
DOI: http://dx . doi . org/10 . 1145/3077136 . 3080652

2 APPROACH
2.1 Greedy query suggestion diversification
Our method for query suggestion diversification assumes that an
initial list of query suggestion candidates R I produced for the user
1 http://www . dmoz . org

817

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

query q 0 with length |R I | = L I is given. We use a relevant term
suggestion method [9] to generate this initial query ranking list.
We being by simplifying the problem of query suggestion diversification. The aim of query suggestion diversification is to satisfy the
average user who enters the query q 0 by finding at least one acceptable query suggestion among the top N query suggestions returned.
This can be achieved by maximizing the following function:
Q
P (R S | q 0 , SC ) = 1 − qc ∈R S (1 − P (qc | q 0 , SC )),
(1)

Turning to the right-hand side of (4), we make the query independence assumption [4] and decompose P (qc | a, SC ) to obtain:
Q
P (qc | q 0 , a, SC ) ← λ 1 P (qc , q 0 ) + (1 − λ 1 ) qt ∈SC P (qc | a, qt ).
(7)
The probability P (qc | a, qt ) in (7) can be estimated by the distance
between query suggestion q 0 and query qt in the search context
given the aspect a. As queries that are submitted within a short
temporal interval are bound to share common query aspects [4],
we estimate the probability P (qc | a, qt ) as:

where SC denotes the search context in a given session of a user
who inputs the initial query q 0 and R S is a ranked list of queries
that contains the top N query suggestion candidates to be returned.
Obviously, we have R S ⊆ R I with |R S | = N , such that N ≤ L I .
Intuitively, the probability P (qc | q 0 , SC ) in (1) denotes the likelihood that the suggested query candidate qc satisfies a user who
enters query q 0 . With the assumption of query independence, the
right-hand side of (1) denotes the probability that at least one query
suggestion can satisfy the user. We further interpolate (1) at the
aspect level and thus we have

P 
Q
P (R S | q 0 , SC ) = a 1 − qc ∈R S (1 − P (qc | q 0 , a, SC )) , (2)

|vqc (a) − vqt (a)|
+/
*
P (qc | a, qt ) ← θ t × ..1 − q
/,
PM
2
(v
(a
)
−
v
(a
))
q
i
q
i
c
t
i=1
,

where θ t = D (q1 )+1 and D (qt ) refers to the interval between pret
vious query qt and the last query qT in the search context SC ; M
denotes the number of aspects of a query and vqc (ai ) denotes the
relevance of query qc to its i-th aspect; see Section 3. This explains
how the term P (qc | q 0 , a, SC ) in (3) can be estimated.
Next, for calculating P (qs | q 0 , a, SC ) in (3), which denotes the
probability of query suggestions that have been chosen in the list
R R addressing query aspect a given the search context SC and input
query q 0 , based on the query independence assumption we can
simplify P (qs | q 0 , a, SC ) in (3) as:
Q
P (qs | q 0 , a, SC ) ← P (qs | a, SC ) = qt ∈SC P (qs | a, qt ), (9)

where a ranges over possible aspects.
To maximize the objective in (2), we propose a natural greedy
algorithm for generating a diverse ranking of query suggestions.
We follow a greedy selection process as follows:
X
Y
q? ← arg max
P (qc | q 0 , a, SC )
(1−P (qs | a, q 0 , SC )), (3)
qc ∈R I \R S a

where P (qs | a, qt ) is computed analogously to P (qc | a, qt ) in (8).

q s ∈R S

which guarantees that a suggested query that is the most different
from previously selected query suggestions in R S is selected at each
step. Thus, it can minimize the redundancy of the ranked list of
query suggestions by iteratively filling the list R S until |R S | = N .
The expression P (qc | q 0 , a, SC ) in (3) is the probability that a
query candidate qc addresses the query aspect a given the input
query q 0 and the session context SC . We estimate this probability
based on the following two parts, with a trade-off λ 1 (0 ≤ λ 1 ≤ 1)
controlling the contribution of each part [16]:
P (qc | q 0 , a, SC ) ← λ 1 P (qc | q 0 ) + (1 − λ 1 )P (qc | a, SC ).

(8)

2.2

Personalized query suggestion
diversification

We generalize the greedy selection rule to a personalized version by
considering a user u’s long-term search history so that q? becomes
X
Y
arg max
P (qc | q 0 , a, SC , u)
(1−P (qs | a, q 0 , SC , u)). (10)
qc ∈R I \R R a

q s ∈R R

For calculating P (qc | q 0 , a, SC , u), we use Bayes’ rule:

(4)

P (qc | q 0 , a, SC , u) =

P (qc | q 0 ) denotes the probability that a suggested query qc is
relevant to the input query q 0 , which is estimated by the semantic
similarity Sq0,qc between qc and q 0 and weighted by the normalized co-occurrence count Cqc ,q0 of qc and q 0 in search sessions as:
P (qc | q 0 ) ← Cqc ,q0 · Sq0,qc . Intuitively, a higher co-occurrence of
two queries qc and q 0 in search sessions would result in a higher
relevance probability of qc and q 0 . Following [9], Cqc ,q0 can be
estimated by
coqc ,q0
Cqc ,q0 =
,
(5)
fq0 + fqc − coqc ,q0
where fq0 and fqc denote the number of search sessions containing
query q 0 and qc , respectively; coqc ,q0 indicates the number of search
sessions containing both query qc and q 0 . For calculating Sq0,qc , we
take the cosine similarity between two queries, represented by the
average of the cosine similarity between query terms w returned
by the word2vec model [15]:
P
P
Sq0,qc ← cos (q 0 , qc ) = W1 w k ∈q0 w j ∈qc cos(w k , w j ), (6)

P (qc )P (a, u, q 0 , SC | qc )
.
P (a, u, q 0 , SC )

(11)

We rewrite the term P (a, u, q 0 , SC | qc ), which can be regarded as
the combination of diversification and personalization, as:
P (a, u, q 0 , SC | qc ) ← λ 2 P (a, q 0 , SC | qc ) + (1 −λ 2 )P (u, q 0 , SC | qc ),
where λ 2 is a tradeoff controlling the contributions of diversification
and personalization. Based on Bayes’ rule, P (a, q 0 , SC | qc ) and
P (u, q 0 , SC | qc ) can be interpolated as
P (a, q 0 , SC | qc ) =
and

P (qc | a, q 0 , SC )P (a, q 0 , SC )
P (qc )

(12)

P (qc | u, q 0 , SC )P (u, q 0 , SC )
,
(13)
P (qc )
respectively. The term P (qc | a, q 0 , SC ) in (12) can be calculated
following (7). Following the independence assumption used in web
search [16], we approximate P (qc | u, q 0 , SC ) in (13) as
Q
P (qc | u, q 0 , SC ) ∝ qt ∈SC P (qc | u)P (qc | q 0 )P (qc | qt ), (14)
P (u, q 0 , SC | qc ) =

where W = |q 0 | · |qc | and |q| is the number of terms in query q.

818

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

where P (qc | u) denotes the probability of suggesting qc to u
according to their long-term search history and is estimated as:
P
P (qc | u) ← |Q (u)| −1 q ∈Q (u ) Sqc ,q ,
(15)

Table 1: Dataset statistics.

where Q (u) are all queries submitted by user u; |Q (u)| is the size
of Q (u); Sqc ,q returns the semantic similarity between two queries
like (6). Similarly, P (qs | a, q 0 , SC , u) in (10) can be estimated.

2.3

Generating query distribution over topics

Training

Test

# Queries
# Unique queries
# Sessions
# Users
Average # queries with clicks per session
Average # queries with clicks per user

7,256,569
746,796
1,428,962
220,946
4.37
28.87

2,628,284
373,397
714,481
110,473
4.35
28.91

distribution parameters α = 0.5 and β = 0.1. We set the number of
query suggestions to N = 10, which is commonly used [14].
For generating the ground truth, i.e., the relevance of a query
q to an aspect a, we follow [6], and use a 5-grade scale (perfect
= 4, excellent = 3, good = 2, fair = 1, and bad = 0) as: relq,a ←
h
i
min( vq (a) , 4). We use MRR [13] and α-nDCG [7] to measure the
ranking and diversification performance of query suggestions.

In PQSD, a key problem is how to represent queries over topics. As
queries are usually short, it makes sense to use clicked documents
to generate their topic distribution rather than using the queries
directly [4]. First, we extract a document description based on ODP
and then generate the topic distribution of documents using Latent
Dirichlet Allocation (LDA) [2]. After that, we obtain a query q’s
P
topic distribution as: vq = d ∈D (q) vd × f (q, d ), where D (q) is the
set of documents clicked in response to query q, vd denotes the
topic distribution of document d, which is vectorized using LDA,
and f (q, d ) indicates the number of clicks on d after submitting
q. For queries without clicked documents, we generate the query
distribution from similar queries that have been vectorized as semantically related queries (or words) often express similar search
topics [3]. We find the most similar vectorized query q label for
a query qnc without clicks by q label ← arg maxql ∈Q L cos(qnc , ql ),
where Q L is a set of vectorized queries. We take the cosine similarity
between two queries like (6).

3

Variables

4 RESULTS AND DISCUSSION
4.1 Performance of query suggestion models
To answer RQ1, we examine the query suggestion performance
of the baselines as well as our PQSD models, which incorporate a
user’s search context for personalization. See Table 2 for the results.
DQS achieves a better performance than MMR in terms of MRR@10
and α-nDCG@10. Hence, we only use DQS as a baseline from now
on. DQS shows a minor MRR improvement against MMR (<1.0%)
and a somewhat higher improvement in terms of α-nDCG@10
against MMR (<1.9%). As to the PQSD models, whatever type
of search context we consider, PQSD outperforms the baseline,
with MRR@10 improvements ranging from 0.8% to 2.0% and αnDCG@10 improvements ranging from 4.3% to 8.9%. The fact that
improvements in α-nDCG are higher than improvements in MRR
can be explained by the fact that in some cases, redundant query
suggestions ranked lower than the final submitted query are removed from the original query suggestion list; this does not affect
the reciprocal rank score but does yield improved diversity scores.
Table 2 shows that PQSDCL+CS achieves the best performance.
Significant improvements against the baseline in terms of MRR@10
and α-nDCG@10 are observed for all PQSD models at the α =
.01 level except for PQSDAL+AS , for which we observe significant
improvements at the α = .05 level. Hence, the content of the search
context does affect the performance of PQSD model.

EXPERIMENTS

Model summary. The baselines to be compared are (1) MMR:
a query suggestion diversification approach based on Maximal
Marginal Relevance (MMR) [5]; (2) DQS: a diversified query suggestion (DQS) model based on the query-URL bipartite graph analysis [11]. We consider four variations of the PQSD model that
differ in the information used as search context for personalization:
(1) PQSDAL+AS uess all queries in a user’s long-term search history
and in the current session; (2) PQSDAL+CS uses all queries in a
user’s long-term search history and only queries with clicks in the
current session; (3) PQSDCL+AS uses only queries with clicks in a
user’s long-term search history and all preceding queries in the
current session; (4) PQSDCL+CS uses only queries with clicks in a
user’s long-term search history and in the current session.
Research questions. (RQ1) Is the PQSD model able to beat stateof-the-art query suggestion models in terms of query suggestion
ranking and diversification? (RQ1) What is the impact on the
performance of PQSD of the choice of search context, i.e., choosing
all queries or only queries with clicks?

Table 2: Performance of query suggestion models. The results produced by the best baseline and the best performer
in each column are underlined and boldfaced, respectively.
Statistical significance of pairwise differences (PQSD models vs. best baseline) determined by a t-test (N /H for α = .01,
or M /O for α = .05).

Datasets and parameters. We use the AOL query log [12] in our
experiments and preprocess the dataset following [8]. In addition,
we split the queries into sessions by 30 minutes of inactivity and
sessions with at least two queries are kept. Table 1 details the
statistics of the dataset used.
For the parameter setup in our experiments, following [16], we
fix λ 1 = 0.5. Regarding λ 2 in (12), we set λ 2 = 0.5 to give equal
weight to diversification and personalization. In the LDA model,
following [1], we set the number of topics to M = 100, and the

Models
MMR
DQS
PQSDAL+AS
PQSDCL+AS
PQSDAL+CS
PQSDCL+CS

819

MRR@10
.6611
.6672
.6726M
.6763N
.6756N
.6807N

α-nDCG@10
.7021
.7152
.7461M
.7644N
.7686N
.7791N

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

MRR@10 at each query position, which is consistent with the findings in Table 2. To sum up, search context consisting of queries with
clicks, whether in a user’s long-term or short-term search history,
can help generate more accurate and diversified query suggestion
rankings.

0.685
DQS
PQSDAL+AS

MRR@10

0.68

PQSDAL+CS
PQSDCL+AS

0.675

PQSDCL+CS

5

0.67

0.665

0.66

1

2

3

4

>4

Query Position

(a) Performance in terms of MRR@10.

-nDCG@10

0.79
0.78

DQS
PQSD

0.77

PQSDAL+CS

AL+AS

PQSDCL+AS

0.76

Acknowledgments. This research was supported by the National Advanced Research Project under no. 6141B08010101, Ahold Delhaize, Amsterdam Data Science, the Bloomberg Research Grant program, the Dutch
national program COMMIT, Elsevier, the European Community’s Seventh
Framework Programme (FP7/2007-2013) under grant agreement nr 312827
(VOX-Pol), the Microsoft Research Ph.D. program, the Netherlands Institute
for Sound and Vision, the Netherlands Organisation for Scientific Research
(NWO) under project nrs 612.001.116, HOR-11-10, CI-14-25, 652.002.001,
612.001.551, 652.001.003, and Yandex. All content represents the opinion of
the authors, which is not necessarily shared or endorsed by their respective
employers and/or sponsors.

PQSDCL+CS

0.75
0.74
0.73
0.72
0.71
0.70

1

2

3

4

>4

Query Position

(b) Performance in terms of α -nDCG@10.

REFERENCES

Figure 1: Performance of PQSD models and the baseline at
different query positions in a session.

4.2

CONCLUSIONS AND FUTURE WORK

We have addressed the task of combining personalization and diversification of query suggestions and proposed a personalized
query suggestion diversification model (PQSD) that is based on a
basic greedy selection algorithm and incorporates a user’s previous
queries as search context for personalization. A variant of the PQSD
model using queries with clicks achieves the best performance in
terms of query ranking accuracy and diversification. As future
work, we plan to evaluate our models on other datasets so as to
verify the effectiveness of our proposal. In addition, we want to
investigate the sensitivity of involved parameters, e.g., the cutoff
number of query suggestion N and the tradeoff λ 2 controlling the
contributions of personalization and diversification.

[1] A. Asuncion, M. Welling, P. Smyth, and Y. W. Teh. On smoothing and inference
for topic models. In UAI, pages 27–34, 2009.
[2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn.
Res., 3(4):993–1022, 2003.
[3] D. Bollegala, Y. Matsuo, and M. Ishizuka. Measuring semantic similarity between
words using web search engines. In WWW, pages 757–766, 2007.
[4] F. Cai, R. Reinanda, and M. de Rijke. Diversifying query auto-completion. ACM
Trans. Inf. Syst., 34(4):1–33, June 2016.
[5] J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for
reordering documents and producing summaries. In SIGIR, pages 335–336, 1998.
[6] O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. Expected reciprocal rank for
graded relevance. In CIKM, pages 621–630, 2009.
[7] C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Buttcher,
and I. MacKinnon. Novelty and diversity in information retrieval evaluation. In
SIGIR, pages 659–666, 2008.
[8] J. Guo, X. Cheng, G. Xu, and X. Zhu. Intent-aware query similarity. In CIKM,
pages 259–268, 2011.
[9] C.-K. Huang, L.-F. Chien, and Y.-J. Oyang. Relevant term suggestion in interactive
web search based on contextual information in query session logs. J. Am. Soc.
Inf. Sci. Technol., 54(7):638–649, May 2003.
[10] S. Liang, F. Cai, Z. Ren, and M. de Rijke. Efficient structured learning for personalized diversification. IEEE Trans. Knowl. Data Eng., 28(11):2958–2973, 2016.
[11] H. Ma, M. R. Lyu, and I. King. Diversifying query suggestion results. In AAAI,
pages 1399–1404, 2010.
[12] G. Pass, A. Chowdhury, and C. Torgeson. A picture of search. In InfoScale ’06,
pages 1–7, 2006.
[13] C. Shah and W. B. Croft. Evaluating high accuracy retrieval techniques. In SIGIR,
pages 2–9, 2004.
[14] Y. Song, D. Zhou, and L.-w. He. Post-ranking query suggestion by diversifying
search results. In SIGIR, pages 815–824, 2011.
[15] M. Tomas, C. Kai, C. Greg, and D. Jeffrey. Efficient estimation of word representations in vector space. In Proceedings of Workshop at ICLR, 2013.
[16] D. Vallet and P. Castells. Personalized diversification of search results. In SIGIR,
pages 841–850, 2012.

Different personalization strategies

For RQ2 we fix the search context by using either all previous
queries or queries with clicks in the current session as well as the
user’s long-term search history. In general, PQSD achieves a better
performance when it incorporates queries with clicks as search context than when using all previous queries. E.g., as shown in Table 2,
PQSDC L+AS beats PQSDAL+AS in terms of both metrics. Similar
results can be found when comparing PQSDC L+CS to PQSDAL+CS .
Queries with clicks more accurately express a user’s search intent,
which is helpful for query suggestion personalization.
Results of the PQSD models and the baseline at the query position
level (in a session) are shown in Fig. 1. As shown in Fig. 1a, as
the search context becomes richer, the performance in terms of
MRR@10 of query suggestion models improves too. E.g, at a late
query position in a session (> 4), PQSDCL+CS improves MRR@10
over earlier query positions (= 2). In addition, as indicated by
the results of the PQSD models at the start of a session (query
position = 1), when user’s short-term search context in current
session is unavailable, PQSD achieves neglible improvements over
the baseline, especially for PQSDAL+AS and PQSDAL+CS .
Regarding the evaluation of diversity, similar results can be found
in Fig. 1b when reporting the performance of query suggestion
models in terms of α-nDCG@10. PQSD achieves relatively larger
improvements against the baseline in terms of α-nDCG@10 than

820


Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

Information Retrieval Model using Generalized Pareto
Distribution and Its Application to Instance Search
Masaya Murata

NTT Communication Science Labs.
3-1 Morinosato Wakamiya, Atsugi-shi,
Kanagawa Pref., Japan
masaya.murata1013@gmail.com

Kaoru Hiramatsu

NTT Communication Science Labs.
3-1 Morinosato Wakamiya, Atsugi-shi,
Kanagawa Pref., Japan
hiramatsu.kaoru@lab.ntt.co.jp

Shin’ichi Satoh

National Institute of Informatics
2-1-2 Hitotsubashi, Chiyoda-ku,
Tokyo, Japan
satoh@nii.ac.jp

LLD or not. Setting the suitable distribution to the objective data is
important for the successful retrieval.
Recently, the distribution is estimated using the extreme value
statistics (EVS) [5]. The distribution that the maximum NTF
follows according to the EVS is adopted in the P model. To my
knowledge, it is the first successful application of the EVS to the IR
model. In this paper, we propose the distribution estimation for
the I model according to the EVS and this is the main contribution.
We also show that the proposed model corresponds to the
extension of the divergence from independence (DFI) [6] which is
a parameter-free IR model. Since the parameters of the proposed
model are estimated according to the data, the retrieval accuracy is
expected to be improved. We demonstrate it for the specific object
search called the instance search [7] using image-query video
retrieval dataset.
The rest of this paper is organized as follows. We describe the
proposed model and explain the relation to the DFI model in
Section 2. We also clarify the difference from the method in [5].
Section 3 shows the experimental justification using the instance
search dataset and the detailed discussion is provided. Finally,
Section 4 concludes this paper.

ABSTRACT
We adopt the generalized Pareto distribution for the informationbased model and show that the parameters can be estimated based
on the mean excess function. The proposed information retrieval
model corresponds to the extension of the divergence from
independence and is designed to be data-driven. The proposed
model is then applied to the specific object search called the
instance search and the effectiveness is experimentally confirmed.

CCS CONCEPTS
• Information systems → Information retrieval; Retrieval
models and ranking; Probabilistic retrieval models; Multimedia and
multimodal retrieval, Video search

KEYWORDS: Information retrieval; information-based model;
divergence from independence; extreme value statistics;
generalized Pareto distribution; video retrieval; instance search
1 INTRODUCTION
Effective information retrieval (IR) models have been actively
studied roughly since 1960s in the IR community. BM25, language
model-based IR (LM) and divergence from randomness (DFR) are
state-of-the-art. The axiomatic approach is also proposed [1].
Recently, information-based model (I model) [2] and percentilebased model (P model) [3] are proposed. These models are simple
compared to the DFR, since only one distribution is necessary (two
distributions are required for the DFR). The problem then becomes
the adequate setting of the distribution.
There are interesting relations such that adopting the log-logistic
distribution (LLD) for I model and P model yields LM with JelinekMercer smoothing and sub-linear normalized term frequency
(NTF) term in the BM25 model, respectively [4][3]. Although these
facts somehow support the effectiveness of I model and P model,
the essential problem is whether the data to be searched follow the

2 EVS AND ITS APPLICATION TO I MODEL
2.1 Brief Introduction of EVS
The EVS provides us what distributions maximum block data and
threshold excess data (TED) asymptotically follow, respectively. In
this paper, we focus on the TED, which is the data larger than a
pre-specified threshold. Under the EVS basic assumption for the
data, it is mathematically shown that as the threshold increases,
the TED asymptotically follows the generalized Pareto distribution
(GPD).
The cumulative distribution function is characterized as follows:
F

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned
by others than ACM must be honored. Abstracting with credit is permitted. To
copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from
Permissions@acm.org.
SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan
© 2017 ACM. ISBN 978-1-4503-5022-8/17/08…$15.00
http://dx.doi.org/10.1145/3077136.3080736

=1− 1+

,

(1)

Here, is the TED and , are the distribution parameters. The
GPD is heavy-tailed for ξ > 0. The mean excess function (MEF) is
defined as follows:
(2)
e
=E − | >
Then, the MEF for the GPD exists for ξ < 1 and becomes
e

1117

=

1−

+

1−

(3)

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

It is proved that the MEF is linear in only for the GPD and we
exploit this nature for designing a IR model in the next subsection.

score ,

−
,

≥

|

,

(4)

Here, , are query and document vectors and is the NTF for
the i-th term. P ≥ | is called the information model and it
should be heavy-tailed to prevent the document ranking score
from becoming diverged.
We then replace the information model with that for the GPD.
Using Eq. (1), equation (4) becomes
score ,

=
,

Here,

−

1+

,

(5)

,

We set = =
− and
=
, which is the
expected term frequency for the i-th term within the document
length = ∑ . is the within-corpus (-dataset) frequency for
the i-th term and = ∑ . Note that ξ > 0 is assumed since the
information model in Eq. (4) should be heavy-tailed.
For the execution of Eq. (5), , ,
should be specified
according to the data to be searched. For a certain , we estimate
the MEF as follows:
1
e
=
−
(6)
# | >

2.4 Difference from the model in [5]
The IR model in [5] also uses the EVS. It is based on the following
P model:

Here, # | > is the number of terms whose NTFs are larger
than a threshold . ∙ denotes zero for ≤ and − for
> . Then, when the estimated MEF seems linear in , applying
the least squares method provides the estimation results for ,
according to Eq. (3). Note that Eq. (3) only holds for ξ < 1 and
therefore, 0 < ξ < 1 is implicitly assumed for this parameter
estimation method.
is the control (tuning) parameter of the proposed model. When
the estimated MEF for a certain is clearly deviated from a linear
function, the aforementioned parameter estimation method is not
applicable. We can vary until the estimated MEF becomes
somehow linear, however, we cannot provide the sophisticated
selection method of . To summarize, the proposed IR model is
=

1+
,

where,
results.

,

−

,

In this case, the terms whose within-document frequencies are
larger than the expected values are only taken into account.
Comparing the DFI equations with the model in Eq. (5), it is
readily shown that , , = 1,1,0 makes Eq. (5) identical to
Eq. (8). Moreover, , , = 1,1,1 in Eq. (5) leads to Eq. (9). On
the other hands, Eq. (7) is based on , , = , , . Therefore,
the proposed model can be regarded as the extension of the DFI in
which the parameters are estimated according to the data to be
searched. Since = 0 1 for DFI, we can think of setting =
0 1 for Eq. (7). Then, the proposed model also becomes
parameter-free.
The setting of = 1 for the GPD corresponds to the setting of
the LLD since the LLD is a special case of the GPD. Therefore, the
DFI can be regarded as the I model using the LLD with = 1.
When the is left as a parameter, the resulting model becomes
equivalent to the LM with Jelinek Mercer smoothing [4].

is the within-document term frequency for the i-th term.

score ,

(8)

,

The DFI simply evaluates the extent the within-document term
frequencies diverge from the expected within-document
frequencies. When the divergence for a certain term is large, the
corresponding weight is designed to be larger. Although the DFI is
parameter-free, the function form is arbitrary. Indeed, the
following form is also possible:
−
score , =
1+
(9)

I model is defined as follows:
=

1+
,

2.2 I model using GPD
score ,

=

score ,

=

≤
,

,

|

(10)

Then,
≤ | is replaced with the cumulative distribution
function that a maximum NTF follows under the EVS basic
is an arbitrary inverse document frequency for
assumption.
the i-th term. Note that the adopted distribution is not the
distribution that the actually follows. Therefore, the implicit
assumption is that the weight becomes large for the case that the
approaches the maximum value.
To the contrary, the proposed model estimates the GPD that the
follows under the EVS basic assumption and does not rely on
the assumption such as the aforementioned one. This is the
primary difference from the method in [5], although the selection
of the NTFs is also different.

(7)

,

3 EXPERIMENTS

are the estimated values based on the least squares

3.1 Instance Search Dataset
We show the effectiveness of the proposed model for the specific
object search called the instance search. It is an image-query video

2.3 Relation to DFI
The DFI is expressed as follows:

1118

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

For all cases of the duplication thresholds 0.999, 0.95, and 0.9, we
confirm that when # | >
is sufficiently large, the
corresponding MEF can be approximately regarded as linear. This
fact supports the use of the GPD assumption and the proposed
parameter estimation method is performed for the linear region.
We then execute Eq. (7) to rank videos. We also vary and the
same parameter estimation procedure is performed for the other
settings of .

retrieval task and the specific object is shown in the image-query.
The system is required to search and rank videos in which the
objects are shown in the decreasing order of relevance degrees.
The following images are object examples.

Figure 2: Estimated MEF for the duplication threshold
0.999. The region in the red circle seems linear. For ≥
, since # | >
becomes small, the MEF becomes
unstable and less trustworthy.

Figure 1: Examples of image-queries. Image queries are
sets of original and region-of-interest (ROI) images. The
white regions in the ROI images specify the objects in the
original images.
The dataset is provided in the TRECVID2012 instance search task
[7]. It is composed of 76751 short videos (the average duration is
about 10 sec.) and 21 objects such as person/object/place. Each
object is provided by five original and ROI images on average. The
relevance judgement data is binary and the mean average
precision (MAP) is adopted as the search accuracy measure.
The frames are extracted from each video by 1 frame/sec and
key-points are detected by the Harris-Laplace detector. Then, the
key-points are described by 128-dimensional SIFT feature vectors.
Same key-point detection and description methods are performed
for all of the image-queries and the duplicated key-points are
removed. This removal procedure is based on the cosine similarity
value (CSV) between two SIFT vectors and the pair of key-points
whose CSV is larger than a certain threshold is identified as
matched. We varied the duplication threshold such as 0.999, 0.95
and 0.9. Then, for each key-point extracted from frames, the
nearest key-point extracted from all of the image-queries is
matched based on the CSV with a threshold of 0.9.

Figure 3: Estimated MEF for the duplication threshold
0.95. For ≫
, the MEF fluctuates since # | >
is
small.

3.2 Results
Figures 2, 3, and 4 depict the estimated MEFs ( =0) for the
duplication thresholds 0.999, 0.95, and 0.9, respectively. The
regions specified by the red circles seem linear and the proposed
parameter estimation is performed only for these regions. Note
that for ≥ 200 in Fig. 2, since # | > becomes small, the
MEF becomes less trustworthy.

Figure 4: Estimated MEF for the duplication threshold
0.9. Compared with Figs. 2 and 3, the size of unstable
region is decreased because # | >
becomes
sufficiently large.

1119

Short Research Paper

SIGIR’17, August 7-11, 2017, Shinjuku, Tokyo, Japan

the document retrieval community [5], there is also a possibility
that such a proposition holds for the text retrieval task. Then, the
inverted index may be dramatically shortened since only the
effective TED ( > 0) are sufficient for the successful retrieval.
This is our immediate future work.

Table 1 shows the MAP results for DFI and proposed models with
the duplication threshold of 0.999. We only list the results for this
setting since they are the best MAP results among ours. As shown
in this table, the search accuracy of the proposed models is
significantly better than those for the DFI models. As mentioned in
Section 2.3, the proposed model is data-driven and we confirmed
that using the estimated parameters from the data leads to the
improvement in the search accuracy.

4 CONCLUSIONS
We proposed a IR model based on the GPD in the I model
framework. We also proposed the parameter estimation method
based on the least squares method. The MEF is estimated from
data to be searched and the linear region is processed by the least
squares, which provides the estimates of the shape parameters for
the GPD model. The proposed IR model corresponds to the
extension of the DFI. Since the model is data-driven, its retrieval
accuracy is significantly improved. We confirmed it using the
image-query video retrieval task called the instance search.

Table 1: MAP Results
IR model

MAP

DFI (Eq. (8))

0.23

DFI (Eq. (9))

0.24

Proposed model with =0

0.29

Proposed model with =1

0.29

REFERENCES

Proposed model with =5

0.30

Proposed model with =10

0.31

Proposed model with =20

0.31

Proposed model with =50

0.31

Proposed model with =100

0.31

[1] H. Fang and C. X. Zhai. 2005. An Exploration of Axiomatic Approaches to
Information Retrieval. In Proceeding of the 28th International ACM SIGIR
Conference on Research and Development in Information Retrieval (SIGIR’05).
ACM, New York, NY, 480–487.
[2] S. Clinchant and E. Gaussier. 2010. Information-Based Models for Ad Hoc IR.
In Proceeding of the 33rd International ACM SIGIR Conference on Research and
Development in Information Retrieval (SIGIR’10). ACM, New York, NY, 234–
241.
[3] Y. Lv and C. X. Zhai. 2012. A Log-Logistic Model-Based Interpretation of TF
Normalization of BM25. In Proceeding of the 34th European Conference on IR
Research (ECIR 2012). Barcelona, Spain, April 1-5, 244–255.
[4] S. Clinchant and E. Gaussier. 2009. Bridging Language Modeling and
Divergence from Randomness Models: A Log-Logistic Model for IR. In
Proceeding of the Second International Conference on the Theory of
Information Retrieval (ICTIR 2009). Cambridge, UK, September 10-12, 54–65.
[5] J. H. Paik. 2015. A Probabilistic Model for Information Retrieval Based on
Maximum Value Distribution. In Proceeding of the 38th International ACM
SIGIR Conference on Research and Development in Information Retrieval
(SIGIR’15). ACM, New York, NY, 585–594.
[6] I. Kocabas, B. T. Dincer, and B. Karaoglan. 2014. A Nonparametric Term
Weighting Method for Information Retrieval Based on Measuring the
Divergence from Independence. Information Retrieval, Vol. 17, Issue 2, 153176.
[7] M. Murata, H. Nagano, R. Mukai, K. Kashino, and S. Satoh. 2014. BM25 With
Exponential IDF for Instance Search. IEEE Transactions on Multimedia, Vol.
16, Issue 6, 1690-1699.

The MAP values scored by the proposed models are comparable
with the highest MAP in the TRECVID2012 instance search task
[7]. It is clearly shown that as increases, the MAP value is
improved further. We discuss this issue in the next subsection.

3.3 Discussion
From Table 1, we confirm that the search accuracy is improved for
large . As mentioned in Section 2.1, as increases, the TED, that
is,

=

− , asymptotically follows the GPD when the EVS

. Since the
basic assumption holds for the NTF, that is,
proposed model is based on the GPD assumption, there is a
possibility that the EVS basic assumption somehow holds for the
NTF. Roughly speaking, when the NTF follows a heavy-tailed
distribution, such a proposition is true.
When large often occurs in a video, the NTF is expected to
follow a heavy-tailed distribution. Considering a video which is
the time series of frame images, similar or even same key-points
often repeatedly occur in the video, which contributes to large .
Such key-points are described as “bursty” in the image/video
retrieval community and it is known that the adequate treatment
is essential for the successful retrieval. Therefore, for the video
retrieval task such as the instance search, the NTF can be expected
to follow a heavy-tailed distribution. The larger supports the
GPD assumption for the TED further and we expect that this
tendency is shown in Table 1.
The results in Table 1 also indicate that the TED with large are
sufficient for the successful video retrieval and that taking the
whole data into account results in the deteriorated search accuracy.
This is also the main finding of this paper. It is interesting to see
whether this proposition also holds for the document retrieval task.
Since heavy-tailed distributions are often assumed for the NTF in

1120


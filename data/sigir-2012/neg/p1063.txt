Explaining Neighborhood-based Recommendations
Sergio Cleger-Tamayo

Juan M. Fernández-Luna

Juan F. Huete

Departamento de Informática.
Universidad de Holguín, Cuba

Departamento de Ciencias de
la Computación e I.A.
CITIC– UGR. Universidad de
Granada, 18071. Spain

Departamento de Ciencias de
la Computación e I.A.
CITIC– UGR. Universidad de
Granada, 18071. Spain

jmfluna@decsai.ugr.es

jhg@decsai.ugr.es

sergio@facinf.uho.edu.cu

ABSTRACT

pendence, we will only consider collaborative information
(nowadays widely available) in the explanations.
The idea motivating our proposal is that by showing explicitly predictions of this system for some items previously
observed, the user can understand the reasoning behind the
recommendations. Besides, we also show that the information presented in the interface can be useful also for improving the recommendations. As far as we know there is no
explanation approach that used this information, which is
an example of hybrid Human/Item explanations [2].

Recommender Systems (RS) attempt to discover users’ preferences, and to learn about them in order to anticipate their
needs. The main task normally associated with a RS is to
offer suggestions for items. However, for most users, RSs are
black boxes, computerized oracles that give advice, but cannot be questioned. In order to improve the quality of predictions and the satisfaction of the users, explanations facilities
are needed. We present a novel methodology to explain recommendations: showing predictions over a set of observed
items. Our proposal has been validated by means of user
studies and lab experiments using MovieLens dataset.

2.

EXPLANATION INTERFACE

We are looking for an effective explanation that would
Categories and Subject Descriptors
help the user to evaluate the quality of the recommendaH.3 [Information Storage and Retrieval]; H.5 [Information tion, according to their own preferences. Obviously, this
explanation strongly depends on the used recommendation
Interfaces and Presentation]
model. In this paper we will assume a neighborhood-based
RS predicting how an active user, a, might rate a target
Keywords
item, t. In general, user-based rating prediction is a process
in which each neighbor, v, suggests a rating for the target
Explanation, Effectiveness, Collaborative Filtering
item, sg(v, t), which are combined
P by weighting the contribution of each one, i.e. r̂a,t ∝ v∈N w(a, v)sg(v, t).
1. INTRODUCTION
Figure A shows a classical interface (bar chart histogram1 )
Usually, when working with RSs, the users do not have anto explain the predicted rating. This interface is the most
other option to trust. The need of justifications and explaconvincing explanation of why a movie was recommended in
nations has started to gain attention during the last decade,
MovieLens [1]. In this case the explanation says that “the
being nowadays more crucial due to shilling attacks favoring
system suggest 3? because it has been rated by other similar
a given item [1, 2]. Although we can find several alternausers as ...”. Although this interface explains in some way
tives for explaining recommendations, it has been widely achow the predicted rating is computed, there is a second
cepted the use of simple interfaces (generally, because they
problem that we are going to consider in this paper: “Why
can be well understood by ordinary users): For example, it
I shall believe the system’s 3? prediction?”.
can be used explanations as “users with similar tastes rate
In case of asking to my friend, I believe (or not) her recthis product as ...”, “customers who bought this item also
ommendations because usually I know her preferences over
bought ...”, etc. These simple explanations might be useful
a set of common rated items. We will try to include this
when recommending in low-risk domains (such as movies,
simple idea in our explanations. A simple approach, also
songs or books), but they are not of much help in a domain
explored in [1], would be to say “because the system made
where the cost of a wrong decision is high, as electronics,
correct predictions in over x% of all products”. This exholiday packages or investments portfolios. In such domains,
planation is independent of the target item, moreover in a
an explanation interface given understandable, effective and
neighborhood-based approach, these predictions may be obacceptable information will be preferred.
tained with quite different neighbors. So, what we propose
In this paper we investigate the use of more informative
is to ask this neighborhood for their prediction for some
explanation interfaces that could assist the users to make
items in the active user’s profile. This information can give
decisions. Having in mind that the proposed approach must
an idea of the quality of this neighborhood and must be
be generalizable, and in order to mitigate the domain de1
We use a bar chart for each possible category (1? to 5?)
plus an additional bar (denoted by “?”) representing that
we have had some problems when finding a minimum set of
neighbors who rated the target item.

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1063

A

trend of these neighbors to underestimate the rating, and
move the decision towards a 4? value.
Evaluation.
In order to evaluate this approach we follow a dual-strategy: Firstly, a classical user study3 using 40
users who rated at least 60 movies in the 100M-MovieLens
dataset. After a training step, each user has to judge the
explanations for 20 anonymous predictions4 . Then, they
have to confirm whether they agree with the predicted rating or not (in this case, we asked for an alternative). The
main conclusions from this experimentation are (i) that our
interface gives more information to the user (it helps to reconsider the given rating the 34% of the times whereas the
bar histogram helped in the 26%), and (ii) that this information is more useful because it helps to predict the given
rating (the original MAE of the system was 0.76, using the
histogram it increases to 0,79 and with our proposal it is
reduced to 0.71). We have also recommended for each user
10 unobserved movies (in this case we show the title of the
movies) and asked then if they would watch the movie. For
this purpose, our explanation interface was useful to the user
(changing a previous decision the 17% of the times).
We also asked the user for their opinion about the interfaces. The results are consistent with our hypothesis: Explanations facilities are necessary in a RS and users definitively
have a look at them. Besides, although in the users’ opinions
prevails subjective elements associated with the simplicity of
the histograms, they prefer to consult the most informative
interface (joining both approaches) in case of doubts.
Secondly, we have performed an empirical study trying to
evaluate if the information showed might give some trends
about the quality of the proposed recommendation. In order
to find tendencies, we have decided to correlate the explaining information with the error obtained in the prediction
for all the users in 100M-MovieLens. We found that there
is no a global pattern that can be applied, the trends depend on the user (what is valid for a user does not have to
be good for a different user). Nevertheless, we found significant trends (p > 0.05) for the 53% of the users. We consider
these results interesting since represents a different piece of
information that can be included in recommending models.

B

C

showed to the user in a graphical way, but there exists some
questions that remain to be solved.
Q1. What items can be used in the explanation? This
point is particularly important because if we show many
items the user might suffer for information overload whereas
if we show a few of them, it might be useless. Particularly,
in this paper we show the predictions for those items rated
by at least 70% of these neighbors. These items represent
the support of the explanations2 , denoted as S, in our experimentation a mean of 20.6 movies were selected.
Q2. How to show the selected items, S? They will be
disposed as points in a two-dimensional graph (Figure B):
On the one hand, the x-axis relates each item, i ∈ S, with
the target one, t. Since we do not use content information, this relationships is obtained by considering how far
are their predictions in such a way that those items with
similar suggestions will be placed at the left. In order to
measure this criterion we use a distance measure d(i, t) ∝
P
v∈N |sg(v, i) − sg(v, t)| . On the other hand, the y-axis
represents the quality of the suggestions, i.e. whether the
neighbors suggestions match the rating given by the active
user toP
the target item, r(a, i). Particularly, we compute
h(i) ∝ v∈N |r(a, i) − sg(v, i)| for each item i ∈ S. In this
way, those items predicted properly by all the members of
the neighborhood will be disposed in top positions of the
y-axis. For these items we aware of a consensus among the
individuals predictions.
Q3. What information is showed for each item in S? To
show the quality of a prediction we use squares , or diamond 3, to represent that this particular neighborhood
hits, or not, the given rating, respectively, and the color
used to fill these figures represents the rating given by the
active user to each movie (we use the same colors as the
ones used in Figure A). By hovering within these figures, an
informational balloon (Figure C) appears showing the particular movie, the real user’s rating (4?) and the prediction
proposed by the system (3?).
By means of this explanation the user has information
about a wide spectrum of situations, ranging from those that
reinforce the system prediction to those explaining a wrong
one. For instance, in our example the user can figure out the

Acknowledgements. This work was supported by the
Spanish Ministerio de Educación y Ciencia (TIN2008-06566C04-01 and TIN2011-28538-C02-02) , Spanish Research Program Consolider Ingenio 2010: MIPRCV (CSD2007-00018)
and Junta de Andalucı́a Excellence Project TIC-04526.

3.

REFERENCES

[1] J. L. Herlocker, J. A. Konstan, and J. Riedl. Explaining
collaborative filtering recommendations. In ACM
conference CSCW’00, 241–250, 2000.
[2] A. Papadimitriou, P.Symeonidis and Y. Manolopoulos.
A generalized taxonomy of explanations styles for
traditional and social recommender systems. Data Min
Knowl Disc, 2011.

2
In case of considering a model-based RS we can use predictions for items related to the target one and/or those items
that best describe the user’s tastes, but how to select the
best ones in this approach remains as open problem.

3

In this paper we only present an snapshot of our study.
The users neither know that they rated these movies nor
that we show the same movies in both interfaces.
4

1064


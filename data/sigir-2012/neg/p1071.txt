Fast On-line Learning for Multilingual Categorization
Michelle Kovesi

Cyril Goutte

Massih-Reza Amini

Interactive Language Tech.
National Research Council
283 Alexandre-Taché
Gatineau, QC, Canada

Interactive Language Tech.
National Research Council
283 Alexandre-Taché
Gatineau, QC, Canada

Lab. d’Informatique de Paris 6
Université Pierre & Marie Curie
4, place Jussieu
75252 Paris, France

Cyril.Goutte@nrc.ca

ABSTRACT

amini@poleia.lip6.fr

our approach performs at least as well as state-of-the art
strategies, while being consistently and signiﬁcantly faster.

Multiview learning has been shown to be a natural and eﬃcient framework for supervised or semi-supervised learning
of multilingual document categorizers. The state-of-the-art
co-regularization approach relies on alternate minimizations
of a combination of language-speciﬁc categorization errors
and a disagreement between the outputs of the monolingual text categorizers. This is typically solved by repeatedly
training categorizers on each language with the appropriate
regularizer. We extend and improve this approach by introducing an on-line learning scheme, where language-speciﬁc
updates are interleaved in order to iteratively optimize the
global cost in one pass. Our experimental results show that
this produces similar performance as the batch approach, at
a fraction of the computational cost.

2. FRAMEWORK
We consider the representation of a bilingual document as
1
2
v
a pair of two vectors x def
= (x , x ), where each vector x
provides the representation of the same document in a given
vectorial space Xv , v ∈ {1, 2} associated to each language.
Our goal is to learn languages-speciﬁc categorizers h1 (x1 )
and h2 (x2 ) that minimize prediction error over new documents in either language. Original work [1] solved this by
minimizing a global loss on a training set S = {(xi , yi )}N
i=1 :
L(h1 , h2 , S) = C(h1 , S) + C(h2 , S) + D(h1 , h2 )
{z
}
|
| {z }
misclassiﬁcation
disagreement

(1)

using either logistic regression or Boosting. These are optimized in turn on each language by minimizing the misclassiﬁcation loss for that language and the disagreement, and
alternating between languages until convergence[1, 2].

Categories and Subject Descriptors
I.2.7 [Artificial Intelligence]: Natural Lang. Processing

Keywords
3. ALGORITHM FOR ONLINE LEARNING

Multilingual text categorisation, on-line learning

When many examples are available, online learning has
been shown to provide an eﬃcient way to train models. Instead of optimizing the model over the entire training set,
online learning randomly picks one example and adjusts the
model based on that example alone. Although it doesn’t
directly optimize the full cost function, it can handle large
datasets very eﬃciently[3].
We consider two linear binary categorizers with parameters wv ∈ Xv , v ∈ {1, 2} associated to each of the two
languages. Each may be trained independently by on-line
learning in the co-classiﬁcation framework outlined above.
However, we propose to jointly train both models in the
same stochastic online learning process. At each iteration
t, a multilingual document (xt , yt ) is picked randomly from
the training set and presented to both model. If it is misclassiﬁed by classiﬁer v (i.e. wv , xvt .yt < 0), the categorizer
is updated using the following rule:
„
«
∂D
(2)
wv ← wv + η yt xvt + λ v (xt , wv , wv )
∂w

1. INTRODUCTION
Large annotated multilingual corpora are massively produced by many national or supra-national initiatives and are
now available for various purposes, e.g. machine translation
[4], semantic web [6] or classiﬁcation [1]. For the latter,
multiview learning was shown to be a natural and eﬃcient
framework for supervised or semi-supervised learning of multilingual document categorizers [2].
We propose a new online learning algorithm for multilingual document categorization that is as eﬃcient as, and
much faster than, state-of-the-art multilingual categorization algorithms. Our approach operates by learning two
language-speciﬁc categorizers, iteratively adjusting their parameters on the basis of the prediction error on each language and the disagreement between the predictions on either language. The main diﬀerence with previous co-classiﬁcation work is that we leverage the structure of perceptron updates in order to learn both categorizers simultaneously instead of alternatingly. Experiments carried out
on Reuters RCV1/RCV2 multilingual documents show that

where wv stands for the categorizer on the other language,
and η is the learning rate, while λ weighs the inﬂuence of the
disagreement term (part of D in eq. 1). Following [1], we set
the disagreement function D to the Kullback-Leibler divergence between the outputs of the categorizers on each view,

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1071

hv and hv , mapped to [0; 1] with a sigmoid transformation
(σ(x) = 1/(1 + e−x )). We then get:
(3)

The algorithm is summarized as follows:
Algorithm: Online co-classiﬁcation
repeat
for i = 1, ..., m do
Pick example (xt , yt ) ∈ Zl at random;
Update w1 for example xt (eq. 2-3);
Update w2 for example xt (eq. 2-3)
end
until Convergence of global loss ;

5000

EXPERIMENTAL RESULTS

1

20

50

We illustrate our method on data from a large extract of
the RCV1 corpus [5], processed and made freely available
for multiview multilingual learning experiments [2].1
We used the entirety of the English and French documents
(N = 111, 740 documents), comprised of both originals and
machine-translated Reuters newswire stories covering 6 categories: C15, CCAT, E21, ECAT, GCAT and M21. In these
experiments, we randomly sampled 20 diﬀerent training sets
of 10,000 documents from the full corpus, each with a corresponding (non-overlapping) test set of 90,000 documents.
All results are averaged over these 20 samples. For each category, we measured the performance using the F-score, and
the training time (in seconds), excluding data load.
Table 1 shows the experimental results obtained using the
state-of-the-art batch algorithm as well as using online approaches with interleaved updates. As observed in the original work of [1], the performance achieved by the English
and French categorizers are very similar, within one point
in F-score. This is due to the fact that we minimize the disagreement between the categorizers, therefore biasing them
to provide the same categorization (and therefore reach similar scores) in either languages. We see also see that the Fscores are very close for both algorithms, apart from ECAT
where the online version does about 1 point better. This
is expected as both algorithms learn similar, linear models minimizing the same cost using similar updates. We do
not expect large diﬀerences in performance, we expect large
diﬀerences in training time [3]. Here, the online approach
provides a very clear and consistent speedup (rightmost column). It is about three times faster, completing training
within 11 to 27 seconds depending on the category, while
the original batch approach requires 34-71 seconds.
In a typical scenario, convergence is achieved by the online approach (at the chosen convergence threshold) using 7
to 10 epochs over the entire training set. By contrast, the
batch algorithm performed as little as 2 (but usually more)
alternate otimizations of the models in each view, each composed of several epochs on the training set. This therefore
multiplies the overall training time. The following ﬁgure
shows that the speedup of the online vs. batch algorithm
actually increases as the training set size increases.

1000

Training time (s)

4.

Computational Effort
online
batch

200

“
”
∂D
(x, wv , wv ) = xv σ(wv , xv ) − σ(wv , xv )
v
∂w

Table 1: Online vs. batch results (F-score and time).
Perf. English Perf. French
Time (s)
Cat.
batch online batch online bat onl
×
C15
79.9
79.8
78.8
78.7
51 17 3.0
CCAT 70.0
70.0
69.1
69.0
65 27 2.4
E21
72.8
72.7
71.9
72.0
56 17 3.3
ECAT
68.7
69.6
67.8
68.9
71 27 2.7
GCAT 78.1
78.1
77.1
77.0
53 17 3.2
M11
88.5
88.3
87.5
87.6
34 11 3.0

2

4

6

8

10

Training set size (x10k documents)

5.

DISCUSSION AND CONCLUSIONS

We propose a novel online algorithm that builds on the coclassiﬁcation work of [1], but leverages the structure of online
perceptron learning in order to simultaneously update the
models on both views at each example presentation, yielding a clear and consistent speedup while providing similar
performance.
This provides a natural way to learn multiple categorizers
in a multiview learning framework, without the need to resort to alternating optimizations of regularized view-speciﬁc
losses as in the original co-classiﬁcation approach. In addition, although we have not yet obtained evidence for that,
we expect that it will scale up better to more than 2 languages, because all models can be updated simulatneously
at each iteration, instead of alternating view-speciﬁc optimizations. We expect that further work will shed light on
the scalability to larger corpora and more languages.

6.

REFERENCES

[1] M.-R. Amini and C. Goutte. A co-classiﬁcation
approach to learning from multilingual corpora.
Machine Learning, 79(1-2), 2010.
[2] M. R. Amini, C. Goutte, and N. Usunier. Combining
coregularization and consensus-based self-training for
multilingual text categorization. In SIGIR’10, 2010.
[3] L. Bottou and Y. LeCun. Large scale online learning. In
NIPS 16, 2004.
[4] A. Eisele and Y. Chen. MultiUN: A multilingual corpus
from united nation documents. In LREC’10, 2010.
[5] D. D. Lewis, Y. Yang, T. Rose, and F. Li. A new
benchmark collection for text categorization research.
J. Machine Learning Research, 5:361–397, 2004.
[6] B. Pouliquen, R. Steinberger, and C. Ignat. Automatic
annotation of multilingual text collections with a
conceptual thesaurus. CoRR, abs/cs/0609059, 2006.

http://multilingreuters.iit.nrc.ca

1072


Finding Web Appearances of Social Network Users
via Latent Factor Model ∗
Kailong Chen†‡

Zhengdong Lu‡

Xiaoshi Yin‡

Yong Yu† Zaiqing Nie‡

† Dept. of Computer Science

‡ Microsoft Research Asia

 School of Computer Science

& Engineering
Shanghai Jiao Tong University
Shanghai, China

49 Zhichun Rd.
Beijing, China

& Engineering
Beihang University
Beijing, China

{chenkl,yyu}@sjtu.edu.cn

zhengdol@microsoft.com
xiaoshiyin@cse.buaa.edu.cn
znie@microsoft.com

ABSTRACT

Name ambiguity is a major obstacle of ﬁnding web appearances for speciﬁc persons, especially the unknown average Joes. Fortunately, social networks like Facebook provide
rich user information such as user proﬁles, friends relations,
which are very useful for disambiguating web appearances.
Here we propose a novel and eﬀective latent factor model to
ﬁnd the low dimensional representations of users and web
pages then measure the relevance between them as a key
element for judgement. Our method not only utilizes the
information provided by social networks, but also considers
the link structure of web pages. Our experiments show all
these considered elements combined help improve targeting
the web pages of a speciﬁed social network user.
Past related research about ﬁnding web appearances has
focused much on name disambiguation by grouping web
pages into clusters, each corresponding to a real person [4, 6,
5]. Han [3] enhanced name disambiguation by exploiting the
semantic knowledge existed in multiple knowledge sources.
Bekkerman [1] disambiguated a group of people in a mail
list based on clustering models.

With the rapid growing of Web 2.0, people spend more time
on social networks such as Facebook and Twitter. In order
to know the people they are interacting with, ﬁnding the
web appearances of them will help the social network users
to a great extent. We propose a novel and eﬀective latent
factor model to ﬁnd web appearances of target social network users. Our method solves the name ambiguity problem
by simultaneously exploring the link structure of social networks and the web. Experiments on real-world data show
the superiority of our method over several baselines.

Categories and Subject Descriptors
H.4.0 [Information Systems]: Information Systems Applications—General

General Terms
Algorithms, Experimentation

Keywords

2. LATENT FACTOR MODEL FOR FINDING WEB APPEARANCES

Name Disambiguation, Social Network, Latent Factor Model

In latent factor model, we try to determine the low dimensional representations for social network users and web
pages. In the ﬁrst step, we format queries by combining each
user’s information such as names, colleges, occupations then
use them to retrieve in a search engine. All the retrieved web pages are web appearances candidates of targeting users
because they contain their names. W is deﬁned as the initial relevance score between social network users and web
pages. This matrix can be regarded as a noisy observation
of the grant truth and it actually provides a lower bound of
the name disambiguation performance. Many strategies can
be used to deﬁne W , such as the text similarity between a
user proﬁle and a web page, or the retrieval score returned
by the search engine, etc. In our experiment, Wi,j is simply
deﬁned as a binary indicator of whether the name of user
i appears in web page j. To consider the observed entries
in W , the latent factors are designed to meet the following
requirement:

1. INTRODUCTION
Searching web pages related to a person in search engines
is a common experience of web users [2]. This is because
the web is a rich knowledge base of people and web users
would like to search the web appearances of their friends or
acquaintances to know more about them. With the rapid
growing of social networks, web users spend more time on
social networks to join in activities via interacting with other people. Finding web appearances of other users on social
networks will meet the user demands to a great extent, because this will help them know more about each other and
have better communications and interactions. In this paper, we propose a novel and eﬀective model to ﬁnd the web
appearances of targeting social network users.
∗This work was done when Kailong Chen and Xiaoshi Yin
were visiting Microsoft Research Asia.

U V ≈ W
Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

(1)

where U = [u1 , u2 , · · · , uN ], V = [v1 , v2 , · · · , vM ]. ui ∈ Rd
and vi ∈ Rd are latent factors of user i and page j respec-

1077

tively. N is the number of users and M is the number of
web pages. d is the dimension of latent factors.
To consider the social relations in disambiguation, we try
to smooth a user’s latent factors by considering his neighborhoods. The smoothing strategy can be expressed as below:
U  U ≈ λe E

Searche Engine
Co-occurrence
Clustering
Latent Factor

(2)

P@10. For comparison, the ﬁrst baseline is that pages are
ranked the same as in the order returned by search engine.
The second baseline, co-occurrence method ranks the pages
by counting the names of a user’s friends appeared in each
page. In another baseline we identify the largest connected subgraph in all retrieved pages as the central cluster G,
then rank web pages according to the Euclidean distances
to the center of G. Here the links of web pages is the same
as the ones in latent factor model. This is based on an
intuitive assumption that the web pages in central cluster
are more likely to be web appearances of the social network
users, as mentioned in [1]. Table 1 shows the performances
of the baselines and the latent factor model. The low performance of search engine results indicate the seriousness
of name ambiguity. The co-occurrence method greatly improves upon the search engine results on both data set. This
shows that the social relations provide valuable context information for name disambiguation, even with a relatively
naive model. Using the link structure of the web as context
knowledge, the result of the clustering model is substantially
better than co-occurrence method. Compared to the clustering baseline, latent factor model achieves 7.0% and 13.8%
improvement on two data sets in terms of MAP and performs the best. Our experiments show that the performance is
relatively insensitive to λe and λp . According to the overall
best performance these parameters are set as λe = 1 and
λp = 1. Similarly the dimension of latent factors d is set as
20. In summary, evaluation results indicate that both the
social network structure and the link structure of the web
can help reduce name ambiguity, and our proposed latent
factor model makes eﬀective use of these information and
performs superior to all the competing models.

(3)

Here P is the adjacent matrix of web pages. However, the
relations between web pages are not explicitly deﬁned as social relations. Here we assume that if two web pages contain
a hyperlink to the same page or one of them link to the other, there is a link between them. This is also based on an
intuitive assumption that if two web pages are close on the
web, the content of them will be more relevant than others.
Considering all the elements mentioned above, we use
Frobenius norm and a linear combination strategy to express
the requirements as the following optimization problem:
min U  U − λe E2 + 2U  V − W 2 + V  V − λp P 2 . (4)
U,V

Mathematically, solving this optimization problem can be
equivalently written as optimization over C as
min C − C0 F


C




s.t. rank(C) ≤ d,


(5)





λe E W
U
U V , C0 =
. The global
W  λp P
V
optimal solution to C can be obtained by performing singular value decomposition on C0 . λe and λp specify the
inﬂuence strength of social relations and the web link structure on latent factor model respectively. After getting the
latent factors, we obtain the relevance score between a user
and a web page by calculating the inner product of their
factors. These relevance scores indicates the probability of
a web page is the web appearance of a speciﬁed user and we
use them to rank the web pages for each user as the ﬁnal
displayed results.

where C =

3.

Industry
MAP
P@10
0.3419 0.2850
0.4825 0.4350
0.6652 0.6150
0.7391 0.7001

Table 1: Evaluation Results on Both Data Sets

Here λe is a constant for scaling, E is the adjacent matrix of
the social network. This is based on an intuitive assumption
that if two users have neighbor relationships like friends,
they are tend to be more similar than others. Similarly, we
also smooth the web pages’ latent factors by meeting the
following requirement:
V  V ≈ λp P

Academia
MAP
P@10
0.3613 0.2900
0.4049 0.4550
0.6546 0.6400
0.7007 0.6650

4.

REFERENCES

[1] R. Bekkerman and A. McCallum. Disambiguating web
appearances of people in a social network. In WWW,
pages 463 – 470, 2005.
[2] R. V. Guha and A. Garg. Disambiguating people in
search. In WWW, 2004.
[3] X. Han and J. Zhao. Structural semantic relatedness: a
knowledge-based method to named entity
disambiguation. In ACL, pages 50–59, 2010.
[4] D. Kalashnikov, R. Nuray-Turan, and S. Mehrotra.
Towards breaking the quality curse.: a web-querying
approach to web people search. In SIGIR. ACM, 2008.
[5] J. Tang, Q. Lu, T. Wang, J. Wang, and W. Li. A
bipartite graph based social network splicing method
for person name disambiguation. In SIGIR, 2011.
[6] M. Yoshida, M. Ikeda, S. Ono, I. Sato, and
H. Nakagawa. Person name disambiguation by
bootstrapping. In SIGIR, pages 10–17. ACM, 2010.

EXPERIMENTS

Two social network data sets are derived from a popular social network site in our experiments. We begin with
a single user and expanded the user-base by following their
friends’ links. To ensure there are enough neighbors for each
person, we remove the nodes whose degree is less than ﬁve
in the base. With two diﬀerent seeds, we get two user sets,
an academia set containing 271 researchers from the areas
of information retrieval, bioinformatics, and an industry set
containing 254 employees in a software company. For each
data set, 20 users with serious name ambiguities are used
to format queries and retrieve the top 100 web pages from
a search engine, and ﬁnally there are 4000 web pages for
evaluation. Pages with no links and pdf ﬁles are disregarded while evaluation. Each web page is manually labeled as
relevant or non-relevant to the given user and the performance are measured by using mean average precision and

1078


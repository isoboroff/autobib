See-To-Retrieve: Efficient Processing of Spatio-Visual
Keyword Queries
Chao Zhang

Lidan Shou

Ke Chen

Gang Chen

College of Computer Science
Zhejiang University, China

{chaozhang,should,chenk,cg}@zju.edu.cn
ABSTRACT

surroundings. In what people call cyber-physical mobile applications, a user holding a smart phone may be able to perform a 3D
walkthrough around her location or issue a reality-augmented Web
search in her real-time camera video. Such applications identify
new data retrieval problems.
Let us look at one example, a tourist in a city of attractions
searches for introductory information about a distant grand church
within her eyesight. With a reality-augmented search gadget, she
can simply type the keyword ‚Äúchurch‚Äù and then expect the Web pages about that particular church to be displayed on her mobile device, as shown in Figure 1. The most distinguishing characteristic of such applications is the need for What-You-RetrieveIs-What-You-See (WYRIWYS). Specifically, we need to retrieve
spatial Web objects which are both visually conspicuous in physical space and semantically relevant in document space.

The wide proliferation of powerful smart phones equipped with
multiple sensors, 3D graphical engine, and 3G connection has nurtured the creation of a new spectrum of visual mobile applications.
These applications require novel data retrieval techniques which
we call What-You-Retrieve-Is-What-You-See (WYRIWYS). However, state-of-the-art spatial retrieval methods are mostly distancebased and thus inapplicable for supporting WYRIWYS. Motivated
by this problem, we propose a novel query called spatio-visual keyword (SVK) query, to support retrieving spatial Web objects that
are both visually conspicuous and semantically relevant to the user.
To capture the visual features of spatial Web objects with extents,
we introduce a novel visibility metric which computes object visibility in a cumulative manner. We propose an incremental method
called Complete Occlusion-map based Retrieval (COR) to answer
SVK queries. This method exploits effective heuristics to prune the
search space and construct a data structure called Occlusion-Map.
Then the method adopts the best-first strategy to return relevant objects incrementally. Extensive experiments on real and synthetic
data sets suggest that our method is effective and efficient when
processing SVK queries.

Search Results:
1. St. Peter's Basilica
The Papal Basilica of
Saint Peter (Latin:
Basilica Sancti Petri),
commonly known as
Saint Peter's Basilica,
is a Late Renaissance
church located within
the Vatican City...
>>View Web Pages

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Search Process

General Terms

Figure 1: An example of WYRIWYS

Algorithms, Experimentation
Unfortunately, the information retrieval community has not realized the importance of supporting WYRIWYS. State-of-the-art spatial access methods are mostly distance-based and thus inapplicable for supporting WYRIWYS. The recent development of spatial
keyword query (SKQ) processing techniques [3, 12, 8, 5, 2] along
with several variants [19, 1] can be utilized to support locationbased keyword search. However, none of these works can provide
WYRIWYS for the following reasons: (1) First, most SKQ techniques overlook the visibility of objects. These techniques model
an object as an entity with location and keywords. A typical SKQ
processor computes the similarity between an object and the query
by combining their spatial proximity and semantic relevancy. Objects that are spatially close to the query location are inclined to
be returned, whether they are visible to the user or not. Considering our example of reality-augmented search, a SKQ may retrieve
numerous unwanted churches which are close but invisible to the
tourist. (2) Second, the previous methods consider each object as a
point of interest. Such a simplification fails to utilize the extent data
of spatial objects, which are readily available among map service

Keywords
Location-based query, Keyword search, Visibility, Indexing

1. INTRODUCTION
The wide proliferation of powerful smart phones equipped with
multiple sensors, 3D graphical engine, and 3G connection has nurtured the creation of a new spectrum of visual mobile applications.
In these applications, users in the real world can be supplied ‚Äúon the
spot‚Äù by cyber information that is tightly coupled with the physical
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGIR‚Äô12, August 12‚Äì16, 2012, Portland, Oregon, USA.
Copyright 2012 ACM 978-1-4503-1472-5/12/08 ...$10.00.

681

providers1 . Thus, visually conspicuous objects have no privilege
over inconspicuous ones when being retrieved.
Motivated by the absence of effective retrieval techniques when
developing a cyber-physical mobile search prototype [16], we study
a novel query called the spatio-visual keyword (SVK) query. Given
a collection C of spatial Web objects and a query q, a SVK query
returns a list of k objects in C with the largest scores, where the score of each object is computed by combining its physical visibility
and semantic relevancy with respect to q. Note that the SVK query
is different from simply imposing visible judgment on distancebased spatial keyword queries, since the visual conspicuousness of
objects should be quantitatively measured, based on human visual
perception. For this purpose, we propose a novel visibility metric,
which measures the visible parts of an object in a cumulative way.
The SVK query is interesting not only because it is useful in real
applications, but also because it introduces several new challenges.
To the best of our knowledge, no state-of-the-art technique exists
for the handling of SVK queries. On one hand, instead of being independent, each object may be partially or totally occluded by other
objects. Therefore, the processing of SVK queries is much more
challenging than that of distance-based spatial keyword queries,
considering the complex correlations among the objects. On the
other hand, existing works [10, 9, 15] on visible spatial queries employ Boolean judgment to deal with visibility analysis. The major
drawback of such a mechanism is that the degree of being visible
cannot be distinguished for visible objects. Thus, the existing visible query techniques are not applicable for SVK queries either.
To address the above problems and effectively process SVK queries,
we propose the Complete Occlusion-map based Retrieval (COR)
method. This method employs the hybrid index IR-tree [5] and
works in a two-step manner. In the first step, a dynamic structure
called Complete Occlusion-Map (COM) is built, which partitions
the surrounding space of the query point into a number of angular ranges and maintains visibility information for each range. In
the second step, COR computes the accurate visibilities for objects, as well as the tightest visibility upper bounds for IR-tree nodes.
By taking advantage of the best-first search, the search space is effectively pruned and the top-k relevant objects are returned in an
incremental manner.
The main contributions of this paper are:

2.

In this section, we review existing works related to SVK queries,
including spatial keyword queries and visible spatial queries.

2.1

Spatial Keyword Queries

Spatial keyword queries have been extensively studied recently.
To retrieve objects relevant to the query keywords within a prespecified region, Chen et al. [3] utilize separate indexes for spatial
and textual features. A set of candidate objects is retrieved using
the index upon one attribute, which is then refined with the index
upon the other attribute. The major drawback of such a mechanism
is that the candidate set obtained based on one feature may be too
huge. To address this problem, Hariharan et al. [12] propose a
hybrid index KR*-tree by augmenting each R*-tree node with a
set of keywords appearing in the corresponding subtree. At query
time, KR*-tree is traversed, objects containing query keywords and
intersecting with the query region are returned. Felipe et al. [8]
propose another hybrid index: the IR2 -tree, which integrates Rtree [11] with signature files. In the query process, the signature
file of an IR2 -tree node is loaded into memory. Thus, nodes that do
not contain all the query keywords are pruned early on and relevant
objects are returned incrementally.
Limited by the nature of signature files, the IR2 -tree does not
support ranking on textual relevancy. Moreover, loading the signature file of all words into the memory may incur substantial I/O
cost. In [5], Cong et al. propose the IR-tree index. Different from
IR2 -tree, IR-tree augments each R-tree node with an inverted file
for the objects contained in the subtree rooted at that node. Based
on IR-tree, Cong et al. develop an efficient solution for answering
location-aware top-k text retrieval (LkT) query. Unfortunately, the
LkT query is essentially distance-based, which fails to consider object visibility. Thus, objects spatially close to the query location are
always inclined to be returned, whether they are visible or not. This
difference renders their query techniques infeasible for answering
SVK queries.
Several other variants of spatial keyword query have also been
studied in [19, 1, 18]. However, these works do not take into account visibilities of objects either, and our focus, the integration of
physical visibility and cyber information, has not been studied yet.

2.2

1. We propose a novel query, namely the SVK query, to retrieve
spatial Web objects that are both visually conspicuous and
semantically relevant. To the best of our knowledge, it is the
first work supporting WYRIWYS for spatial Web objects.

RELATED WORK

Visible Spatial Queries

Visibility analysis has been well studied in the field of computer
graphics [4] and computational geometry [6] in various approaches.
To the best of our knowledge, all these approaches assume the data
are memory-resident. Apparently, this is not a practical assumption
for location-based Web search applications, which usually involve
extremely massive data.
In the database community, Kofler et al. [13] propose the LoDR-tree, which exploits spatial proximity to identify visible objects.
Shou et al. [17] design the HDoV-tree, which pre-computes visibility information and incorporates it into the nodes of LoD-R-tree.
But the genuine purpose of both LoD-R-tree and HDoV-tree lies in
accelerating environment rendering in virtual walkthrough applications. Without maintaining semantic features of objects, they are
not capable of supporting SVK queries. More recently, Nutanong
et al. propose the visible k nearest neighbor (VkNN) query in [15].
The goal is to retrieve k objects with the minimum smallest visible distances (MINVIDIST) to a query point q. Nutanong et al.
prove that it is sufficient to determine the MINVIDIST of an object o by considering only objects nearer than o. On the basis of this
observation, they demonstrate the Post-Pruning and Pre-Pruning algorithms to obtain visible nearest neighbors. Several extensions of
the VkNN query are also studied [10, 9]. These works do consid-

2. We present a quantitative visibility metric, which captures
the analytical visual angle and distance of an object with spatial extent.
3. We propose an incremental method, namely COR, to handle SVK queries. And we conduct extensive experiments on
both real and synthetic data sets to evaluate the performance
of this method.
The rest of this paper is organized as follows. Section 2 reviews existing works on spatial keyword queries and visible spatial queries. Section 3 conducts visibility analysis for spatial Web
objects, and formally defines the SVK query. Section 4 provides a
baseline solution for SVK query processing. Section 5 presents the
detailed COR method. Section 6 empirically evaluates the performance of the proposed solutions. Finally, Section 7 concludes the
paper.
1
http://www.automotiveit.com/bosch-navigation-app-features-3d"artmap"/news/id-00851

682

Relying on the above assumption, we introduce the concepts of
unobstructed segment and unobstructed face to facilitate visibility
computation for objects.

er the presence of obstacles and the occluding correlations among
objects. Nevertheless, the developed techniques do not constitute
good solutions for our problem. First, as aforementioned, these
works employ Boolean visibility judgment and the degrees of being visible are not distinguished. Second, these works only concern
the spatial visibilities of objects, whereas our SVK query focuses
on the fusion of both visibility and textual relevancy.

3.

D EFINITION 1. C is a collection of spatial Web objects and q
is a query point. For any object o ‚àà C, ab is an unobstructed
segment of o iff the following two conditions hold: 1) ab is on the
boundary of o.pol, 2) for any point p on ab, segment pq does not
cut the projected polygon of any object.

PROBLEM DEFINITION

Let C = {o1 , o2 , ...on } be a collection of spatial Web objects
kept by a central server (e.g., a map service provider). Each object o ‚àà C is defined by a tuple (o.pol, o.height, o.doc). Here,
o.pol is an arbitrarily shaped polygon, representing the projection
of o in the horizontal plane; o.height is the vertical height of the
3D object o; and o.doc is o‚Äôs Web document. Given a query q
with the user location and a set of query keywords specified, i.e.,
q = (q.location, q.keywords), a SVK query retrieves objects in
C that are both visually conspicuous and semantically relevant to
q. In the following, we first present a quantitative visibility metric
in Section 3.1, then combine it with textual relevancy to propose
a hybrid ranking mechanism in Section 3.2, based on which we
formulate the SVK query in Section 3.3.

Informally, an unobstructed segment is a segment on the boundary of the projected polygon that can be completely seen by the
observer. For example, in Figure 2(b), the unobstructed segments
of objects o1 ...o4 are represented by bold lines. Take object o2 as a
specific example, segment ab is unobstructed because any point on
ab is not occluded by obstacles. It is not difficult to find that, each
unobstructed segment in the horizontal plane actually determines
an unobstructed face of the object in the 3D space. Below, we give
the formal definition of unobstructed face.
D EFINITION 2. Given an object o ‚àà C, each unobstructed segment ab of o determines an unobstructed face Fab , which is a vertical rectangle of length |ab| and height o.height.

3.1 Visibility Analysis

K

A number of approaches have been proposed in the computer
graphic community to efficiently render visible objects in 3D environments. These approaches assume the 3D models of objects are
memory-resident, and exploit graphical techniques (e.g., hierarchical Z-buffer) to clip out hidden polygons on the surface of an object
so that visible scenes can be rendered vividly on graphical units.
However, these approaches are inapplicable for visibility computation in SVK applications: Given the huge number of spatial Web
objects, it is extremely difficult, if not impossible, for the server to
access all the complex 3D details of objects, and meanwhile ensure
instantaneous response to the query launcher. Hence, there is an
evident necessity of simplifying occlusion detection among 3D objects, in such a way as to alleviate the computation burden on the
server, but simultaneously guaranteeing a considerable precision.
In view of this problem, we employ a strategy which has been
widely adopted in walkthrough systems [4]. This strategy consists of two steps to determine the visibility of each object. First, it
utilizes the horizontal (2D) projections of objects to determine occlusion. Second, for each unobstructed object, it uses an accurate
3D algorithm to compute visibility. The rationale behind the 2D
approximation of the first step is that, in a wide range of SVK scenarios, the heights of objects are actually in the same range of
magnitude, and thus play a less important role in determining if an
object is visible or not. Just as shown in Figure 2(a), in a typical urban area, it is common that the densely distributed buildings are not
significantly distinguishable in height with respect to an observer.
Moreover, since nearer buildings always appear taller than faraway
ones, it is safe to judge whether an object is visible by examining
its horizontal projection (see Figure 2(b)).

o4

o3

o3

o2

(a) Side view

o1

o4

a
o2
b q

K
)

)

O

O

T
Z

Figure 3: Cumulative face visibility
We proceed to analyze the visibility of an unobstructed face. Intuitively, given an unobstructed face F , F appears more conspicuous if it is large and close to the observer. However, the challenge
is how to define being large and close, given the fact that different
parts on an unobstructed face always have different distances and
orientations. To handle this, we develop a cumulative computing
approach. As shown in Figure 3, we divide F into numerous infinitesimal grids. For each grid, say ŒîF , the distances as well as
orientations of all points on ŒîF to q are considered to be equal
due to its infinitesimal size. Based on this property, we represent
the visibility of ŒîF as
vis(q, ŒîF ) =

areaŒîF ¬∑ sin Œ∏ŒîF
dist2ŒîF

(1)

Here, areaŒîF reflects how large ŒîF is; Œ∏ŒîF is the angle be‚àí‚àí‚Üí
tween qŒîF and F , measuring the orientation of ŒîF with respect
to the observer (when Œ∏ = 90‚ó¶ , ŒîF right faces q); distŒîF is the
Euclidean distance between q and ŒîF which tells how close ŒîF
is. Since ŒîF is a 2D grid, its visibility is inversely proportional to
dist2ŒîF instead of distŒîF .
Based on Equation 1, the visibility of the entire unobstructed face
F can be obtained by summing up the visibilities of all the small
grids, as defined in Definition 3.

o1

(b) Top view

Figure 2: An urban area with four buildings

683

D EFINITION 3. Given a query point q and an unobstructed face
F , for any point p = (l, h) ‚àà F , let dist(l, h) be the Euclidean
‚Üí
distance between q and p, and Œ∏(l, h) be the angle between ‚àí
qp and
F , then the visibility of F with respect to q is defined as

sin Œ∏(l, h)
vis(q, F ) =
dldh.
(2)
2
F dist (l, h)

R

R

R
R

R

R

D EFINITION 4. Given an object o, let S(o) be the set containing all the non-overlapping unobstructed faces of o, then the visibility of o with respect to query q is defined as


R

T
R

The object visibility can then be defined by summing up visibilities of all the unobstructed faces belonging to it.

vis(q, o) =

R

vis(q, F ).

R

Figure 4: Top view of ten spatial Web objects

F ‚ààS(o)

Table 1: Documents of objects o1 ...o10

3.2 Ranking Mechanism
Gothic
Church
Museum

To measure the semantic relevancy between a spatial Web object
and a user query, we adopt the classic TF-IDF model, which has
been widely used in traditional search engines. According to the
TF-IDF model, an object o is assigned a higher ranking value if
the query keyword occurs frequently in o.doc and infrequently in
documents of other objects. Below, we give the formal definition of
semantic relevancy, based on which we derive the weighted ranking
score for a spatial Web object.

4.

o3
4
0
0

o4
2
0
0

o5
0
0
3

o6
5
5
0

o7
0
0
4

o8
0
0
2

o9
0
0
4

o10
0
0
5

A BASELINE SOLUTION

In this section, we provide a baseline solution for answering
SVK queries. The idea is quite straightforward. Given a spatial
Web object, its ranking score is a combination of its visibility and
semantic relevancy. Hence, we can exploit separate spatial and textual indexes of objects, and adapt the threshold algorithm [7] to
return top-k results. Algorithm 1 gives an overview of the solution.

t‚ààq.keywords

where
T F (t, o.doc) = 1 + ln(f requency(t, o.doc))

Algorithm 1: Baseline(q, Œ±, k, RT ree, InvertedF ile)

|C|
.
1 + |objects in C that contain t|

Build a list L of all spatial web objects;
Sort L in the descending order of semantic relevancy;
Initialize an empty set A of a fixed size k;
foreach object o in L do
threshold = the least ranking score in A;
if |A| = k and scoremax (q, o) ‚â§ threshold then
break;

score(q, o) = Œ± ¬∑ ||vis(q, o)|| + (1 ‚àí Œ±) ¬∑ ||rel(q, o)||.

1
2
3
4
5
6
7

The weighted ranking score is virtually a linear interpolation that
combines physical visibility and semantic relevancy, and Œ± is a parameter used to balance two aspects. Note that both visibility and
relevancy of an object are normalized into the range [0, 1].

8
9
10
11

3.3

12 return A

D EFINITION 6. Given a collection of spatial Web object C, a
query q, and a pre-specified value Œ± ‚àà [0, 1], for any object o ‚àà C,
the weighted ranking score of o with respect to q is:

The SVK Query

o2
1
2
0

this area may want some introductory information when he faces a
grand church o1 , and thus issues a top-1 SVK query at q with the
keyword ‚Äúchurch‚Äù. As a result, church o1 with its cyber information will be returned to the user, since it is both visually conspicuous and semantically relevant. Note that, although another church
o6 is actually nearer than o1 , it is not returned because it is completely occluded by o7 and is not what the user demands.

D EFINITION 5. Given a collection of spatial Web object C and
a query q, for any object o ‚àà C, the semantic relevancy between q
and o is:

rel(q, o) =
T F (t, o.doc) ¬∑ IDF (t, C)

IDF (t, C) = ln

o1
5
5
0

Based on the definition of weighted ranking score, we formulate
the SVK query as follows.

Compute vis(q, o) with RT ree;
score(q, o) = Œ± ¬∑ ||vis(q, o)|| + (1 ‚àí Œ±) ¬∑ ||rel(q, o)||;
if |A| < k or score(q, o) > threshold then
Update A with o;

As shown, we first build a list L of all spatial Web objects, which
are sorted in the descending order of semantic relevancy. Then we
initialize a empty result set A with a fixed size k, and keep track
of the least ranking score in A as threshold. Next, we scan L
sequentially and progressively update A (lines 4-11). Note that L is
actually unnecessary to be scanned entirely. For object o currently
being processed, if o‚Äôs score is below threshold even when we
set o‚Äôs visibility to the visibility upper bound (line 6), it is ensured
further scanning will not generate top-k results any more and the
algorithm safely terminates.

D EFINITION 7. Given a collection of spatial Web objects C, a
user query q, and an integer k, the result of SVK query is a list L
of spatial Web objects such that, 1)L ‚äÜ C, 2)|L| = k (given that
|C| ‚â• k) , 3)‚àÄo ‚àà L, ‚àÄo ‚àà C ‚àí L, score(q, o) ‚â• score(q, o ).
To specify our previous example query for church, Figure 4 depicts the top view of an area in Rome comprising ten buildings
o1 ...o10 , whose documents are described in Table 1. A tourist in

684

unobstructed face F constituted by four points (0, 0, 0), (0, l0 , 0),
(0, l0 , h0 ) and (0, 0, h0 ), the visibility of F with respect to q can
be derived as follows.
]

Clear as Algorithm 1 appears, the difficult part lies in the computation of object visibility. In the following, we elaborate line 8
and discuss how to derive object visibility with R-tree. Note that
the R-tree only needs to index the projected 2D polygons of objects,
with their heights stored as associating features to support visibility
computation.
In the horizontal plane, each object o occupies an angular range
with respect to the query point q. Apparently, only objects falling in
that angular range and nearer than o can potentially occlude o. We
retrieve such objects using R-tree and call them potential occluders.
Next, we need to retrieve o‚Äôs unobstructed segments, and then sum
up the visibilities of their corresponding unobstructed faces. Recall
Definition 1, a segment ab is identified as unobstructed when any
point on ab is not occluded by other objects in the horizontal plane.
In other words, an unobstructed segment is essentially the nearest
segment to the observer within its angular range. Thus, the problem
is equivalent to comparing edges of o.pol with polygon edges of the
potential occluders, and obtain the nearest segments that belong to
o.pol. Suppose e1 and e2 are two edges sharing a common angular
range [Œ∏low , Œ∏high ], and their portions in [Œ∏low , Œ∏high ] are ab and
cd respectively. Then, as shown in Figure 5, the relationship of
segments ab and cd can be categorized into four cases:

K
)
S
O

\

T
[

Figure 6: Unobstructed face visibility computation
Refer to Figure 6, for any point p ‚àà F , we denote by Œ∏(q, p) the
‚Üí
angle between ‚àí
qp and F , by dist(q, p) the distance between q and
p, and by dist(q, F ) the perpendicular distance from q to face F .
Then the following equation holds.

‚Ä¢ Case 1: ab and cd completely overlap in [Œ∏low , Œ∏high ].
‚Ä¢ Case 2: ab and cd do not intersect in [Œ∏low , Œ∏high ].

sin Œ∏(q, p) =

‚Ä¢ Case 3: ab and cd intersect, and the intersecting point is along Œ∏low or Œ∏high .


vis(q, F )

=

0‚â§y‚â§l0
0‚â§z‚â§h0



EG

DF

G
E

D

=

G

F
EG

D

S E
D


=

F

=
T

T

T

T

&DVH

&DVH

&DVH

&DVH

(3)

Combining Definition 3 and Equation 3, the visibility of F can
be further developed as follows:

‚Ä¢ Case 4: ab and cd intersect, and the intersecting point is along Œ∏ ‚àà (Œ∏low , Œ∏high ).

F

dist(q, F )
dist(q, p)

h0
0



dist(q, F )
dydz
dist3 (y, z)

l0
0

xq
(x2q

3

+ y2 + z2 ) 2

dydz

h0

xq l 0

dz
+
z 2 + x2q + l02
0
l 0 h0
arctan 
xq x2q + l02 + h20
(z 2

x2q )

We can see the visibility of an unobstructed face is closely related to: (1) its area, (2)its minimum visible distance to the query
point, and (3) its maximum visible distance to the query point. This
explains why the cumulative visibility provides an accurate capture
of the visual features of an object.
The above discussion addresses the problem of computing object
visibility and thus makes Algorithm 1 feasible. Unfortunately, the
baseline solution is far from being efficient. On one hand, since
an unobstructed segment is the only occluder in its angular range,
it is highly redundant to retrieve potential occluders repeatedly to
compute visibility for each object in L. On the other hand, the
separation of indexes fails to closely combine the spatial and textual
features of objects, and incurs unnecessary overhead.

Figure 5: Edge relationships
Case 1, 2 and 3 are actually the same to deal with. In the horizontal plane, as long as one segment is nearer than the other along
any direction Œ∏ ‚àà (Œ∏low , Œ∏high ), it is guaranteed that segment will
be nearer for the entire angular range. For Case 4, both segments
are nearer to the query point but in different sub angular ranges. We
need to compute the intersecting point p and split [Œ∏low , Œ∏high ] a‚àí
long the direction of ‚Üí
qp. Then the nearer segment in each sub range
can be easily obtained.
By comparing the polygon edges of o and o‚Äôs potential occluders, we are able to obtain the nearest segments in o‚Äôs angular range,
and identify o‚Äôs unobstructed segments. Then the unobstructed
faces of o in the 3D space can be constructed. The remaining job
is to compute visibility for each unobstructed face and sum them
up. For clarity but without loss of generality, we assume the coordinate of the query point q in the 3D space is (xq , 0, 0) 2 . Given an

5.

THE COR METHOD

In this section, we present the COR method to handle SVK queries
more effectively. This method employs the hybrid index IR-tree,
and performs query processing in two steps. In the first step, a novel structure called Complete Occlusion-Map (COM) is constructed,
underpinning the support for high-performance visibility computation. In the second step, the method uses the best-first strategy to
retrieve the top-k relevant objects incrementally. In what follows,

2
Handling the cases where yq , zq = 0 is straightforward using the
substitution method for integral.

685

we first give a brief introduction to the IR-tree index and the COM
structure in Section 5.1, then elaborate the two steps in Section
5.2 and Section 5.3, and finally discuss the efficiency of the COR
method in Section 5.4.

5.1

R

I

R

H
G
J

Data Structures
K

IR-tree [5] is essentially an extension of R-tree by augmenting
each node with a pointer to an inverted file. For a leaf node NL , its
inverted file indexes the documents of all objects in NL . For an intermediate node NI , its inverted file indexes the pseudo documents
of its child nodes. The pseudo document is an important concept
to facilitate the computation of textual relevancy upper bound, because it summarizes the terms of all child entries. Figure 7 is an
example IR-tree for the spatial Web objects o1 ...o10 shown in Figure 4. The ten polygon-shaped objects are grouped according to
their spatial proximity to build up the IR-tree. Similar to the case
of R-tree, as we detect object occlusion in the horizontal plane, the
IR-tree needs to index only the projected polygons of objects, and stores their corresponding heights as additional feature information.
Table 2 lists inverted file contents for all IR-tree nodes.

R

N6 N1 N2 N3

N1 o1 o4

N2 o10

N3 o2 o3

N4 o8 o9

N5 o5

IF1

IF2

IF3

IF4

IF5

IF7

o7

Table 2: IR-Tree Inverted Files

5.1.2

Gothic
(o1 , 5), (o4 , 2)

Church
(o1 , 5)

(o2 , 1), (o3 , 4)

(o2 , 2)

(o6 , 5)
(N1 , 5), (N3 , 4)
(N5 , 5)
(N6 , 5), (N7 , 5)

(o6 , 5)
(N1 , 5), (N3 , 2)
(N5 , 5)
(N6 , 5), (N7 , 5)

P

L
M
R
R

Q
R

O
N

R

Table 3: Complete Occlusion-Map
AR
[Œ∏qb , Œ∏qa ]
[Œ∏qe , Œ∏qf ]
[Œ∏qg , Œ∏qh ]
[Œ∏qi , Œ∏qj ]
[Œ∏qk , Œ∏ql ]
[Œ∏ql , Œ∏qm ]
[Œ∏qm , Œ∏qn ]

Figure 7: The IR-tree

IF1
IF2
IF3
IF4
IF5
IF6
IF7
IF8

T

these attributes facilitate the visibility computation in the dominated angular range.
In Figure 8, [Œ∏ql , Œ∏qm ] is an angular range empty of unobstructed
segment. Such an angular range indicates no object from C lies in
it. We call it a dummy angular range.
In summary, given a collection of spatial Web objects C and a
query point q, let S(C) be the set of all unobstructed segments
from C, then the COM of q is a partition of the space by S(C) into
a set of angular ranges, each angular range is either dominated or
dummy. Table 3 illustrates the COM for the ten objects shown in
Figure 8.

N7 N4 N5

o6

1

E

Figure 8: Partitioning the surrounding space of q into angular
ranges

N8 N6 N7

IF6

F

R

R

5.1.1 The IR-Tree Index

IF8

D

R

Baroque
(o10 , 5)
(o8 , 2), (o9 , 4)
(o5 , 3), (o7 , 4)
(N2 , 5)
(N4 , 4), (N5 , 4)
(N6 , 5), (N7 , 4)

5.2

SEG
ba
ef
gh
ij
kl
null
mn

OID
1
10
8
7
5
null
4

V IS
vis(q, Fba)
vis(q, Fef )
vis(q, Fgh)
vis(q, Fij)
vis(q, Fkl)
0
vis(q, Fmn)

AN C
(8, 6, 1)
(8, 6, 2)
(8, 7, 4)
(8, 7, 5)
(8, 7, 5)
‚àÖ
(8, 6, 1)

Construction of Complete Occlusion-Map

In this subsection, we discuss the construction of COM. The idea
is to traverse the IR-tree and retrieve all the unobstructed segments
to partition the space. A simple search process is described as following: 1) Initialize COM with a large dummy angular range covering the entire plane. 2) Create a priority queue P Q with the IRtree root node. For each entry in P Q, its MINDIST to the query
point q is used as its key. 3) If the head entry of P Q is a node,
dequeue it and insert all its child entries into P Q. 4) If the head of
P Q is an object, dequeue it and update current COM. To be more
specific, each projected polygon edge of the object is compared
with the current COM components to produce nearer segments. 5)
Repeat step 3) and 4) iteratively. When P Q is empty, the construction finishes.
Unfortunately, the above process needs to access all IR-tree nodes and examine every polygon edge of an object. In the following, we elaborate the construction process by presenting three
heuristics to effectively prune the search space.
Firstly, when incorporating an object o to update COM, one can
verify that some edges are in fact hidden by other edges of o.pol
itself. As a concrete example, for o2 in Figure 8, its edges bc, cd,
and da are occluded by edge ab. Apparently, these edges cannot be
unobstructed and it is safe to skip them. Based on this observation,

Complete Occlusion-Map

In the horizontal plane, each unobstructed segment occupies an
angular range and causes an invisible region with respect to the observer. Moreover, the angular ranges of different unobstructed segments never overlap. Therefore, given a query point q and a collection C of spatial Web objects, the set of all unobstructed segments
from C in fact partitions the space surrounding q into a number
of angular ranges, each corresponding to one or zero unobstructed
segment.
As shown in Figure 8, [Œ∏qb , Œ∏qa ] is an angular range occupied by
unobstructed segment ab. In [Œ∏qb , Œ∏qa ], it is guaranteed that only the
corresponding unobstructed face Fab is visible and all other objects
are hidden behind ab, i.e., the angular range [Œ∏qb , Œ∏qa ] is dominated
by Fab . We call [Œ∏qb , Œ∏qa ] a dominated angular range, and define
a tuple (SEG, OID, V IS, AN C) to describe it, where, SEG denotes the dominating unobstructed segment, V IS is the visibility
of the unobstructed face FSEG , OID is the id of the object that
SEG belongs to, and AN C is an array storing the ancestor node
ids of object oOID in the IR-tree. Later in Section 5.3 we will see,

686

5.3

we introduce the concept of back edge, and derive Heuristic 1 to
avoid unnecessary edge comparisons.

In this subsection, we discuss the computation of accurate ranking scores for objects and ranking score upper bounds for IR-tree
nodes, then propose an efficient algorithm to retrieve top-k objects
incrementally.

D EFINITION 8. Given a spatial Web object o and a query point
q, an edge e of o.pol is a back edge iff for any point p on e, segment
pq cuts at least one other edge of o.pol.

5.3.1

H EURISTIC 1. C is a collection of spatial Web objects and q is
a query point. For any object o ‚àà C, none of the back edges of o
can be unobstructed to q.

H EURISTIC 2. During the construction of COM, if N is an IRtree node satisfying the following two conditions: 1) the query point
q stays outside N ‚Äôs MBR, and 2) N ‚Äôs MBR is completely occluded by current COM. Then no object in N may have unobstructed
segment.
In the horizontal plane, each unobstructed segment in COM could
be interpreted as an enhanced nearest surrounder [14], which is
associated with visibility and ancestor IR-tree nodes. Therefore,
a condition designed in [14] to early terminate nearest surrouder
query also applies in COM construction.

5.3.2

Node Ranking Score Upper Bound

We proceed to discuss visibility upper bound computation for
IR-tree nodes. The key is to utilize the attribute AN C of the COM
structure. Given an IR-tree node N and a dominated COM angular
range intersecting N ‚Äôs MBR, the corresponding unobstructed face
belongs to N if and only if N ‚Äôs id is contained in AN C. Hence,
the computation of visibility upper bound for node N is performed
as following: 1) Obtain all COM components that intersect N ‚Äôs MBR. 2) Find the dominated components whose AN Cs contain N ‚Äôs
id, and suppose they are called candidates. Please note that all
dummy components are ignored here, because no object in N can
actually lie in the dummy angular ranges and the occupation must
be caused by MBR expansion. 3) Group the candidates by their
OIDs, thus unobstructed faces of the same object are gathered into
the same group. 4) Aggregate the V IS in each group to obtain the
group visibility. 5) Find the maximum visibility among all groups
and return it as the visibility upper bound of N , which is denoted
by vis(q, N ).

H EURISTIC 3. The construction of COM can terminate when
the following two conditions hold: 1) current COM does not have
dummy angular ranges, 2) the MINDIST of the head entry in P Q
is larger than the minimum bounding radius of current COM.
Algorithm 2: Construct COM (q, IRT ree)
1 Initialize COM to be dummy;
2 Initialize a priority queue P Q with IRT ree.root;
3 while !P Q.isEmpty() do
4
r = minimum bounding radius of COM ;
5
if !COM.hasDummy() and P Q.head().key ‚â• r then
6
break;

10
11
12
13
14
15

Object Ranking Score

Given an object o, its ranking score is the linear combination
of its visibility and semantic relevancy. The semantic relevancy
is quite straightforward to derive by Definition 5, as the terms of
o.doc are all maintained in the IR-tree. Below, we mainly discuss
the computation of its accurate visibility.
The basic idea is to use the COM structure to select all unobstructed faces that belong to o, and then add up their visibilities.
Relying on the OID attribute, the selection is easy, as exemplified
in the following using Figure 8. In the horizontal plane, object o10
intersects with three COM angular ranges: [Œ∏qb , Œ∏qa ], [Œ∏qe , Œ∏qf ],
and [Œ∏qg , Œ∏qh ]. In [Œ∏qb , Œ∏qa ], the value of OID is 1, indicating that
the unobstructed face must belong to object o1 and o10 is occluded. The case is similar in [Œ∏qg , Œ∏qh ] where OID = 8. However, in
[Œ∏qe , Œ∏qf ], OID is 10. We conclude that the corresponding unobstructed face Fef must belong to o10 , and thus return vis(q, Fef )
as o10 ‚Äôs visibility.

The second optimization aims to avoid unnecessary node expansions. Refer to Figure 8 again, N3 is an IR-tree node bounding
o2 .pol and o3 .pol. During the construction of COM, due to a smaller MINDIST, o1 .pol is examined before N3 and segment ab is
retrieved. As a result, N3 ‚Äôs MBR is completely occluded by segment ab. Thus, neither o2 nor o3 can be visible and N3 can be
pruned.

7
8
9

Incremental Object Retrieval

E=P Q.pophead();
if E is an object then
Update COM with non-back edges of E.obj;

T HEOREM 1. The visibility obtained from the above process is
a tightest visibility upper bound for node N .
P ROOF. Step 1), 2), and 3) actually find all the visible objects in
N . By computing their visibilities in step 4) and comparing them
in step 5), it is guaranteed that no object in N has a larger visibility
than vis(q, N ), but at least one object reaches it.

else
foreach entry e in E do
if e.M BR is not completely occluded then
key = M IN DIST (q, e.M BR);
newEntry=(e,key);
Insert newEntry into P Q;

The semantic relevancy between q and N can be derived from
N ‚Äôs pseudo document. Recall that for any term t, the weight of t
in N ‚Äôs pseudo document is no smaller than that of any object in N .
Combining the visibility upper bound vis(q, N ) and relevancy
upper bound rel(q, N ), N ‚Äôs weighted ranking score upper bound
is given by:

16 return COM
With the above three heuristics, we give the elaborated process
for COM construction in Algorithm 2. As shown, entries of the
IR-tree are accessed in the ascending order of their minimum distances to q. In this way, nearby objects, which may bring about
larger invisible space, are given priority. Hence, the prunable area
keeps shrinking and a large number of upcoming entries are pruned
(Heuristic 2). Moreover, so long as the currently retrieved segments
completely surround q and that their bounding radius is smaller
than the MINDIST of the head entry in P Q. The construction terminates successfully according to Heuristic 3.

score(q, N ) = Œ± ¬∑ ||vis(q, N )|| + (1 ‚àí Œ±) ¬∑ ||rel(q, N )||

(4)

T HEOREM 2. The score computed from Equation 4 is a ranking
score upper bound for N .
P ROOF. For any object o contained in N , the following inequality holds according to Theorem 1:
vis(q, N ) ‚â• vis(q, o)

687

6.1 Data Sets

And according to the property of pseudo document, we have:

Our experiments are based on both real and synthetic data sets.
Similar to [5], the real spatial data set LA3 is used. LA contains 131,461 MBRs, representing street objects in Los Angeles. We
normalize all MBRs in LA into the [0,10000]√ó[0,10000] horizontal space, and assign a height within [10,20] to each MBR. Meanwhile, we have crawled a real textual data set from Gowalla4 , which
is a location-based social network providing checking-in and commenting services. The crawled Gowalla set consists of 28,867 Web
documents. Each document is a collection of user-generated comments that aim to describe a point of interest in Los Angeles. By
randomly selecting a document from the Gowalla set for each spatial object in the LA set, we obtain a spatial-textual data set, named
REALDATA.
We also exploit four synthetic data sets to evaluate scalability of the methods, with a cardinality of 100k, 200k, 500k, and
1,000k. Each object in a synthetic data set is described by a tuple (o.mbr, o.height, o.doc). Here, o.mbr is generated uniformly in the horizontal space with a size no larger than 4.00 √ó 4.00
(length√ówidth), o.height is within [10,20], and o.doc is selected
randomly from the Gowalla set.
We use disk-based R-tree (for Baseline) and IR-tree (for COR)
to index these data sets. The page size is fixed at 4KB and the
maximum number of branches per node is 100.

rel(q, N ) ‚â• rel(q, o)
Thus:
score(q, N ) ‚â• Œ±¬∑||vis(q, o)||+(1‚àíŒ±)¬∑||rel(q, o)|| = score(q, o)
which completes the proof.

5.3.3 Retrieval Algorithm
Theorem 2 ensures a hierarchical order of IR-tree nodes‚Äô ranking
scores. Now, we present the algorithm for object retrieval, which
adopts the best-first strategy and returns top-k objects in an incremental manner. As shown in Algorithm 3, a priority queue P Q is
maintained to store objects and IR-tree nodes to be visited, and is
initialized with the root node of IR-tree. The ranking score of each
entry is used as its key in P Q. If the head entry of P Q is possessed
by an IR-tree node, we expand it and elaborate the ranking scores
of its children. If the head entry is occupied by a spatial Web object
o, it indicates that all the objects in P Q do not have a larger score
than o, thus it is safe to report o as the next most relevant object.
When the top-k objects are obtained or P Q becomes empty, the
algorithm terminates successfully.
Algorithm 3: Object Retrieval(q, Œ±, k, COM, IRT ree)

6.2

1 Initialize an empty result set A;
2 Initialize a priority queue P Q with IRT ree.root;
3 while !P Q.isEmpty() and |A| < k do
4
E=P Q.pophead();
5
if E is an object then
6
Insert E.obj into A;
7
8
9
10
11

else
foreach entry e in E do
score = Œ± ¬∑ ||vis(q, e)|| + (1 ‚àí Œ±) ¬∑ ||rel(q, e)||;
newEntry=(e,score);
Insert newEntry into P Q;

12 return A

5.4

Discussion

In the COR method, the cost of the first step is closely related to
the environment around the query point q. If q lies in a dense area,
the COM construction will be quite efficient. This is because unobstructed segments can be retrieved early to surround q, thus most
IR-tree nodes can be pruned with Heuristic 2 and 3. On the contrary, if q lies in an extremely sparse area, a considerable number
of IR-tree nodes may need to be accessed. The cost of the second
step is expected to be small. On one hand, as proved in Theorem
1, the visibility upper bound for IR-tree node is optimal. On the
other hand, the tightness of the upper bound for semantic relevancy
depends on the number of query keywords. Since fewer keywords indicate tighter upper bound for semantic relevancy and in most
applications a query contains only limited number of keywords, the
relevancy upper bound is also expected to be tight.

6.

Query Result Demonstration

We first issue some test queries, and see if the proposed methods
can indeed retrieve spatial Web objects that are both conspicuous
and relevant. For comparison, we also implemented the LkT algorithm [5], which is designed for distance-based spatial keyword
retrieval. Figure 9 and Table 4 report the results of three test queries
on REALDATA. Specifically, Figure 9(a) shows the 131461 objects
in REALDATA as well as the locations of the three queries. Figure 9(b), 9(c) and 9(d) are the respective zoomed-in results of each
query, where the green rectangles are the top-5 SVK query results
with the inside letters denoting object ids. And we use blue rectangles to highlight objects that are in the top-5 LkT query results but
not in the top-5 SVK list.
As shown, the SVK query can retrieve objects that are physically visible and semantically relevant. Taking the first query as a
concrete example, the returned five objects are all within the user‚Äôs eyesight (see Figure 9(b)) and closely related to ‚Äúcoffee" (see
Table 4). Such query results can serve the user with useful cyber
information regarding the physical world that the user sees, and
thus provide an immersive searching experience. Please note that
although object f is semantically relevant, it does not appear in the
top-5 SVK query results due to low visibility. In contrast, the LkT
query always tends to retrieve objects that are close to the user, even
if they are totally invisible. This is because LkT does not take into
account object visibility and thus cannot provide WYRIWYS.

6.3

Efficiency Study

In this subsection, we report the efficiency of Baseline and COR
under various parameter settings. Table 5 shows the parameter
ranges, where the numbers in bold denote the default settings. For
each experiment set, we evaluate the effect of one parameter while
the others are fixed at their default values, and run 100 randomly
generated queries with their average cost reported. Two performance metrics are employed, i.e., the query time and the number

EXPERIMENTS

In this section, we empirically evaluate the effectiveness and efficiency of the Baseline and COR methods. We implement both
algorithms in JAVA and conduct the experiments on an Intel Core
2 Duo 2.93Ghz PC with 2GB memory.

3
4

688

http://www.rtreeportal.org
http://en.wikipedia.org/wiki/Gowalla

(a) 3 queries on REALDATA

(b) Query result 1

(c) Query result 2

(d) Query result 3

Figure 9: Three test SVK queries on REALDATA and their results
Table 4: A Comparison of SVK and LkT Query Results (Œ± = 0.5 k = 5)
Query

q1 =‚Äúcoffee"

q2 =‚Äúhotel"

q3 =‚Äúfilm"

Object ID
a
b
c
d
e
a
b
c
d
e
a
b
c
d
e

Top-5 SVK Query Results
Object Name
SVK Score
Frances Bakery & Coffee
0.806
McDonald‚Äôs
0.729
Strawberry Restaurant
0.636
Costa Coffee
0.529
Cole‚Äôs Restaurant
0.519
Radisson Hotel
0.946
Rose Bowl Motel
0.874
Holiday Hotel
0.817
Pasadena Inn
0.649
Vegabond Hotel
0.521
Pacific Theater
0.791
Park Hotel
0.619
Highland Club
0.518
Keda Entertainment
0.512
Nunavo Cinema
0.508

Object ID
f
a
b
d
c
a
b
c
g
f
a
e
f
c
b

Top-5 LkT Query Results
Object Name
LkT Score
Starbucks
0.985
Frances Bakery & Coffee
0.966
McDonald‚Äôs
0.818
Costa Coffee
0.798
Strawberry Restaurant
0.743
Radisson Hotel
0.975
Rose Bowl Motel
0.948
Holiday Hotel
0.853
Traveler Motel
0.840
Hudson Hotel
0.759
Pacific Theater
0.846
Nunavo Cinema
0.797
Alex Theater
0.764
Highland Club
0.619
Park Hotel
0.613

of IOs. In the following, we present the efficiency results and our
findings. Unless stated explicitly, REALDATA is used.
Table 5: Parameter ranges and default values
Parameter
k
Œ±
number of keywords

Range
5, 10, 20, 30, 50
0.1, 0.3, 0.5, 0.7, 0.9
1, 2, 3, 4

(a) query time

6.3.1

(b) IO cost

Effect of k

In the first set of experiments, we study the effect of k on the
performance of the two methods, and Figure 10 shows the results. Since COR works in a two-step manner, its cost is broken into
two parts: COR-1 denotes the cost of occlusion-map construction
and COR-2 denotes the cost of top-k objects retrieval. As expected, COR significantly outperforms Baseline in terms of both query
time and I/O cost. The total cost of both methods increase with
k, since a larger k causes a larger search space to obtain relevant
objects. But for COR, the cost of occlusion-map construction is
irrelevant to k. Another interesting finding for COR is that, although the I/O cost of object retrieval step is larger than that of
occlusion-map construction step, the computation cost is smaller.
It is explained by the cheap CPU cost of the most frequently used
id-comparison operations in the retrieval step.

Figure 10: The effect of k
However, Baseline sequentially scans all objects based on semantic
relevancy, and thus suffers from a large number of visibility computations.

(a) query time

Effect of Œ±
In the second experiment set, we study the effect of Œ± and report
the results in Figure 11. Again, we can see COR performs much
better than Baseline. Moreover, Baseline deteriorates dramatically as Œ± increases, whereas COR performs well stably. The reason
behind is that, a large Œ± means more emphasis is put on visibility.

(b) IO cost

6.3.2

Figure 11: The effect of Œ±

6.3.3

Effect of number of keywords

In the third experiment set, we look into the effect of the number
of query keywords. As shown in Figure 12, both methods perform

689

8. ACKNOWLEDGMENTS

worse with an increasing number of query keywords. For Baseline,
a large number of query keywords implies that many objects are
not distinguished in terms of semantic relevancy, thus the threshold algorithm terminates later and more objects need to be examined. For COR, although the cost of occlusion-map construction is
not related to the number of query keywords, the retrieval step incurs additional overhead. Specifically, as the number of keywords
increases, the relevancy upper bound becomes looser. Therefore,
more IR-tree nodes need to be accessed, which elevates the number of IOs. Fortunately, as the ranking score computation is quite
cheap, the query time increases slowly.

(a) query time

This work was supported in part by the National Science Foundation of China (Grant No. 60970124, 60903038, and 61170034).

9.

(b) IO cost

Figure 12: The effect of number of keywords

6.3.4 Results for synthetic data sets
We have also carried out extensive experiments on the synthetic
data sets to evaluate the effects of different parameters. We observe
that the tendencies are quite similar to that of REALDATA. Thus,
we only report a subset of them to demonstrate the scalability of
the two methods. Figure 13 shows the query time and IO cost for
experiments on different data sets, when all parameters are fixed
at their default values. We observe that, Baseline performs worse
with an increasing data set size, whereas COR benefits from it. This
is expected, the performance improvement is from the occlusionmap construction step. When the number of objects is large, the
query point is more likely to lie in a dense area, thus unobstructed
segments can be retrieved early to surround it. As a result, most IRtree nodes are pruned early on and few edge comparison operations
are involved.

(a) query time

REFERENCES

[1] X. Cao, G. Cong, and C. S. Jensen. Retrieving top-k
prestige-based relevant spatial web objects. PVLDB,
3(1):373‚Äì384, 2010.
[2] X. Cao, G. Cong, C. S. Jensen, and B. C. Ooi. Collective
spatial keyword querying. In SIGMOD Conference, pages
373‚Äì384, 2011.
[3] Y.-Y. Chen, T. Suel, and A. Markowetz. Efficient query
processing in geographic web search engines. In SIGMOD
Conference, pages 277‚Äì288, 2006.
[4] D. Cohen-Or, Y. Chrysanthou, C. T. Silva, and F. Durand. A
survey of visibility for walkthrough applications. IEEE
Trans. Vis. Comput. Graph., 9(3):412‚Äì431, 2003.
[5] G. Cong, C. S. Jensen, and D. Wu. Efficient retrieval of the
top-k most relevant spatial web objects. PVLDB,
2(1):337‚Äì348, 2009.
[6] M. de Berg, M. van Kreveld, M. Overmars, and O. Cheong.
Computational Geometry: Algorithms and Applications.
Springer, second edition, 2000.
[7] R. Fagin, A. Lotem, and M. Naor. Optimal aggregation
algorithms for middleware. In PODS, 2001.
[8] I. D. Felipe, V. Hristidis, and N. Rishe. Keyword search on
spatial databases. In ICDE, pages 656‚Äì665, 2008.
[9] Y. Gao, B. Zheng, G. Chen, W.-C. Lee, K. C. K. Lee, and
Q. Li. Visible reverse k-nearest neighbor queries. In ICDE,
pages 1203‚Äì1206, 2009.
[10] Y. Gao, B. Zheng, W.-C. Lee, and G. Chen. Continuous
visible nearest neighbor queries. In EDBT, pages 144‚Äì155,
2009.
[11] A. Guttman. R-trees: a dynamic index structure for spatial
searching. In SIGMOD, pages 47‚Äì57, 1984.
[12] R. Hariharan, B. Hore, C. Li, and S. Mehrotra. Processing
spatial-keyword (sk) queries in geographic information
retrieval (gir) systems. In SSDBM, page 16, 2007.
[13] M. Kofler, M. Gervautz, and M. Gruber. R-trees for
organizing and visualizing 3d gis databases. Journal of
Visualization and Computer Animation, 11(3):129‚Äì143,
2000.
[14] K. C. K. Lee, W.-C. Lee, and H. V. Leong. Nearest
surrounder queries. IEEE Trans. Knowl. Data Eng.,
22(10):1444‚Äì1458, 2010.
[15] S. Nutanong, E. Tanin, and R. Zhang. Incremental evaluation
of visible nearest neighbor queries. IEEE Trans. Knowl. Data
Eng., 22(5):665‚Äì681, 2010.
[16] L. Shou, K. Chen, G. Chen, C. Zhang, Y. Ma, and X. Zhang.
What-you-retrieve-is-what-you-see: a preliminary
cyber-physical search engine. In SIGIR, pages 1273‚Äì1274,
2011.
[17] L. Shou, Z. Huang, and K.-L. Tan. Hdov-tree: The structure,
the storage, the speed. In ICDE, pages 557‚Äì568, 2003.
[18] B. Yao, F. Li, M. Hadjieleftheriou, and K. Hou. Approximate
string search in spatial databases. In ICDE, pages 545‚Äì556,
2010.
[19] D. Zhang, Y. M. Chee, A. Mondal, A. K. H. Tung, and
M. Kitsuregawa. Keyword search in spatial databases:
Towards searching by document. In ICDE, pages 688‚Äì699,
2009.

(b) IO cost

Figure 13: The effect of data set size

7. CONCLUSIONS
This paper reported a novel study on spatio-visual keyword queries
to support WYRIWYS applications. Combining the visual angles
and distances of spatial objects analytically, we proposed a quantitative visibility metric for objects with extents, relying on which
we derived a hybrid ranking mechanism. To effectively process
SVK queries, we proposed the COR method which consisted of two steps in the query processing and was capable of retrieving relevant objects incrementally. The experimental results confirmed the
effectiveness and efficiency of our method when processing SVK
queries.

690


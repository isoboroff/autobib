On the Mathematical Relationship between Expected
n-call@k and the Relevance vs. Diversity Trade-off
Kar Wai Lim

Scott Sanner

Shengbo Guo

ANU & NICTA
Canberra, Australia

NICTA & ANU
Canberra, Australia

Xerox Research Centre Europe
Grenoble, France

karwai.lim@anu.edu.au

ssanner@nicta.com.au

shengbo.guo@xrce.xerox.com

ABSTRACT
It has been previously noted that optimization of the ncall@k relevance objective (i.e., a set-based objective that is
1 if at least n documents in a set of k are relevant, otherwise
0) encourages more result set diversiﬁcation for smaller n,
but this statement has never been formally quantiﬁed. In
this work, we explicitly derive the mathematical relationship
between expected n-call@k and the relevance vs. diversity
trade-oﬀ — through fortuitous cancellations in the resulting
combinatorial optimization, we show the trade-oﬀ is a simple
and intuitive function of n (notably independent of the result
set size k ≥ n), where diversiﬁcation increases as n → 1.

q

...

sk

t1

t2

...

tk

r1

r2

...

rk

t

Here, λ ∈ [0, 1], metric Sim1 measures query-item relevance,
and metric Sim2 measures the similarity between two items.
Presently, little is formally known about how a particular
selection of λ relates to the overall set-based relevance objective being optimized. However, it has been previously noted
that the n-call@k set-based relevance metric (which is 1 if
at least n documents in a set of k are relevant, otherwise 0)
encourages diversity as n → 1 [2, 4]. Indeed, Sanner et al.
[3] have shown that optimizing expected n-call@k for n = 1
corresponds to λ = 0.5 — we extend this derivation to show
n
that λ = n+1
for arbitrary n ≥ 1 (independent of result set
size k ≥ n). This result precisely formalizes a relationship
between n-call@k and the relevance vs. diversity trade-oﬀ.

H.3.3 [Information Search and Retrieval]: Retrieval
Models

Keywords
diversity, set-based relevance, maximal marginal relevance

RELEVANCE VS. DIVERSITY

Subtopic retrieval — “the task of ﬁnding documents that
cover as many diﬀerent subtopics of a general topic as possible” [5] — is a motivating case for diverse retrieval. One of
the most popular result set diversiﬁcation methods is Maximal Marginal Relevance (MMR) [1]. Formally, given an item
set D (e.g., a set of documents) where retrieved items are
denoted as si ∈ D, we aim to select an optimal subset of
items Sk∗ ⊂ D (where |Sk∗ | = k and k < |D|) relevant to a
given query q (e.g., query terms) with some level of diversity
among the items in Sk∗ . MMR builds Sk∗ in a greedy manner
by choosing the next optimal selection s∗k given the set of
∗
= {s∗1 , . . . , s∗k−1 } (recursively
k − 1 optimal selections Sk−1
∗
deﬁning Sk∗ = Sk−1
∪ {s∗k } with S0∗ = ∅) as follows:

2. RELEVANCE MODEL AND OBJECTIVE
We review the probabilistic subtopic model of binary relevance from [3] shown as a directed graphical model in Figure 1. Shaded nodes represent observed variables, unshaded
nodes are latent. Observed variables are the query terms q
and selected items si (where for 1 ≤ i ≤ k, si ∈ D). For the
subtopic variables, let T be a discrete subtopic set. Then
ti ∈ T represent subtopics for respective si and t ∈ T represents a subtopic for query q. The ri are {0, 1} variables that
indicate if respective selected items si are relevant (ri = 1).
The conditional probability tables (CPTs) are as follows:
P (ti |si ) and P (t|q) respectively represent the subtopic distribution for item si and query q. For the ri CPTs, using
I[·] as a {0, 1} indicator function (1 if · is true), item si is
deemed relevant iﬀ its subtopic ti matches query subtopic t:

Sim2 (si , sk )].
s∗k = arg max [λ(Sim1 (q, sk ))−(1 − λ) max
∗
∗
sk ∈D\Sk−1

s2

Figure 1: Latent subtopic binary relevance model.

Categories and Subject Descriptors

1.

s1

si ∈Sk−1

(1)

P (ri = 1|t, ti ) = I[ti = t]
P
We next deﬁne Rk = ki=1 ri , where Rk is the number of
relevant items from the ﬁrst k selections. Reading Rk ≥ n
as I[Rk ≥ n], we express the expected n-call@k objective as

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

Exp-n-Call@k(Sk , q) = E[Rk ≥ n|s1 , . . . , sk , q].

1117

3.

MAIN DERIVATION AND RESULT
Taking MMR’s greedy approach, we select sk given

If we assume each document covers a single subtopic of the
query (e.g., a subtopic represents an intent of an ambiguous
query) then we can assume that ∀i P (ti |siQ
) ∈ {0, 1} and
P (t|q) ∈ {0, 1}. This allows us to convert a
to a max
!
k−1
k−1
Y`
Y`
´
´
1 −P (ti = t|s∗i ) = 1 − 1 −
1 − P (ti = t|s∗i )

∗
Sk−1
:1

∗
s∗k = arg max E[Rk ≥ n|Sk−1
, sk , q]
sk

∗
, sk , q)
= arg max P (Rk ≥ n|Sk−1
sk

i=1
i∈{j
/ 1 ,...,jn−1 }

This query can be evaluated w.r.t. our latent subtopic binary
relevance model in Figure 1 as follows, where we marginalize
out all non-query, non-evidence
variables
P
P P
PTk and deﬁne Tk =
{t, t1 , . . . , tk } and Tk ◦ = t t1 · · · tk ◦:
X“

=arg max
sk

P (t|q) P (tk |sk )

k−1
Y

P (ti |s∗i )

i=1

Tk

∗
· P (Rk ≥ n|Tk , Sk−1
, sk , q)

=1−

sk

X

P (t|q) P (tk |sk )

”

1

+ P (rk = 1|Rk−1 = n−1, tk , t)P (Rk−1 = n−1|Tk-1 )

”

We
over the summands noting that
P distribute initial terms P
tkP (tk |sk )P (rk=1|tk , t) =
tkP (tk |sk )I[tk=t] =P (tk=t|sk ):
–
k−1
Y
X»X
=arg max
P (tk |sk ) P (Rk−1≥ n|Tk-1 )P (t|q) P (ti |s∗i )+
sk

X

Tk-1 tk

|

{z
1

P (t|q)P (tk = t|sk )

t

}
X

i=1

P (Rk−1 = n−1|Tk-1 )

t1 ,...,tk−1

k−1
Y

!

P (ti |s∗i )

i=1

Next we proceed to drop the ﬁrst summand since it is not a
function of sk (i.e., it has no inﬂuence in determining s∗k ):
X
∗
P (t|q)P (tk = t|sk )P (Rk−1= n−1|Sk−1
) (2)
=arg max
sk

=arg max
sk

By similar reasoning, we can derive that the last probability
needed in (2) is recursively deﬁned as P (Rk = n|Sk , t) =
`
´
8
n ≥ 1, k > 1 :
1−P (tk = t|sk ) P (Rk−1 = n|Sk−1 , t)
>
>
>
>
>
+P (tk = t|sk )P (Rk−1 = n−1|Sk−1 , t)
<
´
`
n = 0, k > 1 :
1−P (tk = t|sk ) P (Rk−1 = 0|Sk−1 , t)
>
>
>
n = 1, k = 1 : P (t1 = t|s1 )
>
>
:
n = 0, k = 1 : 1 − P (t1 = t|s1 )

sk

X

t

P (tl = t|s∗l )

j1 ,...,jn−1 l∈{j1 ,...,jn−1 }

m−n+1
n
Sim2 (sk , si , q)
Sim1 (sk , q) −
max
∗
m+1
m + 1 si ∈Sk−1

NICTA is funded by the Australian Government via the Dept. of
Broadband, Comm. and the Digital Economy and the Australian
Research Council through the ICT Centre of Excellence program.

4. REFERENCES

[1] J. Carbonell and J. Goldstein. The use of MMR,
diversity-based reranking for reording documents and
producing summaries. In SIGIR-98. ACM, 1998.
[2] H. Chen and D. R. Karger. Less is more: Probabilistic
models for retrieving fewer relevant documents. In
SIGIR-06. ACM, 2006.
[3] S. Sanner, S. Guo, T. Graepel, S. Kharazmi, and
S. Karimi. Diverse retrieval via greedy optimization of
expected 1-call@k in a latent subtopic relevance model.
In CIKM-11. ACM, 2011.
[4] J. Wang and J. Zhu. Portfolio theory of information
retrieval. In SIGIR-09. ACM, 2009.
[5] C. Zhai, W. W. Cohen, and J. Laﬀerty. Beyond
independent relevance: Methods and evaluation metrics
for subtopic retrieval. In SIGIR-03. ACM, 2003.

P (t|q) P (tk = t|sk )·

Y

i∈[1,k−1]
i∈{j
/ 1 ,...,jn−1 }

Acknowledgements

We can now rewrite (2) by unrolling its recursive deﬁnition.
For expected n-call@k where n ≤ k/2 (a symmetrical result
holds for k/2 < n ≤ k), the explicit unrolled objective is
X

”

Comparing to MMR in (1), we can clearly see that λ = mn+1 .
Assuming m ≈ n since Exp-n-Call@k optimizes for the case
n
where n relevant documents are selected, then λ = n+
.
1

t

s∗k = arg max

P (ti = t|s∗i )

∗
Assuming m selected documents
Sk−1
relevant
then the
`are
´
Q
m
top term (speciﬁcally l ) is non-zero n−1
times. For the
Q
∗
bottom term, it takes n − 1 relevant Sk−1
to satisfy its l ,
and one additional `relevant
document to satisfy the maxi
´
making it non-zero m
times. Factoring
n
P out the max element from the bottom and pushing the t inwards (all legal
due to the {0, 1} subtopic
probability assumption) we get
!
X
m
=arg max
P (t|q)P (tk = t|sk )
n−1
sk
t
|
{z
}
!
relevance: Sim1 (sk ,q)
X
m
−
max
P (ti = t|si )P (t|q)P (tk = t|sk ) .
∗
s
∈S
n
i
k−1 t
|
{z
}
Sim2 (sk ,si ,q)
´
`
´
`
´
`diversity:
m
+ m
= m+1
(PasFrom here we can normalize by n−1
n
n
cal’s rule), leading to fortuitous cancellations and the result:

P (ti |s∗i )

· P (rk ≥ 0|Rk−1 ≥ n, tk , t)P (Rk−1 ≥ n|Tk-1 )
|
{z
}

max

i∈[1,k−1]
j1 ,...,jn−1 l∈{j1 ,...,jn−1 } i∈{j
/ 1 ,...,jn−1 }

i=1

Tk

“

k−1
Y

i=1
i∈{j
/ 1 ,...,jn−1 }

and by substituting this into (3) and distributing, we get
X
X Y
= arg max
P (t|q)P (tk = t|sk )
P (tl = t|s∗l )
sk
t
j1 ,...,jn−1 l∈{j1 ,...,jn−1 } !
X Y
−P (t|q)P (tk = t|sk )
P (tl = t|s∗l ) max P (ti = t|s∗i ) .

We split Rk ≥ n into two disjoint (additive) events (rk ≥
0,Rk−1 ≥ n), (rk=1,Rk−1=n−1) where all ri are D-separated:
=arg max

“

!
`
∗ ´
(3)
1 − P (ti = t|si )

k−1
Y

i=1
i∈{j
/ 1 ,...,jn−1 }

where j1 , . . . , jn−1 ∈ {1, . . . , k − 1} satisfy that ji < ji+1
(i.e., an ordered permutation of n − 1 result set indices).
1
We present a derivation summary; A full derivation may
be found in an online appendix at the authors’ web pages.

1118


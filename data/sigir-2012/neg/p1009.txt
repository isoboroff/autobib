myDJ: Recommending Karaoke Songs From One’s Own
Voice
Kuang Mao, Xinyuan Luo, Ke Chen, Gang Chen, Lidan Shou
College of Computer Science and Technology
Zhejiang University
Hangzhou, China

{mbill, wisp, chenk, cg, should}@zju.edu.cn
Categories and Subject Descriptors
H.3.3 [Information Systems]: Information Retrieval

Keywords
VRP, Learning to rank, Song recommendation

1. EXTENDED ABSTRACT
Singing is a worldwide activity across all walks of life. Many of
us have had Karaoke defeats of singing a beloved song but making
the others plug their ears. A major reason for such failure is that
the songs one loves might not fit his/her personal laryngeal anatomy
which determines the capacity of one’s voice source.
myDJ is a karaoke recommendation system which recommends
proper songs based on the pitch and intensity that one can nicely produce. Unlike most state-of-the-art recommendation systems, which rely on the similarity defined for the contents of songs,
the listening habits of users, or the listening patterns, myDJ is the
first prototype which recommends songs according to one’s physical phonation area. The key challenge in this approach is to connect the singer’s phonation model, which is typically described as a
Vocal Range Profile (VRP)[1] in clinical quantitative voice assessments, to the music database, so that a given profile retrieves suitable songs. Unfortunately, a VRP is not enough to retrieve songs,
as it only describes the minimum and maximum sound pressure
levels (dB) across the singer’s vocal range (Hz) without evaluating
the voice quality. Our work focuses on techniques to build such
connection for retrieval.
myDJ consists of four modules: (1) The singer profiler, which
creates a profile for each singer via a tranditional musical test known
as Messa di voce. The singer profile consists of two parts, the VRP which is depicted as a 2D region, and the Overall Voice Quality (OVQ)[3]combining multiple voice quality features as a distribution over the 2D region defined by VRP. (2) The Midi Song
Database. We consider each song in the database as a document, and the notes in a song at the same pitch or intensity as a pitch
term (PT) or an intensity term(IT) respectively. The duration of
each IT and the TF-IDF weighted duration of each PT, which are
accumulated by the note duration in a song, are the major factors
affecting the fitness of a song. Thus, we define a song’s profile as
the combination of the TF-IDF weights, the PT and IT durations,
and the pitch and intensity values of all notes in it. (3) The learning
to rank module, where algorithm Listnet[2] is applied. (4) The song
recommendation module, where songs are recommended using the
ranking function learned by Listnet.

Figure 1: myDJ Interface
myDj works in two phases:
• The offline training phase: The learning algorithm uses (1)
the singer profiles, and (2) the five-level fitness scored song
profiles which are manually labeled by the singers for themselves, as the training data. During the training process, each
singer profile is considered as a query and the song profiles
as the documents. Thus, the features are extracted from all
(query, document) pairs, and Gradient Descent is applied to
calculate the parameters in the ranking function.
• The online phase: First, the test subject has to take the musical test to acquire the singer profile. Next, feature extraction will be conducted for all (query, document) pairs. To
expedite this process, we utilize a document index to prune
documents (songs) before any feature extraction. Finally, the
rank score of each song is calculated using the ranking function learnt in the first step.
Figure 1 shows a screen shot of myDJ. The left part of the interface
shows a singer profile, where the 2D region indicates the VRP and
the color of each pixel indicates the OVQ value (Red for good and
blue for poor). The top right screen shows a ranked list of songs
being recommended for this subject.

2.

ACKNOWLEDGMENTS

The work is supported in part by the National Science Foundation of China (GrantNo. 61003050, 60970124, and 61170034).

3.

REFERENCES

[1] P. P. Anick Lamarche, Sten Ternström. The singer’s voice range
profile: female professional opera soloists. Journal of voice,
24:540–555, 2010.
[2] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to rank:
from pairwise approach to listwise approach. In ICML, pages
129–136, 2007.
[3] Y. Maryn, P. Corthals, P. V. Cauwenberge, N. Roy, and M. D. Bodt.
Toward improved ecological validity in the acoustic measurement of
overall voice quality: combining continuous speech and sustained
vowels. Journal of voice, 24:410–426, 2010.

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1009


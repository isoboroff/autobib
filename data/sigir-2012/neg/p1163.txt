User-Aware Caching and Prefetching Query Results in
∗
Web Search Engines
Hongyuan Ma

Bin Wang

Institute of Computing Technology, Chinese
Academy of Sciences
Graduate University of Chinese Academy of
Sciences
Beijing, P.R. China 100190

Institute of Computing Technology, Chinese
Academy of Sciences
Beijing, P.R. China 100190

wangbin@ict.ac.cn

mahongyuan@foxmail.com
ABSTRACT

of search results with PDC. PDC divides its cache into a segment which caches top-K queries and a priority queue which caches
follow-up queries. Fagni et al. [1] present static and dynamic cache
(SDC) which is based on historical usage data. SDC divides its
cache into a read-only static cache which caches the most popular
queries and a dynamic cache which caches the rest together with an
adaptive prefetching policy, which is called pre-SDC in this paper.
Web search engine caching and prefetching have been studied by
a number of researchers. As we know, most of earlier studies extract query frequency feature from a query log to select the queries
to be kept in a cache. We take into consideration the fact that some
users who contribute greatly to Web search engines’ page views
(PV), and pay more attention to these users. This paper concentrates on results caching and prefetching, and in particular discusses
the application of user characteristics in the context of Web search
engine results caching. Our goal is to design a mechanism for results caching that exploit the characteristics of Web search engine
users to achieve a high hit ratio for both requests from the special
users group who contributes most to Web search engines and all requests. To do this, we divide results cache into two areas: the first
area caches results for the queries submitted by that special users
group, while the second area is for the rest of the queries.

Query results caching is an efficient technique for Web search engines. In this paper we present User-Aware Cache, a novel approach tailored for query results caching, that is based on user
characteristics. We then use a trace of around 30 million queries
to evaluate User-Aware Cache, as well as traditional methods and
theoretical upper bounds. Experimental results show that this approach can achieve hit ratios better than state-of-the-art methods.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information Search
and Retrieval—Search process; H.3.4 [Information Storage and
Retrieval]: Systems and Software—Performance evaluation (efficiency and effectiveness)

General Terms
Performance, Experimentation

Keywords
Web search engines, query results, caching, prefetching.

1.

2. USER-AWARE RESULTS CACHING &
PREFETCHING

INTRODUCTION

Caching is an effective technique to reduce user response time
and back-end server workload. Millions of queries are submitted
by users daily to Web search engines, and they all expect low latency to receive answers. Results caching and index caching are two
basic approaches for improving the performance of large scale Web search engines. Results cache stores the previous search results
which were recently computed to resolve future queries, while index cache stores the posting lists of the involved query terms to
resolve future query results computing. In addition to these approaches, Web search engines may also prefetch a search engine
results page (SERP) which is the listing of Web pages returned by
the Web search engines in response to a query that it predicts to be
requested in the near future. Lempel and Moran [2] present probability driven cache (PDC) which is based on a probabilistic model
of Web search engine query streams, and examine the prefetching

2.1 User Data Characterization

Percentage of usres

1
0.8
0.6
0.4
0.2
Users
0
1

∗This work was supported by the National Natural Science Foundation of China (Grant No. 61070111).

10
100
Number of pages

1000

Figure 1: Cumulative percentage of users as a function of requested pages (From a famous Chinese Web search engine [3])

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

As discussed in the introduction, different user contributes to the
PV of Web search engine differently. Figure 1 shows that 80% of

1163

users’ requested pages, also termed as PV are within five, and 67%
of the requests received by the Web search engines are submitted by
only 20% of users. Thus, we can draw the following conclusions:
different user’s contribution to Web search engine is different.

60

Hit ratio(%)

50

2.2 User-Aware Cache
Usually, the capacity of a caching system is far less than the volume of requests received by Web search engines, and a user’s query
results page which is prefetched may be flushed out before the next
reference to it, especially for a small size caching system. In order
to decrease the impact of caching capacity on those loyal users, we
divides a fixed amount of available cache into two parts and use
one part as a cache for caching results for the queries submitted
by the special users group which is pre-defined by Web search engines and the other part as a cache for the rest of the queries. It is
not necessary that both parts of the cache use the same replacement and prefetching policy, but in this study we use the same policy
which is LRU replacement and pre-SDC prefetching policy. Note
that User-Aware Cache is formed by the two parts as a whole, and
a query results page can only exist in one part. When received a
query submitted by a user, a results page should first be looked up
in the user’s corresponding part.

30
20

User-Aware+LRU
Local-OPT

10

Upper-Bound
0
5K 10K 20K 50K 75K 100K 150K 200K 250K
Capacity

Figure 2: Comparison of the hit ratios for all requests
infinite in size without prefetching. Thus, user-aware cache with
prefetching can achieve a high hit ratio.
Table 1 shows the hit ratios of the user-aware cache and the
caches which use different prefetching policies without any user
characteristics by varying the cache size. These results in table 1 reveal that the proposed user-aware cache with prefetching performs
better than the cache using LRU replacement policy with Pre-K1 or
Pre-SDC1 prefetching policy.

2.3 User Subset Selection
As shown in figure 1, the distribution of number of query results
pages browsed by users has significant long tail characteristic. The
finding implies that there is a high possibility that some users reference the query results pages frequently. We describe one feature
that can be extracted from the dataset and used for selecting a subset of all users for the partition. The feature in this paper is listed
below:

Table 1: Hit ratios (%) vs. cache sizes
Cache Size Pre-K1 Pre-SDC1 User-Aware
5K
31.58
32.78
35.81
10K
37.46
38.55
42.05
20K
42.40
43.41
47.29
50K
47.62
48.60
52.73
75K
49.78
50.65
54.81
100K
51.25
52.06
56.22
150K
53.29
54.05
58.20
200K
54.78
55.47
59.59
250K
55.99
56.60
60.69

User Follow-up Query Frequency (UFQF): The query frequency of a user is defined as the number of queries including
follow-up queries submitted by this user. In fact, we sort all
user query frequencies in decreasing order and select users who
have the most frequent user query frequencies.

3.

40

EXPERIMENTAL RESULTS

We use a query log from a famous Chinese Web search engine
[3] which contains around 30 million queries of about 5.8 million
people for a period of 2-months (from 09/01/2006 to 10/31/2006).
The first 5 million queries constitute the training set to warm up
the cache. The remaining about 25 million queries are reserved
as the test set. We choose 14,748 users according to UFQF as a
special users group and use the cache whose size is 10% of the
total capacity of the cache to cache the queries submitted by this
group.
The first experiment aims to compare the hit ratio of the useraware cache with the hit ratio of the cache using local optimal
replacement policy which is widely used in the literature and the
upper bound [1] which is achieved on the test set of our query log
when prefetching is not used. Local optimal replacement policy
works as follows: when a results page needs to be evicted, the cache
would evict the page whose next reference will occur farthest in the
next W times requests. W is the constant length of sliding window,
and we set the value of W equal to the cache size in our experiment.
Figure 2 shows the result of this experiment.
In Figure 2, cache size is given as the number of queries that are
cached. It can be seen that there is a significant hit ratio difference
between the cache with local optimal replacement policy and the
user-aware cache. Especially when the cache size is larger than
150K, the user-aware cache hit ratio is larger than the upper bound
on the hit ratio that is achieved if the availability of the cache is

4. CONCLUSIONS
In this study, we introduce a new caching approach which is the
user-aware cache and show that it can achieve better hit ratios. The
future work involves:
• Combining more policies with the user-aware cache;
• Exploring more features used for selecting the queries for the
user-aware cache;
• Analyzing the impact of crawlers and scrapers on the useraware cache.

5. REFERENCES
[1] T. Fagni, R. Perego, F. Silvestri, and S. Orlando. Boosting the
performance of web search engines: Caching and prefetching
query results by exploiting historical usage data. ACM Trans.
Inf. Syst., 24(1):51–78, Jan. 2006.
[2] R. Lempel and S. Moran. Predictive caching and prefetching
of query results in search engines. In Proceedings of the 12th
international conference on World Wide Web, WWW ’03,
pages 19–28, New York, NY, USA, 2003. ACM.
[3] Y. Li, S. Zhang, B. Wang, and J. Li. Characteristics of chinese
web searching: A large-scale analysis of chinese query logs.
Journal of Computational Information Systems,
4(3):1127–1136, 2008.

1164


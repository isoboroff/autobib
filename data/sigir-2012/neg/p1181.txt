SIGIR 2012 Tutorial

(Big) Usage Data in Web Search
Ricardo Baeza-Yates

Yoelle Maarek

Yahoo! Research, Barcelona, Spain

Yahoo! Research, Haifa, Israel

rbaeza@acm.org

yoelle@ymail.com

In practice, such a feature clearly uses more sophisticated
techniques than direct counting, but this simple example illustrates
how even trivial “data crunching” over big real data brings more
value than sophisticated techniques on small datasets. Query logs
have also revolutionized query assistance tools such as related
queries (recommended queries after the search was issued) or query
completions (suggested queries as the query is being typed). While,
in the past, query assistance tools would analyze the document
corpus in order to identify phrases that could serve as alternate
queries, the tremendous growth in Web search engine traffic
allowed these tools to mostly rely on real user-issued queries. Using
query logs as the source corpus significantly improved the quality of
suggestions, at least as perceived by the user. In practice, query
assistance tools are now deployed on all major Web search engines,
and their quality improves as query logs grow. An additional
revolutionary benefit of usage data is to consider clicks as a measure
of satisfaction or at least of interest from the user, as if the user, by
clicking, had actually voted in favor of the clicked element. One
major reason of the quick pace of innovation in Web search can be
credited to these “pseudo-votes”. Instead of testing a new feature, or
any sort of change, on a small sample of beta-users in a controlled
environment, search engines now use real users on a much larger
scale. Various metrics are used to verify whether users react
positively or not to the change, thus helping search engines to
decide whether to deploy the change to all users. After deployment,
user behavior is constantly monitored, not only at pre-launch time,
and features for which clicks or other metrics are decreasing might
be discontinued or retired as it often happens.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]

General Terms
Algorithms, Human Factors

Keywords
Web Retrieval, User Interaction

EXTENDED ABSTRACT
Web Search, which takes its root in the mature field of information
retrieval, evolved tremendously over the last 15 years. The field
encountered its first revolution when it started to deal with huge
amounts of Web pages. Then, a major step was accomplished when
engines started to consider the structure of the Web graph and
leveraged link analysis in both crawling and ranking. Finally, a
more discrete, but no less critical step, was made when search
engines started to monitor and exploit the numerous (mostly
implicit) signals provided by users while interacting with the search
engine. In this tutorial we focus on this “revolution” of large scale
usage data.
In the first part of this tutorial, we focus on usage data, which
typically refers to any type of information provided by the user
while interacting with the search engine. It comes first under its raw
form as a set of individual signals, but is typically mined after
multiple signals have been aggregated and linked to the same
interaction event. The two major types of such data are (1) query
streams, which include the query string that the user issued, together
with the time-stamp of the query, a user identifier, possibly the IP of
the machine on which the browser runs, and (2) click data, which
include the reference to the element the user clicked on the page
together with the timestamp, user identifier, possibly IP, the rank of
the link if it is a result, etc.

In spite of its multiple benefits, adequately leveraging usage data is
not always straightforward. We discuss, in the third part of this
tutorial, the effects of three major factors that often pull in opposite
directions:

Exploiting usage data under its multiple forms brought an
unprecedented wealth of implicit information to Web Search. We
discuss in the second part of this tutorial some of the key Web
search applications that it made possible. One such example is the
query spelling correction feature embodied now in all search
engines. In fact, after years of very sophisticated spell checking
research, simply counting similar queries at a small edit distance
would in most cases surface the most popular spelling as the correct
one, a beautiful and simple demonstration of the wisdom of crowds
principle.

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1181



Size of the data: Large-scale or big usage data is a key prerequisite to inferring new insights. As a consequence, the needs
of the crowd dominate long-tail needs, which are expressed by
definition by very few individuals. Averaging on the more
popular needs can dominate so much, in some cases, that it
conflicts with some specific needs that personalization should
address. More data also brings algorithmic challenges as we
need faster and faster algorithms. Hence, we can have a tradeoff between the quality of the output and the performance to
obtain it.



Personalization: In order for search engines to personalize
their services for a specific user, threy obviously need enough
data to know more about the persona behind the individual, at
the risk of exposing some private aspects. Hence,



personalization in many cases might conflict with the user's
privacy.

Biographies of Presenters

Privacy: One key demand of privacy-protecting activists
pertains to not accumulate too much data on a single individual
over long periods of time, as they want everyone's past to
remain private. As big data is typically gathered over a given
window of time, the longer the window, the bigger the data.
Restricting persistence of data to short periods of time clearly
reduces the amount of data that can be mined and thus
threatens the effectiveness of data aggregation on a large scale,
in particular for personalization.

Ricardo Baeza-Yates is VP of Yahoo! Research for Europe and
Latin America, leading the labs at Barcelona, Spain and Santiago,
Chile. Until 2005, he was the director of the Center for Web
Research at the Department of Computer Science of the Engineering
School of the University of Chile, and ICREA Professor at the Dept.
of Technology of University Pompeu Fabra in Barcelona, Spain. He
is co-author of the bestseller textbook Modern Information Retrieval
by Addison-Wesley, first published in 1999 with a second edition in
2011, as well as co-author of the second edition of the Handbook of
Algorithms and Data Structures, Addison- Wesley, 1991; and coeditor of Information Retrieval: Algorithms and Data Structures,
Prentice-Hall, 1992, among more than 200 other publications. He
has been PC-Chair of the most important conferences in the field of
Web Search and Web Mining. He has given tutorials in most major
conferences many times, including SIGIR, WWW and VLDB. He
is, both, ACM and IEEE Fellow.

These conflicting factors impose serious limitations on leveraging
big usage data. We discuss some ways to tackle these limitations, in
the last part of our tutorial. One solution that we focus on is to
aggregate data in the right way, depending on the context, the task,
the need, so as to increase the amount of relevant data. We show
that aggregated data can be generated in a variety of scenarios, as
the bulk of user queries belong to a few tasks: users are after all not
that different, and many tasks share similarities at some level, for
example find a home page, look for information, perform a
transaction or download a resource. The main differences among
users are not with what they do, but when they do it, how long they
do it and how well they do it. We expect to see many types of
aggregations arising in the future. Indeed, even social search can be
seen as an incarnation of aggregation, where the aggregation is
social and formed by the user's friends and other connections rather
than by a common need.

Yoelle Maarek is the Senior Director of Yahoo! Research in Haifa,
Israel, leading research activities for Yahoo! Mail and Yahoo!
Answers since 2009. Prior to this, Yoelle was the Director of
Google Haifa Engineering Center, which she opened in 2006.
There, she led the development of “Suggest”, Google’s query
completion feature deployed on google.com and YouTube
worldwide. Before this, Yoelle had been with IBM Research, first
in the US, and then in Israel, where she led the search and
collaboration department and became a Distinguished Engineer. She
graduated from the ENPC in Paris, France, and received her DEA in
Computer Science from Paris VI University. Yoelle obtained her
PhD in Computer Science from Technion. She has served as senior
PC member at several SIGIR, WWW and WSDM conferences, and
as PC co-chair of WWW’2009, WSDM’2012 and SIGIR’2012.
Yoelle is a member of the Board of Governors of Technion, and was
appointed ACM Distinguished Scientist in 2010.

We conclude by providing some research directions as well as
discuss with the audience the influence of regulation current or
future such as the recently proposed privacy “bill of rights” in the
US. This tutorial is a sequel of “Web Retrieval: The Role of Users”,
a tutorial offered at SIGIR'2010 in Geneva and then at WSDM'2011
and ECIR'2011.

1182


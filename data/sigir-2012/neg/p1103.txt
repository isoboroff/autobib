Lightweight Contrastive Summarization
for News Comment Mining
Gobaan Raveendran

Charles L. A. Clarke

University of Waterloo, Canada

ABSTRACT

2.

We develop and discuss a news comment miner that presents
distinct viewpoints on a given theme or event. Given a
query, the system uses metasearch techniques to find relevant news articles. Relevant articles are then scraped for
both article content and comments. Snippets from the comments are sampled and presented to the user, based on
theme popularity and contrastiveness to previously selected
snippets. The system design focuses on being quicker and
more lightweight than recent topic modelling approaches,
while still focusing on selecting orthogonal snippets.

The problem of comment mining is somewhat similar to
the concept of review summarization, in which the goal is to
generate summaries of the opinions on a given product. In
contrastive review summarization we wish to also highlight
the differences in multiple products. The work in contrastive
review summarization largely focuses on extracting sentiment and opinion[4]. The problem of extracting sentiment
is somewhat eased by the fact that reviews are often associated with a rating system that provides supervised data.
Furthermore, for news stories, sometimes sentiment extraction may add unnecessary overhead, and highlight unimportant aspects, as the objective facts of the story may be more
interesting.
General multidocument summarization has also provided
a rich source of tools for comment mining. However, much
of this work focuses on creating a single overall summary,
which may not be plausible with comments representing a
lengthy discussion or argument. Furthermore, this work often attempts to create natural language models that are able
to stitch together information in order to ensure that summaries are human readable and coherant[6]. This overhead
is unnecessary and expensive for individuals wishing to get
an overall understanding of user opinion. Topic modeling
approaches employing PLSA have also been used to extract
latent themes within a set of articles[5], however this approach is heavyweight and may incorrectly cluster important
terms causing them to be missed. For example, in our data
it was shown that conservatives preferred writing ‚ÄúBarrack
Hussein Obama‚Äù over the liberal ‚ÄúObama‚Äù.
Some work has recently been invested into comment sentence extraction[2]. This work focuses on extracting interesting sentences from a single blogs comments using models
that explicitly model different types of comments and topic
mixtures. The term-term graph was deemed too heavyweight for the multidocument snippet extraction.
Our final algorithm takes a lightweight approach to review captioning building on simple language models. This
approach attempts to explicitly extract orthogonal sentences
that represent the most discussed points, and is explained
in section 3. This lightweight approach was taken due to its
ability to process our corpus containing over 5 million comments and over 2 million distinct terms within an hour. In
contrast, implementations on PLSA discuss 50,000 by 8,000
term-doc matrices, and execute in about half an hour[1].
In order to understand the data analyzed, we briefly describe the framework used to implement the lightweight comment summarizer.

Categories and Subject Descriptors: H.3.3 [Information Search and Retrieval]: Information filtering; I.2.7 [Natural Language Processing]: Language Models
General Terms: Algorithms, Experimentation
Keywords: Summarization, Comments, Opinion

1.

INTRODUCTION

The study of blogs and other news sources has proved useful for both governments and companies looking to improve
the quality of their services[3]. News sources, however, draw
from a small set of expert users who drive all the discussion in an area. Thus, these sources may not necessarily
represent public opinion. Recently, microblogging sites have
provided a rich source of user opinion which has been heavily researched. Unfortunately, this data can be noisy due to
length restrictions, which limit what can be expressed.
Alternatively, news portals may provide the ability to
comment on articles directly from their websites. These
comments are attached to an article and are relatively unrestricted, allowing for a much wider range of opinion. Commentors also highlight both errors and interesting facets
about articles on any given topic. However, on a highly
debated topic it becomes time consuming to read all the
comments and to understand the distinct perspectives.
Thus, the problem of multidocument comment ranking or
comment mining requires some attention. Our goal should
be to create a system that, given a set of articles and comments on those articles, extracts a set of interesting snippets
from the comments. These snippets should be representative
of the different views of the commentors.
Copyright is held by the author/owner(s).
SIGIR‚Äô12, August 12‚Äì16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1103

RELATED WORK

Internet founding father Vinton Cerf opposes SOPA http://www.examiner.com/intern... The
existing laws are being enforced everyday, without the need for SOPA or PIPA, as was illustrated by last weeks actions. Why do we need new internet piracy laws like SOPA and PIPA?
http://www.examiner.com/intern...
Especially since Google is opposing the bill because it is the world‚Äôs biggest copyright infringer. It
has copied millions (and this is not an exaggeration) of books without permission and seeks to put
them all up on the Net without compensating the copyright holders. And it makes big money from
copyright infringing material on its sites, such as YouTube.
If Hollywood wants to try to protect their profit margins by eliminating online entertainment they
are fighting the wind. Hollywood needs to embrace the web or go the way of the horse and buggy.
There are already websites offering original content that employs more people, more regularly than
movies ever would.
Another reason to not support the bill is simply because the RIAA and MPAA don‚Äôt understand
tech. Hell, RIAA still doesn‚Äôt understand digital distribution of music and the MPAA would still
keep us on VHS tapes if it meant less pirating. Right here just crosses the line.
Table 1: Top four snippets for SOPA in 2012

3.

SYSTEM OVERVIEW

2. Compute a snippet score as follows:
P
unique(t)‚ààS score(t)
score(S) =
length(S)

The input of the system is a query and a date range, for
example ‚ÄúSOPA 01/2012 02/2012‚Äù. The system then uses
metasearch techniques to extract the hundred most relevant
articles from each of over forty-five different news portals.
An associated rule scraper is then used to extract news article and comment data from each link. The comments and
articles are fed to a snippet extractor that attempts to extract a finite set of interesting sentences from the corpus.
The primary innovation comes from applying a known algorithm to a different domain, and the implementation of a
lightweight comment extraction framework.

3.1

3. Present the highest scoring snippet S‚Äô to the user.
4. Set score(t) = 0 ‚àÄt ‚àà S 0
5. Repeat step 1-4 while the score is above a threshold .
 = 0.05 ‚àó l in our case.

4.

Example

number of comments in C containing t + Œ¥
number of comments in C + Œ¥

5.

(1)

number of comments in Cq containing t + Œ¥
(2)
number of comments in Cq + Œ¥
Here we use the additive smoothing parameter Œ¥, with Œ¥
= 1 for our tests. Given this model we can use the K-L
divergence to calculate score(t)

score(t) =

pq (t)log(pq (t)/p(t)))
0

pq (t) > p(t)
otherwise

REFERENCES

[1] M. Blondel. LSA and pLSA in Python, June 2010.
[2] M. Hu, A. Sun, and E.-P. Lim. Comments-Oriented
Blog Summarization by Sentence Extraction. In 16th
CIKM, pages 901‚Äì904, 2007.
[3] L.-W. Ku, L.-Y. Lee, and H.-H. Chen. Opinion
Extraction, Summarization and Tracking in News and
Blog Corpora. In Proceedings of AAAI-2006 Spring
Symposium on Computational Approaches to Analyzing
Weblogs, 2006.
[4] K. Lerman and R. McDonald. Contrastive
Summarization: An Experiment with Consumer
Reviews. In NAACL, pages 113‚Äì116, 2009.
[5] Y. Lu and C. Zhai. Opinion Integration Through
Semi-supervised Topic Modeling. In 17th WWW
Conference, pages 121‚Äì130, 2008.
[6] D. R. Radev and K. R. McKeown. Generating Natural
Language Summaries from Multiple On-Line Sources.
Computational Linguistics, 24:470‚Äì500, Sept. 1998.

pq (t) =

(

CONCLUSION

The ability to quickly and effectively extract comments
from articles opens up a large corpus of data for analyzing and extracting opinion. By using K-L divergence and
a bag of words model we are able to quickly isolate interesting opinions and present analysts‚Äô feedback on how users
generally feel about a given topic. As ongoing research, we
are comparing the results with more heavyweight topic modelling approaches to summarization. Using the current work
as a baseline, we hope to evaluate both algorithms and compare the benefits of each method.

To illustrate the scoring algorithm, we present the results
of extracting four snippets from articles about the internet regulatory legislation nicknamed ‚ÄúSOPA‚Äù. The snippets
highlight multiple opinions such as the existence of competing laws, and perceived copyright infringement by Google.
Initially, we assume a background set of comments C and
a target set of comments Cq ‚äÇ C, that are commenting
about articles relevant to the query q. C is generated by
executing the comment mining engine on as many different
queries as time allows, twenty seven in our case. We can
estimate a language model for each term t in the collection
as follows:
p(t) =

(4)

(3)

We select snippets using the following algorithm.
1. Find a snippet S of at least l contigious words, rounding up to the nearest sentence boundary. We choose
l =50, allowing for human readable snippets.

1104


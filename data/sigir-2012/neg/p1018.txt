Multi-Platform Image Search using Tag Enrichment
Jinming Min1 , Cristover Lopes2 , Johannes Leveling1 , Dag Schmidtke3 and Gareth J. F. Jones1
1

:School of Computing, CNGL, Dublin City University, Dublin, Ireland
2
:Trinity College Dublin, Dublin, Ireland
3
:Microsoft Ireland, Dublin, Ireland

{jmin, jleveling, gjones}@computing.dcu.ie, lopesc@tcd.ie, dags@microsoft.com

Categories and Subject Descriptors:
H.3.3 [INFORMATION STORAGE AND RETRIEVAL] Information Search and Retrieval—Query formulation
General Terms: Algorithms, Experimentation
Keywords: Image retrieval, Query formulation, Relevance feedback, Document expansion

1.

EXTENDED ABSTRACT

The number of images available online is growing steadily and
current web search engines have indexed more than 10 billion images. Approaches to image retrieval are still often text-based and
operate on image annotations and captions. Image annotations (i.e.
image tags) are typically short, user-generated, and of varying quality, which increases the mismatch problem between query terms
and image tags. For example, a user might enter the query wedding
dress while all images are annotated with bridal gown or wedding
gown. This demonstration presents an image search system using
reduction and expansion of image annotations to overcome vocabulary mismatch problems by enriching the sparse set of image tags.
Our image search application accepts a written query as input
and produces a ranked list of result images and annotations (i.e.
image tags) as output [2]. The system integrates methods to reduce and expand the image tag set, thus decreasing the effect of
sparse image tags. It builds on different image collections such as
the Wikipedia image collection1 and the Microsoft Office.com ClipArt collection2 , but can be applied to social collections such as
Flickr as well. Our demonstration system runs on PCs, tablets, and
smartphones, making use of advanced user interface capabilities on
mobile devices.
Figure 1 presents an overview of the complete system for Document Expansion (DE) using Wikipedia as an external resource. Important terms in the original image annotation are used as a query
to retrieve Wikipedia articles and extract DE terms from the topranked documents. These terms are added to the original image
tags to form the enriched tag set. The expanded annotations are
indexed in the retrieval system. The key stage here is to select key
terms from the documents prior to expansion in a process we refer
to as Document Reduction (DR). The objective of DR is to focus
the DE “query” on the most important elements in the tag set.
The system is implemented as a client-server architecture, where
the client realizes the graphical user interface and handles query
1
2

Figure 1: System overview.

Figure 2: Image search system on a PC (left) and on smartphone and tablet (middle and right).
processing. The image annotation index resides on the server side.
Users can try general queries on the system to observe the results
for different system settings, e.g. with document expansion or without document expansion. Under the document expansion setting,
the expanded annotation terms are displayed with the image results. The demo also includes evaluation results on a Wikipedia
image collection for 120 queries. For mean average precision, we
obtain 16% improvement compared to a standard retrieval baseline.
In the future, we plan to investigate a combination of the annotation modification approach with a feedback term selection technique from our previous research work [1]. This method classifies
feedback terms by supervised learning and has proven to improve
feedback term selection in several retrieval tasks.

Acknowledgments
This research is supported by the Science Foundation of Ireland
(grant 07/CE/I1142) as part of CNGL (http://www.cngl.ie/).

2. REFERENCES
[1] J. Leveling and G. J. F. Jones. Classifying and filtering blind
feedback terms to improve information retrieval effectiveness.
In RIAO ’10, pages 156–163. CID, 2010.
[2] J. Min, J. Leveling, D. Zhou, and G. J. F. Jones. Document
expansion for image retrieval. In RIAO ’10, pages 65–71,
2010.

http://www.imageclef.org/wikidata
http://office.microsoft.com/

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1018


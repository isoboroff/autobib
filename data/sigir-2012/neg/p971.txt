Improving Tweet Stream Classification by Detecting
Changes in Word Probability
Kyosuke Nishida, Takahide Hoshide

Ko Fujimura

NTT Service Evolution Laboratories,
NTT Corporation, Kanagawa, Japan

Otsuma Women’s University
Tokyo, Japan

{nishida.kyosuke, hoshide.takahide}
@lab.ntt.co.jp

fujimura@otsuma.ac.jp

ABSTRACT

world. The demand for classifying tweets in order to organize the massive volume of tweets has become more urgent.
Classifying document streams is a challenging problem
because their statistical properties will change over time.
This characteristic is called concept drift, and it is one of
the hottest topics in data mining [2, 13]. There are multiple types of changes, and the eﬀectiveness of strategies for
building classiﬁers depends on the types of changes.
For classifying tweet streams, the trade-oﬀ between quick
response to bursty words and accurate learning of stationary words is a signiﬁcant problem. Conventional methods
conduct temporal selection or weighting on documents; so,
they cannot handle the diﬀerent time-scale changes expected
for each word. We propose a probabilistic classiﬁcation
model, P-Switch, as an extension of the multinomial naive
Bayes classiﬁer. In order to resolve the trade-oﬀ, our model
switches between the two probability estimates based on full
and recent data for each word, by monitoring changes in the
probability of word occurrence. It implements monitoring
by using a control chart [20], which is a statistical process
control tool.
We then describe an implementation method that uses
a word suﬃx array [7]. Our classiﬁcation model can be
formalized as searching the positions of word n-grams of
a new tweet, in the training documents that are concatenated chronologically. We, therefore, regard the construction of full-text search indexes as a learning procedure. This
approach can eﬀectively handle word n-grams, which are
highly important information given the 140 character limit
of tweets.
Experiments on topic classiﬁcation were conducted on three
real-world tweet data sets that have diﬀerent characteristics
in terms of topics, languages, and changes. Results show
that our model oﬀers statistically signiﬁcant improvements
over the standard multinomial naive Bayes classiﬁer and
conventional document weighting and selection methods in
terms of accuracy and macro F1 measures.
Contributions: (i) analysis of the changes in tweet streams,
(ii) proposal of a probabilistic classiﬁcation model that adapts
to and detects changes at word-level, (iii) an implementation
approach that uses word suﬃx arrays for eﬀectively learning temporal factors in word n-grams, and (iv) signiﬁcantly
improved topic classiﬁcation accuracy for tweet streams.
Outline: §2 describes the problem deﬁnitions on document stream classiﬁcation. §3 presents the results of our
analysis and preliminary experiments on tweet streams. §4
explains our proposed model. §5 describes the implementation method. §6 presents the results of the experiments. §7

We propose a classiﬁcation model of tweet streams in Twitter, which are representative of document streams whose statistical properties will change over time. Our model solves
several problems that hinder the classiﬁcation of tweets; in
particular, the problem that the probabilities of word occurrence change at diﬀerent rates for diﬀerent words. Our
model switches between two probability estimates based on
full and recent data for each word when detecting changes
in word probability. This switching enables our model to
achieve both accurate learning of stationary words and quick
response to bursty words. We then explain how to implement our model by using a word suﬃx array, which is a
full-text search index. Using the word suﬃx array allows our
model to handle the temporal attributes of word n-grams effectively. Experiments on three tweet data sets demonstrate
that our model oﬀers statistically signiﬁcant higher topicclassiﬁcation accuracy than conventional temporally-aware
classiﬁcation models.

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications—
Data mining; H.3.3 [Information Storage and Retrieval]:
Information Search and Retrieval

General Terms
Algorithms, Experimentation

Keywords
Twitter, Document classiﬁcation, Data streams, Concept
drift, Control charts, Suﬃx arrays

1. INTRODUCTION
Twitter, a micro-blogging service, has emerged as a new
information infrastructure. Over 300 million status messages, called tweets, are posted per day by users all over the

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
Copyright 2012 ACM 978-1-4503-1472-5/12/08 ...$15.00.

971

describes related work and §8 summarizes the contributions
of this study.

2.

These instance selection and weighting methods will adapt
well to C2, but often fail to handle C1, because learning with
old data worsens the classiﬁcation of most recent data when
sudden changes occur. There is a trade-oﬀ between response
quickness, needed for C1, and learning accuracy, needed for
C2. For example, using a short window improves response
quickness but fails to oﬀer good learning accuracy.
Ensemble methods use a set of classiﬁers adapted to the
current concept [8, 35, 30, 12]. New models are added, and
old or poor models are removed, in a ﬁxed period of time or
when a decrease in classiﬁcation accuracy is observed. Ensemble methods are eﬀective for C2 and C3; e.g., Katkis et
al. proposed a general framework for tracking recurring contexts using ensemble classiﬁers and improved email ﬁltering
accuracy [12].
Feature selection methods dynamically select the most
valuable feature (word) set in order to respond to concept
drift, which is characterized by changes to the underlying
feature space [6, 35, 11]. Feature selection methods are
frequently combined with other methods; e.g., Wenerstrom
et al. [35] proposed a feature-adaptive ensemble approach,
which uses multiple classiﬁers with diﬀerent features.

CLASSIFYING DOCUMENT STREAMS

We address previous work on document stream classiﬁcation and explain the scope of this study.

2.1

Problem Definitions

Problem deﬁnitions for document stream classiﬁcation can
be roughly classiﬁed into three types depending on how the
training and test examples are presented:
[P1] Test-Then-Train (Incremental) [6, 35, 11, 38]
At each time step t = 1, 2, . . ., a classiﬁer is given a
new document dt , and outputs a class prediction, ĉt ,
for dt . It then updates itself based on the true class
label, ct .
[P2] Test-Then-Train (Chunk) [17, 16, 15, 30, 18, 12]
At each t = 1, 2, . . ., a classiﬁer is given a new document set, Dt = {dt,1 , dt,2 , . . .}, and outputs a class prediction, ĉt,j , for each dt,j ∈ Dt . It then updates itself
based on the true class label set, Ct = {ct,1 , ct,2 , . . .}.

2.4

Scope of this Study

Temporally-aware classiﬁcation methods for batch learning have also been proposed [21, 5, 28, 29]: a classiﬁer is
given Dt∗ and Dt for all t = 1, 2, . . . . , T . It outputs a class
prediction, ĉt,j , for each dt,j ∈ Dt , based on (∀t)Dt∗ .

This study handles the incremental test-then-train problem deﬁnition P1, the most basic problem deﬁnition, and
tackles the trade-oﬀ between responding to sudden shift (C1)
and gradual drift (C2). We propose a classiﬁcation model, a
new weighting method at the word level, for tweet streams.
While conventional instance weighting methods use temporal weighting functions on documents, our model is able to
respond to changes in each word. Extending our model to
suit ensemble and dynamic feature selection methods in order to handle recurring themes (C3) is our future work.

2.2

3.

[P3] Train-Then-Test [8]
At each t = 1, 2, . . ., a classiﬁer is given a new training
document set, Dt∗ = {(d∗t,1 , c∗t,1 ), . . .}, and a new test
document set, Dt = {dt,1 , dt,2 , . . .}. It updates itself
based on Dt∗ and then outputs ĉt,j for each dt,j ∈ Dt .

Concept Drift

Concept drift means that the statistical properties of data
change over time [36, 34], and it creates the most diﬃcult
situation in document stream classiﬁcation. There are three
major types of concept drift: [C1] sudden shift, [C2] gradual drift, and [C3] recurring themes.
One example of concept drift is found in the spam mail
ﬁltering problem because mail is characterized by skewed
and changing class distributions, users’ dynamic and growing interests, recurring and periodic themes (e.g., Christmasrelated spam), and intelligent and adaptive adversaries.

2.3

TWEET STREAMS

This section provides the results of analysis and preliminary experiments on the topic classiﬁcation of tweets, where
topics are deﬁned by hashtags.

3.1

Data set

We collected three tweet data sets as shown in Table 1:
tweets on 12 Nippon (Japanese) professional baseball teams
(NPB), tweets on 7 Japanese television networks (TV), and
tweets on 30 major league baseball teams (MLB), by searching hashtags via the Twitter Streaming API (statuses/ﬁlter),
from 13 September 2011 to 26 September 2011.
These data sets consist of tweets that include a single
hashtag; that is, a tweet belongs to a single class. Classes are
hashtags on baseball teams for the NPB and MLB data sets,
and hashtags on television networks for the TV data set.
Retweets (including the tweets containing the string “RT” or
“QT”), replies, mentions are not included in these data sets.
In the problem deﬁnition P1, document d means a tweet text
without any hashtags, and class label c means a hashtag.
For the NPB and TV data sets, we selected noun, verb, and
adjective words by using MeCab 0.98 with IPA dictionary1
for Japanese word segmentation and part of speech labeling.
For the MLB data set, we removed stop words and treated
punctuation and other non-alphabetic characters as separate
tokens.

Learning Strategies

Previous studies on handling concept drift in document
streams employ instance selection, instance weighting, ensemble, and feature selection methods.
Instance selection methods select and adapt to previous training examples [16, 15, 11, 38]. Sliding window is a
typical approach that is used to select the most recent previous examples. Klinkenberg et al. proposed a method for
automatically deciding the size of window and demonstrated
high classiﬁcation performance in the topic classiﬁcation of
news articles [15].
Instance weighting methods assume that newer instances are more essential for classifying the current instance [15, 18, 5, 11, 28, 29]. Lebanon et al. proposed a
naive Bayes classiﬁer with a weighting scheme for handling
temporal document streams [18].

1

972

http://mecab.sourceforge.net

Table 1: Tweet data set. We collected tweets that included a single hashtag from 13 to 26 September 2011
by using Twitter Streaming API. Classes are hashtags on “baseball teams” for NPB and MLB data sets, and
hashtags on “television networks” for TV data set. Each hashtag corresponds to a class label.
Data
NPB

# Tweets
314,210

# Classes
12

Language
Japanese

TV
MLB

249,080
200,521

7
30

Japanese
English

1.0
0.8
0.6
0.4
0.2
0.0
35000

Track Keywords (Hashtags)
#dragons, #hanshin, #giants, #swallows, #carp, #baystars, #sbhawks, #seibulions, #chibalotte,
#loveﬁghters, #orix buﬀaloes, #rakuteneagles
#nhk, #etv, #ntv, #tvasahi, #tbs, #tvtokyo, #fujitv
#angels, #astros, #athletics, #bluejays, #braves, #brewers, #cubs, #dbacks, #dodgers, #indians, #mariners, #marlins, #mets, #nats, #orioles, #padres, #phillies, #pirates, #rangers, #rays,
#reds, #redsox, #rockies, #royals, #sfgiants, #stlcards, #tigers, #twins, #whitesox, #yankees

rakuteneagles
lovefighters
seibulions
baystars
swallows
hanshin

80
NPB
TV
MLB

(a) Cosine Similarity

60
40
0

chibalotte

0

2

4

6

8

10

12

14

16

18

20

22

Sunday, September 18, 2011

500

15000

400
(b) Number of Tweets
13

14

15

16

17

18 19 20 21
September 2011

(b) Daily Number of Tweets
containing “yokohama”

baystars

300
22

23

24

25

26

200
100
0

Figure 1: (a) Cosine similarities between class distributions on 13 September 2011 and all other days.
(b) Total number of tweets for each day.

13

14

15

16

17

18

19

20

21

22

23

24

25

26

September 2011

Figure 3: (a) Hourly number of tweets containing
“home-run” and (b) Daily number of tweets containing “yokohama” from NPB data set.

100%
90%
80%

tvtokyo

70%

tvasahi

60%

fujitv

50%

tbs

40%

ntv

30%

etv

scales. Classiﬁcation models have to respond to these abrupt
and gradual changes in class distribution.

3.2.2 Changes in Word Probability
Fig. 3 shows (a) the hourly number of tweets containing
“home-run” and (b) the daily number of tweets containing
“yokohama” from the NPB data set. “Home-run” is a bursty
word since its relevant classes change rapidly. For example,
a player of the team #chibalotte hit a home-run at 4PM
and the word probability for “home-run” increased suddenly
(Fig. 3a). On the other hand, “yokohama” is a relatively stationary word. The most relevant class #baystars, referring
to the baseball team that has its home ground in Yokohama,
does not change (Fig. 3b).
In summary, the statistical properties of tweet topics change
at diﬀerent rates for diﬀerent words. Conventional instance
weighting and selection methods cannot handle these diﬀerences.

nhk

20%
10%
0%
0

2

4

6
8
10 12 14 16 18
Monday, 19 September 2011

20

22

24 [h]

Figure 2: Class distribution (ten minute periods) for
TV data set, Monday, 19 September 2011.

3.2

orix_buffaloes
chibalotte
sbhawks
carp
giants
dragons

20

25000

5000
0

(a) Hourly Number of Tweets
containing “home-run”

100

Analysis Results

We analyzed tweet streams in terms of the changes in class
distribution and word probability, the occurrence of new
words, and the eﬀectiveness of considering word n-grams.

3.2.3
3.2.1 Changes in Class Distribution

Occurrence of New Words

In order to analyze the occurrence and change of eﬀective
words for classifying tweets, we calculated the chi-squared
statistics χ2c (see details in [39]) of all words for each class c
in each day, and got the daily top 100 words in terms of χ2c
for each class.
Fig. 4 shows (a) the cosine similarities between the daily
top 100 words on 13 September 2011 and all other days and
(b) the cumulative number of distinct daily top 100 words.
The results of Fig. 4 are averaged over classes.
We can see from Fig. 4b that eﬀective words for classifying

Fig. 1 shows (a) the cosine similarities between class distributions on 13 September 2011 and all other days and (b)
the total number of tweets for each day. We can see that the
class distribution on the NPB and MLB data sets ﬂuctuate
more than that on the TV data set. The TV data set also
ﬂuctuates dramatically as shown in Fig. 2, which shows the
class distribution over ten minute periods.
In summary, the class distributions in tweet streams ﬂuctuate constantly and dramatically at micro and macro time

973

1.0
0.8

0.56

NPB
TV
MLB

(a) Cosine Similarity

0.6

0.54
0.52
0.50

0.4

0.48

0.2
0.0
1000
800

Selection
Weighting

(b) Macro average F1 on TV

Selection
Weighting

(c) Macro average F1 on MLB

Selection
Weighting

0.55
0.53

(b) Cum. Num. of Distinct Words

0.51

600

0.49

400

0.47

200

0.45

0

(a) Macro average F1 on NPB

0.46

0.45

13

14

15

16

17

18

19 20 21
September 2011

22

23

24

25

26

0.41
0.37
0.33

Figure 4: (a) Cosine similarities between daily top
100 words on 13 September 2011 and all other days.
(b) Cumulative number of distinct daily top 100
words. These results are averaged over classes.
4500
4000
3500
3000
2500
2000
1500
1000
500
0
100%
80%
60%
40%
20%
0%

0.29
0.25
10000

Unigram
Bigram
Trigram

53.0%
55.0%

46.8%

60.6%

47.0%

47.1%

26.2%
23.2%

68.3%
65.0%

3.3

(b) Distribution on Top 200 Word n-grams
NPB

TV

150000

for identifying the class #whitesox than “white”. Moreover,
Fig. 5b shows that the distribution on top 200 word n-grams
in terms of maxc {χ2c } contains word bigrams and trigrams
(37.6%, 52.0%, 28.1% for the NPB, TV, and MLB data sets).
In summary, considering word sequences can be eﬀective
for classifying tweets because tweets are short and limited
to 140 characters.

Notable n-gram

40.8%

100000
Kernel Width

Figure 6: Macro F1 vs. kernel width of instance
selection and weighting methods with multinomial
naive Bayes classiﬁer (Eqs. (1)–(5))

(a) Number of Kinds of Word n-grams

38.8%

50000

Preliminary Experiments

We applied a temporally-aware multinomial naive Bayes
classiﬁer, which was proposed by Salles et al. [29], and independently, by Lebanon et al. [18], to problem deﬁnition P1.
The temporally-aware multinomial naive Bayes classiﬁer
is given by:
Y
ĉt ← arg max{ pK (c|t)
pK (wi |c, t) },
(1)

MLB

Figure 5: (a) Number of kinds of word n-grams that
occur more than ﬁve times in each day. (b) Distribution of top 200 word n-grams in terms of maxc {χ2c }.
These results are averaged over days. Chi-squared
statistics maxc {χ2c } of a notable n-gram is greater
than that of the ﬁrst word of the notable n-gram.

c

Pt

wi ∈W (dt )

Kh (t − τ )[[cτ = c]]
,
Pt
τ =1 Kh (t − τ )
Pt
=1 Kh (t − τ )fc,τ (wi )
,
pK (wi |c, t) = Pt τP
τ =1
w∈dτ Kh (t − τ )fc,τ (w)

pK (c|t) =
tweets emerge continuously. In particular, the words on the
TV data set changes dramatically. Moreover, the daily top
100 words in the TV data set change periodically because of
the inﬂuence of the day of the week, as shown in Fig. 4a.
In summary, classiﬁcation models have to handle emerging
words as well as recurring and periodic themes eﬀectively.

τ =1

(2)
(3)

where [[·]] is 1 if the predicate is true and 0 otherwise, W (dt )
is the set of selected words in document dt , and fc,τ (w) is
the frequency of word w in dτ . Kh (t − τ ) is a kernel function
such that:

3.2.4

Effects of Word n-grams
The word context of the tweet—which is highly important information given the 140 character limit—is lost in
the bag-of-words model, which assumes that word order is
unimportant.
Accordingly, we investigated whether word n-grams were
useful for classifying tweets or not. We ﬁrst calculated the
chi-squared statistics maxc {χ2c } of all word unigrams, bigrams, and trigrams that occurred more than ﬁve times in
each day. We then found some notable word n-grams, where
the maxc {χ2c } value of a notable word n-gram is greater than
that of the ﬁrst word of the word n-gram (Fig. 5a). For example, from the MLB data set, “white sox” is more suitable

Kh (t − τ ) = [[t − τ < h]],

(4)

Kh (t − τ ) = (1 − (t − τ )/h) · [[t − τ < h]],

(5)

where h is the width of the kernel. Using Eq. (4) means
adopting an instance selection method and using Eq. (5)
means adopting an instance weighting method. The proposal of Salles et al. [29] learns a kernel function with a
training data set; however, its learning cost for P1 is extremely high. Accordingly, we used the above kernel functions in this preliminary experiment. We note that Lebanon
et al. reported that Eq. (5) was the best kernel function in
their experiments [18].

974

where [[·]] is 1 if the predicate is true and 0 otherwise.
Eq. (7) is the class distribution estimated using an exponentially weighted moving average (EWMA), where γ is a
smoothing parameter that represents the degree of weighting decrease (0 < γ < 1). The weighting for each older data
point decreases exponentially, it never reaches zero.

We evaluated the macro F1 measure of the instance selection and weighting methods while changing the value of h
(Fig. 6). Feature selection was conducted by using the chisquared statistics χ2c based on documents {dτ | t − h < τ <
t}: that is, W (dt ) = {w| maxc {χ2c (w)} > 30.0}.
For the TV data set, decreasing kernel width h improved
classiﬁcation accuracy. This data set exhibited signiﬁcant
and frequent changes in class and word probabilities and
new and important words emerged constantly (see Figs. 2
and 4); therefore, learning from newer tweets was important.
The instance weighting method achieved better classiﬁcation
accuracy than the instance selection method in which all
data within the kernel are equivalent. We note that macro
F1 is not a monotonic function of kernel width because of
the existence of recurrent themes, as shown in Fig. 6b.
For the NPB and MLB data sets, decreasing the kernel
width worsened classiﬁcation accuracy. The instance selection and weighting methods cannot learn stationary words
fully if the kernel width is small. These data sets contained
sudden and signiﬁcant shifts in some words at micro time
scales, as shown in Fig. 3a. Responding to such shifts is important for achieving further improvements in classiﬁcation
accuracy.

3.4

4.3

To acquire abilities A2, A3, and A4, our model estimates
the temporally-aware word probability for each word.
First, our model chronologically concatenates documents
given until t for each class c, Dc,t .
A standard multinomial naive Bayes classiﬁer estimates
the word probability of wi in class c with the maximum
likelihood (ML) method,
pML (wi |c, t) = P

Data Characteristics Considered

pEWMA (wi |c, t) =

X

(1 − λ)|Dc,t |−j λ,

(9)

where Jc (wi ) is the position of word wi in Dc,t , Jc (wi ) =
{j | Dc,t [j] = wi , 1 ≤ j ≤ |Dc,t |}, and λ is a smoothing
parameter of EWMA (0 < λ < 1). Eq. (9) is a closed-form
expression of EWMA.
Our model monitors the two probability estimates for each
word wi in class c, and switches between them as follows:
(

pEWMA if pEWMA > pML + L σc,t
,
pML
otherwise
p
p
where σc,t = pML (1 − pML ) λ/(2 − λ).

p(wi |c, t) =

PROPOSED MODEL

(10)
(11)

Note that Eqs. (10) and (11) mean monitoring the statistical process of wi occurring in Dc,t with a Bernoulli EWMA
control chart[31]. EWMA charts are generally used for detecting small shifts in the process mean [20]. The value of L
in Eq. (10) determines the upper control limit of the chart,
pML + Lσc,t . As long as pEWMA is within the control limit,
the word occurrence process is assumed to be currently stable (i.e., our model uses pML ).
Fig. 7 clariﬁes that Eq. (9) preserves the probabilistic interpretation. We can see that the EWMA value, pEWMA ,
tracks the changes in true probability. The EWMA method
is able to respond to sudden shifts quickly. On the other
hand, the ML method is able to estimate the probability
for stationary words more accurately. The ML method,
however, is apt to underestimate the probabilities of bursty
words. This switching of the two probability estimates for
each word enables our model to resolve the trade-oﬀ between
quick response to bursty words and the accurate learning of
stationary words.

4.1 Outline
At each time step t = 1, 2, . . ., our proposed model outputs a class prediction, ĉt , for a new given document, dt , as
follows:
Y
i−1
ĉt ← arg max{ p(c|t)
p(wi |c, wi−n+1
, t) },
(6)
wi ∈W (dt )

i−1
where wi is the i-th word in dt , wi−n+1
is the word sequence
from the (i−n+1)-th to (i−1)-th word in dt , and W (dt ) is
the set of selected words in dt . Our model then updates
itself based on the true class label ct .
Our model, Eq. (6), is a temporally-aware version of the
multinomial naive Bayes classiﬁer. The following sections
describe three essential components: class distribution, word
probability, and word n-gram probability.

4.2 Class Distribution

4.4

To acquire ability A1, our model incrementally updates
the class distribution, p(c|t), based on ct :
p(c|t) = (1 − γ) p(c|t−1) + γ[[ct = c]],

(8)

j∈Jc (wi )

We propose a classiﬁcation model of tweet streams in
which statistical properties will change over time. Our model,
called P-Switch, is based on the analysis results shown in §3.

c

fc (wi )
,
w∈Dc,t fc (w)

where fc (w) is the frequency of w in Dc,t .
Additionally, our model estimates the word probability
with the EWMA method,

From the results of data analysis and preliminary experiments, an ideal classiﬁcation model for handling concept
drift in tweet streams should be able to: [A1] respond to
changes in class distribution, [A2] respond to changes in
word probability, [A3] handle the emergence of new words
eﬀectively, [A4] resolve the trade-oﬀ between quick response
to bursty words and accurate learning of stationary words,
[A5] consider word n-grams, and [A6] treat recurring themes
eﬀectively. We propose a method that realizes the ﬁrst ﬁve
abilities, A1 to A5. A6 lies outside the scope of this study.

4.

Word Probability

Word n-gram Probability

To acquire ability A5, our model extends the bag-of-words
model to the n-gram language model [26]. It uses the absolute discounting method [22, 4] as the smoothing method

(7)

975

0.25
Estimated Probability

i
1
2
3
4
5
6
7
8
9
10

0.20

0.15
True Prob.
ML
EWMA

0.10

0.05

0

0

10000

20000
30000
Number of Word Observations

40000

Figure 8: Word suﬃx array. ‘#’ is a word boundary.
Columns A and B are the set of alphabet and word
positions at which word-aligned suﬃxes start.

Figure 7: Simulation of estimating probabilities of
word occurrence with ML (Eq. (8)) and EWMA
(Eq. (9), λ = 0.002) methods.

Algorithm 1 Learning word n-gram probability with word
suﬃx arrays.
Require: {dt , ct }, document stream
1: for each (dt , ct ) do
2:
Dct ,t ← Dct ,t−1 + dt // append dt after Dct ,t−1
3:
construct WSAct from Dct ,t
4: end for

used in estimating the word n-gram probability:
i−1
, t) =
p(wi |c, wi−n+1

i
) − κ, 0}
max{fc (wi−n+1
+
i−1
fc (wi−n+1
)

i−1
κ · rc (wi−n+1
)
i−1
fc (wi−n+1
)

i−1
p(wi |c, wi−n+2
, t),

(12)

5.2

i−1
) is the number of distinct words following
where rc (wi−n+1
i−1
word sequence wi−n+1
. The lowest order model in this linear interpolation is p(wi |c, t); therefore, Eq. (12) retains the
temporal eﬀects.
The smoothing of Eq. (8) is also calculated according to
the absolute discounting method:
8
κ
>
P
if fc (wi ) = 0
>
<
w∈Dc,t fc (w)
pML (wi |c, t) =
,
(13)
fc (wi )
>
>
otherwise
:P
w∈Dc,t fc (w)

Learning and Classification Procedures

This section shows the learning and classiﬁcation procedures for word n-gram probability (Eqs. (8)–(13)).
Learning constructs WSAs for each class. Algorithm 1
shows the learning algorithm for a document stream, {dt , ct }.
The sequential update of WSA is not supported, so, it reconstructs the WSA of class ct when given a new tweet (dt , ct ).
(lines 2–3)
For reducing the learning time, it is eﬀective to divide
tweets into periods and reconstruct the newest WSA on the
most recent tweets, while retaining old WSAs. We note that
i
it is able to obtain Jc (wi−n+1
) from the divided WSAs by
storing the oﬀset position of each WSA and adding it to the
i
positions of wi−n+1
found by each WSA.
Classiﬁcation needs the fc (wji ), Jc (wji ), and rc (wji ) values (0 ≤ i − j < n) to calculate the word n-gram probability
i
for each word n-gram, wi−n+1
, in class c. Algorithm 2 shows
the pseudo-code that acquires the above values from a WSA.
Our model uses three heuristics for speed enhancement:
(1) caching search results (lines 6–11, 13), (2) caching the
initial search interval for the ﬁrst alphabets [19] (line 3),
and (3) reducing the number of character comparisons by remembering the number of matching characters [19] (line 9).
Caching the search results of (n−1)-grams enables our model
to narrow the initial interval when searching n-grams. The
i
worst case of our approach is O(m log k + fc (wi−n+1
)) time;
however, Ferragina et al. reported in [7] that the O(m log k+
i
fc (wi−n+1
)) algorithm, which includes heuristics 2 and 3, is
i
faster than the O(m+log k +fc (wi−n+1
)) [19] and O(m|Σ|+
i
fc (wi−n+1 )) [1] algorithms.

and Eq. (13) is used instead of Eq. (8).

5.

T = “ab#a#aa#a#ab#baa#aab#a#aa#baa#”
A B Word-aligned Suﬃx
4
2 a#aa#a#ab#baa#aab#a#aa#baa#
22 8 a#aa#baa#
9
4 a#ab#baa#aab#a#aa#baa#
6
3 aa#a#ab#baa#aab#a#aa#baa#
24 9 aa#baa#
18 7 aab#a#aa#baa#
1
1 ab#a#aa#a#ab#baa#aab#a#aa#baa#
11 5 ab#baa#aab#a#aa#baa#
27 10 baa#
14 6 baa#aab#a#aa#baa#

IMPLEMENTATION

We can implement our model by constructing full text
search indexes (e.g., suﬃx arrays [19]) for each Dc,t . This
study uses the word suﬃx array (WSA) [7]. WSA enables
i
our model to eﬃciently get Jc (wi−n+1
), the positions of
i
i
wi−n+1 in Dc,t , for each word n-gram wi−n+1
in each class c.

5.1 Summary of WSA
Let T [1, . . . , l] be a text of length l over a constant-sized
alphabet Σ, tokenized into k words by word-delimiters, and
let I be the set of alphabet positions at which new words
start. The word suﬃx array A[1, . . . , k] is a permutation of
I such that T [A[i−1], . . . , l] < T [A[i], . . . , l] for all 1 < i ≤ k;
i.e., the A array represents the lexicographic order of all sufﬁxes, as shown in Fig. 8 (see details in [7]). The set of word
positions, B, is obtained as a by-product of constructing
i
WSA. Our model uses B to ﬁnd Jc (wi−n+1
) in Dc,t .
WSA can be constructed in O(l) time and O(k) space
when using the linear-time construction algorithms for suﬃx
i
arrays (e.g., [23]). It can search wi−n+1
(alphabet length of
i
m) quickly with a binary search in O(m log k + fc (wi−n+1
)),
as in suﬃx arrays.

5.3

Implementation Details

We used the original implementation of the WSA construction algorithm2 by Fischer [7] and the sais library3 ,
2
3

976

http://ab.inf.uni-tuebingen.de/people/fischer/wordSA.tgz
http://sites.google.com/site/yuta256/sais

lection method [39]: that is, W (dt ) = {w| maxc {χ2c (w)} >
30.0}, and conducted the smoothing of Eq. (13): κ = 0.9.

Algorithm 2 Acquiring classiﬁcation parameters for class c.
Require: d = “w1 #w2 # · · · #wz #” = w1z , new document
Require: R(a), search range of WSA for each alphabet a
Require: W (d), set of selected words in d
1: for i = 1 to z do
2:
next if wi ∈ W (d)
3:
R ← R(wi [1])
4:
for j = i to i + n − 1 do
5:
s ← wji // word (i − j + 1)-gram.
6:
if is_cached?(s) = true then
7:
fc (s), Jc (s), rc (s), R(s) ← get_cache(s)
8:
else
9:
fc (s), Jc (s), rc (s), R(s) ← search_by_WSA(s, R)
10:
set_cache(s, fc (s), Jc (s), rc (s), R(s))
11:
end if
12:
break if fc (s) < 0
13:
R ← R(s) // narrow next search range.
14:
end for
15: end for
16: return {fc (wji ), Jc (wji ), rc (wji )|1 ≤ i ≤ z, 0 ≤ i−j < n}

6.1

6.1.1 Class Distribution
In order to evaluate the eﬀects by introducing the temporallyaware class distribution described in Eq. (7), we evaluated
the Proposal1 model:
Y
ĉt ← arg max{ p(c|t)
pML (wi |c, t) },
(14)
c

wi ∈W (dt )

which extends the standard multinomial naive Bayes classiﬁer, MNB:
Y
ĉt ← arg max{ p(c)
pML (wi |c, t) },
(15)
c

wi ∈W (dt )

while changing smoothing parameter γ from 0.001 to 0.5.
We can see from Fig. 10 that the Proposal1 model, where
γ = 0.01, performed statistically signiﬁcantly better than
MNB (McNemar’s test; p < .001). We note that the multinomial naive Bayes classiﬁer that assumes a uniform class
distribution performed poorly.

0.3
Construction Time [sec]
0.25
0.2

6.1.2 Word Probability

0.15

In order to evaluate the eﬀects of switching between the
two probability estimates described in Eq. (10), we evaluated
the Proposal2 model:
Y
ĉt ← arg max{ p(c|t)
p(wi |c, t) },
(16)

0.1
0.05

c

0
0

5

10
15
20
Number of Alphabets (x 105 )

25

30

wi ∈W (dt )

which extends the Proposal1 model, while changing smoothing parameter λ from 0.0001 to 0.01. Other parameter settings were: γ = 0.01 and L = 0.5 for all data sets.
Fig. 11 shows that the Proposal2 model, when λ = 0.002,
performed statistically signiﬁcantly better than the Proposal1
model for all data sets (McNemar’s test; p < .001). The
switching of the two probability estimates: pEWMA , which
is based on recent data, and pML , which is based on data that
cover long-term period, enables the Proposal2 model to resolve the trade-oﬀ between quick response to bursty words
and the accurate learning of stationary words. Moreover,
treating class distribution and word probability at diﬀerent
time scales (γ and λ), unlike instance selection and weighting methods, is eﬀective in classifying tweet streams.
We also note that the best value for λ is the same for all
three data sets, which have diﬀerent change characteristics
as shown in Figs. 1 and 4.

Figure 9: Construction time of word suﬃx array
on tweets of class #dragons on NPB data set. Total 53,000 tweets, 399,825 words, 2,701,985 alphabets.
CPU: Xeon X5680 3.33GHz, Memory: 192GB.

which implements Nong et al.’s induced sorting algorithm [23],
as the suﬃx array construction algorithm used by WSA. We
also used Kasai et al.’s algorithm [10] for calculating the
longest common preﬁxes. The character encoding of tweets
was UTF-8, and the number of alphabets was 256; i.e., a
three-byte Japanese character consisted of three alphabets.
Fig. 9 shows the results of constructing WSA on the tweets
in class #dragons for the NPB data set: the construction
time of WSA was linear to the number of alphabets.

6.

Effects of Individual Contributions

Our model, P-Switch, is also a temporally-aware version
of multinomial naive Bayes. The following sections demonstrate the eﬀects of our model’s components.

6.1.3 Word n-gram Probability

EXPERIMENTS

In order to evaluate the eﬀects of introducing the temporallyaware word n-gram probability described in Eq. (12), we
evaluated our P-switch model deﬁned in Eq. (6), while changing the value of n from 1 (corresponds to the Proposal2
model) to 5. Other parameters settings were: γ = 0.01,
λ = 0.002, L = 0.5 for all data sets.
We can see from Fig. 12 that our model performed best
when n = 2, and there were statistical diﬀerences (McNemar’s test; p < .001) between n = 1 and n = 2 on NPB and

In order to evaluate the impact that our proposed model
has on the incremental test-then-train problem deﬁnition
P1 (see §2), we ﬁrst evaluated our model components and
then compared our model against three conventional versions of multinomial naive Bayes classiﬁers (standard, instance weighting, and instance selection), by using the three
tweet data sets shown in Table 1.
The classiﬁers used the chi-squared statistics feature se-

977

Table 2: Overall accuracy and macro F1 results. Bold-faced results were statistically signiﬁcantly better than
other results (McNemar’s test; p < .001).
NPB
TV
MLB
Methods
Accuracy [%]
MacroF1 [%]
Accuracy [%]
MacroF1 [%]
Accuracy [%]
MacroF1 [%]
MNB
55.87
53.81
50.61
50.71
48.29
43.92
MNB-W 50.57 (−5.396) 47.24 (−6.573)
54.77 (+4.160) 53.96 (+3.256)
33.82 (−14.47) 26.85 (−17.06)
MNB-S
51.57 (−4.298) 48.02 (−5.785)
53.26 (+2.649) 52.53 (+1.822)
38.29 (−10.00) 31.60 (−12.32)
Proposal1 60.52 (+4.652) 56.61 (+2.805)
62.82 (+12.21) 62.11 (+11.40)
56.05 (+7.751) 47.03 (+3.119)
Proposal2 65.87 (+9.998) 61.46 (+7.654)
70.77 (+20.16) 70.22 (+19.52)
60.26 (+11.97) 50.59 (+6.671)
P-Switch 66.90 (+11.04) 62.88 (+9.072)
70.80 (+20.19) 70.31 (+19.60)
60.86 (+12.56) 51.40 (+7.480)
0.65

0.60

0.55

0.630
0.625
0.620
0.615
0.610
0.704
0.703
0.702
0.701
0.700
0.517
0.514
0.511
0.508
0.505

Macro average F1

NPB
TV
MLB

0.50

0.45

0.40

0.35

MNB: Eq.(15)
Uniform ML

0.001

Proposal1: Eq.(14)

0.01
0.1
Smoothing Value for Class Prior

1

Macro average F1

NPB
TV
MLB

0.60
0.55
0.50
0.45

Proposal1
ML

0.0001

Proposal2: Eq.(16)
0.001
0.01
Smoothing Value for Word Probability

(c) Macro average F1 on MLB
Proposal2
1

P-Switch: Eq.(6)
2
3
4
Value of N for Word N-gram

5

the instance selection method (MNB-S; Eqs. (1) and (4))
(see details in §3.3 and [29, 18]). Parameter settings were:
γ = 0.01, λ = 0.002, L = 0.5, and n = 2. The kernel width
of MNB-W and MNB-S was h = 10,000, which was the best
value for the TV data set. Note that the best value of h for
the NPB and MLB data sets was ∞ (corresponds to MNB)
as shown in Fig. 6.
Fig. 13 plots macro F1 of the classiﬁers vs. the training
number of tweets (time steps). Table 2 is the overall accuracy and macro F1 of the classiﬁers after learning all data.
Although the NPB and MLB data sets contain various
changes, MNB performed better than MNB-W and MNBS; that is, learning stationary words with suﬃcient data is
more important than responding to bursty words for these
data sets. Our model resolved the trade-oﬀ between quick
response and accurate learning by switching between the
two probability estimates for each word. It oﬀered a statistically signiﬁcant improvement over MNB, up to 11.04%
and 12.56% in terms of overall accuracy, and up to 9.072%
and 7.480% in terms of macro F1 , for the NPB and MLB
data sets, respectively (McNemar’s test; p < .001).
Considering temporal eﬀects enabled MNB-W and MNBS to perform better than MNB on the TV data set; however, increasing the number of training tweets is not eﬀective
for achieving their higher classiﬁcation accuracy, as shown
in Fig. 13b. This is because using the small kernel width
yields rapid dropping of old data. MNB, which learns all
data, performed worst because the TV data set contained
sudden and signiﬁcant shifts as shown in Fig. 2. Our PSwitch model was able to respond to both the sudden shift
and gradual drift; therefore, it achieved statistically signiﬁ-

0.75

0.65

(b) Macro average F1 on TV

n.s.

Figure 12: Eﬀects of introducing temporally-aware
i−1
word n-gram probability, p(wi |c, wi−n+1
, t). γ = 0.01,
λ = 0.002, and L = 0.5.

Figure 10: Eﬀects of introducing temporally-aware
class distribution, p(c|t). “Uniform” means the multinomial naive Bayes classiﬁer that assumes a uniform
class distribution.

0.70

(a) Macro average F1 on NPB

0.1

Figure 11: Eﬀects of introducing temporally-aware
word probability, p(wi |c, t). γ = 0.01 and L = 0.5.

MLB data sets. Larger values of n worsened classiﬁcation
accuracy because the zero frequency problem is serious in
higher-order n-gram models [37].

6.2 Overall Results
§6.1 demonstrated that all of our individual contributions
are eﬀective in handling concept drift in tweet streams.
We next compared the whole P-Switch model against conventional methods for handling concept drift: a temporallyaware multinomial naive Bayes classiﬁer with the instance
weighting method (MNB-W; Eqs. (1) and (5)), and with

978

0.65

Some studies that use suﬃx arrays (SAs) for document
classiﬁcation have been proposed. Teo and Vishwanathan
proposed fast and space eﬃcient string kernels based on SAs
and used the kernel with the support vector machine [33].
Okanohara and Tsujii proposed a logistic regression model
with all-eﬀective substrings, which are found with SAs [24].
These studies target the ﬁnding of eﬀective feature spaces
for batch learning; our model, on the other hand, uses lazy
learning for streaming documents—generalization beyond
the training data is delayed until a new document is given.
Salles et al. proposed temporally-aware versions of Rocchio and k-nearest neighbors classiﬁers that conduct temporal weighting on documents [29], in addition to the multinomial naive Bayes classiﬁer described in Eq. (1). Their experiments showed that there were no signiﬁcant diﬀerences
among the classiﬁers. We ﬁnd that responding to changes
at the word level is more important than model selection for
classifying document streams.

P-Switch
MNB-W
MNB-S
MNB

0.6

0.55

0.5

0.45
(a) Cum. Macro average F1 on NPB

0.4

0

100000

200000

300000

0.75
0.7
P-Switch
MNB-W
MNB-S
MNB

0.65
0.6

8. CONCLUSIONS
We proposed a classiﬁcation model of tweet streams, which
are representative of document streams whose statistical properties change over time.
We analyzed tweet streams by examining the changes in
class distribution and word probability, the occurrence of
new words and recurring themes, and the eﬀectiveness of
considering word n-grams. In particular, we demonstrated
that tweet streams change signiﬁcantly at the word level—
the word occurrence probability changes at diﬀerent rates
for diﬀerent words.
Our model solves this problem by detecting changes in
word occurrence probability for each word. It switches between two probability estimates, the maximum likelihood
and exponentially weighted moving average estimates, by
using a control chart and is very eﬀective in achieving both
accurate learning of stationary words and quick response to
bursty words. Also, it handles the changes in class distributions and extends the bag-of-words model to cover the
n-gram language model. It preserves the probabilistic interpretation of the multinomial naive Bayes classiﬁer.
We then presented an implementation method that uses a
word suﬃx array. This approach enables our model to eﬀectively handle word n-grams, which are highly important information given the 140 character limit of tweets. This new
idea, searching the positions of words in documents concatenated chronologically, allows consideration of the temporal
eﬀects on changing word streams.
Experiments on topic classiﬁcation were conducted using
three real-world tweet data sets: tweets about Japanese
baseball teams, television networks in Japan, and major
league baseball teams. Results demonstrated that our model
performed statistically signiﬁcantly better than conventional
instance weighting and selection models. In particular, our
model was superior to the multinomial naive Bayes classiﬁer with an instance weighting method by up to 16.33% and
16.35% in terms of accuracy and macro F1 , for the television
network data set.

0.55
0.5
(b) Cum. Macro average F1 on TV

0.45

0

50000

100000

150000

200000

250000

0.55
0.5
0.45
P-Switch
MNB-W
MNB-S
MNB

0.4
0.35
0.3
0.25

(c) Cum. Macro average F1 on MLB

0.2

0

50000
100000
150000
Number of Tweets (=Time Step)

200000

Figure 13: Number of tweets vs. cumulative macro
F1 on (a) NPB, (b) TV, and (c) MLB data sets.
γ = 0.01, λ = 0.002, L = 0.5, n = 2, and h = 10000.
cant improvements over MNB, up to 20.19% and 19.60% in
terms of overall accuracy and macro F1 , respectively (McNemar’s test; p < .001).

7.

RELATED WORK

As related work on classiﬁcation of tweets, Sriram et al.
devised a naive Bayes classiﬁer for identifying tweet types
such as news, events, opinions, deals, and private messages
based on author information and tweet texts [32]. Sakaki
et al. devised a support vector machine for ﬁnding tweets
related to an event (e.g., earthquake) [27]. Kinsella et al.
uses metadata from hyperlinked objects to improve topic
classiﬁcation [14]. The above studies, however, employ batch
learning and do not consider concept drift. While sentiment
classiﬁcation methods have been proposed most recently [9,
3, 25], they also do not consider temporal eﬀects.

9.

REFERENCES

[1] M. I. Abouelhoda, S. Kurtz, and E. Ohlebusch.
Replacing suﬃx trees with enhanced suﬃx arrays. J.
Discrete Algorithms, 2(1):53–86, 2004.

979

[2] A. Bifet, J. Gama, M. Pechenizkiy, and I. Zliobaite.
Handling concept drift: Importance, challenges and
solutions. In PAKDD Tutorial, 2011.
[3] S. Brody and N. Diakopoulos.
Cooooooooooooooollllllllllllll!!!!!!!!!!!!!! using word
lengthening to detect sentiment in microblogs. In
EMNLP, pages 562–570, 2011.
[4] S. F. Chen and J. Goodman. An empirical study of
smoothing techniques for language modeling.
Computer Speech & Language, 13(4):359–393, 1999.
[5] L. C. da Rocha, F. Mourão, A. M. Pereira, M. A.
Gonçalves, and W. Meira Jr. Exploiting temporal
contexts in text classiﬁcation. In CIKM, pages
243–252, 2008.
[6] S. J. Delany, P. Cunningham, and B. Smyth. ECUE:
A spam ﬁlter that uses machine learning to track
concept drift. In ECAI, page 627, 2006.
[7] P. Ferragina and J. Fischer. Suﬃx arrays on words. In
CPM, pages 328–339, 2007.
[8] G. Forman. Tackling concept drift by temporal
inductive transfer. In SIGIR, pages 252–259, 2006.
[9] L. Jiang, M. Yu, M. Zhou, X. Liu, and T. Zhao.
Target-dependent twitter sentiment classiﬁcation. In
ACL, pages 151–160, 2011.
[10] T. Kasai, G. Lee, H. Arimura, S. Arikawa, and
K. Park. Linear-time longest-common-preﬁx
computation in suﬃx arrays and its applications. In
CPM, pages 181–192, 2001.
[11] I. Katakis, G. Tsoumakas, E. Banos, N. Bassiliades,
and I. P. Vlahavas. An adaptive personalized news
dissemination system. J. Intell. Inf. Syst.,
32(2):191–212, 2009.
[12] I. Katakis, G. Tsoumakas, and I. Vlahavas. Tracking
recurring contexts using ensemble classiﬁers: an
application to email ﬁltering. Knowl. Inf. Syst.,
22:371–391, 2010.
[13] L. Khan, M. Pechenizkiy, and I. Zliobaite, editors. 2nd
International Workshop on Handling Concept Drift in
Adaptive Information Systems, 2011.
[14] S. Kinsella, A. Passant, and J. G. Breslin. Topic
classiﬁcation in social media using metadata from
hyperlinked objects. In ECIR, pages 201–206, 2011.
[15] R. Klinkenberg. Learning drifting concepts: example
selection vs. example weighting. Intell. Data Anal.,
8:281–300, 2004.
[16] R. Klinkenberg and T. Joachims. Detecting concept
drift with support vector machines. In ICML, pages
487–494, 2000.
[17] R. Klinkenberg and I. Renz. Adaptive information
ﬁltering: Learning in the presence of concept drifts. In
ICML/AAAI-98, pages 33–40, 1998.
[18] G. Lebanon and Y. Zhao. Local likelihood modeling of
temporal text streams. In ICML, pages 552–559, 2008.
[19] U. Manber and E. W. Myers. Suﬃx arrays: A new
method for on-line string searches. SIAM J. Comput.,
22(5):935–948, 1993.
[20] D. C. Montgomery. Introduction to statistical quality
control. John Wiley & Sons, 6th edition, 2008.
[21] F. Mourão, L. C. da Rocha, R. B. Araújo, T. Couto,
M. A. Gonçalves, and W. M. Jr. Understanding

[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]
[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]

[39]

980

temporal aspects in document classiﬁcation. In
WSDM, pages 159–170, 2008.
H. Ney, U. Essen, and R. Kneser. On structuring
probabilistic dependences in stochastic language
modeling. Computer Speech & Language, 8:1–38, 1994.
G. Nong, S. Zhang, and W. H. Chan. Linear suﬃx
array construction by almost pure induced-sorting. In
DCC, pages 193–202, 2009.
D. Okanohara and J. ichi Tsujii. Text categorization
with all substring features. In SDM, pages 838–846,
2009.
A. Pak and P. Paroubek. Twitter as a corpus for
sentiment analysis and opinion mining. In LREC,
2010.
F. Peng, D. Schuurmans, and S. Wang. Augmenting
naive bayes classiﬁers with statistical language models.
Inf. Retr., 7(3-4):317–345, 2004.
T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake
shakes twitter users: real-time event detection by
social sensors. In WWW, pages 851–860, 2010.
T. Salles, L. C. da Rocha, F. Mourão, G. L. Pappa,
L. Cunha, M. A. Gonçalves, and W. Meira Jr.
Automatic document classiﬁcation temporally robust.
JIDM, 1(2):199–212, 2010.
T. Salles, L. C. da Rocha, G. L. Pappa, F. Mourão,
W. Meira Jr., and M. A. Gonçalves. Temporally-aware
algorithms for document classiﬁcation. In SIGIR,
pages 307–314, 2010.
M. Scholz and R. Klinkenberg. Boosting classiﬁers for
drifting concepts. Intell. Data Anal., 11(1):3–28, 2007.
S. E. Somerville, D. C. Montgomery, and G. C.
Runger. Filtering and smoothing methods for mixed
particle count distributions. Int. Journal of Prod.
Res., 40(13):2991–3013, 2002.
B. Sriram, D. Fuhry, E. Demir, H. Ferhatosmanoglu,
and M. Demirbas. Short text classiﬁcation in twitter
to improve information ﬁltering. In SIGIR, pages
841–842, 2010.
C. H. Teo and S. V. N. Vishwanathan. Fast and space
eﬃcient string kernels using suﬃx arrays. In ICML,
pages 929–936, 2006.
A. Tsymbal. The problem of concept drift: deﬁnitions
and related work. Technical Report TCD-CS-2004-15,
Trinity College Dublin, 2004.
B. Wenerstrom and C. Giraud-Carrier. Temporal data
mining in dynamic feature spaces. In ICDM, pages
1141–1145, 2006.
G. Widmer and M. Kubat. Learning in the presence of
concept drift and hidden contexts. Machine Learning,
23(1):69–101, 1996.
I. H. Witten and T. C. Bell. The zero-frequency
problem: Estimating the probabilities of novel events
in adaptive text compression. IEEE Trans. Inf.
Theory, 37(4):1085–1094, 1991.
E. S. Xiouﬁs, M. Spiliopoulou, G. Tsoumakas, and
I. P. Vlahavas. Dealing with concept drift and class
imbalance in multi-label stream classiﬁcation. In
IJCAI, pages 1583–1588, 2011.
Y. Yang and J. O. Pedersen. A comparative study on
feature selection in text categorization. In ICML,
pages 412–420, 1997.


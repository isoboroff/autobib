Opinion Summarisation through Sentence Extraction:
an Investigation with Movie Reviews
Marco Bonzanini, Miguel Martinez-Alvarez and Thomas Roelleke
Queen Mary University of London

{marcob,miguel,thor}@eecs.qmul.ac.uk

ABSTRACT

the short passage which gives the overall sentiment of the review.
From the user’s perspective, the advantage of having a summarised
review consists in a reduced effort to understand the message of the
document, given that the key information is preserved. Traditional
summarisation techniques can be applied for this task, although a
more opinion-oriented approach is needed, since the goal is not to
better describe the topic of the review in a single sentence, but to
capture its overall polarity. In order to verify whether the summarisation task preserves the information about the sentiment of
reviews, text classification is performed on the original documents
and on the produced summaries.
The contributions of this work are two-fold: firstly, we show how
the summaries based on subjectivity well represent the polarity of
the full-text review; secondly, we investigate different techniques
for identifying the key passage of a review with respect to polarity.
Experiments on a movie review data-set show the importance of
subjectivity detection for polarity classification.

In on-line reviews, authors often use a short passage to describe
the overall feeling about a product or a service. A review as a
whole can mention many details not in line with the overall feeling, so capturing this key passage is important to understand the
overall sentiment of the review. This paper investigates the use
of extractive summarisation in the context of sentiment classification. The aim is to find the summary sentence, or the short passage, which gives the overall sentiment of the review, filtering out
potential noisy information. Experiments on a movie review dataset show that subjectivity detection plays a central role in building
summaries for sentiment classification. Subjective extracts carry
the same polarity of the full text reviews, while statistical and positional approaches are not able to capture this aspect.

Categories and Subject Descriptors
H.4.m [Information Systems Applications]: Miscellaneous

2.

General Terms
Algorithms, Experimentation

Keywords

2.1

Summarisation, Sentiment Classification, Opinion Mining

1.

EXTRACTIVE SUMMARISATION

Different sentence selection techniques can be applied to produce
various kinds of extractive summaries. This section outlines the
different approaches taken into account for the experimental study.

Luhn’s Approach

Firstly, the traditional Luhn’s approach [1] is used to score the sentences according to their significance. The top-n sentences are selected to create the summary. The results for this approach are
labelled as Luhn-n, where n is the number of sentence used to create the summary. The significance score of a sentence is based on
clustering of sentence tokens using a distance threshold (5 is the
distance used in this poster). The significant words are chosen according to their frequency, i.e. the terms with higher tf, excluding
stop words, are considered significant. The significance score for a
sentence will be the maximum score for any of its clusters.

INTRODUCTION

New interest in the area of Sentiment Analysis is pushed by the
popularity of on-line resources, which allow users to review products and services. One of the main tasks in this field is the classification of documents according to the overall polarity, i.e. either
positive or negative. A common behaviour among reviewers is to
summarise the overall sentiment of the review in a short passage,
or even in a single sentence. However, the rest of the review can
express different feelings from the overall judgement. Moreover,
often a review contains sentences which do not provide any information about opinions, i.e. they are not subjective. This is the case
of movie reviews, where a short picture of the plot can be given
to open the review, without commenting on it. Previous work has
shown how the detection of subjective sentences can improve the
sentiment classification [3].
This poster investigates how summarisation techniques can be applied in the context of sentiment classification of on-line reviews.
More specifically, the aim is to capture the summary passage, i.e.

2.2

Position-based Approaches

A second family of summarisers is built on top of an empirical
observation: often reviewers tend to summarise their overall feeling
in a sentence or in a short paragraph, placed either at the beginning
or at the end of the review. In this case, a summary can be created
simply selecting the n opening, or closing, sentences. Results for
these approaches are labelled as First-n and Last-n, respectively.

2.3

Subjectivity Detection

The previous approaches do not consider the subjective nature of
the reviews. To overcome this issue, a classifier can be used to identify and filter subjective sentences. A specific data-set, described in
Section 3, is used to train the classifier. Filtering out the objective

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1121

4.

sentences and aggregating only the subjective ones can already be
seen as a summarisation approach. The average compression rate
of the data under analysis is around 60%. Results for this approach
are labelled as Subjective-Full.

2.4

The first observation is that statistical and positional summarisation
approaches do not provide any improvement to the sentiment classification results. In fact, the performances are substantially worse
for both NB and SVM. The explanation behind this behaviour is
that these approaches are not explicitly opinion-oriented, so they
are not able to capture the sentiment behind a review. The quality
of sentiment classification for subjective extracts is instead in line
with the full review classification. Subjective extracts through NB
achieves a 1.5% better result compared to the classification of full
text. On the SVM side, the classification of subjective extracts is
performed slightly worse than the full text. In other words, the subjectivity detection step preserves the most important information
about polarity, and this aspect is captured by both classifiers. In
order to further analyse this finding, experiments on objective extracts classification have been also performed. The objective sentences have been aggregated, building the counterparts of the subjective extracts. The micro-averaged F1 values for the objective
extracts classification were below 75% for both classifiers, hence
significantly worse than both the full review and subjective extract
classification. When further summarisation is performed on the
subjective extracts, the results drop again. In Table 1, we can observe a similar behaviour between summaries created from the full
text and summaries created from the subjective extracts. As further analysis, we also examine the classification of the summaries
with respect to the full documents. In other words, we verify if a
full text and its respective summary are classified under the same
label, without considering whether this is the correct answer or not.
In 91% of the cases, the subjective summaries are assigned to the
same label of the correspondent full text. For all the other summarisation approaches, this value drops below 80%, and in some cases
below 70%. This is further evidence of the connection between
subjectivity and polarity.
Sentence extraction techniques purely based on statistical or positional approaches do not capture the subjectivity of a review, and
hence are inadequate to summarise the sentiment of the document.
On the contrary, subjectivity detection produces results which are
comparable to the full text classification. Further summarisation
on top of subjectivity detection, again fails to capture the polarity of documents, as more opinion-oriented approaches are needed.
Showing a subjective extract instead of the full text, a potential user
would need to read about 60% of a review, or even less, in order to
understand its polarity.

Summarising Subjective Extracts

One of the first two approaches can be applied to subjective extracts, in order to increase the compression rate. In the results,
this family of approaches is labelled as follows: Subjective-Luhnn for the summaries produced using Luhn’s approach on the subjective sentences, Subjective-First-n and Subjective-Last-n for the
summaries based on the subjective sentence positions.

3.

EXPERIMENTAL STUDY

The evaluation of summarisation systems is a research issue in itself [2]. The purpose of this work is observing how summarisation preserves the opinion of a document, so the evaluation is performed w.r.t. the polarity classification, i.e. a good summary is ideally able to carry the same polarity of the full document. Full text
reviews and summaries are classified according to their overall polarity. Traditional machine learning approaches can be applied for
this classification task. Specifically, Naive Bayes (NB) and Support
Vector Machine (SVM) classifiers are considered, using unigrampresence as features. The feature selection for NB is based on document frequency, being a commonly used selection strategy.
For the subjectivity detection, a data-set of subjective and objective sentences is used to train the classifiers [3]. This data-set contains 5000 subjective sentences, taken from RottenTomatoes1 snippets, and 5000 objective sentences, taken from IMDb2 plots. The
classifiers can be considered reliable enough for the subjectivity
detection task which leads to the generation of subjective extracts
(micro-average F1 results on this data-set, with a five-folding cross
validation, are 88.85 for NB and 88.68 for SVM).
The sentiment classification has been evaluated on a different
movie review data-set firstly used in [3], containing reviews taken
from IMDb and annotated as positive or negative. The data-set contains 2000 documents, evenly distributed between the two classes.
Table 1 reports the results of the micro-averaged F1 scores [4] on
the review data-set. The macro-averaged results are very similar to
the micro-averaged ones, given the data-set is well balanced.
Table 1: Micro-averaged F1 results of sentiment classification
NB
SVM
83.31
87.10
Full Review
70.12
70.28
Luhn-1
75.47
74.96
Luhn-3
68.94
68.82
First-1
70.61
70.49
Last-1
70.81
70.43
First-3
75.58
76.57
Last-3
84.61
86.82
Subjective-Full
71.02
70.50
Subjective-Luhn-1
74.92
74.91
Subjective-Luhn-3
69.33
68.90
Subjective-First-1
70.90
71.15
Subjective-Last-1
71.12
71.07
Subjective-First-3
75.49
76.26
Subjective-Last-3

1
2

DISCUSSION AND CONCLUSION

5.

REFERENCES

[1] H.P. Luhn. The automatic creation of literature abstracts. IBM
Journal of research and development, 2(2):159–165, 1958.
[2] A. Nenkova and K. McKeown. Automatic summarization.
Foundations and Trends in Information Retrieval,
5(2-3):103–233, 2011.
[3] B. Pang and L. Lee. A sentimental education: Sentiment
analysis using subjectivity summarization based on minimum
cuts. In Proceedings of the 42nd Annual Meeting on
Association for Computational Linguistics, pages 271–278.
Association for Computational Linguistics, 2004.
[4] Fabrizio Sebastiani. Machine learning in automated text
categorization. ACM Comput. Surv., 34(1):1–47, 2002.

http://www.rottentomatoes.com
http://www.imdb.com

1122


Fixed versus Dynamic Co-Occurrence Windows in
TextRank Term Weights for Information Retrieval
Wei Lu

Qikai Cheng

Christina Lioma

School of Information
Management
Wuhan University, China

School of Information
Management
Wuhan University, China

Computer Science
University of Copenhagen,
Denmark

reedwhu@gmail.com

chengqikai0806@gmail.com

ABSTRACT

c.lioma@diku.dk

TextRank is a variant of PageRank typically used in graphs
that represent documents, and where vertices denote terms
and edges denote relations between terms. Quite often the
relation between terms is simple term co-occurrence within
a ﬁxed window of k terms. The output of TextRank when
applied iteratively is a score for each vertex, i.e. a term
weight, that can be used for information retrieval (IR) just
like conventional term frequency based term weights.
So far, when computing TextRank term weights over cooccurrence graphs, the window of term co-occurrence is always ﬁxed. This work departs from this, and considers dynamically adjusted windows of term co-occurrence that follow the document structure on a sentence- and paragraphlevel. The resulting TextRank term weights are used in a
ranking function that re-ranks 1000 initially returned search
results in order to improve the precision of the ranking. Experiments with two IR collections show that adjusting the
vicinity of term co-occurrence when computing TextRank
term weights can lead to gains in early precision.

assumption in these approaches is that the vicinity of term
co-occurrence is ﬁxed for all terms. To our knowledge, there
is no theoretical or intuitive basis for this assumption.
Fixed-window term co-occurrence may not be optimal for
TextRank term weights. Lexical aﬃnities may span across
more words in longer sentences than they do in shorter sentences. Hence, adjusting the co-occurrence window according to the discourse span of the text might be a better choice.
Based on this intuition, in this work we look at the eﬀect of
dynamically adjusted windows of term co-occurrence upon
their resultant TextRank term weights. We experiment with
co-occurrence windows that follow the document structure
on two levels of granularity: sentences and paragraphs. For
each of these, we compute term weights using TextRank, and
use them for retrieval using the ranking model of [2], i.e. linearly combined with inverse document frequency (idf). Experiments using these TextRank term weights for re-ranking
the top 1000 search results show that sentence-based cooccurrence can outperform ﬁxed-window co-occurrence in
terms of early precision.

Categories and Subject Descriptors

2. CO-OCCURRENCE WINDOWS

H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

2.1

Methodology

We experiment with two datasets: Reuters RCV1 from
TREC 2002 (2.5GB, 50 title-only queries) and INEX 2005
(764MB, 40 content-only queries). We build a separate graph
for each document: terms are represented as vertices (initially unweighted), and term co-occurrence within a window
is represented as an undirected edge linking the vertices of
the co-occurring terms. We use TextRank [6] to compute
iteratively the score of each vertex vi :

Keywords
TextRank, term co-occurrence

1. INTRODUCTION
Associative networks have long been used to represent
units of text and their interconnecting relations [5]. The
symbolic structures that emerge from these representations
correspond to graphs, where text constituents are represented as vertices and their interconnecting relations as edges.
Graph ranking algorithms, such as the TextRank [5, 6] variant of PageRank, have been used successfully in keyword
extraction [6], classiﬁcation [3] and information retrieval [2]
to compute term weights from graphs of individual documents, where vertices represent the document’s terms, and
edges represent term co-occurrence within a ﬁxed window.
Using these computations iteratively, the weight of a term
can be estimated with respect to the terms that fall in its
vicinity and their respective term weights. An underlying

s(vi ) = (1 − δ) + δ ×


j∈V (vi )

S(vj )
|V (vj )|

(1)

where s(vi ) is the TextRank score of vertex vi , V (·) denotes
the set of vertices connecting with a vertex, | · | marks cardinality, and 0 ≤ δ ≤ 1 is a damping factor that integrates into
the computation the probability of jumping randomly from
one vertex to another. We iterate the formula 200 times,
using the default δ = 0.85 [6]. The ﬁnal score of each vertex
represents a term weight where the higher the number of
diﬀerent words that a given word co-occurs with, and the
higher their weight, the higher the weight of this word. It
has been shown that a nonlinear correlation exists between
such TextRank term weights and term frequency based term
weights [5].

Copyright is held by the author/owner(s).
SIGIR’12, August 12–16, 2012, Portland, Oregon, USA.
ACM 978-1-4503-1472-5/12/08.

1079

We use these term weights to compute the score of a document for a query (s(d, q)) according to [2]:

s(d, q) =
log idfi × log s(i)
(2)

min length
max length
min tokens
max tokens
average tokens

i∈q

para (RCV1)
1
31696
1
4662
20.35

sent (INEX)
1
7920
1
2447
15.73

para (INEX)
1
111136
1
17379
58.51

Table 1: Sentence (sent) and paragraph (para)
statistics per retrieval dataset.

where i is a query term, and s(i) is the corresponding TextRank score for vertex vi . No document length normalisation is used. We use Porter’s stemmer for the documents
and queries.
To compare ﬁxed versus dynamically adjusted windows of
term co-occurrence, we use a baseline where the window of
term co-occurrence is ﬁxed to the best values reported in
the IR literature (albeit for other datasets)1 [2]: k =5 & 6.
We compare this baseline against term co-occurrence that
is dynamically adjusted to the length of each (a) sentence
and (b) paragraph2 , separately. The sentence/paragraph
term statistics are displayed in Table 1. We evaluate this
comparison in a re-ranking scenario, where the task is to
re-rank an initially retrieved set of 1000 documents. For
the INEX collection (where relevance assessments apply to
document sections) we consider a document relevant if any
of its containing sections is assessed relevant.

2.2

sent (RCV1)
1
1731
1
250
19.87

Re-ranking top 1000 retrieved documents
co-occurrence
RCV1
window
NDCG MRR
P@10
NDCG
5 terms
0.5238 0.6736
0.4300
0.5541
ﬁxed
6 terms
0.5025
0.6559
0.4280
0.5540
sentence
0.5119
0.6811 0.4340 0.5543
dynamic
paragraph
0.5178
0.6574
0.4160
0.5545

INEX
MRR
0.6865
0.6966
0.7021
0.6975

P@10
0.4750
0.4714
0.4743
0.4714

Table 2: Retrieval performance with TextRank term
weights using fixed vs. dynamic co-occurrence windows, on two datasets. Bold font marks best scores.

the ranking of Blanco et al. [1, 2]. Unlike all these existing
approaches where term co-occurrence is ﬁxed to a window
of k terms at all times, we reasoned that term co-occurrence
should be varied according to sentence or paragraph length.
Our motivation was that meaningful term relations may
span across more words in longer sentences than they do
in shorter sentences, hence ﬁxing term co-occurrence may
not be optimal for all terms.
Preliminary experiments in a re-ranking scenario with two
retrieval datasets showed that sentence-based co-occurrence
can lead to early precision gains over ﬁxed term co-occurrence
at 5 and 6 terms, which are optimal values in the IR literature. More experiments with larger datasets and fullranking (as opposed to re-ranking) documents are needed
to investigate the optimal term co-occurrence vicinity. This
small-scale work contributes a novel comparison between
ﬁxed versus dynamically adjusted co-occurrence windows for
TextRank term weights, and the initial ﬁnding that sentencebased co-occurrence can improve early precision.
Acknowledgments. Work partially funded by DANIDA
(grant no. 10-087721) and the National Natural Science
Foundation of China (grant no. 71173164).

Findings

Table 2 shows diﬀerent metrics of retrieval performance
when using ﬁxed versus sentence- and paragraph-length windows of term co-occurrence. We see that results vary3 . For
average precision (NDCG) ﬁxed co-occurrence is best for
RCV1, and sentence-based co-occurrence is best for INEX.
The reverse happens for precision in the top 10 retrieved
documents (P@10): ﬁxed co-occurrence is best for INEX,
and sentence-based co-occurrence is best for RCV1. The
only consistent trend is in the precision of the single top
retrieved document (MRR), which beneﬁts more from dynamically adjusted co-occurrence consistently for both collections. This ﬁnding is novel, considering the earlier position of [6] that the larger the window of co-occurrence, the
lower the precision. This ﬁnding indicates that larger window sizes may lead to gains in precision, if however they are
not ﬁxed but rather dynamically adjusted to text units like
sentences.
Finally, sentences appear to be an overall better boundary
of term co-occurrence than paragraphs, with the exception
of NDCG for INEX where paragraph-based co-occurrence
slightly outperforms sentence-based co-occurrence (and they
both outperform ﬁxed co-occurrence). This could be due
to the fact that INEX paragraphs are relatively short and
focused content-wise [4].

4.

REFERENCES

[1] R. Blanco and C. Lioma. Random walk term weighting
for information retrieval. In W. Kraaij, A. P. de Vries,
C. L. A. Clarke, N. Fuhr, and N. Kando, editors,
SIGIR, pages 829–830. ACM, 2007.
[2] R. Blanco and C. Lioma. Graph-based term weighting
for information retrieval. Inf. Retr., 15(1):54–92, 2012.
[3] S. Hassan, R. Mihalcea, and C. Banea. Random walk
term weighting for improved text classiﬁcation. Int. J.
Semantic Computing, 1(4):421–439, 2007.
[4] S. Malik, G. Kazai, M. Lalmas, and N. Fuhr. Overview
of inex 2005. In N. Fuhr, M. Lalmas, S. Malik, and
G. Kazai, editors, INEX, volume 3977 of Lecture Notes
in Computer Science, pages 1–15. Springer, 2005.
[5] R. Mihalcea and D. Radev. Graph-Based Natural
Language Processing and Information Retrieval.
Cambridge University Press, 2011.
[6] R. Mihalcea and P. Tarau. Textrank: Bringing order
into text. In EMNLP, pages 404–411. ACL, 2004.

3. CONCLUSION
We modelled individual documents as separate graphs
where vertices represent terms, and co-occurrence relations
among terms represent edges. Using the TextRank model
of Mihalcea et al. [5, 6] we computed vertex weights corresponding to term weights, which we used for retrieval using
1
In non-IR literature, optimal ﬁxed values are: k =2,4 for
classiﬁcation [3] and k =2 for keyword extraction [6], however these values consistently underperform for IR [1, 2].
2
We treat these elements as paragraphs: p (for RCV1) and
ilrj, ip1, ip2, ip3, ip4, ip5, item-none, p, p1,
p2, p3, Bib, Bm, St (for INEX).
3
Results were not stat. signiﬁcant when the t-test was used.

1080


Short Research Papers 1B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

On Topic Di�iculty in IR Evaluation:
The E�ect of Systems, Corpora, and System Components
Fabio Zampieri

University of Udine
Udine, Italy
zampieri.fabio@spes.
uniud.it

Kevin Roitero

University of Udine
Udine, Italy
roitero.kevin@spes.
uniud.it

J. Shane Culpepper
RMIT University
Melbourne, Australia
shane.culpepper@
rmit.edu.au

ABSTRACT

Technion
Haifa, Israel
kurland@ie.technion.
ac.il

Stefano Mizzaro

University of Udine
Udine, Italy
mizzaro@uniud.it

RQ1. Given a collection, what is the e�ect of choosing a di�erent
set of systems on the di�culty of topics?
RQ2. Given a set of systems, what is the e�ect of the corpus of
documents (or sub-corpora of a corpus) on topic di�culty?
RQ3. What is the e�ect of system components on topic di�culty?
RQ4. What is the relative e�ect of choosing di�erent systems, corpora, and system components on topic di�culty?

In a test collection setting, topic di�culty can be de�ned as the
average e�ectiveness of a set of systems for a topic. In this paper
we study the e�ects on the topic di�culty of: (i) the set of retrieval
systems; (ii) the underlying document corpus; and (iii) the system
components. By generalizing methods recently proposed to study
system component factor analysis, we perform a comprehensive
analysis on topic di�culty and the relative e�ects of systems, corpora, and component interactions. Our� ndings show that corpora
have the most signi�cant e�ect on topic di�culty.

2

RELATED WORK

A body of related work focuses on studying factors that a�ect
system e�ectiveness, such as topic composition, collection, and
system components. Sanderson et al. [11] investigated the e�ect of
splitting a TREC collection into sub-collections based on system
e�ectiveness, and identi�ed several interesting sub-collection effects induced by the splits. Banks et al. [1] provided an overview
of methods that can be applied to analyze the performance of IR
systems on TREC collections and its relation to topics, collections
and other factors. One common statistical tool used for this problem is the Analysis of Variance (ANOVA), which was recently used
by Ferro and Silvello [5] to compare combinations of collections,
metrics, and systems. They showed that stop lists, IR models, and
component interactions have a signi�cant but small e�ect on overall system e�ectiveness. The same approach was adopted by Ferro
and Sanderson [4] and Ferro et al. [3], whose experiments show
the existence of a signi�cant sub-corpus e�ect relative to system
e�ectiveness; however, the e�ect is smaller than both system and
topic e�ects, with topic e�ect being the most signi�cant. Similar
experiments using the sub-corpora of a single collection showed
that the system e�ect is smaller than the topic e�ect [4]. However,
none of these studies speci�cally addresses the e�ect of factors on
topic di�culty which we study here. Moreover, all of them compare
sub-corpora of the same collection, which has some drawbacks.
TREC corpora are built with a “working assumption” that they
are somehow complete, and working on sub-corpora can sometimes negate this assumption. In this paper, we do not only analyze
what happens on incomplete sub-corpora, but we are also able to
compare across di�erent corpora.

ACM Reference Format:
Fabio Zampieri, Kevin Roitero, J. Shane Culpepper, Oren Kurland, and Stefano Mizzaro. 2019. On Topic Di�culty in IR Evaluation: The E�ect of
Systems, Corpora, and System Components. In Proceedings of the 42nd
International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’19). ACM, New York, NY, USA, 4 pages. https:
//doi.org/10.1145/3331184.3331279

1

Oren Kurland

INTRODUCTION

Topic di�culty, de�ned as the average e�ectiveness of a set of systems on a topic [9, 10], is a well-studied problem in the IR literature.
It is loosely related to the problem of Query Performance Prediction (QPP), which aims to estimate the e�ectiveness of a system for
a given query when no relevance judgments are available [2]. In
classical QPP, however, the aim is to predict the performance of a
speci�c system for a speci�c query; in this paper we study topic
di�culty for a set of systems. This is a di�erent problem that can
be justi�ed by the aim of understanding the “general” di�culty
of a topic [7–10]. It also leads naturally to the research issue of
�nding representative sets of systems, i.e., sets for which di�culty
would generalize to other sets. Our overall goal is to understand
the e�ect of three factors (the set of systems, the document corpus,
and the system components) on topic di�culty. To the best of our
knowledge, this problem has only been investigated from a system
e�ectiveness perspective. We achieve this goal by extending factor
analysis methods recently proposed to study the e�ect of system
components on e�ectiveness of systems [4–6]. We address four
research questions:

3 EXPERIMENTS
3.1 Experimental Setting

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for pro�t or commercial advantage and that copies bear this notice and the full citation
on the� rst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speci�c permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR ’19, July 21–25, 2019, Paris, France
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00
https://doi.org/10.1145/3331184.3331279

Datasets. Table 1 summarizes the datasets used for our experiments. We focus on� ve TREC (Text REtrieval Conference) collections. Our datasets are purposefully chosen to include overlapping
sets of topics, systems, and corpora. The set of R04 topics includes
TREC6 topics (301-350), TREC7 topics (351-400), TREC8 topics (401450), half of the Robust03 topics (601-650), and 50 additional topics

909

Short Research Papers 1B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Table 1: Datasets used in our experiments.

aOO systems

Track

Year

Topics

O�cial

Uno�cial

TREC6
TREC7
TREC8
R04
C17

Ad Hoc
Ad Hoc
Ad Hoc
Robust
Common Core

1997
1998
1999
2004
2017

50
50
50
249
50

74
103
129
110
75

158
158
158
158
158

8

Acronym

0.8

C17
TREC6
TREC7
TREC8

C17

50
50
50
50

50
11
17
16

TREC6
50
0
0

TREC7

The Financial Times
Federal Register
Congressional Record
FBI Service
The New York Times

TREC6-8

R04

x
x
x
x

x
x
x

8

τ

0.81

Uandom systems
0.8
0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

τ

0.25

0.50

0.75

0.7

0.0
0.00

0.8

τ

0.25

0.50

0.75

0.6

0.8

τ

0.25

0.50

0.75

0.72

0.0
0.00

0.8

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.25

0.50

2

0.75

0.0
0.00

0.25

0.50

2

0.75

τ

0.84

0.2

0.0
0.00

0.6

aOO systems
0.8

x

τ

τ

0.25

0.50

0.75

0.65

0.2

0.0
0.00

0.25

0.50

2

0.75

0.0
0.00

8

τ

0.51

woUst systems
0.8

τ

0.43

0.25

0.50

2

0.75

Uandom systems
0.8

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

τ

0.25

0.50

0.75

0.38

0.0
0.00

0.8

τ

0.25

0.50

0.75

0.36

0.8

τ

0.25

0.50

0.75

0.4

0.0
0.00

0.8

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.8

τ

0.25

0.50

0.75

0.84

0.0
0.00

0.8

τ

0.25

0.50

0.75

0.76

τ

0.25

0.50

0.75

0.76

0.8

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.8

τ

0.25

0.50

0.75

0.95

0.0
0.00

0.8

τ

0.25

0.50

0.75

0.87

τ

0.25

0.50

0.75

0.92

0.8

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0
0.00

0.0
0.00

0.0
0.00

0.50

0.75

0.25

0.50

0.75

τ

0.0
0.00

0.6

0.25

0.25

0.50

0.75

0.37

0.25

0.50

0.75

0.75

0.2

0.0
0.00

0.8

τ

0.0
0.00

0.6

0.0
0.00

0.46

0.2

0.0
0.00

0.8

τ

0.2

0.0
0.00

0.6

0.0
0.00

2

best systems
0.8
0.6

0.8

8

0.48

0.6

0.0
0.00

that were speci�cally introduced in R04. C17 has 50 topics, which
were also originally included in the R04 set of topics; C17 has a few
topics that overlap with TREC6-8 (see Table 2). Table 3 shows the
document corpora used in each collection: R04 and TREC6-8 share,
apart from C17, the same corpora; C17 is based only on NYT.
For each of the TREC collections we use the o�cially-submitted
runs. We also supplement available runs using several open source
search engines in order to produce system con�gurations that
are directly comparable across collections: Terrier, Atire, and Indri (www.terrier.org, www.atire.org, www.lemurproject.org). The
158 system variants are generated by systematically alternating
and combining the ranker, stemmer, and stopword con�gurations,
but� xing con�gurations to be identical across all test collections.
Henceforth we distinguish between o�cial systems/runs (O) from
TREC, and uno�cial system con�gurations (U) generated by us.
Both O and U systems produce ranked lists of 1000 documents.
Metrics. We use Average Precision (AP) as an e�ectiveness measure.
Given a system si and a topic t j , we denote the corresponding score
which is a real number between 0 and 1 as AP(si , t j ). By averaging
the AP values over each topic, we obtain the Average AP (AAP),
1 Õm AP(s , t ).
a measure of topic di�culty [9, 10]: AAP(t j ) = m
i j
i=1
A high AAP value indicates that the topic is easy, and a low AAP
indicates that the topic is di�cult for a speci�c collection and set of
system runs. We use Kendall’s as the primary correlation coe�cient in this work, as it is well-suited to compute partial correlations
in fully-ranked data [1].

3.2

woUst systems
0.8

C17

2

Corpus name

FT
FR
CR
FBIS
NYT

0.63

Figure 1: Scatterplots of AAP values for C17 (�rst row) and
R04 (second row), computed over di�erent sets of systems
(y-axis: U = Uno�cial; x-axis: O = O�cial).

50

Table 3: Corpora of documents used in the datasets.
Acronym

τ

0.6

0.0
0.00

50
0

best systems
0.8
0.6

0.8

TREC8

0.8

0.6

0.0
0.00

Table 2: The number of common topics between collections.
R04

τ

0.25

0.50

0.75

τ

0.0
0.00

0.25

0.50

0.75

0.94

0.25

0.50

0.75

Figure 2: Scatterplots of AAP values computed over R04 vs.
C17 (�rst two rows), and R04 vs. TREC6 (3rd and 4th rows),
using either the o�cial (O) runs (1st and 3rd row) or the uno�cial (U) ones.
to collections. For each plot, a point is de�ned by the AAP value
computed over the set of o�cial systems (on the x axis) and the
AAP value computed over the set of uno�cial systems (on the y
axis). High correlations are observed in almost every case. Selecting
a particular group of systems does not seem to a�ect the correlation,
even though a signi�cant overall drop can be seen when values
are computed using only the best systems (i.e., the 30 best o�cial
and the 30 best uno�cial). Therefore, for a given corpus, topic
di�culty seems quite stable and does not appear to change much
across di�erent sets of systems, although they heavily di�er in
terms of implementation and components. The correlation values
drop, however, when relying only on the most e�ective systems.

Results

RQ1: System E�ects. We� rst illustrate and discuss how topic
di�culty changes when we select a di�erent set of systems. In
Figure 1, scatter plots of AAP values for R04 and C17 topics are
shown; the other collections, not shown due to space limits, exhibit
similar trends. Columns correspond to subsets of systems, each
containing 30 elements (with the exception of the� rst column,
which represents the set of all systems), while rows correspond

910

Short Research Papers 1B: Recommendation and Evaluation

8

τ

best systems
0.8

τ

0.3

woUst systems
0.8

τ

0.23

Uandom systems
0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0
0.00

0.8

8

0.27

τ

0.25

0.50

0.75

0.39

0.0
0.00

0.8

τ

0.25

0.50

0.75

0.4

0.0
0.00

0.8

τ

0.25

0.50

0.75

0.38

0.0
0.00

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0
0.00

0.25

0.50

0.75

0.0
0.00

0.25

0.50

0.75

0.0
0.00

0.25

0.50

0.75

τ

τ

0.0
0.00

.rRvetz

0.26

0.25

0.50

0.8

R04

all systems
0.8

SIGIR ’19, July 21–25, 2019, Paris, France

0.75

PRrter

τ = 0.76

τ = 0.72
0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0

0.39

0.25

0.50

0.75

Figure 3: Scatterplots of AAP values computed over R04 subcollections: FT vs FR (1st row) and FT vs. FBIS (2nd row).
C17

0.8

RQ2: Corpora E�ects. We now turn to the e�ect of document
corpora on topic di�culty. In Figure 2, we see that the correlation
between AAP values of R04 and C17 is 0.48 for o�cial systems
(1st row, 1st column), and 0.38 for uno�cial ones (2nd row, 1st
column). It is somewhat higher for o�cial systems, although they
di�er across collections whereas the uno�cial con�gurations are
identical. Similar results are observed when selecting a particular
subset of systems (columns 2-4). In contrast, the correlations between R04 and TREC6 are very high: 0.84 when computed over
o�cial systems (3rd row, 1st column), and 0.95 when computed
over uno�cial systems (4th row, 1st column). Also in this case,
selecting a subset of systems does not seem to a�ect correlations.
We obtained the same results for TREC7-8 (not shown here).
As R04 and C17 include di�erent document corpora (see Table 3),
these results suggest that topic di�culty is indeed quite sensitive
to the document corpus. When comparing these results to previous
work [3, 4], we observe two di�erences: only sub-corpora were
used, not di�erent corpora as we do here, and system e�ectiveness
was studied, not topic di�culty as we do here.
Figure 3 provides also evidence to sub-corpora e�ects over R04.
It shows how topic di�culty changes across the sub-corpora of
R04 (shown in Table 3). Here again, the correlation of AAP values
computed over di�erent sub-collections is very low: the highest
correlation is between AAP values computed over FT and FBIS (2nd
row), while other values do not exceed 0.3.
To summarize: (i) we� nd very low correlations when changing
signi�cantly the corpus (R04 vs. C17), thereby generalizing the
�nding about low correlations on di�erent sub-corpora also to the
case of di�erent complete corpora; (ii) in one case (R04 vs. C17),
we� nd the strange result that computing AAP using the same
uno�cial system set leads to lower correlation than when using
the o�cial—and di�erent—system set; but this is not con�rmed on
other datasets;� nally (iii) if the changes to the corpus are small
(R04 vs. TREC6) then correlations are high.
RQ3: System Component E�ects. We now turn to our third research question, which focuses on the impact of system components
on topic di�culty; in particular, we consider stemming and query
expansion. Since these are quite dramatic changes to the systems,
we expect quite signi�cant changes to AAP values, and probably
low correlations. Figure 4 shows, for each topic in the R04 and
C17 collections, the di�erence of AAP values computed over the
baselines (i.e., systems without stemmer and query expansion) and

τ = 0.76

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0

τ = 0.74

Figure 4: Di�erences between AAP values computed over
baselines (i.e., systems without stemmer and query expansion) and those computed over systems using stemmers.
R04
τ = 0.78
0.8

0.6

C17
0.8

τ = 0.77

0.6

0.4

0.4

0.2

0.2

0.0

0.0

Figure 5: Di�erences in AAP computed over baselines and
over systems using query expansion.
when using two common stemmers (Krovetz and Porter). Due to
space limitations, we do not show the results for the all stemmer
and collection combinations. For many of the topics, stemming
leads to little or no signi�cant improvement in terms of AAP. In a
few cases, however, there are signi�cant increases and decreases in
AAP, which occur for the same topics across di�erent stemmers.
The highest di�erences in AAP was observed for the R04 topics
(see the 1st row), which appear to be quite sensitive to the stemmer
used.
Figure 5 shows the AAP di�erences between the baselines and
systems using query expansion for R04 and C17. For R04 (1st column), we see frequent increases in AAP and infrequent decreases.
However, for C17 (2nd column) decreases in AAP are negligible
(the same is also true for TREC6-8, not shown).
The results show that system components can have variable
e�ects on topic di�culty. In particular, we see that, for a� xed subset
of topics in a given collection, topic di�culty can considerably
change if we add a stemming or query expansion to the set of

911

Short Research Papers 1B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Table 4: ANOVA table for the model described by Eq. 1.
Factor

SS

DF

F

p-value

corpus
system
topic
corpus:topic
corpus:system

1.5537
48.4639
3045.68
1120.13
6.4594

2
168
248
496
336

140.299
52.0968
2217.86
407.84
3.4718

<
<
<
<
<

1e-6
1e-6
1e-6
1e-6
1e-6

Table 5: ANOVA table for the model described by Eq. 2.

2

0.0003
0.0103
0.6603
0.2423
0.0009

systems. However, the correlations, shown in Figures 4 and 5, are
quite high: somehow unexpectedly, relative topic di�culty remains
quite stable despite the changes to the systems (stemming or query
expansion) are quite signi�cant.
RQ4: Comparing relative e�ects with ANOVA. In an attempt
to provide a more principled and, at the same time, concise analysis,
we investigate the e�ects of systems, corpora, and system components using ANOVA as part of our� nal research question. In
particular, we de�ne two ANOVA models (see Equations (1) and
(2)), which are described below. Tables 4 and 5 show the outcome
of each ANOVA test. For each factor, we report the Sum of Squares
(SS), the Degrees of Freedom (DF), the F statistics, the p-value, and
the e�ect-size ( 2 ) which quanti�es the proportional variance of
each factor [4–6]. The� rst model decomposes the e�ectiveness
(measured by AP) into system, topic, and corpus e�ects:
AP(i, j) = µ + si + t j + c z + c z si + c z t j + i j

SS

DF

F

p-value

corpus
topic
system
ir_model
qe
stemmer
corpus:system
corpus:qe

15.7907
2528.42
52.6792
2.8554
2.0049
0.3708
5.9907
0.2012

2
248
168
22
1
6
336
2

1133.24
1463.35
45.007
18.6294
287.777
8.8723
2.5591
14.4394

<
<
<
<
<
<
<
<

1e-6
1e-6
1e-6
1e-6
1e-6
1e-6
1e-6
1e-6

2

0.0050
0.8157
0.0166
0.0008
0.0006
0.0001
0.0011
6.045e-05

We� nd that topic di�culty is a�ected by the document corpora
of collections: there is a signi�cant corpus-e�ect on topic di�culty
in all of the collections tested. Also, there is a signi�cant systeme�ect, although not so large. Finally, we see a smaller e�ect of
system components on topic di�culty, with the exception of a
few limited cases. Although the standard ANOVA analysis shows a
strong variance across topics and system e�ects that are higher than
the corpus e�ects, we alsof� nd that topic di�culty is reasonably
stable across system sets and system components, thus con�rming
that it is a reasonable and measurable concept. We found only
two exceptions with low correlations: the comparison across the
di�erent corpora of R04 and C17 and the comparison across R04 subcorpora (Figures 2 and 3). Although the latter might be due to the
incomplete nature of sub-corpora, the former con�rms that topic
di�culty is mostly a�ected by the underlying document collection.
In the future we plan to extend the analysis to more collections,
to� ne-tune the parameters of the uno�cial systems to each dataset,
and to study more system and topic components.
Acknowledgements. This work was partially supported by the
Israel Science Foundation (grant no. 1136/17), the Australian Research Council’s Discovery Projects Scheme (DP170102231), a Google
Faculty Award, and an Amazon Research Award.

(1)

where terms identify AP(i, j) of i-th system and j-th topic, grand
mean (µ), z-th corpus (c z ), corpus-system (c z si ) and corpus-topic
(c z t j ) interactions, and model error ( i j ). Table 4 shows the results
of the ANOVA analysis for Eq. (1). All e�ects are statistically signi�cant. Systems have a small e�ect (0.0103), while topics have the
greatest e�ect (0.6603). The interaction e�ect between corpus and
topic is also large but, perhaps surprisingly, both the relative e�ect
of the corpus, and the interaction between corpus and system is
negligible. The second model focuses on system components:

REFERENCES

AP(i, j) = µ + si + t j + moq + stk + qe + c z + c z si + c z t j + i j (2)

[1] David Banks, Paul Over, and Nien-Fan Zhang. 1999. Blind men and elephants:
Six approaches to TREC data. Information Retrieval 1, 1 (1999), 7–34.
[2] David Carmel and Elad Yom-Tov. 2010. Estimating the query di�culty for information retrieval. Synthesis Lectures on Information Concepts, Retrieval, and
Services 2, 1 (2010), 1–89.
[3] Nicola Ferro, Yubin Kim, and Mark Sanderson. 2019. Using Collection Shards to
Study Retrieval Performance E�ect Sizes. ACM TOIS 5, 44 (2019), 59.
[4] Nicola Ferro and Mark Sanderson. 2017. Sub-corpora impact on system e�ectiveness. In Proceedings of the 40th ACM SIGIR. ACM, 901–904.
[5] Nicola Ferro and Gianmaria Silvello. 2016. A general linear mixed models approach to study system component e�ects. In 39th ACM SIGIR. 25–34.
[6] Nicola Ferro and Gianmaria Silvello. 2018. Toward an anatomy of IR system
component performances. JASIST 69, 2 (2018), 187–200.
[7] Donna Harman and Chris Buckley. 2009. Overview of the reliable information
access workshop. Information Retrieval 12, 6 (2009), 615–641.
[8] Stefano Mizzaro, Josiane Mothe, Kevin Roitero, and Md Zia Ullah. 2018. Query Performance Prediction and E�ectiveness Evaluation Without Relevance Judgments:
Two Sides of the Same Coin. In The 41st ACM SIGIR (SIGIR ’18). 1233–1236.
[9] Stefano Mizzaro and Stephen Robertson. 2007. Hits Hits TREC: Exploring IR
Evaluation Results with Network Analysis. In Proceedings 30th SIGIR. 479–486.
[10] Kevin Roitero, Eddy Maddalena, and Stefano Mizzaro. [n. d.]. Do Easy Topics
Predict E�ectiveness Better Than Di�cult Topics?. In ECIR2017. 605–611.
[11] Mark Sanderson, Andrew Turpin, Ying Zhang, and Falk Scholer. 2012. Di�erences
in e�ectiveness across sub-collections. In Proc. of the 21st ACM CIKM. 1965–1969.

where terms identify IR model (moq ), stemmer (stk ), query expansion (qe ), corpus-system (c z si ) and corpus-topic (c z t j ) interactions.
The results of the ANOVA test for Eq. (2) are shown in Table 5. All
e�ects are statistically signi�cant, and the topic e�ect is the largest
(0.8157); the system e�ect is signi�cant but small. Again, somewhat surprisingly, the corpus interactions have a negligible e�ect
on AP scores. All other e�ects are not signi�cant. In summary,
the ANOVA analyses show that AP scores are a�ected mostly by
topics and systems, with the greatest e�ects being attributable to
the topic e�ect; furthermore, system components, corpus, and the
interaction between corpus and systems have very little e�ect on
AP. Nevertheless, the impact of topics on AP clearly varies based
on the corpus.

4

Factor

CONCLUSIONS AND FUTURE WORK

This is the� rst study that speci�cally addresses topic di�culty in
a systematic way: we use di�erent corpora, not just sub-corpora;
we run the same set of systems across di�erent datasets; and we
rely on datasets featuring common topics. To do so, we exploit the
topic overlap between C17 and R04 with previous collections, and
we supplement our analysis using a comprehensive set of uno�cial
but reproducible systems.

912


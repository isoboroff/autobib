Workshop

SIGIR ’19, July 21–25, 2019, Paris, France

EARS 2019: The 2nd International Workshop on ExplainAble
Recommendation and Search
Yongfeng Zhang

Yi Zhang

Department of Computer Science
Rutgers University
yongfeng.zhang@rutgers.edu

School of Engineering
University of California Santa Cruz
yiz@soe.ucsc.edu

Min Zhang

Chirag Shah

Department of Computer Science
Tsinghua University
z-m@tsinghua.edu.cn

School of Communication and Information
Rutgers University
chirags@rutgers.edu
models to generate recommendation and search lists, such as userbased and item-based collaborative filtering for recommendation,
which provide recommendations based on similar users or items,
or TF-IDF based retrieval models for search, which provide document ranking lists according to word similarity between different
documents.
However, state-of-the-art recommendation and search models
extensively rely on complex machine learning and latent representation models such as matrix factorization or even deep neural
networks, and they work with various types of information sources
such as ratings, text, images, audio or video signals. The complexity
nature of state-of-the-art models make search and recommendation
systems as blank-boxes for both end users and system designers,
and the lack of explainability weakens the transparency, persuasiveness, and trustworthiness of the system, making explainable
recommendation and search important research issues to the research community.
In a broader sense, researchers in the broader artificial intelligence community have also realized the importance of Explainable
AI, which aims to address a wide range of AI explainability problems in deep learning, computer vision, automatic driving systems,
and natural language processing tasks. Very recently, a series of AI
regulations have entered into force, such as the EU General Data
Protection Regulation (GDPR) and The California Consumer Privacy Act of 2018, which emphasize the “principle of transparency”
of intelligent algorithms, and imply the “right to explanation” of
algorithmic decisions in AI systems. As an important branch of AI
research, this further highlights the importance and urgency for
our research community to discuss and address the explainability
issues of various recommendation and search systems.
The first edition of the workshop was successfully hosted with
SIGIR 2018 in Ann Arbor, Michigan. In the second edition, we hope
the workshop will not only present state-of-the-art research on
Explainable IR, but also generate insightful debates about the recent
regulations regarding AI interpretability, to a broader community
including but not limited to IR, machine learning, AI, Data Science,
and beyond.

ABSTRACT
Explainable recommendation and search attempt to develop models
or methods that not only generate high-quality recommendation or
search results, but also interpretability of the models or explanations
of the results for users or system designers, which can help to
improve the system transparency, persuasiveness, trustworthiness,
and effectiveness, etc. This is even more important in personalized
search and recommendation scenarios, where users would like to
know why a particular product, web page, news report, or friend
suggestion exists in his or her own search and recommendation
lists. The workshop focuses on the research and application of
explainable recommendation, search, and a broader scope of IR
tasks. It will gather researchers as well as practitioners in the field
for discussions, idea communications, and research promotions. It
will also generate insightful debates about the recent regulations
regarding AI interpretability, to a broader community including but
not limited to IR, machine learning, AI, Data Science, and beyond.

1

MOTIVATION AND APPROPRIATENESS

Explainable recommendation and search attempt to develop models
or methods that not only generate high-quality recommendation or
search results, but also intuitive explanations of the results, which
can help users to better understand the results, or help system
designers to better understand how the system or model works.
It can eventually help to improve the system transparency, persuasiveness, trustworthiness, and effectiveness. Explainability is
even more important in personalized search or recommendation
scenarios, where users would like to know why a particular web
page, product, news report, or friend suggestion exists in his or her
own search or recommendation lists.
The motivation of the workshop is to promote the research and
application of Explainable Recommendation and Search, under the
background of Explainable AI in a broader sense. Early recommendation and search systems adopted intuitive yet easily explainable
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGIR ’19, July 21–25, 2019, Paris, France
© 2019 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6172-9/19/07.
https://doi.org/10.1145/3331184.3331649

2

THEME AND PURPOSE

The purpose of the workshop is to gather researchers and practitioners of the IR community to communicate the latest ideas
and research achievements on explainable recommendation and

1438

Workshop

SIGIR ’19, July 21–25, 2019, Paris, France

search, discuss about the advantages and disadvantages of existing
approaches, and share the ideas of future directions of recommendation and search in the explanation perspective. Based on this
workshop, we would not only like to present the latest research
achievements, but also connect researchers in the community that
are interested in the explainable recommendation and search topic
to promote this direction in the following years.
The main themes and topics of the workshop include but are not
limited to:

In this talk we describe our efforts in building a broad product
graph, a graph that starts shallow with core entities and relationships, and allows easily adding verticals and relationships in a
pay-as-you-go fashion. We describe our efforts on knowledge extraction, linkage, and cleaning to significantly improve the coverage
and quality of product knowledge. We also present our progress
towards our moon-shot goals including harvesting knowledge from
the web, hands-off-the-wheel knowledge integration and cleaning,
human-in-the-loop knowledge learning, and graph mining and
graph-enhanced search.
Bio: Dr. Xin Luna Dong is a Principal Scientist at Amazon, leading
the efforts of constructing Amazon Product Knowledge Graph. She
was one of the major contributors to the Google Knowledge Vault
project, and has led the Knowledge-based Trust project, which is
called the “Google Truth Machine” by Washington’s Post. She has
co-authored book “Big Data Integration”, was awarded ACM Distinguished Member, VLDB Early Career Research Contribution Award
for “advancing the state of the art of knowledge fusion”, and Best
Demo award in Sigmod 2005. She serves in VLDB endowment and
PVLDB advisory committee, and is a PC co-chair for VLDB 2021,
ICDE Industry 2019, VLDB Tutorial 2019, Sigmod 2018 and WAIM
2015.

• New Models for Explainable Information Retrieval
– Explainable shallow models
– Explainable neural models
– Explainable sequential modeling
– Explainable optimization theories
– Causal inference for explainable analysis
• Different Information Sources for Explanation
– Text-based modeling and explanation
– Image-based modeling and explanation
– Using knowledge-base for explanation
– Audio-based modeling and explanation
– Video-based modeling and explanation
– Integrating heterogenous information for explanation
• User Behavior Analysis and HCI for Explanation
– Explanation and user satisfaction
– Mouse movement analysis
– Eye tracking and attention modeling
• New Types of Explanations
– Textual sentence explanations
– Visual explanations
– Statistic-based explanations
– Aggregated explanations
– Context-aware explanations
• Evaluation of Explainable Information Retrieval
– Offline evaluation measures and protocols
– Online evaluation measures and protocols
– User study for explanation evaluation
• New Applications
– Explainable product recommendation and search
– Explainable social recommendation and search
– Explainable news recommendation and search
– Explainable POI recommendation and search
– Explainable multimedia recommendation and search

3

4

ACCEPTED CONTRIBUTIONS
• Charles-Emmanuel Dias, Vincent Guigue and Patrick Gallinari. Personalized Attention for Textual Profiling and Recommendation.
• X. Chen, X. Chen and Y. Zhang. Generating Natural Language Explanations for Personalized Recommendation.
• Kyoung-Rok Jang, Sung-Hyon Myaeng, Hee-Cheol Seo and
Joo-Hee Park. Selection and Interpretation of Embedding
Subspace for Query Classification.
• Xianchao Wu. Learning-to-Explain: Recommendation Reason Determination Through Q20 Gaming.
• Massimo Melucci. Can Structural Equation Models Interpret
Search Systems?
• Y. Nakamura, Y. Asano and M. Yoshikawa. DiaQueTT: A
Diachronic and Queryable Topic-Tracking Model.
• Rishabh Jain and Pranava Madhyastha. Model Explanations
under Calibration.
• Diana C. H. Bocanegra and J. Ziegler. Assessing the Helpfulness of Review Content for Explaining Recommendations.
• Abraham Gale and Amelie Marian. Metrics for Explainable
Ranking Functions.
• A. K. Jaiswal, H. Liu and I. Frommholz. Effects of Foraging
in Personalized Content-based Image Recommendation.
• Farhan Khawar and Nevin L. Zhang. Learning Hierarchical
Item Categories from Implicit Feedback Data for Efficient
Recommendations and Browsing.
• Masoud Davari, Ran Yu and Stefan Dietze. Understanding
The Influence of Task Difficulty on User Fixation Behavior.
• Zhizhuang Li, Zhengzhou Zhu and Teng Yang. Exercises
Recommendation Method Based on Machine Learning.
• Zhizhuang Li, Zhengzhou Zhu and Teng Yang. An Exercise
Recommendation Method for K-12 Students Based on the
Syllabus.

KEYNOTE SPEECH

Title: Building a broad knowledge graph for products.
Abstract: Knowledge graphs have been used to support a wide
range of applications and enhance search results for multiple major search engines, such as Google and Bing. At Amazon we are
building a Product Graph, an authoritative knowledge graph for
all products in the world. The thousands of product verticals we
need to model, the vast number of data sources we need to extract
knowledge from, the huge volume of new products we need to
handle every day, and the various applications in Search, Discovery, Personalization, Voice, that we wish to support, all present big
challenges in constructing such a graph.

1439

Workshop

5

SIGIR ’19, July 21–25, 2019, Paris, France

team has continuously achieved multiple top performances during
10 years. She also contributed in INTENT tasks in NTCIR evaluation as task co-organizer from 2011 to 2013. Dr. Zhang served as PC
chair at WSDM 2017, as well as area chairs or senior PC members at
CIKM and AIRS, and PC members at SIGIR, WWW, WSDM, KDD,
ACL, etc. Currently she is also the executive director of Tsinghua
University-Microsoft Research Asia Joint Research Lab on Media
and Search, and the vice director of Tsinghua-Sohu Joint Research
Lab of Search Technology.

ORGANIZERS

Biography of the organizers and their main research experience
related to the proposed workshop topic are as follows.
Yongfeng Zhang is an Assistant Professor in the Department of
Computer Science at Rutgers University (The State University of
New Jersey). His research interest is in Recommendation and Search
Systems, Economic Data Science, and Conversational Systems. In
the previous he was a postdoc advised by Prof. W. Bruce Croft in
the Center for Intelligent Information Retrieval (CIIR) at UMass
Amherst, and did his PhD and BE in Computer Science at Tsinghua
University, with a BS in Economics at Peking Univeristy. He is a
Siebel Scholar of the class 2015, and a Baidu Scholar of the class
2014. Together with coauthors, he has been consistently working
on explainable recommendation and search models [1–14]. His recent work on explainability of search and recommendation models
include visually explainable recommendation, knowledge graph
embedding for explainable recommendation, natural language generation for explainable recommendation, as well as explainable
product search in e-commerce.

Chirag Shah is an Associate Professor of Information Science
and an affiliate member of Computer Science at Rutgers University. Until recently he was a Visiting Research Scientist at Spotify.
His research interests include studies of interactive information
retrieval/seeking, trying to understand the task a person is doing
and providing proactive recommendations. He also studies social
media and data generated by wearable devices as kinds of signals
that can help us understand and impact human behaviors. He applies them to various problems related to search, personalization,
and recommendation. Recently he has also been exploring ways to
reduce bias and bring fairness in search and in general in Machine
Learning. His work falls under and uniquely connects Computer
Science, Data Science, and Information Science. He received his PhD
in Information Science from University of North Carolina (UNC) at
Chapel Hill. He holds an MTech, Computer Science & Engineering
from Indian Institute of Technology (IIT) Madras, India and an
MS, Computer Science from University of Massachusetts (UMass)
Amherst. He has published and talked extensively on topics related
to social and collaborative information seeking, interactive information retrieval, and social media. He serves as a consultant to the
United Nations Data Analytics on various Data Science projects
involving social and political issues, peacekeeping, climate change,
and energy.

Yi Zhang is a professor in the School of Engineering, University
of California Santa Cruz. Her research interests include large scale
information retrieval, recommendation systems, internet advertising, data mining, natural language processing, and applied machine
learning. She has published chapters, journal articles, and papers
at top conferences in these areas, such ACM SIGIR, WWW, CIKM,
IEEE ICDM, ICML, COLINGS, HLT. She received NSF Faculty Early
Career Award in 2010, an Air Force Research Young Investigator
Award in 2008, the Best Paper Award at ACM SIGIR in 2002, and
several other awards. Her Information Retrieval and Knowledge
Management Lab is doing research sponsored by several government agencies and companies (Microsoft, Yahoo, Google, NEC,
Bosch, Nokia etc.). She has served as a consultant or technical advisor for companies. She regularly serves on the program committees
of the very best conferences in her research areas. She has served as
area chair or senior PC member at ACM SIGIR, EMNLP, and ACM
Recommender Systems. She has served as conference co-chair in
charge of Information Retrieval area at the ACM Conference on Information and Knowledge Management, and tutorial chair for ACM
SIGIR. She is serving as an associate editor for ACM Transaction
on Information Systems. Dr. Zhang received her Ph.D. from School
of Computer Science at Carnegie Mellon University, specializing in
Language and Information Technologies.

REFERENCES
[1] Q. Ai, V. Azizi, X. Chen, and Y. Zhang. 2018. Learning Heterogenous Knowledge
base Embeddings for Explainable Recommendation. Algorithms (2018).
[2] Xu Chen, Zheng Qin, Yongfeng Zhang, and Tao Xu. 2016. Learning to rank
features for recommendation over multiple categories. In SIGIR. ACM, 305–314.
[3] X. Chen, H. Xu, Y. Zhang, J. Tang, Y. Cao, H. Zha, and Z. Qin. 2018. Sequential
Recommendation with User Memory Networks. In WSDM. ACM.
[4] Xu Chen, Yongfeng Zhang, and Zheng Qin. 2019. Dynamic Explainable Recommendation based on Neural Attentive Models. AAAI (2019).
[5] Xu Chen, Yongfeng Zhang, Hongteng Xu, Yixin Cao, Zheng Qin, and Hongyuan
Zha. 2019. Visually Explainable Recommendation. SIGIR (2019).
[6] X. Xian, Z. Fu, S. Muthukrishnan, G. de Melo, and Y. Zhang. 2019. Reinforcement
Knowledge Graph Reasoning for Explainable Recommendation. SIGIR (2019).
[7] Yongfeng Zhang. 2015. Incorporating phrase-level sentiment analysis on textual
reviews for personalized recommendation. In WSDM. ACM, 435–440.
[8] Yongfeng Zhang. 2017. Explainable Recommendation: Theory and Applications.
arXiv preprint arXiv:1708.06409 (2017).
[9] Yongfeng Zhang and Xu Chen. 2018. Explainable Recommendation: A Survey
and New Perspectives. arXiv preprint arXiv:1804.11192 (2018).
[10] Y. Zhang, G. Lai, M. Zhang, et al. 2014. Explicit Factor Models for Explainable
Recommendation based on Phrase-level Sentiment Analysis. SIGIR (2014), 83–92.
[11] Y. Zhang, H. Zhang, et al. 2014. Do Users Rate or Review? Boost Phrase-level
Sentiment Labeling with Review-level Sentiment Classification. SIGIR (2014).
[12] Y. Zhang, M. Zhang, Y. Zhang, G. Lai, Y. Liu, et al. 2015. Daily-aware personalized
recommendation based on feature-level time series analysis. In WWW.
[13] Y. Zhang, Y. Zhang, and M. Zhang. 2018. Report on EARS’18: 1st International
Workshop on ExplainAble Recommendation and Search. SIGIR Forum (2018).
[14] Yongfeng Zhang, Yi Zhang, and Min Zhang. 2018. SIGIR 2018 Workshop on
ExplainAble Recommendation and Search (EARS 2018). SIGIR (2018).

Min Zhang is an associate professor in the Department of Computer Science and Technology (DCST), Tsinghua University. She
received her Bachelor and PhD degrees from DCST at Tsinghua
University in 1999 and 2003, respectively. During the past years,
she has visited DFKI Germany, City University of HongKong, Kyoto
University, and MSRA as visiting researcher. Dr. Zhang specializes
in information retrieval, Web user behavior analysis and machine
learning. She has published more than 100 papers on important
international journals and conferences, such as JASIST, JIR, SIGIR,
WWW, WSDM, CIKM, etc. She has participated in TREC (Text REtrieval Conference) benchmarks as the team leader since 2002. Her

1440


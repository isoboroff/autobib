Short Research Papers 3B: Recommendation and Evaluation

SIGIR ‚Äô19, July 21‚Äì25, 2019, Paris, France

NRPA: Neural Recommendation with Personalized Attention
Hongtao Liu

Fangzhao Wu

Wenjun Wang

College of Intelligence and
Computing, Tianjin University
htliu@tju.edu.cn

Microsoft Research Asia
wufangzhao@gmail.com

College of Intelligence and
Computing, Tianjin University
wjwang@tju.edu.cn

Xianchen Wang

Pengfei Jiao‚àó

Chuhan Wu

College of Intelligence and
Computing, Tianjin University
wangxc@tju.edu.cn

Center for Biosafety Research and
Strategy, Tianjin University
pjiao@tju.edu.cn

Electronic Engineering
Tsinghua University
wuch15@mails.tsinghua.edu.cn

Xing Xie
Microsoft Research Asia
xing.xie@microsoft.com

ABSTRACT

1

Existing review-based recommendation methods usually use the
same model to learn the representations of all users/items from
reviews posted by users towards items. However, different users
have different preference and different items have different characteristics. Thus, the same word or the similar reviews may have
different informativeness for different users and items. In this paper
we propose a neural recommendation approach with personalized
attention to learn personalized representations of users and items
from reviews. We use a review encoder to learn representations of
reviews from words, and a user/item encoder to learn representations of users or items from reviews. We propose a personalized
attention model, and apply it to both review and user/item encoders to select different important words and reviews for different
users/items. Experiments on five datasets validate our approach can
effectively improve the performance of neural recommendation.

Recommender Systems (RS) are an information filtering systems
that can learn user‚Äôs interests and hobbies based on their historical behavior records, and predict users preference or ratings for
items, which are ubiquitous today at e-commerce platforms such
as Amazon and Netflix.
A number of works have been proposed for recommendation
systems. Collaborative Filtering (CF) [3] techniques are one of the
most popular recommender methods, which are extensively used
in industry. Many of CF techniques are based on matrix factorization (MF) that decomposes the user-item rating matrix into two
matrices corresponding to latent features of users and items [6].
However, these methods represent users and items only based on
numeric ratings while the ratings suffer from the natural sparsity.
Using text reviews to model user preference and item features is
one approach to alleviate the above issues [1, 2, 4, 8, 9]. For example, ConvMF [2] integrates convolutional neural network into
probabilistic matrix factorization to exploit both ratings and item description documents. TARMF [4] utilizes attention-based recurrent
neural networks to extract topical information from reviews and
integrates textual features into probabilistic matrix factorization to
enhance the performance of recommendation.
Despite their significant improvement of performance in recommendation, most existing methods learn the representations from
reviews for all users or items using the same model and ignore
the deep personalized feature of users and items. As a concrete
example, suppose that User A cares more about the price of items
than the quality and User B cares more quality than price, both of
them write a similar review such as ‚Äúthis camera with a high price
is easy to use.‚Äù and then User A would give the camera a unsatisfied
rating since the price is high while User B would vote a satisfied
rating. Thus, the same reviews are of different informativeness in
terms of different users or items and it is necessary to be more
personalized when learning representations from reviews for users
or items. As a result, we should exploit the individuality of users
and items for neural recommendation.
To this end, we propose a Neural Recommendation with hierarchical Personalized Attention (NRPA) model to learn personalized
representation for users and items. Specifically, our NRPA contains

CCS CONCEPTS
‚Ä¢ Information systems ‚Üí Recommender systems.

KEYWORDS
Neural recommendation; Personalized attention; Review mining
ACM Reference Format:
Hongtao Liu, Fangzhao Wu, Wenjun Wang, Xianchen Wang, Pengfei Jiao,
Chuhan Wu, and Xing Xie. 2019. NRPA: Neural Recommendation with
Personalized Attention. In 42nd Int‚Äôl ACM SIGIR Conference on Research
& Development in Information Retrieval (SIGIR‚Äô19), July 21‚Äì25, 2019, Paris,
France. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3331184.
3331371
‚àó *Corresponding

Author: Pengfei Jiao, pjiao@tju.edu.cn

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGIR ‚Äô19, July 21‚Äì25, 2019, Paris, France
¬© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00
https://doi.org/10.1145/3331184.3331371

1233

INTRODUCTION

Short Research Papers 3B: Recommendation and Evaluation

SIGIR ‚Äô19, July 21‚Äì25, 2019, Paris, France

ÔøΩ u,i
R

and I indicates the user set and item set, respectively. R ‚àà R |U |√ó |I |
denotes the rating matrix and D ‚àà R |U |√ó |I | means the text review
collection. du,i = {w 1 , ¬∑ ¬∑ ¬∑ , wT } denotes the review written by user
u for item i.

FM

qur

Œ≤1
MLP
User Id

d u ,1

+

ÔøΩùêÆùêÆ
ùê©ùê©

...

Œ≤i

du ,i

Œ≤n

review level
attention

...

du ,n

Œ±1 Œ± 2 Œ± t

MLP

...

w2

d i ,1

word level
attention

Œ≤i

word

w T embedding

User-Net

qri

Œ≤n

...

MLP

d i ,n

d i ,i

Item Id

Œ± 2 Œ±t

...

MLP

...

q iw

Cj = œÉ (Wj ‚àó Mu,i + bj ) , 1 ‚â§ j ‚â§ K ,

w1

...

w2

Item-Net

Personalized Attention Vector over Word Level. We first explore
how to generate the attention vector quw for the user u which can embody the personalization. Since each user or item has the unique id
feature, we first represent all users and items into low-dimensional
vectors via an embedding layer based on their IDs. As shown in
Figure 1, given the id embedding of the user u, we utilize Multilayer
Perceptron (MLP) to generate the personalized attention vector for
user u, denoted as:

two components, i.e., a review encoder to learn representations of
reviews, a user/item encoder to learn representations of user/item
from their reviews. In review encoder, we utilize Convolutional
Neural Network (CNN) to extract semantic features of reviews
from words, and then use personalized word-level attention to
select more important words in a review for each user/item. In
user/item encoder we apply personalized review-level attention to
learn the user/item representation via aggregating all the reviews
representations according to their weights. Moreover, the wordand review-level attention vectors of a user/item are generated by
two multi-layer neural networks with the user/item ID embedding
as input. The two attention vectors can be seen as a indicator for
each user and item under hierarchical views (i.e., word and review
level). At last, we combine the representations of a user and a target
item and feed them into a Factorization Machine [6] layer to predict
the rating that the user would vote the item. We conduct extensive
experiments on five benchmark datasets for recommendation with
reviews. The results validate the effectiveness of our personalized
attention.

quw = ReLU(W1 uid + b1 ) ,

(2)

where W1 is the weight matrix of MLP, b1 is the bias term and uid
is the ID embedding of user u.
User-Specific Attention over Word Level. As mentioned above, not
all words of a review are equally important for the representation of
the review meaning. To highlight the important words, we employ
the attention pooling mechanism in word level, denoted as:
–¥k = quw Azk ,

(3)

exp(–¥k )
Œ± k = √çT
, Œ± k ‚àà (0, 1) ,
j=1 exp(–¥j )

(4)

where A is the harmony matrix in attention, quw is the attention
vector specifically for the user u obtained above, and zk is the
representations of the k-th word above. Œ± i is attention weight of
the i-th word in the review. Similarly, the item i has an unique
attention vector denoted as qiw in Item-Net. Afterwards, we obtain
the representation of the i-th review of user u via aggregating
feature vectors of all words:

PROPOSED METHOD

In this section, we introduce our NRPA approach in detail. Our
approach contains three major components, i.e., a User-Net to learn
user representations, an Item-Net to learn item representations, and
a rating prediction module to predict the rating scores based on user
and item representations. Both User-Net and Item-Net contain two
modules, i.e., a review encoder to learn representations of reviews
from words and a user/item encoder to learn representations of
users and items from reviews. The overview of our NRPA approach
is shown in Figure 1.

2.1

(1)

where ‚àó is the convolution operator, K is the number of filters and
Wj is the weight matrix of the j-th filter. Each column in C (denoted
as zk ‚àà R K ) represents the semantic feature of the k-th word in
the review.

wT

Figure 1: The framework of our NRPA approach.

2

Word Embedding and Convolution. Given a review du,i , we first
embed each word w k in du,i to a dw dimensional vector wk via
word embedding. Then, we transform the review du,i into a matrix
Mu,i = [w1 , w2 , ¬∑ ¬∑ ¬∑ , wT ]. Afterwards, we perform convolution
operator to calculate the feature matrix of the review C ‚àà R K √óT :

CNN

convolution

CNN

w1

Œ≤1

Œ±1

...

quw

ÔøΩùê¢ùê¢
ùê©ùê©

du,i =

T
√ï

Œ± j zj .

(5)

j=1

2.2

User and Item Encoder

After we have obtained all the review representations of users and
items above, we will explore how to aggregate them together to
represent users or items. As stated above, different reviews are
of different importance for representation of user. Besides, the
information of a review varies from different users. Hence, we
introduce a user-specific attention mechanism to focus on the useful
reviews for each user.

Review Encoder

We utilize word embedding to map each word into low-dimensional
vectors and use Convolutional Neural Network (CNN) to extract
the semantic features of text reviews. Then, we introduce a personalized attention into our model to highlight important words. Some
notations used in the following section are defined as follows: U

1234

Short Research Papers 3B: Recommendation and Evaluation

SIGIR ‚Äô19, July 21‚Äì25, 2019, Paris, France

Table 1: Statistics of the five datasets in our experiments.

Personalized Attention Vectors over Review Level. Based on the
user id embedding uid , we utilize another MLP layer to generate
the personalized review-level attention vector for user u:
qur

= ReLU(W2 uid + b2 ) ,

Dataset
Yelp13
Yelp14
Elec.
Games
Foods

(6)

where ReLU is the activation function, W2 is the weight matrix, b2
is the bias term.
User-Specific Attention over Review Level. Given the review set
du = {du,1 , du,2 , ¬∑ ¬∑ ¬∑ , du, N }, we apply attention to highlight those
informative reviews and de-emphasize those meaningless. To be
specific, we compute the weight Œ≤ j of the j-th review of the i-th
user as follows:
e j = qur A2 du,j ,
(7)
exp(e j )
Œ≤ j = √çN
, Œ≤ j ‚àà (0, 1) ,
(8)
exp(ek )
k =1

N
√ï

Œ≤ j du,j .

PMF
CTR
ConvMF+
DeepCoNN
NARRE
TARMF
NRPA

j=1

3.2

Rating Prediction

oÃÇ = pÃÉu ‚äï pÃÉi ,
| oÃÇ |
√ï

wÃÇ i oÃÇi +

i=1

density
2.965
1.144
0.014
0.089
0.118

Yelp13
0.985
0.975
0.917
0.880
0.879
0.875
0.872

Yelp14
1.053
1.013
0.954
0.910
0.906
0.909
0.897

Elec.
1.411
1.284
1.241
1.232
1.215
1.147
1.047

Games
1.297
1.147
1.092
1.130
1.112
1.043
1.014

Foods
1.251
1.139
1.084
0.985
0.986
1.019
0.953

Performance Evaluation

We evaluate our method NRPA with the following baseline methods:

In this section we predict the ratings based on pÃÉu and pÃÉi . First,
we concatenate pÃÉu and pÃÉi and feed into a Factorization Machine
(FM) [6] to predict rating:

RÃÇu,i = wÃÇ 0 +

#ratings
78,966
231,163
1,689,188
231,780
151,254

works [1, 10], we utilize Mean Squared Error (MSE) as the evaluation metric.

(9)

Similarly, we can get the feature of item i, denoted as pÃÉi .

2.3

#items
1,633
4,194
63,001
10,672
8,713

Table 2: Comparisons between NRPA and baselines.

where A2 is the matrix in attention; qur is the query vector for
the user u and each users have a unique attention vector to find
informative reviews. Afterwards, we obtain the text feature pÃÉu of
user u via aggregating all the reviews according to their weights:
pÃÉu =

#users
1,631
4,818
192,403
24,303
14,681

| oÃÇ | √ï
| oÃÇ |
√ï

‚Ä¢ PMF [5] models the latent factors for users and items by
introducing Gaussian distribution.
‚Ä¢ CTR [7] learns interpretable latent structure from usergenerated content to integrate probabilistic modeling into
collaborative filtering.
‚Ä¢ ConvMF+ [2] incorporates convolutional neural network
into Matrix Factorization to learn item features from item
review documents.
‚Ä¢ DeepCoNN [10] models users and items via combining all
their associated reviews by convolutional neural network.
‚Ä¢ NARRE [1] is a newly proposed method that introduces
neural attention mechanism to build the recommendation
model and select highly-useful reviews simultaneously.
‚Ä¢ TARMF [4] is a recommendation model which utilizes attentionbased recurrent neural networks to extract topical information from review documents.

(10)

vÃÇi , vÃÇj oÃÇi oÃÇ j ,

(11)

i=1 j=i+1

where ‚äï is the concatenation operation; wÃÇ 0 and wÃÇ i are both parameters in FM.

3 EXPERIMENTS
3.1 Datasets and Experimental Settings
Our experiments are conducted on five benchmark datasets. The
first two datasets Yelp 2013 (denoted as Yelp13) and Yelp 2014 (denoted as Yelp14) are selected from Yelp Dataset Challenge1 . The
other three datasets Electronics, Video Games and Gourmet Foods
are selected from Amazon dataset2 , and we denote them as Elec.,
Games and Foods respectively. Note that all datasets contain reviews with ratings (from 1 to 5). The details of the datasets are
shown in Table 1. We randomly split each dataset into training set,
validation set and test set with 80%, 10% and 10% respectively.
In our experiments, we use validation dataset to tune the hyperparameters in our model. The word embedding vectors are 300dimensional. The dimension of ID embedding is set to 32. The
number of filters in CNN and the dimension of attention vectors
is 80. The window size of CNN is set to 3. Following previous

The MSE results of all methods are shown in Table 2. Our model
NRPA outperforms all the baseline methods among all the five
datasets which indicates the robust effectiveness of our personalized attention in modeling users and items. Besides, we can observe
that (1) The methods with reviews perform better than those methods with only ratings (i.e., PMF and CTR). The reason may be that
the reviews with the rich semantic textual information are powerful in capturing the feature of users and items. (2) Though both
NARRE and TARMF utilize the attention mechanism to focus on
more important information, our method NRPA achieves a better
performance than them. We conclude that our model NRPA with hierarchical attention can exploit the deep personalized features (i.e.,
word level and review level) of users and items, which can represent
users and items more precise. This result is consistent with our

1 https://www.yelp.com/dataset/challenge
2 http://jmcauley.ucsd.edu/data/amazon/

1235

Short Research Papers 3B: Recommendation and Evaluation

SIGIR ‚Äô19, July 21‚Äì25, 2019, Paris, France







06(

06(



153$
XVHUDWWHQWLRQ
LWHPDWWHQWLRQ
ZRDWWHQWLRQ




<HOS
<HOS
)RRGV








<HOS

06(

153$
ZRUGOHYHO
UHYLHZOHYHO
ZRDWWHQWLRQ



4



<HOS

<HOS

)RRGV

intuitive motivation that users and items should be characterized
by individuation in recommendation.

Effectiveness of Personalized Attention

In this section we further explore the effectiveness of our personalized attention module. First we evaluate the effect of user attention
and item attention respectively. From the results in Figure 2 (experiments on three datasets for space limitation), we can find that
comparing with the variant without attention (i.e., average weight
for all reviews), both variants with user attention and item attention
can improve the performance of rating prediction in recommendation. This is because different users or items always have their
unique preference or features. And our personalized attention can
effectively capture the personality of users and items, which is
beneficial for learning a precise representation of users and items.
Besides, we explore the effectiveness of word-level attention
and review-level attention. As shown in Figure 3, we can observe
that the variants with only word-level attention and only reviewlevel attention can both perform better than the model without any
attention. This is because word level attention can recognize those
important words for each user or item; review level attention can
help to focus on the more informative reviews during modeling
user preference and item features.

3.4

CONCLUSION

In this paper, we propose a neural recommendation approach with
personalized attentions to learn personalized user and item representations from reviews. The core of our approach is a personalized
attention model whose query vectors are learned from the embeddings of user and item IDs. We apply this attention model to both
review encoder and user/item encoder to select different important
words and reviews for different users and items. In this way the
different preference of users and different characteristics of items
can be better captured. The experiments on five benchmark datasets
show that our approach can effectively improve the performance
of neural recommendation.

Figure 3: Effectiveness of word- and review-level attentions.

3.3



see that as the dimension increases, the MSE first decrease, then
reaches the best, and decreases afterwards. When dimension is too
smaller, the attention vectors may not learn the diversity of users
and items enough. However if the dimension becomes too large,
the model may suffer from overfitting. The optimal value of the ID
dimension is 32 regardless of different datasets.







Figure 4: The influence of ID embedding dimension.

Figure 2: Effectiveness of user and item attentions.





'LPHQVWLRQRI,'(PEHGGLQJ

<HOS )RRGV

ACKNOWLEDGMENTS
This work was supported by the National Key R&D Program of
China (2018YFC0809800, 2018YFC0831000), the National Natural
Science Foundation of China (91746205, 91746107, 51438009).

REFERENCES
[1] Chong Chen, Min Zhang, Yiqun Liu, and Shaoping Ma. 2018. Neural attentional
rating regression with review-level explanations. In WWW. 1583‚Äì1592.
[2] Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, and Hwanjo Yu.
2016. Convolutional matrix factorization for document context-aware recommendation. In RecSys. 233‚Äì240.
[3] Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon.com recommendations:
Item-to-item collaborative filtering. Internet Computing (2003), 76‚Äì80.
[4] Yichao Lu, Ruihai Dong, and Barry Smyth. 2018. Coevolutionary Recommendation Model: Mutual Learning between Ratings and Reviews. In WWW. 773‚Äì782.
[5] Andriy Mnih and Ruslan R Salakhutdinov. 2008. Probabilistic matrix factorization.
In NIPS. 1257‚Äì1264.
[6] Steffen Rendle. 2010. Factorization machines. In ICDM. 995‚Äì1000.
[7] Chong Wang and David M Blei. 2011. Collaborative topic modeling for recommending scientific articles. In KDD. 448‚Äì456.
[8] Xianchen Wang, Hongtao Liu, Peiyi Wang, Fangzhao Wu, Hongyan Xu, Wenjun
Wang, and Xing Xie. 2019. Neural Review Rating Prediction with Hierarchical
Attentions and Latent Factors. In DASFAA. 363‚Äì367.
[9] Chuhan Wu, Fangzhao Wu, Junxin Liu, and Yongfeng Huang. 2019. Hierarchical
User and Item Representation with Three-Tier Attention for Recommendation.
In NAACL.
[10] Lei Zheng, Vahid Noroozi, and Philip S Yu. 2017. Joint deep modeling of users
and items using reviews for recommendation. In WSDM. 425‚Äì434.

Parameter Analysis

Since our personalized attention vectors are generated by the user
and item id embedding, this section explores the effect of varying
dimension of the id embedding. From the result in Figure 4, we can

1236


Doctoral Consortium

SIGIR ’19, July 21–25, 2019, Paris, France

Informing the Design of Conversational IR Systems: Framework
and Result Presentation
Souvick Ghosh

School of Communication and Information (SC&I)
Rutgers University
New Brunswick, NJ
souvick.ghosh@rutgers.edu
in user-system interactions. The first step would be to modify the
existing frameworks to explain the anomalies if any. We are likely
to follow a grounded theory approach to check the validity of the
existing frameworks.
RQ2: How does the mode (text, audio) of result (information)
presentation influence the users’ experiences in a search task? Do the
users prefer any specific modality over others for result presentation
in a conversational search setting? Using an audio-only input channel,
are the system responses and results presented, as perceived by the
user, consistent across all the modalities?
The limitations for audio-only search interfaces can be attributed to the transient and linear nature of speech, which requires
information to be transmitted in smaller chunks (short audios or
limited results) [5] to prevent overloading the users’ short-term
memory. Thus, traditional text-based systems are preferred when
the expected result is complex and in the form of images, graphs,
and videos.
We propose an empirical laboratory-based Wizard of Oz experiment to evaluate the users’ preference of modalities when using
conversational search systems. While the user will play the role
of the seeker, an expert searcher will assume the role of the Wizard. The experiment will be a within-subjects design, in which the
users will perform different search tasks using the three different
systems – a baseline system, and two experimental systems. There
will be a total of four tasks. We aim to collect different types of
data during our study, like the users’ background and demographic
information, the details of the search session, and the pre-test and
post-task questionnaire, the user-intermediary interaction details,
and the exit interview to assess the users’ search experience. Our
observations will inform future designs and help to create a better
understanding of such systems.

ABSTRACT
Conversational systems allow the user to describe his information
problem in natural language, which in turn allows for a better understanding of his knowledge gap (or information need). Additionally,
the system can ask follow-up questions to resolve ambiguities and
provide more fine-tuned answers to satisfy the information needs
of the user. The use of natural language dialogues, over multiple
turns, is the reason why these systems are called “conversational.”
In situations like driving, cooking, or exercising, where traditional
search may be difficult or erroneous, conversational systems allow
hands-free and eyes-free operation, and so, the user can multitask.
Such systems are also better suited for people with a visual or manual impairment or people with limited literacy skills. The following
research questions guide the overall direction and objective of the
research study:
RQ1: Are the existing frameworks in information retrieval sufficient in explaining the searcher-system interaction in a voice-based
environment? What are the modifications required, if any, to explain
such interactions?
Some of the early researches proposed different ways in which
we can incorporate dialogues in an IR system [3, 6]. If conversation
is viewed as information seeking dialogue, it can be modeled based
on different speech or dialogue acts. The Conversation for Action
(CfA) model [6] was later extended to develop the Conversational
Roles (COR) model[4]. Both these models acknowledge that conversation is controlled by the behavior or intention of the participants.
An alternate approach has been adopted by Belkin et al.[1] who
conceptualize IR as interactive information seeking and propose
various information seeking strategies (ISS) and example scripts to
model the pattern of human-computer interaction. In recent work,
the desirable properties of such a system have been highlighted by
Radlinski and Craswell [2]
In our research, we investigate the nature of interactions which
occur between the user and the system and the cognitive capabilities
expected of such systems. We plan on analyzing different publicly
available conversational search data to assess the completeness of
the previously described frameworks. As most of the frameworks
were developed at a time when spoken searches and conversational
systems were not as popular, we expect newer patterns and stages

REFERENCES
[1] Nicholas J Belkin, Colleen Cool, Adelheit Stein, and Ulrich Thiel. 1995. Cases,
scripts, and information-seeking strategies: On the design of interactive information retrieval systems. Expert systems with applications 9, 3 (1995), 379–395.
[2] Filip Radlinski and Nick Craswell. 2017. A theoretical framework for conversational
search. In Proceedings of the 2017 Conference on Conference Human Information
Interaction and Retrieval. ACM, 117–126.
[3] Stefan Sitter and Adelheit Stein. 1992. Modeling the illocutionary aspects of
information-seeking dialogues. Information Processing & Management 28, 2 (1992),
165–180.
[4] Stefan Sitter and Adelheit Stein. 1996. Modeling information-seeking dialogues:
The conversational roles (COR) model. RIS: Review of Information Science (online
journal) 1, 1 (1996), 165–180.
[5] Johanne R Trippas, Damiano Spina, Mark Sanderson, and Lawrence Cavedon.
2015. Results presentation methods for a spoken conversational search system. In
Proceedings of the First International Workshop on Novel Web Search Interfaces and
Systems. ACM, 13–15.
[6] Terry Winograd, Fernando Flores, and Fernando F Flores. 1986. Understanding
computers and cognition: A new foundation for design. Intellect Books.

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGIR ’19, July 21–25, 2019, Paris, France
© 2019 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6172-9/19/07.
https://doi.org/10.1145/3331184.3331422

1454


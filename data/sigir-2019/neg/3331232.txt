Session 5A: Conversation and Dialog

SIGIR ’19, July 21–25, 2019, Paris, France

Triple-to-Text: Converting RDF Triples into High-Quality
Natural Languages via Optimizing an Inverse KL Divergence
Yaoming Zhu1

Juncheng Wan1
1

Zhiming Zhou 1 Liheng Chen1
Xin Jiang2 Yong Yu1

Lin Qiu1 Weinan Zhang1

Shanghai Jiao Tong University 2 Noah’s Ark Lab, Huawei Technologies
{ymzhu,junchengwan,heyohai,lhchen,lqiu,yyu}@apex.sjtu.edu.cn
wnzhang@sjtu.edu.cn,Jiang.Xin@huawei.com

1

ABSTRACT
Knowledge base is one of the main forms to represent information in a structured way. A knowledge base typically consists of
Resource Description Frameworks (RDF) triples which describe the
entities and their relations. Generating natural language description of the knowledge base is an important task in NLP, which
has been formulated as a conditional language generation task
and tackled using the sequence-to-sequence framework. Current
works mostly train the language models by maximum likelihood
estimation, which tends to generate lousy sentences. In this paper,
we argue that such a problem of maximum likelihood estimation
is intrinsic, which is generally irrevocable via changing network
structures. Accordingly, we propose a novel Triple-to-Text (T2T)
framework, which approximately optimizes the inverse KullbackLeibler (KL) divergence between the distributions of the real and
generated sentences. Due to the nature that inverse KL imposes
large penalty on fake-looking samples, the proposed method can
significantly reduce the probability of generating low-quality sentences. Our experiments on three real-world datasets demonstrate
that T2T can generate higher-quality sentences and outperform
baseline models in several evaluation metrics.

INTRODUCTION

Wapakoneta

astronaut

occupation

Neil Armstrong

birthPlace

nationality

location

United States

<Neil Armstrong, occupation, astronaut>
<Neil Armstrong, nationality, United States>
<Neil Armstrong, birthPlace, Wapakoneta>
<Wapakoneta, Location, United States>

RDF
Triples

(a) Knowledge base and its RDF triples.

CCS CONCEPTS

Natural
Sentence

· Computing methodologies → Natural language generation;

KEYWORDS

Neil Armstrong was an American
astronaut born in Wapakoneta, a city in
the United States

(b) Corresponding natural language description.

Natural Language Generation, Sequence to Sequence Generation,
Knowledge Bases

Figure 1: A small knowledge base, (a) its associated RDF
triples and (b) an example of the corresponding natural language description.

ACM Reference Format:
Yaoming Zhu, Juncheng Wan, Zhiming Zhou, Liheng Chen, Lin Qiu, Weinan
Zhang, Xin Jiang, Yong Yu. 2019. Triple-to-Text: Converting RDF Triples
into High-Quality Natural Languages via Optimizing an Inverse KL Divergence.In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’19), July 21–25, 2019,
Paris, France. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/
3331184.3331232

Knowledge bases (KB) are gaining attention for their wide range
of industrial applications, including, question answering (Q&A) systems [20, 58], search engines [16], recommender systems [29] etc.
The Resource Description Frameworks (RDF) is the general framework for representing entities and their relations in a structured
knowledge base. Based on W3C standard [38], each RDF datum is a
triple consisting of three elements, in the form of (subject, predicate,
object). An instance can be found in Figure 1(a), which illustrates a
knowledge base about Neil Armstrong and its corresponding RDF
triples.
Based on the RDF triples, the Q&A systems can answer questions such as "which country does Neil Armstrong come from?"
Although such tuples in RDF allow machines to process knowledge

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGIR ’19, July 21–25, 2019, Paris, France
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00
https://doi.org/10.1145/3331184.3331232

455

Session 5A: Conversation and Dialog

SIGIR ’19, July 21–25, 2019, Paris, France

Table 1: Glossary

efficiently, they are generally hard for humans to understand. Some
human interaction interfaces (e.g., DBpedia1 ) are designed to deliver
knowledge bases in the form of RDF triples in a human-readable
way.
In this paper, given a knowledge base in the form of RDF triples,
our goal is to generate natural language description of the knowledge bases which are grammatically correct, easy to understand,
and capable of delivering the information to humans. Figure 1(b)
lays out the natural language description given the knowlege base
about Neil Armstrong.
Traditionally, the Triple-to-Text task relies on rules and templates [11, 13, 51], which requires a large number of human efforts.
Moreover, even if these systems are developed, they are often faced
with problems of low scalability and inability to handle complex
logic.
Recently, with significant progress on deep learning, the neural
network (NN) based natural language generation models, especially the sequence to sequence framework (SEQ2SEQ) [48], have
achieved remarkable success in machine translation[3] and text
summarization[42]. The SEQ2SEQ framework has also been employed to translate knowledge bases into natural languages. Vougiouklis et al. [54] proposed Neural Wikipedian to generate summaries of the RDF triples.
However, most existing studies focus on the design of the model
structure [54], while paying less attention to the training objective.
These models are usually trained via maximum likelihood estimation, which is equivalent to minimizing Kullback-Leibler (KL)
divergence between the ground-truth conditional distribution (P)
and the estimated distribution (G), i.e., KL(P ∥G). Models trained
with KL divergence tend to have high diversity, but at the same
time, they are likely to generate shoddy samples [30].
In such tasks, we usually care more about the quality of the
translation and care less about diversity. Hence, we propose the
triple-to-text model. By introducing a new component called judger,
we optimize the model in two directions: minimizing the approximated inverse KL divergence and maximizing the self-entropy.
Our main contributions can be summarized as follows:
· We propose a theoretically sound and empirically effective
framework (T2T) for optimizing the inverse KL divergence
for conditional language generation task of translating a
knowledge base into its natural language description.
· We conduct a series of experiments on different datasets to
validate our proposed method. The results show that our
method outperforms baselines in common metrics.
We organize the remaining parts of this paper as follows. In
Section 2, we formulate the problem and introduce the preliminaries. In Section 3, we provide our analysis of why it is preferable
to optimize an inverse KL divergence. Then Section 4 details our
proposed model. We then present the experiment results in Section
5. Finally, we discuss the related work in Section 6 and conclude
the paper in Section 7.

2

Symbol
F
t
⟨si , pi , oi ⟩
S
w
X
Y
xi
yi
y <i
P
Gθ
Mϕ
θ
ϕ

2.1

Description
a knowledge base that consists of RDF triples
a resource description framework (RDF) triple
subject, predicate and object within a RDF triple
a sentence
a word in a sentence
conditional context for SEQ2SEQ framework
target context for generative models
i-th token from conditional context
i-th token from target context
prefix of target context: {y1 , y2 , · · · , yi−1 }
the target (ground-truth) distribution
learned distribution of generator
learned distribution of judger
parameters of generator
parameters of judger

Task Definition

A knowledge base F is formulated as a set of RDF triples, i.e.,
F = {t 1 , t 2 , · · · , t N }, where each RDF triple ti is represented as
⟨si , pi , oi ⟩. The three elements in a triple denote subject, predicate
and object, respectively. Given the knowledge base F , our goal
is to generate a natural language sentence S which consists of a
sequence of words [w 1 , w 2 , · · · , w M ], where wm denotes the m-th
word in the sentence S. The generated sequence S is required to be
grammatically sound and correctly represent all the information
contained in the knowledge base F .

2.2

Sequence to Sequence Framework

Our work is based on the sequence to sequence framework (SEQ2SEQ).
The standard sequence to sequence framework consists of an encoder and a decoder. Both of them are parameterized by recurrent
neural networks (RNN).
The encoder takes in a sequence of discrete tokens X = [x 1 , x 2 , · · · , x L ].
At t-th step, the encoder takes in a token and updates the hidden
state recurrently:
htenc = f enc (htenc
−1 , ex t ),

(1)

where ex t denotes the word embedding [41] of the t-th token. In
general, ex t = We x t , where We is a pre-trained or learned word embedding matrix with each column representing a embedding vector
of a token; given x t is a one-hot vector, We x t get the corresponding
column of We for token x t . f enc is a nonlinear function. Long shortterm memory (LSTM) [28] and gated recurrent unit (GRU) [10] are
often considered as the paradigm of the function. The final output of
enc
enc
encoder is an array of hidden states Henc = [henc
1 , h2 , · · · , hL ].
Each hidden state can be regarded as a vector representation of all
the previous tokens.
The decoder takes in the hidden states Henc of the encoder as
input and outputs a sequence of hidden states Hdec . The hidden
state at its t-th step is computed by:

FORMULATION AND PRELIMINARIES

In this section, we formulate the task and introduce the preliminaries of language generation models.

htdec = f dec (htdec
−1 , eyt −1 , ct ),

1 https://wiki.dbpedia.org/

456

(2)

Session 5A: Conversation and Dialog

SIGIR ’19, July 21–25, 2019, Paris, France

(a) P

(b) KL(P ∥G)

(c) KL(G ∥P )

Figure 2: (a) shows the target distribution P, and the histogram in the background represents frequency of different samples;
(b), (c) illustrate the empirical results of G by minimizing KL(P ∥G) and KL(G ∥P) respectively.

3

where eyt −1 is the word embedding of the last output token of the
decoder, and ey0 is set to be a zero vector. ct is a function of hidden
states of encoder that provides the summary of the input sequence
at step t, and typical choices include: i) ct = henc
L ; ii) the attention
enc
enc
enc
mechanism [3] with ct = д(h1 , h2 , · · · , hL , htdec
−1 ).
In general, generation of language is modeled as an autoregressive sequential generation process with each token sampled from
the probability distribution conditioning on its previous tokens.
The probability distribution of t-th token is parameterized by a
softmax over an affine transformation of the decoder’s hidden state
at step t, i.e.
Pr(yt |x 1 , x 2 , · · · , x L , y <t ) = softmax(W htdec + b),

In this section, we will give a detailed discussion on the fundamental
problems of minimizing KL divergence in training and explain why
we choose the inverse KL divergence as our optimization objective.
We will also discuss several related solutions.

3.1

(3)

Y

Since the KL divergence is non-negative, it is minimized when
G θ = P. Unfortunately, in real-world scenarios, the target P is
usually a very complex distribution. Given limited capacity, the
learned probabilistic model G θ may only be a rough approximation.
As pointed out in [1], KL(P ∥G θ ) goes to infinity if P(Y ) > 0 and
G θ (Y ) → 0, which means that the cost function is extremely high
when the distribution of generator fails to cover some patterns of
the real data. On the other hand, the cost function is relatively low
when the generator is low-quality samples, as KL(P ∥G θ ) goes to
zero if G θ (Y ) > 0 and P(Y ) → 0.
That is, although the optimal is guaranteed to be G θ = P under
MLE objective, during training, the estimated distribution G θ (y) is
more likely to have a wide coverage and possibly contain samples
out of the real distribution, as illustrated in Figure 2(b). In practice, models trained via MLE have a high probability of generating
rarely-seen sequences, most of which are inconsistent with human
expressions due to exposure bias [7].
With a similar argument to the behavioral tendency of KL(P ∥G θ ),
it can be shown that KL(G θ ∥P) has less penalty to "mode collapse",
which means G tend to generate a family of similar samples. By
contrast, KL(G θ ∥P) assigns a large penalty to fake-looking samples.
The typical non-optimal estimation, as illustrated in Figure 2(c),
is that it covers several major modes of the real distribution, but
misses several minor modes.
We here argue that in the conditional language generation task,
especially such the triple-to-text tasks, minimizing the inverse KL
divergence would be more preferred. Because, in these translation
tasks, people usually care more about the quality of the generated
text, rather than their diversity. In other words, it is tolerable to have

(4)

t =1

2.3

Maximum Likelihood Estimation (MLE)

Training neural language models through maximum likelihood
estimation (MLE) is the most widely used method. The objective is
equivalent to minimizing the cross entropy between the real data
distribution P and the estimated probability distribution G θ by the
generative models:
JG (θ ) = EY ∼P [log G θ (Y )] = −H (P, G θ ),

Practical Tendency of KL and Inverse KL

The KL divergence between two distributions P and G θ is formulated as
Õ
P(Y )
.
(7)
KL(P ∥G θ ) =
P(Y ) log
G θ (Y )

where W and b are the weight matrix and the bias vector of output
layer respectively, and y <t denotes the first t − 1 tokens of target
content. The probability distribution of the entire output sequence
Y conditioning on the input sequence X is thus modeled as
Pr(Y |X ) = Pr(y1 , y2 , · · · , yT |x 1 , x 2 , · · · , x L )
T
Ö
=
Pr(yt |x 1 , x 2 , · · · , x L , y <t ).

OBJECTIVE ANALYSIS

(5)

where Y denotes a complete sequence sampled from the real data
distribution P and H denotes the cross entropy.
Maximizing Eq. 5 is equivalent to minimizing the KullbackLeibler (KL) divergence between target distribution P and learned
distribution G θ , which is defined as

P(Y ) 
KL(P ∥G θ ) = EY ∼P log
= H (P, G θ ) − H (P),
(6)
G θ (Y )
where H (P) is a constant irrelevant to parameter θ .
For clarity, we here ignore the conditional context X here. We
will later regard the maximum likelihood estimation as minimizing
the Kullback-Leibler (KL) divergence.

457

Session 5A: Conversation and Dialog

SIGIR ’19, July 21–25, 2019, Paris, France

3.3

low diversity, but it is usually unacceptable to be grammatically
incorrect or miss important information.
Natural Language
Text Pre-processor
Entity to Types

Zero Padding

JM (ϕ) = E(X,Y )∼P [log Mϕ (Y |X )].

Decoder

...

Attention
Mechanism
Encoder

...

Embedding

...

(9)

Note that, although the judger distribution Mϕ might suffer from
the problems as mentioned earlier of MLE, i.e., it does not precisely
model all the modes, it generally widely covers the distribution with
the major modes having large probability masses. Then, based on
this inaccurate estimated distribution Mϕ , we minimize the inverse
KL divergence KL(G θ ∥Mϕ ). As we discussed before, the inverse
KL divergence cares more about the major modes and tends to
ignore these minor modes, including small fake modes stemming
from imperfect MLE estimation, so the shortcoming of MLE-based
estimated distribution Mϕ poses no serious problems here.
It is also important to notice that, if the two steps in our algorithm
both get the optimum, we have G θ = P, which is the same as
previous methods. The key benefit of our algorithm is that when it
does not get the optimum, the generated samples still tend to be
feasible.

...

Embedding

Estimation of the Real Distribution P

In most real applications, P is an empirical distribution and not
directly accessible. For this reason we could not directly optimize
the inverse KL divergence. In our proposed method, we introduce a
new module Mϕ , called judger, to approximate target distribution
P. The judger is trained via maximum likelihood estimation and
the objective function for Mϕ is

RDF Pre-processor
Entity to Types

3.4

Tokenizer & Shuffle

Some previous works also recognized the limitations of KL divergence and alleviated this problem with various optimization methods. Generative Adversarial Networks (GAN) [24] introduced a
module named discriminator to distinguish whether a sample is
from the real distribution or is forged by G θ . In theory, given a
perfect discriminator, the training objective of GAN is equivalent
to minimize Jensen-Shannon Divergence, which is defined as the
symmetrized version of two aforementioned divergences:

1
JSD(P ∥G θ ) = KL(P ∥M) + KL(G θ ∥M) ,
(10)
2
1
where M = 2 (P + G θ ) is the average of two distributions.
GAN is initially designed for generating continuous data, which
is not directly applicable to discrete tokens, such as language sentences. SeqGAN [56] is introduced to generate discrete tokens via
adversarial training. However, the generative models trained by SeqGAN tend to have high variance due to the REINFORCE algorithm
[55].
Another attempt to leverage Jensen-Shannon divergence on sequence generation tasks is CoT [37]. CoT introduces a new module,
the mediator Mϕ , which estimates the mixture data distribution
1 (P + G ) via maximum likelihood estimation. Then M is used
θ
ϕ
2
to guide the training of the generator G θ with JSD. However, in
practice, we find that the optimization of Mϕ could be problematic.
According to our experiments, as the real distribution becomes
complicated, Mϕ tends to get a distribution to fit G θ rather than
accurately modeling the 12 (P + G θ ). We explain this phenomenon
as follows.
The real distribution P is relatively complex, and the estimated
distribution G θ tends to be simple and smooth. Because of the wide
coverage tendency of MLE, Mϕ would cover 12 (P + G θ ) in general;

Knowlegde Bases

Figure 3: General framework. Sentences and RDF triples are
pre-processed into discrete tokens. Then after embedding,
they are fed into an encoder-decoder neural network with
attention mechanism.

3.2

The Decomposed Objective of Inverse KL

Here, we explain the property of inverse KL divergence via objective decomposition. We will show that minimizing the inverse KL
divergence KL(G θ ∥P) can be regarded as a direct optimization of
the performance of the Turing test.
In Turing test , we assume that the human judges know the
accurate natural language distribution P.[39] Given a language
sample X , its quality is scored by P(X ). Thus the averaged score
in a Turing test can be modeled as the negative cross-entropy
−H (G θ , P) = EY ∼G θ [log P(Y )].
The inverse KL divergence can be rewritten as
KL(G θ ∥P) = H (G θ , P) − H (G θ ).

JS Divergence: GANs and CoT

(8)

Eq. 8 illustrates that the objective of minimizing an inverse KL
divergence can be be decomposed into two parts:
· Minimizing H (G θ , P), which corresponds to the objective of
Turing test.
· Maximizing H (G θ ), the self-entropy of the generator. It helps
expand the support of G θ , to avoid disjoint support between
P and G θ , which may lead to gradient vanish problem [1].

458

Session 5A: Conversation and Dialog

Real Distribution and Samples

SIGIR ’19, July 21–25, 2019, Paris, France

Distribution of Judger

Distribution of Generator

Figure 4: The overall training process of our proposed algorithm.
while due to limited capacity of Mϕ , Mϕ tends to fit the simple one,
i.e., G θ .
The problem that Mϕ captures limited differences between P
and G θ makes the training hard to converge.
Note that one key difference is that the target mediator distribution in CoT is dynamical and involves with the learning distribution
G θ , while the judger in our method is estimating the static distribution P.

4

objects in the RDF triples and their corresponding entities in the
sentences into their types.
For example, given a knowledge base [("Bill Gates", "founder",
"Microsoft Corporation") , ("Microsoft Corporation", "startDate",
"April 4, 1975" )] and its corresponding human-annotated natural
sentence "Bill Gates founded the Microsoft Corporation in April
4, 1975". The pre-process module will map "Bill Gates," "Microsoft
Corporation" and "April 4, 1975" into "PERSON," "CORPORATION"
and "DATE" respectively, in both RDFs and the corresponding sentences. The pre-process can reduce the size of the vocabulary list,
and improve the generalization capacity of the model so that it can
handle most dates rather than just "April 4, 1975". Considering that
the nodes in the knowledge bases are unordered, we also apply
permutation among the triples to enhance the training data, and we
believe this approach can improve the generalization capabilities
of the final generation model.
The pre-processed RDF triples are then transformed into a sequence of discrete tokens. We use commas to separate elements
within an RDF triple, and semicolons to separate different RDFs.
For instance, the knowledge base mentioned above is turned into
"PERSON, founder, CORPORATION; CORPORATION, startDate,
DATE". Simultaneously, zero padding is used to fill all sequences
into the same length.
Finally, a SEQ2SEQ method introduced in Section 2.2 is used
to encode the processed triple and then translate it into a humanunderstandable sentence. To enhance the performance of the encoderdecoder model, attention mechanisms [3] are used in our proposed
framework. Figure 3 illustrates the general structure of this method.

METHODOLOGY

In this section, we will first explain how to convert the task into a
sequence-to-sequence generation problem, and then illustrate the
details of how to optimize it with inverse KL divergence.
Algorithm 1: Triple-to-Text algorithm
Input: a corpus of knowledge bases and its corresponding
natural sentences {(F , S)}, hyper-parameters m and д
Output: a generator G θ , a judger Mϕ
1 Pre-process the knowledge bases corpus {(F , S)} into discrete
token sequence pairs {(X , Y )}
2 Initialize G θ and M ϕ with random parameters θ and ϕ
3 Pre-train G θ using Maximum Likelihood Estimation (optional)
4 while G θ not converge do
5
for m steps do
6
Sample from sequence pairs {(X , Y )}
7
Update judger Mϕ via maximizing
E(X,Y )∼P [log Mϕ (Y |X )]
8
end
9
for д steps do
10
Sample conditional context X̂ from pairs {(X , Y )}
11
Generate the estimated target sentence Ŷ given X̂
according to G θ
12
Update generator G θ via minimizing
h
i
G (Ŷ | X̂ )
by Eq. 15
E(X̂, Ŷ )∼G log θ
θ

13
14
15

4.2

The general idea of the proposed method is that: a module Mϕ
called judger is introduced to approximate the target distribution P,
which is trained via maximum likelihood estimation. Based on the
approximated distribution Mϕ , we then minimize the inverse KL
divergence KL(G θ ∥Mϕ ). The overall process is illustrated in Figure
4.
Because we target at the sequence to sequence translation task,
the distribution of generator is modeled as a chain product of probability distribution of the next token yt conditioning on the input
sequence X and prefix y <t ,

M ϕ (Ŷ | X̂ )

end
end
return G θ , Mϕ

4.1

Algorithm Details

General Framework

The SEQ2SEQ framework cannot process graph-based data like
RDF triples directly. Thus we first use a pre-processing technique
similar to the one mentioned in [50]. It substitutes the subjects and

G θ (Y |X ) =

T
Ö
t =1

459

дθ (yt |y <t , X ).

(11)

Session 5A: Conversation and Dialog

SIGIR ’19, July 21–25, 2019, Paris, France

Table 2: Dataset statistics, including the number of RDF triples-sentence pairs used in training and test, the number of RDF
triples per datum, the (maximum) number of tokens per sentence and the vocabulary list size.
Dataset
WebNLG
SemEval
Baidu SKE

#Train
20288
8000
19520

#Test
2240
2717
2000

#RDF Triples
1-7
1
1-5

#sentence length
82
97
84

T
Ö

mϕ (yt |y <t , X ).

(12)

t =1

The objective function for Mϕ is
JM (ϕ) = E(X,Y )∼P [log Mϕ (Y |X )].

(13)

Given Mϕ which estimates the real distribution P, we then update
G θ via minimizing the inverse KL divergence KL(G θ ∥Mϕ ):
h
G (Y |X ) i
,
(14)
JG (θ ) = KL(G θ ∥Mϕ ) =
log θ
E
Mϕ (Y |X )
(X,Y )∼G θ

5.2

(X,Y )∼G θ

T
hÕ
t =1

i
log дθ (yt |X , y <t ) − log mϕ (yt |X , y <t ) .

Implementation Details

The generator consists of a word embedding matrix, an encoder, a
decoder, and the output layer. For the word embedding, we maintain
two different sets of embeddings for encoder and decoder respectively; both are of 64 dimensions. Both encoder and decoder are
built as an LSTM [28] with hidden units of 128 dimensions. The
dimension of hidden units of the output layer is also 128. We apply
Bahdanau attention [3] to the context vector c t , which is computed
as the weighted sum of encoder states. For the judger, we use the
same configuration as the generator.
For the initialization, all initial parameters follow a standard
Gaussian distribution N (0, 1). All models are optimized using Adam
optimization [32] with a learning rate of 0.001 and a batch size of
64. The hyper-parameters of д and m in the algorithm are both set
as 1, which makes the objective of the generator gradually harder
as indicated in Section 4.2. We also pre-train the generator via MLE
with the number pre-train epochs set as 2.

where (X , Y ) ∼ G θ denotes the data pair where X is sampled from
conditional context and Y is the output of generator given X as
input. The objective can be directly optimized by taking Eq. (11)
and (12) into Eq (14), which can be reformulated as
E

#vocabulary in triples
2718
7333
22713

Baidu SKE2 is a large-scale human annotated dataset with more
than 410,000 triples in over 200,000 real-world Chinese sentences,
bounded by a pre-specified schema with 50 types of predicates.
Each sample in SKE contains one sentence and a set of associated
tuples. SKE Tuples are expressed in forms of (subject, predicate,
object, subject type, object type). In our experiments, we only use
knowledge bases related to Film and TV works domain, and each
Chinese character is treated as a distinct token.
We select some data in the three data sets and divide them into
a training set and a test set. Table 2 shows some statistical details
about the data.

Within our framework, the judger is trained to model the target
distribution via maximum likelihood estimation. The judger Mϕ is
also modeled as a chain product of conditional distributions,
Mϕ (Y |X ) =

#vocabulary in sentence
4678
24986
25027

(15)

Algorithm 1 illustrated the overall algorithm of our proposed
method. Note that instead of training the judger to convergence at
the beginning, the judger and the generator are trained alternately.
From the perspective of curriculum learning [8], by gradually increasing the complexity of the generator’s training objective, it
improves the generalization ability of the generator and helps find
a better local optimum. Our method shares the same computational
complexity as MLE training.

5.3

Baseline Algorithms

We validate our proposed method for RDF triple-to-text (we will
later refer to as T2T) by comparing it with the following baselines.
To give a fair comparison, we apply the same RDF pre-processing
technique discussed in Section 4.1 to all the baselines.

5 EXPERIMENTS
5.1 Datasets
Our methods are evaluated on the following datasets.

· MLE. A common method for training sequence to sequence
framework. For a fair comparison, the parameter setting of
the generator is the same with our model.
· CoT. We adapt CoT [37] into conditional sequence generation task. As its authors suggested, the size of the hidden
unit of the mediator is twice the size of the generator.
· Pointer-Generator Network (PG). See et al. [46] proposed
pointer-generator network. Their work can be regarded as a
combination of SEQ2SEQ and pointer network [53].
· SeqGAN. Yu et al. [56] used an adversarial network to provide the reward and train a sequence generator with policy

WebNLG [23] is extracted from 15 different DBPedia [2] categories,
which consists of 25,298 (data, text) pairs and 9,674 distinct data
units. The data units are sets of RDF triples, and the texts are
sequences of one or more sentences verbalizing these data units. It
also provides a set of 373 distinct RDF properties.
SemEval-2010 Task 8 [27] was originally designed for multi-way
classification of semantic relations between pairs of nominals. It
contains 10,717 samples, divided as 8,000 for training and 2,717 for
testing. The dataset contains nine relation types. Since each example
is a sentence annotated for a pair of entities and the corresponding
relation class for this entity pair in this dataset, we can extract an
RDF triple from each sentence.

2 http://ai.baidu.com/broad/introduction

460

Session 5A: Conversation and Dialog

SIGIR ’19, July 21–25, 2019, Paris, France

Table 3: Comparison of model performance.

MLE
CoT
SeqGAN
PG
NW
T2T

BLEU-3 ↑
WebNLG SemEval
40.8
4.24
9.84
1.90
42.0
4.11
41.7
4.21
35.8
2.80
42.4
4.35

SKE
18.6
15.7
19.0
17.9
14.6
20.3

BLEU-4 ↑
WebNLG SemEval
30.2
2.73
6.40
1.41
24.4
2.63
30.9
2.06
24.6
1.87
32.2
2.83

SKE
15.6
12.9
14.1
14.1
11.9
17.1

5.4

CoT
0.258

PG
0.231

SeqGAN
0.244

NW
0.155

SKE
1.01
1.08
1.10
1.12
1.92
0.947

METEOR ↑
WebNLG SemEval
0.636
0.222
0.349
0.102
0.597
0.231
0.628
0.197
0.302
0.143
0.641
0.247

SKE
0.349
0.305
0.344
0.310
0.301
0.367

pi ∈P

where P is the set of all kinds of predicate. The "predicate accuracy"
is defined as precision of p̂ in Eq. 16 being the correct predicate
describing the sentence Y .
We also use forward perplexity (FPPL) to evaluate the quality of
the generated text. Different from the traditional perplexity evaluated only on generative models, FPPL evaluate perplexity of generated samples from generator G θ using another language model
(denoted as Hψ ) trained on real data via MLE. According to Zhao
et al. [31], FPPL measures the fluency of generated sentences.

Table 4: predicate accuracy on SemEval dataset.
MLE
0.240

TER ↓
SemEval
1.07
1.16
1.11
1.13
1.17
0.957

for each predicate class p ′ , where X p ′ denotes the triple ⟨s, p ′, o⟩.
Then, we can use the likelihood of generative model to predict the
predicate given subject s, object o and sentence X p , the predicted
predicate p̂ is
p̂ = arg max G θ (Y |X pi )
(16)

gradient. According to [35] and our initial experiments, in
SEQ2SEQ framework, when the discriminator is parameterized as a convolutional neural network, it is difficult for the
discriminator in SeqGAN to improve the generator. We thus
follow [35] and adapt the discriminator into a hierarchical
recurrent neural network [34].
• Neural Wikipedian (NW). Vougiouklis et al. [54] used a
standard feed-forward neural network to encode RDF triples.
Then the vectors derived from encoders are concatenated and
used as the input of the decoder which generates summaries
for RDF triples.

methods
accuracy

WebNLG
0.497
1.085
0.534
0.607
1.664
0.473

T2T
0.276

FPPL(Gθ ) = e −Ey∼Gθ log Hψ (y)

(17)

In our experiments, Hψ is implemented as an LSTM-based SEQ2SEQ
model, whose word embedding size is set as 64, encoder hidden
unit and decoder hidden unit is all set as 300.

Metrics

For natural language generation tasks, the most widely accepted
metric is human evaluation [6]. While human evaluation is reliable,
it is hardly applied to quality evaluating of large corpus since it will
involve too many human resources. Therefore, we have to introduce automatic metrics for evaluating all the sentences our system
has generated. However, to our knowledge, no single automatic
evaluation metric is sufficient to measure the performance of a
natural language generation system [43]. Thus, in order to give
objective results, we use a variety of automatic metrics to compare
our models and benchmarks.
We have adopted three widely used word-level metrics: BLEU
[45], TER [47] and METEOR [5]. BLEU and METEOR3 to calculate
the number of n-grams of the generated sentence occurs within the
set of references.
Besides the traditional word-based metrics, we also evaluate
the generator via likelihood and perplexity. Inspired by likelihoodbased discrimination[40], we design a new metric which we refer to as "predicate accuracy". In detail, given a single RDF triple
X p = ⟨s, p, o⟩, a natural sentence Y describing the triple and a generative model G θ , we can calculate G θ (Y |X p ), i.e. the predictive
likelihood of the target sentence. If we keep subject s and object o unchanged, and substitute predicate p with another predicate p ′ , then
our generative model can derive a probability density G θ (Y |X p ′ )

Table 5: Forward perplexity among three datasets.
methods
MLE
CoT
SeqGAN
PG
NW
T2T

5.5

WebNLG
1.810
2.423
3.556
2.151
2.461
1.589

SemEval
2.918
2.579
4.129
3.180
2.771
2.067

SKE
7.046
6.643
7.834
8.078
6.916
3.565

Experiments Results

Table 3 shows the overall results of each training method on BLEU,
TER, and METEOR among the three datasets. From the results,
we find that our proposed T2T method improves the quality of
the generated sentence on these word-based metrics. As we have
analyzed, generators optimized via inverse KL divergence tend to
generate text with more common expressions, while other baselines
tend to use some low-quality text. Thus, sentences from T2T will
overlap more words with reference text, which means it can achieve
better performance on the word based metrics like BLEU.
The experiments on FPPL also validated our conclusion. Table
5(b) shows the results of FPPL on WebNLG dataset. Low forward

3 We use METEOR 1.5 (https://www.cs.cmu.edu/ alavie/METEOR/README.html), with

parameters suggested by Denkowski et al. [15] for universal evaluation

461

Session 5A: Conversation and Dialog

methods

●

T2T

SIGIR ’19, July 21–25, 2019, Paris, France

methods

MLE

T2T

●

methods

MLE

●

T2T

MLE

15
5.0

●

2.0
1.5

11

4.0

3.0
2.5

13

4.5

●

● ●●
●●
●
● ● ● ●●
●
●
●●●● ●●
●
●
●
●●● ●● ●● ●
● ●●
● ●● ● ●
●
● ●●●●●●●● ●●● ● ●● ●●●●●● ●●●●● ●● ●●● ● ●●●
● ● ●● ●● ●●● ●●●●●●● ●●●
●
●
●
●

3.5
3.0
2.5
2.0

forward PPL

3.5

forward PPL

forward PPL

4.0 ●

●
●
● ●
● ●
●
● ● ● ●● ●● ●
●
● ●●
● ●
●
●
●
●
●● ● ● ● ● ●
●
●●
● ● ●●● ●
●
●
●
●
●
● ●
●
●
● ●● ● ●● ●●●● ●●●● ●●●●● ● ●●●●●● ● ●●● ●● ● ●●●
●
●●
● ● ●●
● ●
● ●
●
●

●

9
7

●
●
●●● ●
● ●
●

5
3

0

10

20

30

40

50

epochs

60

(a) WebNLG

70

80

90

0

10

20

30

40

50

epochs

60

70

80

90

0

●

● ●●
●
●
●
● ●●
●●●
●
●● ●●●
●
●
●
●●
●●
●
●
● ●
●● ●●
●
●
●
●●
●
● ●
●
●
●● ●●
● ●
●●●● ● ●●●● ●
●
●● ●
●● ● ●●●●● ●
● ●●● ●
● ●●
●
●●●●
●
● ●

10

20

30

(b) SemEval

40

50

epochs

60

70

80

90

(c) BaiduSKE

Figure 5: Forward perplexity training curves on Three datasets respectively.
Table 6: Human evaluation on WebNLG dataset.

perplexity validates that our method allows the generator to generate high-frequency language patterns more and better. We plot the
training curves of FPPL.
Table 4 shows the predicate accuracy of different training methods on SemEval datasets. Our model can fit the logical connection
between real sentences and RDF predicates better compared with
baselines.
Human evaluation is conducted on WebNLG dataset to validate
the performance of our framework further. We choose WebNLG
dataset because it consists of more RDF triples and its reference
sentences are relatively simple. We randomly select 20 RDF triples
from the dataset, along with the corresponding sentences generated
by T2T and baselines. Ten human volunteers are asked to rate the
sentences from two aspects: grammar and correctness. The score
on grammar is used to judge whether the sentence contains grammatical errors, improper use of words and repetition. Correctness
measures whether the sentence accurately represents the information in the RDF triples. The score for each criterion takes an
integer between 1 and 10. Volunteers are given both scoring criteria
and examples. Table 6 lists the results of overall human evaluation
score.
Table 7 presents samples of generated sentences from different
baselines and T2T given a knowledge base about Amatriciana sauce.
Compared with baselines, the text generated from T2T is not only
grammatically sound and correctly expresses all the information
from RDF triples as well. We also found that when the length of
the generated sentence is long, the quality of output from SeqGAN
is compromised, which may because they use Monte Carlo sampling to guide the generator, which will introduce variance. The
sentences generated by MLE correctly express the knowledge, but
the grammar and the words are not quite authentic. Text generated
using Pointer-Generator suffers from repetition. Neural Wikipedian
can hardly express all information soundly given multiple triples.

6

methods
MLE
CoT
PG
SeqGAN
NW
T2T

6.1

Grammar
7.6
5.5
7.1
8.0
6.3
8.6

Correctness
6.7
3.5
5.6
5.8
4.6
7.1

Knowledge Base to Natural Language

Previous approaches on generating natural language from knowledge bases can be categorized into the following types: rule-based,
template-based and neural language model based.
Generating sentences based on knowledge bases with handcrafted rules is the main technology in traditional NLG systems,
which often involves domain-specific knowledge and only works for
a particular data type. Bontcheva et al. [9] designed a set of rules to
generate natural language reports from medical data automatically.
O’Donnell et al. [44] designed a text generation system by utilizing
the potential rules from relational databases. They specified the
semantics of relational databases and reconstructed an "Intelligent
Labelling Explorer" (ILEX) system. Based on that, the ILEX system
can interpret entities from databases based on information like
domain taxonomy and specification of the data type. Cimiano et
al. [11] presented a principled language generation architecture
by analyzing statistical information derived from a domain corpus.
Their system can write recipes based on RDF representations of a
cooking domain. They mainly focus on extracting lexicon and then
formulate the recipes with a parse tree.
Template-based generation is another traditional approach to
convert structured data into text. In general, developing such kind
of system often requires complex design about grammar, semantic
and lexicalization [14]. Kukich [33] designed a knowledge-based
report generator which infers semantic messages from the data and
then maps that information into a grammar-based template. Flanigan et al. [22] proposed a two-stage method for natural language
generation from Abstract Meaning Representation [4]. Duma et al.
[18] formulated a system which automatically learns sentence templates using the corpus extracted from Simple English Wikipedia
and DBpedia.

RELATED WORKS

Our task can be regarded as a combination of two problems. One is
on the training of neural language models; another is on converting
knowledge bases (structured data) into natural languages.

462

Session 5A: Conversation and Dialog

SIGIR ’19, July 21–25, 2019, Paris, France

Table 7: Sample output of the system.
RDF inputs
Reference
MLE
CoT
SeqGAN
PG
NW
T2T

<Italy , capital , Rome>, <Italy , leaderName , Matteo Renzi>, <Amatriciana sauce , country , Italy>,
<Italy , leaderName , Laura Boldrini>
Amatriciana sauce is a traditional sauce in italy ( the capital of which is rome ) , where two of the country ’ s leaders
are matteo renzi and laura boldrini .
Italy is called a country Amatriciana sauce . Matteo Renzi and Laura Boldrini are leaders in Italy where the capital
is Rome .
Laura Boldrini is a leader in Italy where Rome is the capital of the country of Italy where where valencia is bacon.
Amatricana sauce comes from Italy , a political leader and the capital is Rome . matteo renzi and Laura Boldrini are
one of the leaders of Italy is
Amatriciana sauce , a traditional italian dish from the Rome of the italian , where Rome the the leader is either two
leaders include Matteo Renzi.
the leader of Italy is Laura Boldrini where amatriciana sauce can be found .
Amatriciana sauce is from the country of Italy where capital is Rome . its leader is Laura Boldrini and Matteo Renzi
leads the country .

7

The former two technologies have good availability, reliability
and do not rely on large quantities of corpora to train the model.
However, they require a labor expert and have poor scalability.

6.2

CONCLUSION

In this paper, we studied the problem of converting knowledge
base RDF triples into natural languages. To handle this problem,
we formulated it as a conditional natural language problem and
utilized the discrete sequence generative models. We analyzed the
limitations of existing methods on conditional sequence generative
models and proposed a new method T2T which approximately
optimizes an inverse Kullback-Leibler divergence between the real
distribution and the learned one. We validated the proposed method
on three benchmark datasets. The experiment results show that
our method outperforms the baselines.
Our model is not limited in the task of translating knowledge
bases RDF triples to natural languages; it can also be applied to
other conditional generation tasks like machine translation and
question answering systems, which we leave as future work.

Neural Language Models

Sequence-to-sequence model [19] adopts an end-to-end generation
method that converts a meaning representation into a sentence.
As attention mechanism [3] presents advantages in soft-searching
the most relevant information among a sequence in neural machine translation task, Nallapati et al. [42] proposed a sequenceto-sequence attentional model to tackle text summarization task.
See at al. [46] proposes a hybrid pointer-generator network facilitating copying words from the source text via pointing [53] while
retaining the ability to produce new words via generator, and uses
coverage to discourage repetition. Yu et al. [56] proposed SeqGAN
framework that introduces GAN discriminator [24] to provide the
reward signal and uses policy gradient technique [49] to bypass
the generator differentiation problem. Lu et al. [37] proposed Cooperative Training (CoT) that coordinately trains a generative module and an auxiliary predictive module, to optimize the estimated
Jensen-Shannon divergence.
Besides the studies on design and training of language models,
the researchers also proposed many indicators for evaluating the
quality of samples generated by language models. These metrics can
be classified into word-based metrics and grammar-based metrics.
Word-based metrics move from simple n-gram overlap (including
BLEU, TER [47], ROUGE [36], NIST [17], LEPOR [25], CIDER [52]
and METEOR [5]) to semantic similarity like Semantic Text Similarity [26]. Grammar-based metrics include F-score, MaxMatch [12],
I-measure [21]. Besides, instead of comparing sentences words by
words, EmbSim [57] compares the word embeddings. Some metrics
are likelihood-based metrics that estimate the cross-entropy between the generated sentences and the true data, such as NLLoracle
[56] that estimates average negative log-likelihood of generated
sentences on oracle LSTM.

ACKNOWLEDGMENTS
The work is sponsored by Huawei Innovation Research Program.
The corresponding author Weinan Zhang thanks the support of
National Natural Science Foundation of China (61702327, 61772333,
61632017), Shanghai Sailing Program (17YF1428200). Any opinions,
findings and conclusions or recommendations expressed in this
material are those of the authors and do not necessarily reflect
those of the sponsor.

REFERENCES
[1] Martin Arjovsky and Léon Bottou. 2017. Towards principled methods for training
generative adversarial networks. arXiv preprint arXiv:1701.04862 (2017).
[2] Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak,
and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. In The
semantic web. Springer, 722ś735.
[3] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473 (2014).
[4] Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf
Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider.
2013. Abstract meaning representation for sembanking. In Proceedings of the 7th
Linguistic Annotation Workshop and Interoperability with Discourse. 178ś186.
[5] Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for
MT evaluation with improved correlation with human judgments. In Proceedings

463

Session 5A: Conversation and Dialog

[6]
[7]
[8]
[9]
[10]

[11]
[12]
[13]

[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]
[24]
[25]
[26]
[27]

[28]
[29]
[30]
[31]
[32]

SIGIR ’19, July 21–25, 2019, Paris, France

[33] Karen Kukich. 1983. Design of a knowledge-based report generator. In ACL.
Association for Computational Linguistics, 145ś150.
[34] Jiwei Li, Minh-Thang Luong, and Dan Jurafsky. 2015. A hierarchical neural
autoencoder for paragraphs and documents. arXiv preprint arXiv:1506.01057
(2015).
[35] Jiwei Li, Will Monroe, Tianlin Shi, Sėbastien Jean, Alan Ritter, and Dan Jurafsky.
2017. Adversarial Learning for Neural Dialogue Generation. In EMNLP. 2157ś
2169.
[36] Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries.
Text Summarization Branches Out (2004).
[37] Sidi Lu, Lantao Yu, Weinan Zhang, and Yong Yu. 2018. CoT: Cooperative Training
for Generative Modeling. arXiv preprint arXiv:1804.03782 (2018).
[38] D-Lib Magazine. 1998. An Introduction to the Resource Description Framework.
D-Lib Magazine (1998).
[39] Matthew V Mahoney. 1999. Text compression as a test for artificial intelligence.
In AAAI/IAAI. 970.
[40] Geoffrey McLachlan. 2004. Discriminant analysis and statistical pattern recognition.
Vol. 544. John Wiley & Sons.
[41] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
NeurIPS. 3111ś3119.
[42] Ramesh Nallapati, Bowen Zhou, Caglar Gulcehre, Bing Xiang, et al. 2016. Abstractive text summarization using sequence-to-sequence rnns and beyond. arXiv
preprint arXiv:1602.06023 (2016).
[43] Jekaterina Novikova, Ondřej Dušek, Amanda Cercas Curry, and Verena Rieser.
2017. Why we need new evaluation metrics for nlg. arXiv preprint
arXiv:1707.06875 (2017).
[44] Michael O’Donnell, Alistair Knott, Jon Oberlander, and Chris Mellish. 2000. Optimising text quality in generation from relational databases. In INLG. Association
for Computational Linguistics, 133ś140.
[45] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a
method for automatic evaluation of machine translation. In ACL. Association for
Computational Linguistics, 311ś318.
[46] Abigail See, Peter J Liu, and Christopher D Manning. 2017. Get to the point:
Summarization with pointer-generator networks. arXiv preprint arXiv:1704.04368
(2017).
[47] Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John
Makhoul. 2006. A study of translation edit rate with targeted human annotation.
In Proceedings of association for machine translation in the Americas, Vol. 200.
[48] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning
with neural networks. In NeurIPS. 3104ś3112.
[49] Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. 2000.
Policy gradient methods for reinforcement learning with function approximation.
In NeurIPS. 1057ś1063.
[50] Bayu Distiawan Trisedya, Jianzhong Qi, Rui Zhang, and Wei Wang. 2018. GTRLSTM: A Triple Encoder for Sentence Generation from RDF Data. In ACL, Vol. 1.
1627ś1637.
[51] Ross Turner, Somayajulu Sripada, and Ehud Reiter. 2010. Generating approximate
geographic descriptions. In EMNLP. Springer, 121ś140.
[52] Ramakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh. 2015. Cider:
Consensus-based image description evaluation. In Proceedings of the IEEE conference on computer vision and pattern recognition. 4566ś4575.
[53] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. In
NeurIPS. 2692ś2700.
[54] Pavlos Vougiouklis, Hady Elsahar, Lucie-Aimée Kaffee, Christophe Gravier, Frederique Laforest, Jonathon Hare, and Elena Simperl. 2018. Neural wikipedian:
Generating textual summaries from knowledge base triples. JWS (2018).
[55] Ronald J Williams. 1992. Simple statistical gradient-following algorithms for
connectionist reinforcement learning. Machine learning 8, 3-4 (1992), 229ś256.
[56] Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017. SeqGAN: Sequence
Generative Adversarial Nets with Policy Gradient.. In AAAI. 2852ś2858.
[57] Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and
Yong Yu. 2018. Texygen: A Benchmarking Platform for Text Generation Models.
SIGIR (2018).
[58] Lei Zou, Ruizhe Huang, Haixun Wang, Jeffrey Xu Yu, Wenqiang He, and Dongyan
Zhao. 2014. Natural language question answering over RDF: a graph data driven
approach. In SIGKDD. ACM, 313ś324.

of the acl workshop on intrinsic and extrinsic evaluation measures for machine
translation and/or summarization. 65ś72.
Anja Belz and Ehud Reiter. 2006. Comparing automatic and human evaluation of
NLG systems. In 11th Conference of the European Chapter of the Association for
Computational Linguistics.
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. 2015. Scheduled
sampling for sequence prediction with recurrent neural networks. In NeurIPS.
1171ś1179.
Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston. 2009.
Curriculum learning. In ICML. ACM, 41ś48.
Kalina Bontcheva and Yorick Wilks. 2004. Automatic report generation from
ontologies: the MIAKT approach. In International conference on application of
natural language to information systems. Springer, 324ś335.
Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase
representations using RNN encoder-decoder for statistical machine translation.
arXiv preprint arXiv:1406.1078 (2014).
Philipp Cimiano, Janna Lüker, David Nagel, and Christina Unger. 2013. Exploiting
ontology lexica for generating natural language texts from RDF data. (2013).
Daniel Dahlmeier and Hwee Tou Ng. 2012. Better evaluation for grammatical
error correction. In NAACL. Association for Computational Linguistics, 568ś572.
Robert Dale, Sabine Geldof, and Jean-Philippe Prost. 2003. CORAL: Using natural
language generation for navigational assistance. In Proceedings of the 26th Australasian computer science conference-Volume 16. Australian Computer Society,
Inc., 35ś44.
Kees Van Deemter, Mariët Theune, and Emiel Krahmer. 2005. Real versus
template-based natural language generation: A false opposition? Computational
Linguistics 31, 1 (2005), 15ś24.
Michael Denkowski and Alon Lavie. 2014. Meteor universal: Language specific translation evaluation for any target language. In Proceedings of the ninth
workshop on statistical machine translation. 376ś380.
Li Ding, Tim Finin, Anupam Joshi, Rong Pan, R Scott Cost, Yun Peng, Pavan
Reddivari, Vishal Doshi, and Joel Sachs. 2004. Swoogle: a search and metadata
engine for the semantic web. In CIKM. ACM, 652ś659.
George Doddington. 2002. Automatic evaluation of machine translation quality
using n-gram co-occurrence statistics. In Baltic HLT. Morgan Kaufmann Publishers Inc., 138ś145.
Daniel Duma and Ewan Klein. 2013. Generating natural language from linked
data: Unsupervised template extraction. In IWCS. 83ś94.
Ondřej Dušek. 2016. Sequence-to-Sequence Natural Language Generation. Interaction (2016).
Anthony Fader, Luke Zettlemoyer, and Oren Etzioni. 2014. Open question answering over curated and extracted knowledge bases. In SIGKDD. ACM, 1156ś1165.
Mariano Felice and Ted Briscoe. 2015. Towards a standard evaluation method for
grammatical error detection and correction. In NAACL. 578ś587.
Jeffrey Flanigan, Chris Dyer, Noah A Smith, and Jaime Carbonell. 2016. Generation from abstract meaning representation using tree transducers. In NAACL.
731ś739.
Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura PerezBeltrachini. 2017. The webnlg challenge: Generating text from rdf data. In
INLG. 124ś133.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial
nets. In NeurIPS. 2672ś2680.
Aaron LF Han, Derek F Wong, and Lidia S Chao. 2012. LEPOR: A robust evaluation
metric for machine translation with augmented factors. Proceedings of COLING
2012: Posters (2012), 441ś450.
Lushan Han, Abhay L Kashyap, Tim Finin, James Mayfield, and Jonathan Weese.
2013. UMBC_EBIQUITY-CORE: semantic textual similarity systems. In *SEM,
Vol. 1. 44ś52.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid
Ó Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano, and Stan
Szpakowicz. 2009. Semeval-2010 task 8: Multi-way classification of semantic
relations between pairs of nominals. In Proceedings of the Workshop on Semantic
Evaluations: Recent Achievements and Future Directions. Association for Computational Linguistics, 94ś99.
Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural
computation 9, 8 (1997), 1735ś1780.
Zan Huang, Wingyan Chung, Thian-Huat Ong, and Hsinchun Chen. 2002. A
graph-based recommender system for digital library. In Proceedings of the 2nd
ACM/IEEE-CS joint conference on Digital libraries. ACM, 65ś73.
Ferenc Huszár. 2015. How (not) to train your generative model: Scheduled
sampling, likelihood, adversary? arXiv preprint arXiv:1511.05101 (2015).
Yoon Kim, Kelly Zhang, Alexander M Rush, Yann LeCun, et al. 2017. Adversarially
Regularized Autoencoders. arXiv preprint arXiv:1706.04223 (2017).
Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).

464


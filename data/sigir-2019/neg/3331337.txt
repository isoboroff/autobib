Short Research Papers 3B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Improving Collaborative Metric Learning with Efficient
Negative Sampling
Viet-Anh Tran, Romain Hennequin, Jimena Royo-Letelier, Manuel Moussallam
Deezer Research & Development, Paris, France
research@deezer.com

ABSTRACT

is the distance between intra-class (same label) samples (anchor
and positive), D(a, n) is the distance between inter-class (different
labels) samples (anchor and negative) and α > 0 is a margin constant. The main idea is to enforce inter-class pairs to be far away
from intra-class pairs at least by a margin α. This favors clustering
of same class samples. As pointed out in [6, 19], minimizing L is
not easy as the number of possible triplets grows cubically with
the number of identities. Furthermore, a naive uniform sampling
strategy would select trivial triplets for which the gradient of L is
negligible. As a result, learning may be slow and stuck in a local
minima [21]. To address this problem, some works proposed to
select only hard samples (D(a, p) > D(a, n)) for training [15, 16].
Hard samples mining, however, selects triplets with noisy (high
variance) gradients of L. Models may then struggle to effectively
push inter-class pairs apart, and end up in a collapsed state [14, 21].
A relaxed alternative is to mine only semi-hard samples [14]: triplets
in which the negative is not necessarily closer to the anchor than
the positive, but which still produce a strictly positive loss. This
strategy improves the robustness of training by avoiding overfitting
outliers in the training set [4]. It typically converges quickly in the
first iterations, but eventually runs out of informative samples and
stops making progress. In [21] authors attributed this phenomenon
to the concentration of the gradient’s variance of L for semi-hard
samples to a small region. To address this issue, they proposed to
select negative samples based on their distances to anchors. They
demonstrated that this strategy results in the variance of the gradient of L being spread in a larger range, and thus consistently
produces informative triplets [21].
Its ability to deal with large-scale catalogs and data sparsity [19]
makes the triplet loss model suitable for recommendation tasks. It
has indeed been recently proposed as the CML model [7], reaching competitive results with traditional Matrix Factorization (MF)
methods [13, 22]. CML assumes that users and items can be placed
in a joint low dimensional metric-space. Recommendations are
then easily done based on their proximity measured by their Euclidean distance. CML can achieve competitive accuracy [7] but
we show in this paper that it requires large batches to do so, because of it’s simplistic uniform negative sampling strategy. Owing
to memory limitations, this makes CML unable to scale in highdimensional scenarios, e.g., when building a hybrid multimedia
recommender system that learns jointly from interaction data and
high-dimensional item contents such as audio spectrograms [9].
For that reason, following the idea in [21], we replace the default
uniform sampling by a 2-stage strategy, which finds triplets that
are consistently informative for learning. This enables CML to be
competitive with uniform sampling, even with small batches, both
in terms of accuracy and popularity bias.

Distance metric learning based on triplet loss has been applied
with success in a wide range of applications such as face recognition, image retrieval, speaker change detection and recently recommendation with the Collaborative Metric Learning (CML) model.
However, as we show in this article, CML requires large batches to
work reasonably well because of a too simplistic uniform negative
sampling strategy for selecting triplets. Due to memory limitations,
this makes it difficult to scale in high-dimensional scenarios. To
alleviate this problem, we propose here a 2-stage negative sampling strategy which finds triplets that are highly informative for
learning. Our strategy allows CML to work effectively in terms of
accuracy and popularity bias, even when the batch size is an order
of magnitude smaller than what would be needed with the default
uniform sampling. We demonstrate the suitability of the proposed
strategy for recommendation and exhibit consistent positive results
across various datasets.

CCS CONCEPTS
• Information systems → Recommender systems; • Computing methodologies → Metric learning;

KEYWORDS
Recommender Systems, Collaborative Filtering, Triplet Loss, Metric
Learning
ACM Reference Format:
Viet-Anh Tran, Romain Hennequin, Jimena Royo-Letelier, Manuel Moussallam. 2019. Improving Collaborative Metric Learning with Efficient Negative Sampling. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’19),
July 21–25, 2019, Paris, France. ACM, New York, NY, USA, 4 pages. https:
//doi.org/10.1145/3331184.3331337

1

INTRODUCTION

Distance metric learning aims at representing data points in a space
where proximity accounts for similarity. A recent popular approach
in face recognition [14], image retrieval [17] or speaker change detection [2] formalizes this problem as a triplet loss optimization task,
namely minimizing: L = max(D(a, p) − D(a, n) + α, 0) where D(a, p)
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR ’19, July 21–25, 2019, Paris, France
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00
https://doi.org/10.1145/3331184.3331337

1201

Short Research Papers 3B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Our contributions are threefold: (1) We study the influence of
batch size on the CML’s performance. (2) We propose a 2-stage
negative sampling that makes CML efficient with small batches. (3)
We demonstrate the suitability of our sampling strategy on three
real-world datasets, for the Top-N recommendation task, in terms
of accuracy and popularity bias. We note especially a significant
improvement over standard CML on music recommendation. We
also provide code to reproduce our results1 .

"spread-out" over the space. Intuitively, two randomly sampled nonmatching vectors are "spread-out" if they are orthogonal with high
probability. To this end, they proved that if p1 , p2 are two vectors
independently and uniformly sampled from the unit sphere in Rd ,
the probability density of pT1 p2 satisfies
p(pT1 p2

2

, 2)

if − 1 ≤ s ≤ 1
otherwise

where Beta(a, b) is the beta distribution
this distri
 function. From

bution, they further found that E pT1 p2 = 0 and E (pT1 p2 )2 = d1 ,
and proposed the Global Orthogonal Regularization (GOR) to enforce the spread of latent vectors. The application of GOR for CML
is thus:

Consider a dataset with N users, M items and the binary interaction
M × N matrix R, where Ri j indicates the only positive implicit
feedback (e.g., clicks, listens, view histories logs etc.) between the
i-th user and the j-th item. We use S = {(i, j) | Ri j = 1} to denote
the set of user-item pairs where there exists implicit interactions.
The considered task is to predict the items/users that are likely to
interact together.

L = Ltriplet + λд LGOR
2 h 1 Õ
1 Õ Õ
vTj vk +
LGOR =
Q
Q
(i, j)∈B k ∈N i j

Collaborative Metric Learning

Õ

(i, j)∈B k ∈N i j

(vTj vk )2 −

(2)
1i
d +
(3)

CML [7] learns a joint metric space of users and items to encode S.
The idea is to learn a metric that pulls the positive pairs in S closer
while pushing the negative pairs (pairs not in S) relatively further
apart compared to the positive ones, based on the following loss:
Õ
Ltriplet =
w i j [D 2 (ui , vj ) − min D 2 (ui , vk ) + α]+ + λc Lc
(i, j)∈B

Beta(


0


2 PRELIMINARIES
2.1 Problem Formulation

2.2

= s) =

d −1 −1

2

 (1−s )d −12 1


where λд is an hyperparameter, Q = |B| × |Ni j | and d is the dimension of the latent space.

3.2

k ∈N i j

2-stage negative sampling

To construct a batch, we first randomly sample pairs in S as in [7]
to get the anchor users and the positive items. Our strategy aims at
replacing the uniform sampling for the set Ni j negative items in a
triplet by a 2-stage setting as described below.
In the first stage, we sample C negative candidates from all items
in the dataset based on their frequencies as proposed in the popular
Word2Vec algorithm in natural language processing [11] and its
application for the recommendation task [1, 3, 12]:

s.t. ∀p ≤ M, q ≤ N : ||up ||2 ≤ 1, ||vq ||2 ≤ 1
(1)
where ui , vj are, respectively, user and item latent vectors in Rd ,
B ⊂ S is the set of positive pairs in the considered mini-batch,
Ni j ⊂ {k |(i, k) < S } is a set of negative samples per triplet, α > 0 is
a margin constant, D is the Euclidean distance and w i j is a weight
based on the number of negatives in Ni j falling inside the α-ball
to penalize items at a lower rank [20], [.]+ = max(., 0), Lc is regularization term (weighted by the hyper parameter λc ) used to
de-correlate the dimensions in the learned metric [7]. The recommendation for an user is then made by finding the k nearest items
around her/him in the latent space.
In this work, we set w i j to 1 for fair comparison between different
sampling strategies. Furthermore, we do not use Lc for all models
because we have inferior results for the uniform sampling with
this regularization (with the code provided by authors on github2 ).
Additionally, all user and item vectors are normalized to the unit
sphere: ∀p ≤ M, q ≤ N : ||up ||2 = 1, ||vq ||2 = 1 (by adding a
L 2 -normalization step after the user/item embedding layer) instead
of being bound within the unit ball.

Pr(j) = Í

f (j)β
j′

f (j ′ )β

,

(4)

where f (j) is the interaction frequency of item j and the parameter β plays a role in sharpening or smoothing the distribution. A
positive β leads to a sampling that favors popular items, a β equal
to 0 leads to items being sampled uniformly, while a negative β
makes unpopular items being more likely sampled. In this work,
we use a positive β to favor popular items as negative samples. The
motivation is that due to the popularity bias in interaction data
[18], popular items tend to be close together. A challenge is thus
to push non-matching popular items farther away in the latent
space. Spreading popular items apart could then help to reduce the
popularity bias often witnessed in recommendation.
In the second stage, we select informative negative items from
the C previous candidates in a similar manner as in [21]. Given the
latent vector of a positive item vj , we sample a negative item index
n, with corresponding latent factor vn as follows:

3 SAMPLING STRATEGY
3.1 Spread-out Regularization
In [23], the authors argued that in order to fully exploit the expressive power of the embedding, latent vectors should be sufficiently



,
 T1

Pr(n|vj ) ∝ p(vj vn =s)

 0,


1 Code

available at: https://github.com/deezer/sigir2019-2stagesampling
2 Original CML https://github.com/changun/CollMetric

1202

0≤s ≤1
otherwise

Short Research Papers 3B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Table 1: Statistics of the datasets

This strategy has two objectives: first, the choice of this probability function offers triplets with a larger range of gradient’s variance than what would be obtained with semi-hard triplet sampling [21]. Second, it puts high probability on items n that produce
high positive value for vTj vn , hence inducing positive values for
Ltriplet and large values for LGOR . Indeed, it’s obvious that with
positive vTj vn , LGOR increases as vTj vn gets higher. At the same
time, for each positive-negative pair (vj , vn ), we have ||vj − vn ||22 =
||vj ||22 + ||vn ||22 − 2vTj vn = 2 − 2vTj vn , so the greater the value

Dataset

User#

Item#

Rating#

Density

Amazon Movies
Book Crossing
Echonest

11181
3593
31521

94661
127339
159063

620059
240020
1405671

0.058%
0.052%
0.028%

the first stage is 1.0 for Amazon movies and Echonest and 0.8 for
Book crossing. Finally, λд is 0.01 when the number of negatives is
1 and 2 and to 0.001 as the number of negatives is 5.

of vTj vn is, the closer the positive-negative points are. This leads
to a smaller difference between D 2 (ui , vj ) and D 2 (ui , vn ), making
Ltriplet more likely to be positive. It thus induces higher loss values
compared to the uniform sampling case, and hopefully results in
gradients more suitable for training.

4.2

Comparison Results

4.2.1 Uniform sampling. Performance of CML with uniform sampling [7] is summarized in Table 2 (Uni sub-table). We discuss results
for the Amazon movies dataset as the same trend can be observed
on the two others. We see that the performance of CML in terms
of MAP and NDCG heavily decreases when using small batches,
especially when |Ni j | = 1. For example, when the batch size is an
order of magnitude smaller (256 vs 4096), MAP relatively decreases
by 19% (2.26 → 1.82) and NDCG by 14% (7.55 → 6.47). This drop
supports the idea that the number of informative triplets is low in
small batches with the uniform sampling setup. With more negatives per triplet (|Ni j | = 5), this decrease is alleviated, about 7%
relative drop against 19% for MAP (2.48 → 2.31) and 5% relative
drop against 14% for NDCG (8.06 → 7.68). Additionally, another
issue of CML is being prone to a strong popularity bias (MMR). As
shown in Table 2 this bias increases with the batch size: e.g., from
256 to 4096, with 1 negative per triplet, MMR raises relatively by
29% (86.4 → 111.8).

4 EXPERIMENTS
4.1 Experimental Settings
4.1.1 Datasets. We experiment with three datasets covering different domains: namely movie, book and music recommendations.
Amazon movies [5]: The Amazon dataset is the consumption
records with reviews from Amazon.com. We use the user-movie
rating from the movies and tv category 5-core. The data is binarized
by keeping only ratings greater than 4 as implicit feedback. Users
with less than 20 positive interactions are filtered out.
Book crossing [24]: The dataset contains book ratings which scale
from 0 to 10 with the higher score indicating preference. Again,
explicit ratings are binarized by keeping values of five or higher as
implicit feedback. Only users with more than 10 interactions are
then kept.
Echonest [10]: The EchoNest Taste Profile dataset contains user
playcounts for songs of the Million Song Dataset (MSD). After
deduplicating songs, playcount data is binarized by considering
values of five or higher as implicit feedback. Finally, only users with
more than 20 interactions and items with which at least 5 users
interacted.
The characteristics of these three datasets after filtering are
summarized in Table 1.

4.2.2 Popularity-based sampling. To confirm our intuition on the
necessity of pushing non-matching popular items farther away
(as discussed in the Section 3.2), we study the popularity-based
negative sampling method of Equation (4). Table 2 (Pop sub-table)
reveals a high impact of this strategy on the performance of CML in
terms of MAP & NDCG. Specifically, with smaller batch size (256 vs
4096), the MAP with popularity-based sampling already surpasses
the best result of the uniform sampling, by 3.6% for movies (2.26
→ 2.57), 8.7% for books (1.15 → 1.25) and 40% for music (5.71 →
8.0) respectively. As expected, the recommendations are less biased
towards popular items: MMR decreases by 80% on Amazon movies
(86.4 → 17.2), 90.8% on Book crossing (44.5 → 4.1) and 77% on
Echonest (146.7 → 33.8).

4.1.2 Evaluation Methodology. We divide user interactions into
4-fold for cross-validation where three folds are used to train the
model and the remaining fold is used for testing. Based on the
ranked preference scores, we adopt Mean Average Precision (MAP)
and Normalized Discounted Cumulative Gain (NDCG) to measure
whether ground-truth items are present on the ranked list of preferences truncated at 50 items and their positions. In addition, we
calculate the Mean of Median Rank (MMR) of recommended items
to assess the popularity bias of the model.

4.2.3 2-stage sampling. While popular-based negative sampling is
efficient with small batches, the reported NDCG of this strategy is
slightly worse than what can be obtained by uniform sampling on
large batches (except for the Echonest). In book recommendation,
the gap is quite significant with a 6.3% decrease (4.13 → 3.87).
To further improve the performances of the CML model on small
batches, we add on top of the popularity strategy a second stage
based on dot product weighted sampling as described in Section
3.2. This enables CML with small batches to have a competitive
NDCG w.r.t the best result using the uniform sampling strategy. In
detail, with 16 times smaller batch size, 2-stage sampling yields the
same NDCG for book recommendation and reaches a 2.1% increase
for movie recommendation (8.06 → 8.23), 33.6% increase for music
recommendation (14.5 → 19.37). Meanwhile MAP is remarkably

4.1.3 Parameters setting. The parameter C should be chosen in
order to retain a sufficient number of candidates while limiting the
amount of computations occurring in the second stage. We set it
to 2000 and leave its optimization to future work. Besides that, the
latent dimension d is set to 128 and the margin α to 1. For the other
parameters, the 4-fold cross-validation mentioned above is used
to choose the best values using grid-search. Adam optimizer [8] is
used for all models. The learning rate is 0.0001, the parameter β for

1203

Short Research Papers 3B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Table 2: CML’s performance with different sampling strategies, number of negatives per triplet and batch sizes. The format
is mean ± std obtained from 4 runs on cross-validation splits. The italic bold face shows the best values for uniform strategy
while bold face shows the best overall values
.
Sam

|Ni j |

1
Uni
2

5

Pop

2st

1
2
5
1
2
5

Batch
4096
1024
256
4096
1024
256
4096
1024
256
256

256

MAP(%)

Amazon Movies
NDCG(%)

MMR

MAP(%)

Book Crossing
NDCG(%)

MMR

MAP(%)

Echonest
NDCG(%)

MMR

2.26 ± 0.06
2.13 ± 0.08
1.82 ± 0.04
2.34 ± 0.06
2.23 ± 0.04
2.04 ± 0.07
2.48 ± 0.05
2.45 ± 0.06
2.31 ± 0.02
2.12 ± 0.02
2.43 ± 0.04
2.57 ± 0.07
2.32 ± 0.06
2.57 ± 0.03
2.73 ± 0.03

7.55 ± 0.12
7.19 ± 0.16
6.47 ± 0.10
7.72 ± 0.10
7.49 ± 0.10
6.98 ± 0.12
8.06 ± 0.13
8.01 ± 0.13
7.68 ± 0.04
7.14 ± 0.01
7.83 ± 0.12
7.89 ± 0.06
7.78 ± 0.14
8.14 ± 0.04
8.23 ± 0.02

111.8 ± 0.1
101.7 ± 1.5
86.4 ± 2.4
114.5 ± 0.2
109.5 ± 0.2
96.0 ± 1.9
118.5 ± 0.4
115.2 ± 0.6
107.2 ± 0.2
26.2 ± 0.3
24.3 ± 0.02
17.2 ± 0.04
32.9 ± 0.1
27.9 ± 0.1
19.6 ± 0.1

1.12 ± 0.07
1.08 ± 0.08
0.93 ± 0.04
1.15 ± 0.08
1.13 ± 0.06
1.04 ± 0.10
1.15 ± 0.08
1.15 ± 0.08
1.12 ± 0.09
1.04 ± 0.07
1.22 ± 0.07
1.25 ± 0.04
1.26 ± 0.08
1.3 ± 0.08
1.38 ± 0.09

3.98 ± 0.11
3.86 ± 0.14
3.50 ± 0.06
4.06 ± 0.12
3.97 ± 0.13
3.74 ± 0.17
4.13 ± 0.14
4.07 ± 0.09
3.94 ± 0.16
3.54 ± 0.06
3.87 ± 0.14
3.75 ± 0.06
4.13 ± 0.13
4.12 ± 0.11
4.12 ± 0.15

55.2 ± 0.4
53.2 ± 0.4
44.5 ± 1.2
54.9 ± 0.9
54.5 ± 1.2
49.5 ± 0.8
53.7 ± 0.8
55.2 ± 0.6
53.5 ± 1.0
8.3 ± 0.04
6.9 ± 0.13
4.1 ± 0.01
10.1 ± 0.1
7.6 ± 0.1
4.5 ± 0.01

4.88 ± 0.02
4.41 ± 0.01
3.66 ± 0.03
5.16 ± 0.04
4.85 ± 0.08
4.18 ± 0.06
5.71 ± 0.04
5.56 ± 0.05
5.11 ± 0.01
6.48 ± 0.11
7.26 ± 0.06
8.0 ± 0.01
6.99 ± 0.03
7.91 ± 0.14
8.70 ± 0.07

12.78 ± 0.01
11.70 ± 0.04
9.90 ± 0.12
13.39 ± 0.05
12.60 ± 0.09
11.14 ± 0.09
14.50 ± 0.09
14.17 ± 0.04
13.10 ± 0.04
15.55 ± 0.17
17.0 ± 0.03
18.44 ± 0.08
16.69 ± 0.05
18.32 ± 0.13
19.37 ± 0.06

241.8 ± 1.4
196.5 ± 0.6
146.7 ± 2.2
265.5 ± 1.1
231.7 ± 3.0
175.0 ± 5.3
315.5 ± 1.4
287.5 ± 2.5
229.1 ± 1.0
54.3 ± 1.6
46.1 ± 0.2
33.8 ± 0.3
96.1 ± 0.2
78.9 ± 0.2
48.4 ± 0.8

enhanced for all datasets, 10% (2.48 → 2.73), 20% (1.15 → 1.38)
and 52% (5.71 → 8.7) for movie, book and music recommendation
respectively. Note that 2-stage sampling makes the MMR slightly
higher than that of the popularity-based strategy, but it is still
significantly lower than the one with uniform sampling.

5

[8] Diederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. http://arxiv.org/abs/1412.6980
[9] Jongpil Lee, Kyungyun Lee, and Jiyoung Park. 2018. Deep Content-User Embedding Model for Music Recommendation. http://arxiv.org/abs/1807.06786
[10] Brian McFee, Thierry Bertin-Mahieux, Daniel P.W. Ellis, and Gert R.G. Lanckriet.
2012. The million song dataset challenge. In Proceedings of the 21st International
Conference on World Wide Web (WWW).
[11] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
Advances in Neural Information Processing Systems (NIPS). 3111–3119.
[12] Cataldo Musto, Giovanni Semeraro, Marco De Gemmis, and Pasquale Lops. 2015.
Word Embedding Techniques for Content-based Recommender Systems: An
Empirical Evaluation.. In Proceedings of the 9th ACM Conference on Recommender
Systems (RecSys). ACM.
[13] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings
of the 25th Conference on Uncertainty in Artificial Intelligence (AUAI).
[14] Florian Schroff, Kalenichenko Dmitry, and Philbin James. 2015. Facenet: A
unified embedding for face recognition and clustering. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR). IEEE.
[15] Abhinav Shrivastava, Abhinav Gupta, and Ross Girshick. 2016. Training regionbased object detectors with online hard example mining. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE.
[16] Edgar Simo-Serra, Eduard Trulls, Luis Ferraz, Iasonas Kokkinos, Pascal Fua, and
Francesc Moreno-Noguer. 2015. Discriminative learning of deep convolutional
feature point descriptors. In Proceedings of the IEEE International Conference on
Computer Vision (ICCV). IEEE.
[17] Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio Savarese. 2016. Deep Metric
Learning via Lifted Structured Feature Embedding. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR). IEEE.
[18] Harald Steck. 2011. Item popularity and recommendation accuracy. In Proceedings
of the 5th ACM Conference on Recommender Systems (RecSys). ACM, 125–132.
[19] Chong Wang, Xue Zhang, and Xipeng Lan. 2017. How to train triplet networks
with 100k identities?. In ICCV Workshops.
[20] Jason Weston, Samy Bengio, and Nicolas Usunier. 2010. Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning
81.1 (2010), 21–35.
[21] Chao-Yuan Wu, R. Manmatha, Alexander J. Smola, and Philipp Krahenbuhl.
2017. Sampling Matters in Deep Embedding Learning. In Proceedings of the IEEE
International Conference on Computer Vision (ICCV). IEEE, 2859–2867.
[22] Hu Yifan, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for
implicit feedback datasets. In Procedding of IEEE International Conference on
Acoustics Data Mining (ICDM). IEEE.
[23] Xu Zhang, Felix X. Yu, Sanjiv Kumar, and Shih-Fu Chang. 2017. Learning Spreadout Local Feature Descriptors. In Proceedings of the IEEE International Conference
on Computer Vision (ICCV). IEEE.
[24] Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, and Georg Lausen. 2005.
Improving recommendation lists through topic diversification. In Proceedings of
the 14th International Conference on World Wide Web (WWW).

CONCLUSIONS

We proposed a 2-stage sampling strategy that enables the CML
model to perform efficiently with batch size an order of magnitude
smaller than what would be needed with the default uniform sampling. At its heart, a set of samples is first selected based on their
popularity. Then, informative ones are drawn from this set based
on their inner product weights with anchors. Experiments demonstrate positive results across various datasets, especially for music
recommendation for which the proposed approach increased very
significantly the performance of the system. In future work, we will
leverage this sampling strategy to jointly learn from multimedia
content and collaborative data where huge batches are prohibitive
due to memory limitations.

REFERENCES
[1] Oren Barkan and Noam Koenigstein. 2016. Item2vec: neural item embedding for
collaborative filtering. In IEEE 26th International Workshop on Machine Learning
for Signal Processing (MLSP). IEEE, 1–6.
[2] Hervé Bredin. 2017. Tristounet: triplet loss for speaker turn embedding. In Procedding of IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP). IEEE.
[3] Hugo Caselles-Dupré, Florian Lesaint, and Jimena Royo-Letelier. 2017. Word2Vec
applied to Recommendation: Hyperparameters Matter. In Proceedings of the 11th
ACM Conference on Recommender Systems (RecSys). ACM.
[4] Ben Harwood, Vijay Kumar B G, Gustavo Carneiro, Ian Reid, and Tom Drummond. 2017. Smart mining for deep metric learning. In Proceedings of the IEEE
International Conference on Computer Vision (ICCV). IEEE.
[5] Ruining He and Julian McAuley. 2016. Ups and downs: Modeling the visual
evolution of fashion trends with one-class collaborative filtering. In Proceedings
of the 25th International Conference on World Wide Web (WWW).
[6] Alexander Hermans, Beyer Lucas, and Leibe Bastian. 2017. In defense of the
triplet loss for person re-identification. http://arxiv.org/abs/1703.07737 arXiv
preprint arXiv:1703.07737.
[7] Cheng-Kang Hsieh, Longqi Yang, Yin Cui, Tsung-Yi Lin, Serge J. Belongie, and
Deborah Estrin. 2017. Collaborative metric learning. In Proceedings of the 26th
International Conference on World Wide Web (WWW).

1204


Short Research Papers 2B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Gated Spectral Units: Modeling Co-evolving Patterns for
Sequential Recommendation
Lei Zheng

Ziwei Fan

Chun-Ta Lu

Department of Computer Science
University of Illinois at Chicago
IL, US
lzheng21@uic.edu

Department of Computer Science
University of Illinois at Chicago
IL, US
zfan20@uic.edu

Department of Computer Science
University of Illinois at Chicago
IL, US
clu29@uic.edu

Jiawei Zhang

Philip S. Yu

IFM Lab, Department of Computer
Science
Florida State University
FL, US
jiawei@ifmlab.org

Department of Computer Science
University of Illinois at Chicago
IL, US
psyu@uic.edu

ABSTRACT

User I

Exploiting historical data of users to make future predictions lives
at the heart of building effective recommender systems (RS). Recent approaches for sequential recommendations often render past
actions of a user into a sequence, seeking to capture the temporal dynamics in the sequence to predict the next item. However,
the interests of users evolve over time together due to their mutual influence, and most of existing methods lack the ability to
utilize the rich coevolutionary patterns available in underlying data
represented by sequential graphs.
In order to capture the co-evolving knowledge for sequential
recommendations, we start from introducing an efficient spectral
convolution operation to discover complex relationships between
users and items from the spectral domain of a graph, where the
hidden connectivity information of the graph can be revealed. Then,
the spectral convolution is generalized into an recurrent method
by utilizing gated mechanisms to model sequential graphs. Experimentally, we demonstrate the advantages of modeling co-evolving
patterns, and Gated Spectral Units (GSUs) achieve state-of-the-art
performance on several benchmark datasets.

swimming
suit

inﬂuence

User II

bottle
openner

goggle

shoes

wine
socks
t1

t2

t3

t4

t5

t6

t7

t8

t9

t10

time

Figure 1: An example illustrates how activities of user coevolves over time. Yellow and green circles denote purchases
of user I and user II, respectively. (Best viewed in color)
ACM Reference Format:
Lei Zheng, Ziwei Fan, Chun-Ta Lu, Jiawei Zhang, and Philip S. Yu. 2019.
Gated Spectral Units: Modeling Co-evolving Patterns for Sequential Recommendation. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’19),
July 21–25, 2019, Paris, France. ACM, New York, NY, USA, 4 pages. https:
//doi.org/10.1145/3331184.3331329

1

INTRODUCTION

What will a customer buy next? The importance of this question
cannot be overstated for building effective recommender systems
(RS). RS intersect multiple products and customers, where characteristics of users and perceptions of items not only shift over time
but also influence each other. This complex temporal information
raises unique challenges.
In order to build a predictive model for users’ future purchases,
we observe that a user’s actions are correlated to not only his or
her past activities but also other users’ behaviors. Interests of users
co-evolve over time and their preferences influence each other
dynamically. For example, as shown in Fig. 1, if user u 1 is related
to user u 2 , when u 1 purchases a pair of shoes at time t 3 , u 2 may
buy a pair of socks for u 1 at a later time, say t 5 . Some time later (t 7 ),
when u 2 shops a bottle of wine, it is reasonable to expect u 1 to be
interested in a bottle opener. We term this phenomenon of evolving
actions of users and their mutual influence over time as co-evolving
patterns. It is no doubt that effectively capturing such rich patterns
can help reason over complex non-linear user-item interactions.

CCS CONCEPTS
• Information systems → Recommender systems; • Computing methodologies → Neural networks;

KEYWORDS
Sequential Recommendation, Spectral, Graph

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGIR ’19, July 21–25, 2019, Paris, France
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6172-9/19/07. . . $15.00
https://doi.org/10.1145/3331184.3331329

1077

Short Research Papers 2B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Table 1: Notations
Existing approaches [11, 13] often lack the ability of learning
the co-evolving knowledge, resulting in a limited understanding
on behaviors of users and how they influence each other over time.
Early works focus on modeling the shifting patterns of a user’s
preferences and the popularity of an item by introducing additional
variables changing over time. Recent models first regard activities
of a user as a sequence, and then propose Markov Chain (MC) based
methods to capture the item dependencies or correlations within
the sequence. For instance, in Fig. 1, user u 1 shops a goggle at t 5
time because of the purchase of a swimming suit at the time of t 1 .
Another line of work adopts Recurrent Neural Networks (RNNs)
to model the sequence. However, almost all of them fail to capture
the rich co-evolving patterns.
In this paper, in order to utilize the co-evolving patterns and
capture dependencies between actions across different users, we
first formulate timestamped user-item interactions into Sequential
Evolving Graphs (SEGs) (see Definition 2.1), where co-evolutionary
knowledge can be revealed. Then, we generalize a spectral unit
into a recurrent model by introducing gated mechanisms [1] to
model the co-evolving patterns from spectral domains. The proposed
model, Gated Spectral Units (GSUs), recurrently takes a sequence
of graphs as input, and learns state vectors of users and items to
summarize co-evolving patterns within the sequence. Our work
makes the following contributions:

Notation
U, I
Ii+ , Ii−
nu , n i
Gt = {U, I, Et }
Lt
(l ) (l )
Ut , Λt
Hut , Hit
Wz , Wh , Wr
bz , bh , br
∆

3 PROPOSED MODEL
3.1 Spectral Convolution
A recently proposed method [12], SpectralCF, extends the idea of
spectral convolutions to the task of collaborative filtering. Specifically, given a user-item bipartite graph G and its graph laplacian L =
I−D−1 A, where D and A denote the degree matrix and adjacent matrix of G, respectively, the spectral convolution operation is defined
 u 
 u 
h
h̃
T
=
Uf
(Λ)U
, where U ∈ R(nu +ni )×(nu +ni ) and
as:
θ
hi
h̃i

• Novelty: To our knowledge, it is the very first recommendation
method to model sequential graphs from spectral domains.
• Demonstrated Effectiveness: It is demonstrated that the coevolving patterns can be effectively captured from spectral domains of temporal graphs.
• High Performance: Benefiting from the co-evolving knowledge
being effectively captured, GSU significantly outperforms stateof-the-art methods on three real-world datasets.

2

Λ ∈ R(nu +ni )×(nu +ni ) are eigenvectors and eigenvalues of L, respectively; fθ (Λ) is a convolutional filtering function placed on
eigenvalues; hu ∈ R(nu ×1) and hi ∈ R(ni ×1) respectively denote
state vectors of users and items, and h̃u ∈ R(nu ×1) and h̃i ∈ R(ni ×1)
represent new state vectors of users and items, respectively, learned
from the spectral domain.
Nonetheless, the number of parameters in fθ (Λ) is linear to the
dimensionality of data, resulting in an unscalable model. To circumvent this issue, [12] utilizes a polynomial approximation to approxÍP
imate дΘ (Λ) as дθ (Λ) ≈ p=0
θ ′ Λp . As a result, the spectral con pu 
 u 
H̃
⊺ + UΛU ⊺ ) H
volution is reformulated as
=
(UU
Θ,
Hi
H̃i
where Hu ∈ R(nu +ni )×F and Hu ∈ R(nu +ni )×F are F -dimensional
row-vectors for users and items, respectively; and Θ ∈ R(F ×F ) is a
generalized convolutional filter with F channels and F filters.
However, as we aim to model co-evolving patterns from sequential graphs other than one static graph, computing the eigendecomposition of laplacians of multiple graphs would be prohibitively expensive. In order to adopt the aforementioned spectral
convolution operation for modeling sequential graphs, we notice
that, rather than the full eigen-decomposition, top-l eigenvectors
and eigenvalues are sufficient to approximate L. Thus, we adopt
ARPACK [6], a most popular iterative eigensolver. Its complexity is
O((nu + ni )l 2 + el), where e stands for the number of edges, and
linear w.r .t . the graph size (nu + ni ). Due to the sparsity of our
(l )
graphs, we have e ≪ nu + ni . Given the top-l eigenvectors Ut and

BACKGROUND AND PRELIMINARIES

Let us denote a set of users as U and an item set I. Ii+ represents
the set of all items liked by user i and Ii− stands for the remaining
items. Each user-item interaction is represented as a tuple (i, j, tˆ),
denoting that user i has interacted with item j at timestamp tˆ. We
define Sequential Evolving Graphs (SEGs) as:
Definition 2.1. (Sequential Evolving Graphs). Sequential Evolving
Graphs (SEGs) are represented as a sequence of bipartite graphs G =
{G1 , G2 , ..., Gt , ...}. The t th bipartite graph Gt is defined as Gt =
{U, I, Et }, where U and I are the user set and item set, respectively
and Et denotes an edge set connecting users in U and items in I. For
an edge (i, j, tˆ) ∈ Et , it denotes user i has interacted with item j at
timestamp tˆ when ∆(t − 1) < tˆ ≤ ∆t.1
Given SEGs of length T , we aim to predict edges (user-item interactions) to be formed in GT +1 . Throughout the paper, we denote
scalars by either lowercase or uppercase letters, vectors by boldfaced lowercase letters, and matrices by boldfaced uppercase letters.
Important notations are summarized in Table 1.

1 In

Description
user and item set
a set of items liked by user i, and all other
items without interactions with user i
number of users and items
the t th graph consisting of user set U, item
set I and edge set Et
the laplacian matrix of the t th graph
the top-l eigenvectors and eigenvalues of Lt
hidden state matrices of users and items at
timestamp t
convolutional filters of update, candidate
and reset gate
bias vectors of update, candidate and reset gate
time interval

(l )

eigenvalues Λt of the t th graph, we have:
 u 
 u 
Ht −1
H̃t
(l ) (l ) ⊺
(l ) (l ) (l ) ⊺
=
(U
U
+
U
Λ
U
)
Θ,
t
t
t
t
t
Hit −1
H̃it

the case that Et is empty, we remove Gt from G .

1078

(1)

Short Research Papers 2B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

where Hut−1 ∈ R(nu +ni )×F and Hit −1 ∈ R(nu +ni )×F are state matrices of users and items from the previous time step t − 1; H̃ut and
 u 
Ht −1
on the current graph Gt .
H̃it are learned by convolving
Hit −1
As such, H̃ut and H̃it captures the evolving patterns by integrating
information from the previous step (t − 1) with newly formed connections of the current step t. Hereafter, we denote
con theu spectral

Ht −1
volution operation in Eq. 1 as a function: Conv(
, Gt ; Θ),
Hit −1
parameterized by a convolutional filter Θ.

3.2

to obtain HTu and HTi . And, the score of an edge (i, j) ∈ ET +1 at
step T + 1 can be calculated as HTu (i, :)⊺ HTi (j, :), where HTu (i, :) and
HTi (j, :) denote the i th and j th row of HTu and HTi , respectively. We
optimize the parameters of GSUs by minimizing the loss as:
L=


Hut−1
, Gt ; Θ) is cai
Ht −1
pable of capturing the patterns co-evolving from the previous graph
to the current graph. It is an natural idea to introduce gated mechanisms [1] into our spectral convolution to capture co-evolving
patterns from a sequence of graphs. Therefore, we present Gated
Spectral Units (GSUs), which are capable of learning the co-evolving
patterns from sequential graphs.
In GSUs, the update gate Zt ∈ R(nu +ni )×F convolves the historical state matrices on the current graph to decide how much the
unit updates its state matrices. It is computed by:
 u 
Ht −1
Zt = σ (Conv(
, Gt ; Wz ) + bz ),
(2)
Hit −1

4

EXPERIMENTS

In this section we conduct experiments to answer the following
research questions:
• RQ1: Are the co-evolving patterns being effectively captured?
• RQ2: How do the co-evolving patterns work for handling the
cold-start problem?

where Wz ∈ R(nu +ni )×F , bz ∈ R(nu +ni )×1 , and σ denotes the
sigmoid function. A candidate gate generates a candidate state
matrices by resetting the previous Hut−1 and Hit −1 , and convolving
them on Gt as:
 u 
 u 
Ht −1
Ĥt
=
tanh(Conv(R
⊙
, Gt ; Wh ) + bh ), (3)
t
Hit −1
Ĥit

4.1

Datasets

In our experiments, we use three publicly available timestamped
datasets: (1) ML-1M: [2] MovieLens-1M contains 1, 000, 209 ratings,
6, 014 users and 3, 706 movies; (2) ADM [7]: Amazon Digital Music
5-core includes 4, 731 users, 2, 420 video games; (3) AIV: Amazon
Instant Videos 5-core is collected by [7] and consists of 4, 818 users
and 1, 685 items. For each dataset, we select the most recent item of
each user for testing and the second most recent one for validation.
All remaining items will be used for training. To create SEGs to
capture co-evolving patterns, we set the time interval ∆ as 1 day for
ML-1M and AIV, and 7 for ADM to reduce the numder of graphs.
As a result, we attain the SEGs of length (K) 977, 754, and 1, 472 for
the dataset of ML-1M, ADM, and AIV, respectively.

where Wh ∈ R(nu +ni )×F , bh ∈ R(nu +ni )×1 , and the reset gate
Rt ∈ R(nu +ni )×F is similar to the update gate as below:
(4)

where Wr ∈ R(nu +ni )×F and br ∈ R(nu +ni )×1 . Finally, the output of
GSUs at time
 tu is alinear interpolation between the previous
 u state

Ht −1
Ĥt
(nu +n i )×F and the candidate
matrices
∈
R
∈
Hit −1
Ĥit
R(nu +ni )×F as below:
 u 
 u 
 u 
Ht −1
Ht
Ĥt
),
(5)
=
Z
⊙
+
(1
−
Z
)
⊙
t
t
Hit
Hit −1
Ĥit

4.2

Experimental Settings

Evaluation Protocols. We evaluate all models in two metrics: Hit
Ratio@10 (HR@10) and NDCG@10. For each user i, we randomly
sample 999 negative items, and rank these items with the groundtruth item. Based on the rankings of these 1, 000 items, HR@10
and NDCG@10 can be evaluated. The Adam optimizer [5] with the
learning rate of 0.001 is adopted, and l in Eq. 1 and T are empirically
set to 6 and 10, respectively.
Comparative Models. We compare GSUs with six state-of-the-art
algorithms. They can be categorized into two groups: (1) Nonsequential Models: BPR [8] and SpectralCF [12]; (2) Sequential
Models: FPMC [9], TransRec [3], GRU4Rec [4] and Caser [10].
The first group is added to validate the usefulness of sequential
recommendation models, and the second group is for demonstrating
the advantage of modeling co-evolving patterns.

where ⊙ denotes the element-wise multiplication.
Overall, given the initial state matrices, Hu0 and Hi0 , which are
randomly initialized as trainable parameters, GSUs are able to recurrently process a sequence of graphs, and output state matrices
of users and items of the last step, which summarize the co-evolving
patterns within the sequence.

3.3

(6)

where λ is an regularization term. Eq. 6 seeks to maximize the
difference between the scores of an existing edge (i, j) ∈ ET +1 and
a non-existing edge (i, j ′ ), where j ′ is sampled from Ii− .
For evaluation, the last T graphs of SEGs of length K are taken
into GSUs to attain HTu and HTi . The final item recommendation
for a user i is given by ranking the score HTu (i, :)⊺ HTi (j, :) in a
descending order.



Rt = σ (Conv(Hut−1 , Hit −1 , Gt ; Wr ) + br ),

j ′ ∈Ii−

+λ(||HTu ||F2 + ||HTi ||F2 ),

Gated Spectral Units

Recall that our spectral convolution Conv(

Í
− (i, j)∈ ET +1 ln σ (HTu (i, :)⊺ HTi (j, :) − HTu (i, :)⊺ HTi (j ′, :))

Optimization and Prediction

Given SEGs of length K generated from the training data, we randomly sample a batch of SEGs of lengthT +1 (T +1 ≪ K) for training.
For each SEGs of length T + 1, we feed the first T graphs into GSUs

1079

Short Research Papers 2B: Recommendation and Evaluation

SIGIR ’19, July 21–25, 2019, Paris, France

Table 2: Performance comparison in HR@10 and NDCG@10. The best and second best method are boldfaced and underlined,
respectively. ⋆ and ⋆⋆ denote the statistical significance for p < 0.05 and p < 0.01, respectively, compared to the best competitor.
Dataset
ML-1M
ADM
AIV

0.05

HR@10
NDCG@10
HR@10
NDCG@10
HR@10
NDCG@10

ADM

0.07
0.06

Metric

TransRec
GRU4Rec

BPR
0.061
0.025
0.022
0.011
0.072
0.022

SpectralCF FPMC
0.081
0.031
0.031
0.018
0.088
0.031

0.08

0.04

0.06

0.03

0.04

0.099
0.041
0.043
0.021
0.010
0.037

AIV

0.10

Caser
GSUs

0.092
0.039
0.041
0.019
0.096
0.034

TransRec GRU4Rec Caser

TransRec
GRU4Rec

0.00

0.02

HR@10

NDCG@10

0.00

HR@10

NDCG@10

Figure 2: Performance comparison in HR@10 and
NDCG@10 under a sparse setting, where each user is
associated with only one user-item interaction for training.

4.3

27.2%
35.6%
27.4%
41.7%
29.1%
82.9%

0.061⋆⋆
0.065⋆⋆
0.034⋆
0.151⋆
0.075⋆

ACKNOWLEDGMENTS

Performance Comparison (RQ1 and RQ2)

This work is supported in part by NSF through grants IIS-1526499,
IIS-1763325, and CNS-1626432, and NSFC 61672313. This work is
also partially supported by NSF through grant IIS-1763365.

In this section we compare GSUs with six state-of-the art methods to
answer RQ1 and RQ2. Table 2 shows the performance comparison
in terms of HR@10 and NDCG@10. Overall, GSUs improves the
best comparative method by 27.9% and 53.4% in terms of HR@10
and NDCG@10, respectively, averaging on all three datasets. This
experiment reveals two interesting observations: (1) Non-sequential
methods underperform sequential methods, indicating the benefits
of modeling the short- and long- term dynamics in users’ actions; (2)
Regardless of the data sets and the evaluation metrics, the proposed
GSUs always achieve the best performance. This shows that by
leveraging the power of co-evolving patterns, GSUs can better predict
users’ future actions.
We are interested in if co-evolving patterns are helpful for alleviating the cold-start problem. As such, we conduct experiments
under an extremely sparse setting, where we only use the first interaction of each user for training, and the second and third one
for validation and test, respectively. All others are discarded. Consequently, we obtain SEGs of length 458 and 1, 158 for the datasets
of ADM and AIV, respectively. Fig. 2 illustrates the performance
comparison under the sparse setting. In ADM, GSUs outperform
the best comparative method, GRU4Rec, by 32.3% and 31.8% in
HR@10 and NDCG@10, respectively. In AIV, GSUs beat the best
performing competitor, Caser, by 47.6% and 34.8% in HR@10 and
NDCG@10, respectively. It is validated that, benefiting from the
ability of capturing co-evolving patterns, GSUs can better handle
cold-start users than state-of-the-art comparative methods.

5

0.103
0.045
0.048
0.022
0.117
0.041

GSUs vs. best

0.131⋆⋆

into Sequential Evolving Graphs (SEGs) (see Definition 2.1). Then,
in order to utilize co-evolutionary patterns from SEGs, we propose
Gated Spectral Units (GSUs). GSUs incorporate gated mechanisms
into a spectral convolution. In this way, GSUs are able to learn
from sequential graphs and capture the co-evolving patterns from
spectral domains. In experiments, we demonstrate the usefulness of
leveraging co-evolving patterns by comparing GSUs with six stateof-the-art comparative methods. Overall, averaging on all three
datasets, GSUs achieve 27.9% and 53.4% improvements over the
best performing competitor in terms of HR@10 and NDCG@10,
respectively.

Caser
GSUs

0.02
0.01

0.102
0.046
0.051
0.024
0.111
0.039

GSUs

REFERENCES
[1] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014.
Empirical evaluation of gated recurrent neural networks on sequence modeling.
arXiv preprint arXiv:1412.3555 (2014).
[2] F Maxwell Harper and Joseph A Konstan. 2016. The movielens datasets: History
and context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4 (2016),
19.
[3] Ruining He, Wang-Cheng Kang, and Julian McAuley. 2017. Translation-based
recommendation. In Proceedings of the Eleventh ACM Conference on Recommender
Systems. ACM, 161–169.
[4] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.
2015. Session-based recommendations with recurrent neural networks. arXiv
preprint arXiv:1511.06939 (2015).
[5] Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).
[6] Richard B Lehoucq, Danny C Sorensen, and Chao Yang. 1998. ARPACK users’
guide: solution of large-scale eigenvalue problems with implicitly restarted Arnoldi
methods. Vol. 6. Siam.
[7] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel.
2015. Image-based Recommendations on Styles and Substitutes. arXiv preprint
arXiv:1506.04757 (2015).
[8] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings
of the twenty-fifth conference on uncertainty in artificial intelligence. AUAI Press,
452–461.
[9] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In Proceedings
of the 19th international conference on World wide web. ACM, 811–820.
[10] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the Eleventh ACM
International Conference on Web Search and Data Mining. ACM, 565–573.
[11] Lei Zheng, Bokai Cao, Vahid Noroozi, S Yu Philip, and Nianzu Ma. 2017. Hierarchical collaborative embedding for context-aware recommendations. In 2017
IEEE International Conference on Big Data (Big Data). IEEE, 867–876.
[12] Lei Zheng, Chun-Ta Lu, Fei Jiang, Jiawei Zhang, and Philip S Yu. 2018. Spectral
collaborative filtering. In Proceedings of the 12th ACM Conference on Recommender
Systems. ACM, 311–319.
[13] Lei Zheng, Vahid Noroozi, and Philip S Yu. 2017. Joint Deep Modeling of Users
and Items Using Reviews for Recommendation. In Proceedings of the Tenth ACM
International Conference on Web Search and Data Mining. ACM, 425–434.

CONCLUSIONS

Despite the promising results achieved by recent sequential methods, most of them fail to leverage the co-evolving patterns, and such
patterns are affluent in users actions and beneficial for reasoning
over intricate user-item relationships.
In order to power RS with the ability to capture co-evolving
patterns, we first formulate the dynamic user-item bipartite graph

1080

